2019-05-08 21:32:11 - INFO - saving to ./teacher-student-master/results/teacher_results/resnet_v2_1
2019-05-08 21:32:11 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=30, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.03, model='resnet', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./teacher-student-master/results/teacher_results', resume='', save='resnet_v2', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-08 21:32:11 - INFO - creating model resnet
2019-05-08 21:32:11 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 30, 'lr': 0.03, 'wd': 0}
2019-05-08 21:32:11 - INFO - number of parameters: 5849966
2019-05-08 21:32:19 - INFO - training regime: {0: {'optimizer': 'SGD', 'lr': 0.03, 'weight_decay': 0, 'momentum': 0.9}, 81: {'lr': 0.01}, 122: {'lr': 0.001, 'weight_decay': 0}, 164: {'lr': 0.0001}}
2019-05-08 21:32:19 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:32:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:32:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:32:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:32:19 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.886 (0.886)	Data 0.255 (0.255)	Loss 2.2585 (2.2585)	Prec@1 16.000 (16.000)	Prec@5 65.000 (65.000)
2019-05-08 21:32:23 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.081 (0.095)	Data 0.000 (0.005)	Loss 1.8839 (2.0016)	Prec@1 29.000 (25.784)	Prec@5 85.000 (80.255)
2019-05-08 21:32:27 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.080 (0.087)	Data 0.000 (0.003)	Loss 1.6325 (1.8596)	Prec@1 40.000 (31.822)	Prec@5 89.000 (84.139)
2019-05-08 21:32:31 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 1.4487 (1.7804)	Prec@1 49.000 (34.861)	Prec@5 91.000 (85.947)
2019-05-08 21:32:35 - INFO - TRAINING - Epoch: [0][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 1.3959 (1.6994)	Prec@1 47.000 (37.960)	Prec@5 92.000 (87.592)
2019-05-08 21:32:39 - INFO - TRAINING - Epoch: [0][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 1.1930 (1.6332)	Prec@1 58.000 (40.562)	Prec@5 96.000 (88.821)
2019-05-08 21:32:43 - INFO - TRAINING - Epoch: [0][300/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.2324 (1.5800)	Prec@1 52.000 (42.605)	Prec@5 98.000 (89.761)
2019-05-08 21:32:48 - INFO - TRAINING - Epoch: [0][350/500]	Time 0.048 (0.083)	Data 0.000 (0.001)	Loss 1.2387 (1.5300)	Prec@1 58.000 (44.613)	Prec@5 96.000 (90.490)
2019-05-08 21:32:52 - INFO - TRAINING - Epoch: [0][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 1.1444 (1.4810)	Prec@1 61.000 (46.541)	Prec@5 94.000 (91.060)
2019-05-08 21:32:56 - INFO - TRAINING - Epoch: [0][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 1.0005 (1.4380)	Prec@1 59.000 (48.157)	Prec@5 97.000 (91.605)
2019-05-08 21:33:00 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 1.2180 (1.2180)	Prec@1 59.000 (59.000)	Prec@5 93.000 (93.000)
2019-05-08 21:33:01 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.028 (0.033)	Data 0.000 (0.005)	Loss 1.0114 (1.2107)	Prec@1 63.000 (59.824)	Prec@5 94.000 (93.431)
2019-05-08 21:33:03 - INFO - 
 Epoch: 1	Training Loss 1.3985 	Training Prec@1 49.706 	Training Prec@5 92.110 	Validation Loss 1.2330 	Validation Prec@1 58.960 	Validation Prec@5 93.430 	
2019-05-08 21:33:03 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:33:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:33:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:33:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:33:03 - INFO - TRAINING - Epoch: [1][0/500]	Time 0.248 (0.248)	Data 0.193 (0.193)	Loss 1.1826 (1.1826)	Prec@1 59.000 (59.000)	Prec@5 97.000 (97.000)
2019-05-08 21:33:07 - INFO - TRAINING - Epoch: [1][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.9215 (1.0050)	Prec@1 71.000 (64.647)	Prec@5 98.000 (96.843)
2019-05-08 21:33:11 - INFO - TRAINING - Epoch: [1][100/500]	Time 0.070 (0.083)	Data 0.000 (0.003)	Loss 1.0382 (0.9965)	Prec@1 58.000 (65.386)	Prec@5 94.000 (96.980)
2019-05-08 21:33:16 - INFO - TRAINING - Epoch: [1][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.9872 (0.9769)	Prec@1 67.000 (66.166)	Prec@5 99.000 (97.000)
2019-05-08 21:33:20 - INFO - TRAINING - Epoch: [1][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.9220 (0.9592)	Prec@1 74.000 (66.697)	Prec@5 97.000 (96.995)
2019-05-08 21:33:24 - INFO - TRAINING - Epoch: [1][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.9596 (0.9433)	Prec@1 63.000 (67.239)	Prec@5 97.000 (97.139)
2019-05-08 21:33:28 - INFO - TRAINING - Epoch: [1][300/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.8506 (0.9311)	Prec@1 67.000 (67.628)	Prec@5 98.000 (97.203)
2019-05-08 21:33:32 - INFO - TRAINING - Epoch: [1][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.9273 (0.9164)	Prec@1 65.000 (68.142)	Prec@5 98.000 (97.316)
2019-05-08 21:33:36 - INFO - TRAINING - Epoch: [1][400/500]	Time 0.077 (0.082)	Data 0.000 (0.001)	Loss 0.6407 (0.9044)	Prec@1 76.000 (68.491)	Prec@5 99.000 (97.392)
2019-05-08 21:33:40 - INFO - TRAINING - Epoch: [1][450/500]	Time 0.076 (0.082)	Data 0.000 (0.001)	Loss 0.7712 (0.8914)	Prec@1 71.000 (69.007)	Prec@5 99.000 (97.475)
2019-05-08 21:33:45 - INFO - EVALUATING - Epoch: [1][0/100]	Time 0.280 (0.280)	Data 0.252 (0.252)	Loss 0.8073 (0.8073)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-08 21:33:46 - INFO - EVALUATING - Epoch: [1][50/100]	Time 0.024 (0.032)	Data 0.000 (0.005)	Loss 0.7468 (0.8559)	Prec@1 75.000 (70.686)	Prec@5 100.000 (98.118)
2019-05-08 21:33:47 - INFO - 
 Epoch: 2	Training Loss 0.8825 	Training Prec@1 69.260 	Training Prec@5 97.526 	Validation Loss 0.8566 	Validation Prec@1 70.700 	Validation Prec@5 98.180 	
2019-05-08 21:33:47 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:33:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:33:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:33:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:33:48 - INFO - TRAINING - Epoch: [2][0/500]	Time 0.249 (0.249)	Data 0.202 (0.202)	Loss 0.8960 (0.8960)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-08 21:33:52 - INFO - TRAINING - Epoch: [2][50/500]	Time 0.081 (0.086)	Data 0.000 (0.005)	Loss 0.6791 (0.7012)	Prec@1 77.000 (75.902)	Prec@5 96.000 (98.412)
2019-05-08 21:33:56 - INFO - TRAINING - Epoch: [2][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.7022 (0.7005)	Prec@1 75.000 (75.535)	Prec@5 100.000 (98.515)
2019-05-08 21:34:00 - INFO - TRAINING - Epoch: [2][150/500]	Time 0.080 (0.085)	Data 0.000 (0.002)	Loss 0.5148 (0.7109)	Prec@1 84.000 (75.205)	Prec@5 99.000 (98.437)
2019-05-08 21:34:04 - INFO - TRAINING - Epoch: [2][200/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.6876 (0.7062)	Prec@1 71.000 (75.438)	Prec@5 97.000 (98.438)
2019-05-08 21:34:09 - INFO - TRAINING - Epoch: [2][250/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.7758 (0.7012)	Prec@1 72.000 (75.570)	Prec@5 98.000 (98.482)
2019-05-08 21:34:12 - INFO - TRAINING - Epoch: [2][300/500]	Time 0.073 (0.083)	Data 0.000 (0.002)	Loss 0.5788 (0.6957)	Prec@1 81.000 (75.821)	Prec@5 100.000 (98.528)
2019-05-08 21:34:16 - INFO - TRAINING - Epoch: [2][350/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.6707 (0.6891)	Prec@1 80.000 (76.165)	Prec@5 98.000 (98.561)
2019-05-08 21:34:20 - INFO - TRAINING - Epoch: [2][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.7906 (0.6868)	Prec@1 72.000 (76.237)	Prec@5 97.000 (98.556)
2019-05-08 21:34:24 - INFO - TRAINING - Epoch: [2][450/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.6744 (0.6814)	Prec@1 79.000 (76.441)	Prec@5 100.000 (98.565)
2019-05-08 21:34:28 - INFO - EVALUATING - Epoch: [2][0/100]	Time 0.298 (0.298)	Data 0.273 (0.273)	Loss 0.7316 (0.7316)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-08 21:34:30 - INFO - EVALUATING - Epoch: [2][50/100]	Time 0.024 (0.033)	Data 0.001 (0.006)	Loss 0.8230 (0.7924)	Prec@1 74.000 (74.725)	Prec@5 97.000 (98.000)
2019-05-08 21:34:31 - INFO - 
 Epoch: 3	Training Loss 0.6769 	Training Prec@1 76.614 	Training Prec@5 98.576 	Validation Loss 0.7931 	Validation Prec@1 74.080 	Validation Prec@5 98.290 	
2019-05-08 21:34:31 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:34:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:34:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:34:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:34:32 - INFO - TRAINING - Epoch: [3][0/500]	Time 0.242 (0.242)	Data 0.182 (0.182)	Loss 0.7521 (0.7521)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-08 21:34:36 - INFO - TRAINING - Epoch: [3][50/500]	Time 0.088 (0.084)	Data 0.000 (0.004)	Loss 0.6030 (0.5735)	Prec@1 82.000 (79.980)	Prec@5 98.000 (98.882)
2019-05-08 21:34:40 - INFO - TRAINING - Epoch: [3][100/500]	Time 0.085 (0.082)	Data 0.000 (0.003)	Loss 0.5982 (0.5815)	Prec@1 80.000 (79.842)	Prec@5 99.000 (98.881)
2019-05-08 21:34:44 - INFO - TRAINING - Epoch: [3][150/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.4854 (0.5910)	Prec@1 84.000 (79.536)	Prec@5 100.000 (98.841)
2019-05-08 21:34:48 - INFO - TRAINING - Epoch: [3][200/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.5093 (0.5878)	Prec@1 83.000 (79.776)	Prec@5 100.000 (98.816)
2019-05-08 21:34:52 - INFO - TRAINING - Epoch: [3][250/500]	Time 0.087 (0.081)	Data 0.000 (0.002)	Loss 0.7093 (0.5845)	Prec@1 75.000 (79.916)	Prec@5 98.000 (98.817)
2019-05-08 21:34:56 - INFO - TRAINING - Epoch: [3][300/500]	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 0.5197 (0.5804)	Prec@1 86.000 (80.100)	Prec@5 99.000 (98.821)
2019-05-08 21:35:00 - INFO - TRAINING - Epoch: [3][350/500]	Time 0.079 (0.081)	Data 0.000 (0.001)	Loss 0.5933 (0.5786)	Prec@1 77.000 (80.194)	Prec@5 100.000 (98.846)
2019-05-08 21:35:04 - INFO - TRAINING - Epoch: [3][400/500]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.4360 (0.5754)	Prec@1 86.000 (80.299)	Prec@5 99.000 (98.863)
2019-05-08 21:35:08 - INFO - TRAINING - Epoch: [3][450/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.5523 (0.5710)	Prec@1 82.000 (80.503)	Prec@5 98.000 (98.909)
2019-05-08 21:35:13 - INFO - EVALUATING - Epoch: [3][0/100]	Time 0.288 (0.288)	Data 0.262 (0.262)	Loss 0.6912 (0.6912)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-08 21:35:14 - INFO - EVALUATING - Epoch: [3][50/100]	Time 0.024 (0.032)	Data 0.000 (0.005)	Loss 0.6258 (0.7086)	Prec@1 81.000 (76.157)	Prec@5 98.000 (98.314)
2019-05-08 21:35:15 - INFO - 
 Epoch: 4	Training Loss 0.5702 	Training Prec@1 80.504 	Training Prec@5 98.926 	Validation Loss 0.7173 	Validation Prec@1 75.650 	Validation Prec@5 98.420 	
2019-05-08 21:35:15 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:35:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:35:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:35:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:35:16 - INFO - TRAINING - Epoch: [4][0/500]	Time 0.250 (0.250)	Data 0.186 (0.186)	Loss 0.4803 (0.4803)	Prec@1 84.000 (84.000)	Prec@5 97.000 (97.000)
2019-05-08 21:35:20 - INFO - TRAINING - Epoch: [4][50/500]	Time 0.087 (0.083)	Data 0.000 (0.004)	Loss 0.5527 (0.5051)	Prec@1 81.000 (83.039)	Prec@5 99.000 (99.294)
2019-05-08 21:35:24 - INFO - TRAINING - Epoch: [4][100/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.5651 (0.5131)	Prec@1 81.000 (82.624)	Prec@5 99.000 (99.198)
2019-05-08 21:35:28 - INFO - TRAINING - Epoch: [4][150/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.4525 (0.5125)	Prec@1 86.000 (82.556)	Prec@5 98.000 (99.212)
2019-05-08 21:35:32 - INFO - TRAINING - Epoch: [4][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.7550 (0.5172)	Prec@1 74.000 (82.338)	Prec@5 99.000 (99.229)
2019-05-08 21:35:36 - INFO - TRAINING - Epoch: [4][250/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.5309 (0.5112)	Prec@1 82.000 (82.510)	Prec@5 98.000 (99.191)
2019-05-08 21:35:41 - INFO - TRAINING - Epoch: [4][300/500]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.3756 (0.5066)	Prec@1 85.000 (82.728)	Prec@5 100.000 (99.209)
2019-05-08 21:35:45 - INFO - TRAINING - Epoch: [4][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.5889 (0.5059)	Prec@1 81.000 (82.721)	Prec@5 99.000 (99.245)
2019-05-08 21:35:49 - INFO - TRAINING - Epoch: [4][400/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.5080 (0.5069)	Prec@1 84.000 (82.628)	Prec@5 100.000 (99.252)
2019-05-08 21:35:53 - INFO - TRAINING - Epoch: [4][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.4084 (0.5048)	Prec@1 87.000 (82.776)	Prec@5 100.000 (99.253)
2019-05-08 21:35:57 - INFO - EVALUATING - Epoch: [4][0/100]	Time 0.282 (0.282)	Data 0.258 (0.258)	Loss 0.5309 (0.5309)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-08 21:35:59 - INFO - EVALUATING - Epoch: [4][50/100]	Time 0.033 (0.032)	Data 0.000 (0.005)	Loss 0.6145 (0.6584)	Prec@1 81.000 (77.686)	Prec@5 99.000 (98.824)
2019-05-08 21:36:00 - INFO - 
 Epoch: 5	Training Loss 0.5036 	Training Prec@1 82.750 	Training Prec@5 99.250 	Validation Loss 0.6484 	Validation Prec@1 77.630 	Validation Prec@5 98.970 	
2019-05-08 21:36:00 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:36:00 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:36:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:36:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:36:00 - INFO - TRAINING - Epoch: [5][0/500]	Time 0.256 (0.256)	Data 0.212 (0.212)	Loss 0.4396 (0.4396)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-08 21:36:04 - INFO - TRAINING - Epoch: [5][50/500]	Time 0.082 (0.084)	Data 0.000 (0.005)	Loss 0.4778 (0.4490)	Prec@1 84.000 (84.490)	Prec@5 100.000 (99.333)
2019-05-08 21:36:08 - INFO - TRAINING - Epoch: [5][100/500]	Time 0.079 (0.082)	Data 0.000 (0.003)	Loss 0.6909 (0.4355)	Prec@1 81.000 (85.010)	Prec@5 98.000 (99.386)
2019-05-08 21:36:12 - INFO - TRAINING - Epoch: [5][150/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.4522 (0.4465)	Prec@1 86.000 (84.695)	Prec@5 99.000 (99.391)
2019-05-08 21:36:17 - INFO - TRAINING - Epoch: [5][200/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.4417 (0.4457)	Prec@1 85.000 (84.701)	Prec@5 100.000 (99.443)
2019-05-08 21:36:21 - INFO - TRAINING - Epoch: [5][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.3574 (0.4464)	Prec@1 88.000 (84.693)	Prec@5 100.000 (99.390)
2019-05-08 21:36:25 - INFO - TRAINING - Epoch: [5][300/500]	Time 0.091 (0.083)	Data 0.000 (0.002)	Loss 0.4475 (0.4458)	Prec@1 83.000 (84.711)	Prec@5 100.000 (99.369)
2019-05-08 21:36:29 - INFO - TRAINING - Epoch: [5][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.4308 (0.4474)	Prec@1 86.000 (84.627)	Prec@5 100.000 (99.390)
2019-05-08 21:36:33 - INFO - TRAINING - Epoch: [5][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.4428 (0.4481)	Prec@1 82.000 (84.551)	Prec@5 99.000 (99.364)
2019-05-08 21:36:38 - INFO - TRAINING - Epoch: [5][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.4715 (0.4465)	Prec@1 87.000 (84.639)	Prec@5 98.000 (99.366)
2019-05-08 21:36:42 - INFO - EVALUATING - Epoch: [5][0/100]	Time 0.303 (0.303)	Data 0.277 (0.277)	Loss 0.4446 (0.4446)	Prec@1 84.000 (84.000)	Prec@5 98.000 (98.000)
2019-05-08 21:36:43 - INFO - EVALUATING - Epoch: [5][50/100]	Time 0.030 (0.034)	Data 0.001 (0.006)	Loss 0.3404 (0.5002)	Prec@1 89.000 (83.941)	Prec@5 99.000 (98.667)
2019-05-08 21:36:45 - INFO - 
 Epoch: 6	Training Loss 0.4451 	Training Prec@1 84.734 	Training Prec@5 99.376 	Validation Loss 0.4941 	Validation Prec@1 83.860 	Validation Prec@5 98.870 	
2019-05-08 21:36:45 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:36:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:36:45 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:36:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:36:45 - INFO - TRAINING - Epoch: [6][0/500]	Time 0.255 (0.255)	Data 0.213 (0.213)	Loss 0.3799 (0.3799)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-08 21:36:49 - INFO - TRAINING - Epoch: [6][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.4572 (0.3823)	Prec@1 85.000 (86.961)	Prec@5 100.000 (99.608)
2019-05-08 21:36:53 - INFO - TRAINING - Epoch: [6][100/500]	Time 0.089 (0.084)	Data 0.000 (0.003)	Loss 0.3238 (0.3962)	Prec@1 90.000 (86.257)	Prec@5 100.000 (99.515)
2019-05-08 21:36:58 - INFO - TRAINING - Epoch: [6][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.3897 (0.3921)	Prec@1 85.000 (86.391)	Prec@5 100.000 (99.517)
2019-05-08 21:37:02 - INFO - TRAINING - Epoch: [6][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.3516 (0.3930)	Prec@1 91.000 (86.328)	Prec@5 100.000 (99.512)
2019-05-08 21:37:06 - INFO - TRAINING - Epoch: [6][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.1883 (0.3955)	Prec@1 95.000 (86.287)	Prec@5 100.000 (99.526)
2019-05-08 21:37:10 - INFO - TRAINING - Epoch: [6][300/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.4497 (0.3951)	Prec@1 82.000 (86.309)	Prec@5 100.000 (99.515)
2019-05-08 21:37:14 - INFO - TRAINING - Epoch: [6][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.3084 (0.3971)	Prec@1 91.000 (86.279)	Prec@5 99.000 (99.467)
2019-05-08 21:37:18 - INFO - TRAINING - Epoch: [6][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.4309 (0.3970)	Prec@1 85.000 (86.269)	Prec@5 99.000 (99.479)
2019-05-08 21:37:22 - INFO - TRAINING - Epoch: [6][450/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.5521 (0.3970)	Prec@1 80.000 (86.228)	Prec@5 99.000 (99.501)
2019-05-08 21:37:26 - INFO - EVALUATING - Epoch: [6][0/100]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.6018 (0.6018)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-08 21:37:28 - INFO - EVALUATING - Epoch: [6][50/100]	Time 0.028 (0.033)	Data 0.000 (0.005)	Loss 0.4558 (0.5369)	Prec@1 84.000 (82.314)	Prec@5 98.000 (99.216)
2019-05-08 21:37:29 - INFO - 
 Epoch: 7	Training Loss 0.3983 	Training Prec@1 86.210 	Training Prec@5 99.496 	Validation Loss 0.5471 	Validation Prec@1 81.530 	Validation Prec@5 99.300 	
2019-05-08 21:37:29 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:37:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:37:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:37:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:37:29 - INFO - TRAINING - Epoch: [7][0/500]	Time 0.278 (0.278)	Data 0.214 (0.214)	Loss 0.2956 (0.2956)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 21:37:34 - INFO - TRAINING - Epoch: [7][50/500]	Time 0.079 (0.086)	Data 0.000 (0.005)	Loss 0.4847 (0.3467)	Prec@1 80.000 (88.078)	Prec@5 99.000 (99.686)
2019-05-08 21:37:38 - INFO - TRAINING - Epoch: [7][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.3468 (0.3504)	Prec@1 87.000 (87.703)	Prec@5 100.000 (99.614)
2019-05-08 21:37:42 - INFO - TRAINING - Epoch: [7][150/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.3551 (0.3559)	Prec@1 88.000 (87.563)	Prec@5 100.000 (99.603)
2019-05-08 21:37:46 - INFO - TRAINING - Epoch: [7][200/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.3317 (0.3606)	Prec@1 88.000 (87.448)	Prec@5 100.000 (99.582)
2019-05-08 21:37:50 - INFO - TRAINING - Epoch: [7][250/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.3302 (0.3625)	Prec@1 91.000 (87.414)	Prec@5 100.000 (99.574)
2019-05-08 21:37:54 - INFO - TRAINING - Epoch: [7][300/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.4395 (0.3665)	Prec@1 86.000 (87.259)	Prec@5 100.000 (99.581)
2019-05-08 21:37:58 - INFO - TRAINING - Epoch: [7][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.3446 (0.3665)	Prec@1 89.000 (87.311)	Prec@5 100.000 (99.564)
2019-05-08 21:38:02 - INFO - TRAINING - Epoch: [7][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2537 (0.3674)	Prec@1 87.000 (87.297)	Prec@5 100.000 (99.574)
2019-05-08 21:38:06 - INFO - TRAINING - Epoch: [7][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.3919 (0.3671)	Prec@1 86.000 (87.302)	Prec@5 100.000 (99.570)
2019-05-08 21:38:11 - INFO - EVALUATING - Epoch: [7][0/100]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.3918 (0.3918)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-08 21:38:12 - INFO - EVALUATING - Epoch: [7][50/100]	Time 0.027 (0.032)	Data 0.000 (0.005)	Loss 0.3622 (0.5305)	Prec@1 84.000 (82.941)	Prec@5 100.000 (99.059)
2019-05-08 21:38:13 - INFO - 
 Epoch: 8	Training Loss 0.3668 	Training Prec@1 87.304 	Training Prec@5 99.560 	Validation Loss 0.5236 	Validation Prec@1 82.870 	Validation Prec@5 99.180 	
2019-05-08 21:38:13 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:38:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:38:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:38:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:38:14 - INFO - TRAINING - Epoch: [8][0/500]	Time 0.252 (0.252)	Data 0.183 (0.183)	Loss 0.4543 (0.4543)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-08 21:38:18 - INFO - TRAINING - Epoch: [8][50/500]	Time 0.075 (0.087)	Data 0.000 (0.004)	Loss 0.3665 (0.3390)	Prec@1 87.000 (88.529)	Prec@5 100.000 (99.647)
2019-05-08 21:38:22 - INFO - TRAINING - Epoch: [8][100/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.2555 (0.3431)	Prec@1 91.000 (88.218)	Prec@5 100.000 (99.604)
2019-05-08 21:38:26 - INFO - TRAINING - Epoch: [8][150/500]	Time 0.038 (0.083)	Data 0.000 (0.002)	Loss 0.4227 (0.3356)	Prec@1 88.000 (88.550)	Prec@5 100.000 (99.695)
2019-05-08 21:38:30 - INFO - TRAINING - Epoch: [8][200/500]	Time 0.076 (0.083)	Data 0.000 (0.002)	Loss 0.3146 (0.3369)	Prec@1 90.000 (88.463)	Prec@5 100.000 (99.687)
2019-05-08 21:38:34 - INFO - TRAINING - Epoch: [8][250/500]	Time 0.074 (0.082)	Data 0.000 (0.002)	Loss 0.3885 (0.3379)	Prec@1 91.000 (88.426)	Prec@5 100.000 (99.693)
2019-05-08 21:38:38 - INFO - TRAINING - Epoch: [8][300/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.3637 (0.3357)	Prec@1 83.000 (88.472)	Prec@5 100.000 (99.684)
2019-05-08 21:38:43 - INFO - TRAINING - Epoch: [8][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.3332 (0.3347)	Prec@1 88.000 (88.524)	Prec@5 100.000 (99.695)
2019-05-08 21:38:47 - INFO - TRAINING - Epoch: [8][400/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.4772 (0.3330)	Prec@1 85.000 (88.584)	Prec@5 100.000 (99.696)
2019-05-08 21:38:51 - INFO - TRAINING - Epoch: [8][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.1848 (0.3333)	Prec@1 93.000 (88.559)	Prec@5 100.000 (99.667)
2019-05-08 21:38:55 - INFO - EVALUATING - Epoch: [8][0/100]	Time 0.283 (0.283)	Data 0.257 (0.257)	Loss 0.4452 (0.4452)	Prec@1 88.000 (88.000)	Prec@5 97.000 (97.000)
2019-05-08 21:38:56 - INFO - EVALUATING - Epoch: [8][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.3118 (0.4405)	Prec@1 91.000 (85.471)	Prec@5 99.000 (99.255)
2019-05-08 21:38:58 - INFO - 
 Epoch: 9	Training Loss 0.3333 	Training Prec@1 88.558 	Training Prec@5 99.678 	Validation Loss 0.4382 	Validation Prec@1 85.390 	Validation Prec@5 99.330 	
2019-05-08 21:38:58 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:38:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:38:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:38:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:38:58 - INFO - TRAINING - Epoch: [9][0/500]	Time 0.281 (0.281)	Data 0.218 (0.218)	Loss 0.1728 (0.1728)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-08 21:39:02 - INFO - TRAINING - Epoch: [9][50/500]	Time 0.086 (0.084)	Data 0.000 (0.005)	Loss 0.2596 (0.2971)	Prec@1 95.000 (90.020)	Prec@5 100.000 (99.667)
2019-05-08 21:39:06 - INFO - TRAINING - Epoch: [9][100/500]	Time 0.085 (0.082)	Data 0.000 (0.003)	Loss 0.3698 (0.2981)	Prec@1 86.000 (89.772)	Prec@5 100.000 (99.733)
2019-05-08 21:39:10 - INFO - TRAINING - Epoch: [9][150/500]	Time 0.075 (0.081)	Data 0.000 (0.002)	Loss 0.2933 (0.3037)	Prec@1 90.000 (89.596)	Prec@5 100.000 (99.742)
2019-05-08 21:39:14 - INFO - TRAINING - Epoch: [9][200/500]	Time 0.088 (0.081)	Data 0.000 (0.002)	Loss 0.2615 (0.3062)	Prec@1 93.000 (89.517)	Prec@5 100.000 (99.721)
2019-05-08 21:39:18 - INFO - TRAINING - Epoch: [9][250/500]	Time 0.082 (0.081)	Data 0.000 (0.002)	Loss 0.2216 (0.3040)	Prec@1 90.000 (89.633)	Prec@5 100.000 (99.737)
2019-05-08 21:39:22 - INFO - TRAINING - Epoch: [9][300/500]	Time 0.093 (0.081)	Data 0.000 (0.001)	Loss 0.3297 (0.3036)	Prec@1 89.000 (89.571)	Prec@5 100.000 (99.748)
2019-05-08 21:39:26 - INFO - TRAINING - Epoch: [9][350/500]	Time 0.068 (0.081)	Data 0.000 (0.001)	Loss 0.4106 (0.3080)	Prec@1 84.000 (89.390)	Prec@5 99.000 (99.752)
2019-05-08 21:39:30 - INFO - TRAINING - Epoch: [9][400/500]	Time 0.079 (0.081)	Data 0.000 (0.001)	Loss 0.2460 (0.3093)	Prec@1 90.000 (89.304)	Prec@5 100.000 (99.751)
2019-05-08 21:39:34 - INFO - TRAINING - Epoch: [9][450/500]	Time 0.087 (0.081)	Data 0.000 (0.001)	Loss 0.2592 (0.3093)	Prec@1 90.000 (89.308)	Prec@5 100.000 (99.747)
2019-05-08 21:39:39 - INFO - EVALUATING - Epoch: [9][0/100]	Time 0.329 (0.329)	Data 0.276 (0.276)	Loss 0.3506 (0.3506)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-08 21:39:40 - INFO - EVALUATING - Epoch: [9][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.3138 (0.4077)	Prec@1 90.000 (86.431)	Prec@5 99.000 (99.412)
2019-05-08 21:39:42 - INFO - 
 Epoch: 10	Training Loss 0.3076 	Training Prec@1 89.338 	Training Prec@5 99.750 	Validation Loss 0.4187 	Validation Prec@1 86.110 	Validation Prec@5 99.580 	
2019-05-08 21:39:42 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:39:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:39:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:39:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:39:42 - INFO - TRAINING - Epoch: [10][0/500]	Time 0.253 (0.253)	Data 0.197 (0.197)	Loss 0.1964 (0.1964)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-08 21:39:46 - INFO - TRAINING - Epoch: [10][50/500]	Time 0.087 (0.084)	Data 0.000 (0.005)	Loss 0.2772 (0.2593)	Prec@1 89.000 (91.216)	Prec@5 100.000 (99.784)
2019-05-08 21:39:50 - INFO - TRAINING - Epoch: [10][100/500]	Time 0.085 (0.083)	Data 0.000 (0.003)	Loss 0.1982 (0.2701)	Prec@1 92.000 (90.822)	Prec@5 100.000 (99.782)
2019-05-08 21:39:54 - INFO - TRAINING - Epoch: [10][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.2352 (0.2760)	Prec@1 92.000 (90.510)	Prec@5 100.000 (99.768)
2019-05-08 21:39:58 - INFO - TRAINING - Epoch: [10][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.4321 (0.2814)	Prec@1 85.000 (90.259)	Prec@5 100.000 (99.791)
2019-05-08 21:40:03 - INFO - TRAINING - Epoch: [10][250/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.3219 (0.2807)	Prec@1 89.000 (90.335)	Prec@5 99.000 (99.781)
2019-05-08 21:40:07 - INFO - TRAINING - Epoch: [10][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.3158 (0.2816)	Prec@1 88.000 (90.276)	Prec@5 100.000 (99.787)
2019-05-08 21:40:11 - INFO - TRAINING - Epoch: [10][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.2080 (0.2804)	Prec@1 93.000 (90.336)	Prec@5 100.000 (99.801)
2019-05-08 21:40:15 - INFO - TRAINING - Epoch: [10][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.2155 (0.2801)	Prec@1 90.000 (90.302)	Prec@5 100.000 (99.796)
2019-05-08 21:40:19 - INFO - TRAINING - Epoch: [10][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2688 (0.2810)	Prec@1 92.000 (90.282)	Prec@5 100.000 (99.783)
2019-05-08 21:40:23 - INFO - EVALUATING - Epoch: [10][0/100]	Time 0.305 (0.305)	Data 0.267 (0.267)	Loss 0.3238 (0.3238)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-05-08 21:40:25 - INFO - EVALUATING - Epoch: [10][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.3851 (0.4134)	Prec@1 83.000 (86.392)	Prec@5 100.000 (99.176)
2019-05-08 21:40:26 - INFO - 
 Epoch: 11	Training Loss 0.2849 	Training Prec@1 90.204 	Training Prec@5 99.774 	Validation Loss 0.4152 	Validation Prec@1 86.230 	Validation Prec@5 99.340 	
2019-05-08 21:40:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:40:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:40:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:40:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:40:26 - INFO - TRAINING - Epoch: [11][0/500]	Time 0.283 (0.283)	Data 0.215 (0.215)	Loss 0.3241 (0.3241)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-08 21:40:30 - INFO - TRAINING - Epoch: [11][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.2720 (0.2488)	Prec@1 88.000 (91.529)	Prec@5 100.000 (99.941)
2019-05-08 21:40:35 - INFO - TRAINING - Epoch: [11][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.1514 (0.2552)	Prec@1 96.000 (91.198)	Prec@5 100.000 (99.891)
2019-05-08 21:40:39 - INFO - TRAINING - Epoch: [11][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.3958 (0.2558)	Prec@1 82.000 (91.219)	Prec@5 100.000 (99.894)
2019-05-08 21:40:43 - INFO - TRAINING - Epoch: [11][200/500]	Time 0.076 (0.083)	Data 0.000 (0.002)	Loss 0.2117 (0.2563)	Prec@1 93.000 (91.303)	Prec@5 99.000 (99.886)
2019-05-08 21:40:47 - INFO - TRAINING - Epoch: [11][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.2022 (0.2537)	Prec@1 93.000 (91.390)	Prec@5 100.000 (99.876)
2019-05-08 21:40:51 - INFO - TRAINING - Epoch: [11][300/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.2802 (0.2551)	Prec@1 90.000 (91.359)	Prec@5 100.000 (99.850)
2019-05-08 21:40:55 - INFO - TRAINING - Epoch: [11][350/500]	Time 0.075 (0.082)	Data 0.000 (0.001)	Loss 0.2423 (0.2538)	Prec@1 93.000 (91.405)	Prec@5 99.000 (99.832)
2019-05-08 21:40:59 - INFO - TRAINING - Epoch: [11][400/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.2686 (0.2570)	Prec@1 90.000 (91.284)	Prec@5 100.000 (99.820)
2019-05-08 21:41:03 - INFO - TRAINING - Epoch: [11][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.1736 (0.2579)	Prec@1 94.000 (91.226)	Prec@5 100.000 (99.812)
2019-05-08 21:41:08 - INFO - EVALUATING - Epoch: [11][0/100]	Time 0.301 (0.301)	Data 0.274 (0.274)	Loss 0.2996 (0.2996)	Prec@1 89.000 (89.000)	Prec@5 98.000 (98.000)
2019-05-08 21:41:09 - INFO - EVALUATING - Epoch: [11][50/100]	Time 0.026 (0.033)	Data 0.000 (0.006)	Loss 0.2318 (0.4281)	Prec@1 92.000 (86.765)	Prec@5 100.000 (99.137)
2019-05-08 21:41:11 - INFO - 
 Epoch: 12	Training Loss 0.2594 	Training Prec@1 91.148 	Training Prec@5 99.808 	Validation Loss 0.4301 	Validation Prec@1 86.420 	Validation Prec@5 99.150 	
2019-05-08 21:41:11 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:41:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:41:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:41:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:41:11 - INFO - TRAINING - Epoch: [12][0/500]	Time 0.260 (0.260)	Data 0.198 (0.198)	Loss 0.1866 (0.1866)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 21:41:15 - INFO - TRAINING - Epoch: [12][50/500]	Time 0.085 (0.084)	Data 0.000 (0.005)	Loss 0.3187 (0.2219)	Prec@1 92.000 (92.235)	Prec@5 100.000 (99.863)
2019-05-08 21:41:19 - INFO - TRAINING - Epoch: [12][100/500]	Time 0.078 (0.084)	Data 0.000 (0.003)	Loss 0.1853 (0.2303)	Prec@1 93.000 (92.010)	Prec@5 100.000 (99.842)
2019-05-08 21:41:23 - INFO - TRAINING - Epoch: [12][150/500]	Time 0.073 (0.083)	Data 0.000 (0.002)	Loss 0.1460 (0.2380)	Prec@1 94.000 (91.682)	Prec@5 100.000 (99.868)
2019-05-08 21:41:27 - INFO - TRAINING - Epoch: [12][200/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.1808 (0.2423)	Prec@1 95.000 (91.577)	Prec@5 100.000 (99.861)
2019-05-08 21:41:31 - INFO - TRAINING - Epoch: [12][250/500]	Time 0.070 (0.082)	Data 0.000 (0.002)	Loss 0.2153 (0.2423)	Prec@1 91.000 (91.598)	Prec@5 100.000 (99.861)
2019-05-08 21:41:35 - INFO - TRAINING - Epoch: [12][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.3313 (0.2407)	Prec@1 88.000 (91.621)	Prec@5 100.000 (99.860)
2019-05-08 21:41:39 - INFO - TRAINING - Epoch: [12][350/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.2361 (0.2429)	Prec@1 92.000 (91.533)	Prec@5 100.000 (99.860)
2019-05-08 21:41:43 - INFO - TRAINING - Epoch: [12][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.1361 (0.2426)	Prec@1 95.000 (91.539)	Prec@5 100.000 (99.870)
2019-05-08 21:41:48 - INFO - TRAINING - Epoch: [12][450/500]	Time 0.095 (0.082)	Data 0.000 (0.001)	Loss 0.2123 (0.2449)	Prec@1 93.000 (91.466)	Prec@5 100.000 (99.865)
2019-05-08 21:41:52 - INFO - EVALUATING - Epoch: [12][0/100]	Time 0.286 (0.286)	Data 0.261 (0.261)	Loss 0.2559 (0.2559)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-08 21:41:53 - INFO - EVALUATING - Epoch: [12][50/100]	Time 0.040 (0.032)	Data 0.000 (0.005)	Loss 0.3035 (0.3822)	Prec@1 89.000 (87.451)	Prec@5 100.000 (99.353)
2019-05-08 21:41:55 - INFO - 
 Epoch: 13	Training Loss 0.2431 	Training Prec@1 91.556 	Training Prec@5 99.868 	Validation Loss 0.3791 	Validation Prec@1 87.470 	Validation Prec@5 99.460 	
2019-05-08 21:41:55 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:41:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:41:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:41:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:41:55 - INFO - TRAINING - Epoch: [13][0/500]	Time 0.257 (0.257)	Data 0.198 (0.198)	Loss 0.2053 (0.2053)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 21:41:59 - INFO - TRAINING - Epoch: [13][50/500]	Time 0.089 (0.087)	Data 0.000 (0.005)	Loss 0.2115 (0.1997)	Prec@1 93.000 (93.588)	Prec@5 100.000 (99.843)
2019-05-08 21:42:03 - INFO - TRAINING - Epoch: [13][100/500]	Time 0.087 (0.084)	Data 0.000 (0.003)	Loss 0.1981 (0.2007)	Prec@1 93.000 (93.248)	Prec@5 100.000 (99.901)
2019-05-08 21:42:07 - INFO - TRAINING - Epoch: [13][150/500]	Time 0.078 (0.084)	Data 0.000 (0.002)	Loss 0.2160 (0.2095)	Prec@1 92.000 (92.914)	Prec@5 100.000 (99.881)
2019-05-08 21:42:12 - INFO - TRAINING - Epoch: [13][200/500]	Time 0.075 (0.084)	Data 0.000 (0.002)	Loss 0.2078 (0.2137)	Prec@1 93.000 (92.721)	Prec@5 100.000 (99.881)
2019-05-08 21:42:16 - INFO - TRAINING - Epoch: [13][250/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.1802 (0.2171)	Prec@1 94.000 (92.538)	Prec@5 100.000 (99.884)
2019-05-08 21:42:20 - INFO - TRAINING - Epoch: [13][300/500]	Time 0.072 (0.083)	Data 0.000 (0.002)	Loss 0.1369 (0.2180)	Prec@1 96.000 (92.512)	Prec@5 100.000 (99.877)
2019-05-08 21:42:24 - INFO - TRAINING - Epoch: [13][350/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.2019 (0.2216)	Prec@1 92.000 (92.368)	Prec@5 100.000 (99.880)
2019-05-08 21:42:28 - INFO - TRAINING - Epoch: [13][400/500]	Time 0.093 (0.083)	Data 0.000 (0.001)	Loss 0.2724 (0.2224)	Prec@1 91.000 (92.364)	Prec@5 99.000 (99.873)
2019-05-08 21:42:32 - INFO - TRAINING - Epoch: [13][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.1840 (0.2207)	Prec@1 93.000 (92.446)	Prec@5 100.000 (99.876)
2019-05-08 21:42:36 - INFO - EVALUATING - Epoch: [13][0/100]	Time 0.323 (0.323)	Data 0.282 (0.282)	Loss 0.4904 (0.4904)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-08 21:42:38 - INFO - EVALUATING - Epoch: [13][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.4205 (0.4445)	Prec@1 89.000 (86.098)	Prec@5 98.000 (99.118)
2019-05-08 21:42:39 - INFO - 
 Epoch: 14	Training Loss 0.2208 	Training Prec@1 92.432 	Training Prec@5 99.872 	Validation Loss 0.4372 	Validation Prec@1 86.070 	Validation Prec@5 99.290 	
2019-05-08 21:42:39 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:42:39 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:42:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:42:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:42:39 - INFO - TRAINING - Epoch: [14][0/500]	Time 0.244 (0.244)	Data 0.188 (0.188)	Loss 0.1980 (0.1980)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 21:42:44 - INFO - TRAINING - Epoch: [14][50/500]	Time 0.087 (0.088)	Data 0.000 (0.004)	Loss 0.2422 (0.2044)	Prec@1 95.000 (92.980)	Prec@5 99.000 (99.902)
2019-05-08 21:42:48 - INFO - TRAINING - Epoch: [14][100/500]	Time 0.080 (0.086)	Data 0.000 (0.003)	Loss 0.1779 (0.2060)	Prec@1 95.000 (92.941)	Prec@5 100.000 (99.871)
2019-05-08 21:42:52 - INFO - TRAINING - Epoch: [14][150/500]	Time 0.079 (0.085)	Data 0.000 (0.002)	Loss 0.1956 (0.2064)	Prec@1 92.000 (92.947)	Prec@5 100.000 (99.901)
2019-05-08 21:42:56 - INFO - TRAINING - Epoch: [14][200/500]	Time 0.092 (0.085)	Data 0.000 (0.002)	Loss 0.2266 (0.2006)	Prec@1 93.000 (93.109)	Prec@5 99.000 (99.920)
2019-05-08 21:43:00 - INFO - TRAINING - Epoch: [14][250/500]	Time 0.069 (0.084)	Data 0.000 (0.002)	Loss 0.1737 (0.1980)	Prec@1 95.000 (93.203)	Prec@5 100.000 (99.920)
2019-05-08 21:43:04 - INFO - TRAINING - Epoch: [14][300/500]	Time 0.079 (0.084)	Data 0.000 (0.001)	Loss 0.1049 (0.1965)	Prec@1 97.000 (93.279)	Prec@5 100.000 (99.917)
2019-05-08 21:43:08 - INFO - TRAINING - Epoch: [14][350/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.2053 (0.1984)	Prec@1 95.000 (93.191)	Prec@5 100.000 (99.915)
2019-05-08 21:43:12 - INFO - TRAINING - Epoch: [14][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2125 (0.1996)	Prec@1 94.000 (93.140)	Prec@5 99.000 (99.908)
2019-05-08 21:43:17 - INFO - TRAINING - Epoch: [14][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.1713 (0.2028)	Prec@1 95.000 (93.040)	Prec@5 100.000 (99.907)
2019-05-08 21:43:21 - INFO - EVALUATING - Epoch: [14][0/100]	Time 0.300 (0.300)	Data 0.274 (0.274)	Loss 0.3808 (0.3808)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-05-08 21:43:22 - INFO - EVALUATING - Epoch: [14][50/100]	Time 0.027 (0.033)	Data 0.001 (0.006)	Loss 0.4192 (0.4240)	Prec@1 89.000 (86.784)	Prec@5 100.000 (99.471)
2019-05-08 21:43:24 - INFO - 
 Epoch: 15	Training Loss 0.2041 	Training Prec@1 92.982 	Training Prec@5 99.904 	Validation Loss 0.4119 	Validation Prec@1 86.980 	Validation Prec@5 99.600 	
2019-05-08 21:43:24 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:43:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:43:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:43:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:43:24 - INFO - TRAINING - Epoch: [15][0/500]	Time 0.240 (0.240)	Data 0.196 (0.196)	Loss 0.1891 (0.1891)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 21:43:28 - INFO - TRAINING - Epoch: [15][50/500]	Time 0.071 (0.081)	Data 0.000 (0.005)	Loss 0.1084 (0.1639)	Prec@1 97.000 (94.333)	Prec@5 100.000 (99.980)
2019-05-08 21:43:32 - INFO - TRAINING - Epoch: [15][100/500]	Time 0.081 (0.082)	Data 0.000 (0.003)	Loss 0.1341 (0.1762)	Prec@1 95.000 (93.842)	Prec@5 100.000 (99.931)
2019-05-08 21:43:36 - INFO - TRAINING - Epoch: [15][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.1351 (0.1799)	Prec@1 97.000 (93.695)	Prec@5 100.000 (99.914)
2019-05-08 21:43:40 - INFO - TRAINING - Epoch: [15][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.1650 (0.1839)	Prec@1 95.000 (93.532)	Prec@5 100.000 (99.910)
2019-05-08 21:43:45 - INFO - TRAINING - Epoch: [15][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.1433 (0.1816)	Prec@1 96.000 (93.685)	Prec@5 100.000 (99.912)
2019-05-08 21:43:49 - INFO - TRAINING - Epoch: [15][300/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.3489 (0.1850)	Prec@1 86.000 (93.571)	Prec@5 100.000 (99.910)
2019-05-08 21:43:53 - INFO - TRAINING - Epoch: [15][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2790 (0.1878)	Prec@1 90.000 (93.467)	Prec@5 100.000 (99.912)
2019-05-08 21:43:57 - INFO - TRAINING - Epoch: [15][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.1504 (0.1900)	Prec@1 97.000 (93.374)	Prec@5 99.000 (99.910)
2019-05-08 21:44:01 - INFO - TRAINING - Epoch: [15][450/500]	Time 0.060 (0.082)	Data 0.001 (0.001)	Loss 0.2083 (0.1935)	Prec@1 93.000 (93.244)	Prec@5 99.000 (99.914)
2019-05-08 21:44:05 - INFO - EVALUATING - Epoch: [15][0/100]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.3309 (0.3309)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-08 21:44:06 - INFO - EVALUATING - Epoch: [15][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.3129 (0.4322)	Prec@1 89.000 (87.216)	Prec@5 98.000 (99.431)
2019-05-08 21:44:08 - INFO - 
 Epoch: 16	Training Loss 0.1941 	Training Prec@1 93.236 	Training Prec@5 99.912 	Validation Loss 0.4223 	Validation Prec@1 87.180 	Validation Prec@5 99.500 	
2019-05-08 21:44:08 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:44:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:44:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:44:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:44:08 - INFO - TRAINING - Epoch: [16][0/500]	Time 0.293 (0.293)	Data 0.251 (0.251)	Loss 0.2173 (0.2173)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 21:44:12 - INFO - TRAINING - Epoch: [16][50/500]	Time 0.076 (0.087)	Data 0.000 (0.006)	Loss 0.1578 (0.1534)	Prec@1 96.000 (94.549)	Prec@5 100.000 (99.980)
2019-05-08 21:44:16 - INFO - TRAINING - Epoch: [16][100/500]	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 0.1978 (0.1568)	Prec@1 93.000 (94.208)	Prec@5 100.000 (99.960)
2019-05-08 21:44:20 - INFO - TRAINING - Epoch: [16][150/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.0736 (0.1597)	Prec@1 97.000 (94.331)	Prec@5 100.000 (99.934)
2019-05-08 21:44:25 - INFO - TRAINING - Epoch: [16][200/500]	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 0.1466 (0.1664)	Prec@1 96.000 (94.065)	Prec@5 100.000 (99.915)
2019-05-08 21:44:29 - INFO - TRAINING - Epoch: [16][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.1920 (0.1702)	Prec@1 93.000 (93.964)	Prec@5 100.000 (99.904)
2019-05-08 21:44:33 - INFO - TRAINING - Epoch: [16][300/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.2521 (0.1722)	Prec@1 93.000 (94.027)	Prec@5 99.000 (99.900)
2019-05-08 21:44:37 - INFO - TRAINING - Epoch: [16][350/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.2381 (0.1724)	Prec@1 94.000 (94.046)	Prec@5 100.000 (99.906)
2019-05-08 21:44:41 - INFO - TRAINING - Epoch: [16][400/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.1454 (0.1717)	Prec@1 91.000 (94.072)	Prec@5 100.000 (99.915)
2019-05-08 21:44:45 - INFO - TRAINING - Epoch: [16][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.2086 (0.1731)	Prec@1 90.000 (94.022)	Prec@5 100.000 (99.918)
2019-05-08 21:44:49 - INFO - EVALUATING - Epoch: [16][0/100]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.4667 (0.4667)	Prec@1 89.000 (89.000)	Prec@5 98.000 (98.000)
2019-05-08 21:44:51 - INFO - EVALUATING - Epoch: [16][50/100]	Time 0.037 (0.033)	Data 0.000 (0.005)	Loss 0.2942 (0.4257)	Prec@1 91.000 (87.471)	Prec@5 99.000 (99.373)
2019-05-08 21:44:52 - INFO - 
 Epoch: 17	Training Loss 0.1752 	Training Prec@1 93.952 	Training Prec@5 99.920 	Validation Loss 0.4168 	Validation Prec@1 87.270 	Validation Prec@5 99.470 	
2019-05-08 21:44:52 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:44:52 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:44:52 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:44:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:44:52 - INFO - TRAINING - Epoch: [17][0/500]	Time 0.241 (0.241)	Data 0.190 (0.190)	Loss 0.1735 (0.1735)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 21:44:57 - INFO - TRAINING - Epoch: [17][50/500]	Time 0.080 (0.085)	Data 0.000 (0.005)	Loss 0.1931 (0.1525)	Prec@1 93.000 (94.569)	Prec@5 100.000 (99.941)
2019-05-08 21:45:01 - INFO - TRAINING - Epoch: [17][100/500]	Time 0.084 (0.083)	Data 0.000 (0.003)	Loss 0.1613 (0.1503)	Prec@1 97.000 (94.822)	Prec@5 100.000 (99.950)
2019-05-08 21:45:05 - INFO - TRAINING - Epoch: [17][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.2417 (0.1544)	Prec@1 93.000 (94.649)	Prec@5 99.000 (99.960)
2019-05-08 21:45:09 - INFO - TRAINING - Epoch: [17][200/500]	Time 0.071 (0.083)	Data 0.000 (0.002)	Loss 0.1154 (0.1545)	Prec@1 96.000 (94.697)	Prec@5 100.000 (99.950)
2019-05-08 21:45:13 - INFO - TRAINING - Epoch: [17][250/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0746 (0.1561)	Prec@1 98.000 (94.614)	Prec@5 100.000 (99.960)
2019-05-08 21:45:17 - INFO - TRAINING - Epoch: [17][300/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.2409 (0.1597)	Prec@1 92.000 (94.445)	Prec@5 100.000 (99.960)
2019-05-08 21:45:21 - INFO - TRAINING - Epoch: [17][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.1610 (0.1589)	Prec@1 96.000 (94.507)	Prec@5 100.000 (99.957)
2019-05-08 21:45:25 - INFO - TRAINING - Epoch: [17][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.1574 (0.1609)	Prec@1 94.000 (94.409)	Prec@5 100.000 (99.948)
2019-05-08 21:45:29 - INFO - TRAINING - Epoch: [17][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0906 (0.1635)	Prec@1 97.000 (94.275)	Prec@5 100.000 (99.942)
2019-05-08 21:45:34 - INFO - EVALUATING - Epoch: [17][0/100]	Time 0.301 (0.301)	Data 0.277 (0.277)	Loss 0.2534 (0.2534)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 21:45:35 - INFO - EVALUATING - Epoch: [17][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.2769 (0.3650)	Prec@1 91.000 (88.667)	Prec@5 100.000 (99.627)
2019-05-08 21:45:37 - INFO - 
 Epoch: 18	Training Loss 0.1657 	Training Prec@1 94.184 	Training Prec@5 99.936 	Validation Loss 0.3601 	Validation Prec@1 88.830 	Validation Prec@5 99.660 	
2019-05-08 21:45:37 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:45:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:45:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:45:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:45:37 - INFO - TRAINING - Epoch: [18][0/500]	Time 0.248 (0.248)	Data 0.186 (0.186)	Loss 0.0664 (0.0664)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 21:45:41 - INFO - TRAINING - Epoch: [18][50/500]	Time 0.084 (0.085)	Data 0.000 (0.004)	Loss 0.1918 (0.1325)	Prec@1 93.000 (95.647)	Prec@5 100.000 (99.941)
2019-05-08 21:45:45 - INFO - TRAINING - Epoch: [18][100/500]	Time 0.079 (0.084)	Data 0.000 (0.003)	Loss 0.0958 (0.1344)	Prec@1 97.000 (95.614)	Prec@5 100.000 (99.970)
2019-05-08 21:45:49 - INFO - TRAINING - Epoch: [18][150/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.1590 (0.1389)	Prec@1 94.000 (95.411)	Prec@5 100.000 (99.967)
2019-05-08 21:45:53 - INFO - TRAINING - Epoch: [18][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.2252 (0.1444)	Prec@1 92.000 (95.174)	Prec@5 99.000 (99.955)
2019-05-08 21:45:57 - INFO - TRAINING - Epoch: [18][250/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.1786 (0.1493)	Prec@1 95.000 (94.980)	Prec@5 100.000 (99.952)
2019-05-08 21:46:02 - INFO - TRAINING - Epoch: [18][300/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.1451 (0.1491)	Prec@1 96.000 (94.993)	Prec@5 100.000 (99.960)
2019-05-08 21:46:06 - INFO - TRAINING - Epoch: [18][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0652 (0.1515)	Prec@1 97.000 (94.849)	Prec@5 100.000 (99.954)
2019-05-08 21:46:10 - INFO - TRAINING - Epoch: [18][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.1625 (0.1508)	Prec@1 94.000 (94.830)	Prec@5 100.000 (99.960)
2019-05-08 21:46:14 - INFO - TRAINING - Epoch: [18][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.2386 (0.1516)	Prec@1 89.000 (94.772)	Prec@5 100.000 (99.960)
2019-05-08 21:46:18 - INFO - EVALUATING - Epoch: [18][0/100]	Time 0.293 (0.293)	Data 0.269 (0.269)	Loss 0.2238 (0.2238)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-08 21:46:20 - INFO - EVALUATING - Epoch: [18][50/100]	Time 0.039 (0.033)	Data 0.000 (0.006)	Loss 0.2574 (0.3904)	Prec@1 92.000 (88.020)	Prec@5 100.000 (99.373)
2019-05-08 21:46:21 - INFO - 
 Epoch: 19	Training Loss 0.1534 	Training Prec@1 94.704 	Training Prec@5 99.954 	Validation Loss 0.3832 	Validation Prec@1 88.110 	Validation Prec@5 99.500 	
2019-05-08 21:46:21 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:46:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:46:21 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:46:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:46:21 - INFO - TRAINING - Epoch: [19][0/500]	Time 0.274 (0.274)	Data 0.230 (0.230)	Loss 0.1186 (0.1186)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 21:46:26 - INFO - TRAINING - Epoch: [19][50/500]	Time 0.076 (0.086)	Data 0.000 (0.005)	Loss 0.1335 (0.1348)	Prec@1 95.000 (95.373)	Prec@5 100.000 (99.980)
2019-05-08 21:46:30 - INFO - TRAINING - Epoch: [19][100/500]	Time 0.080 (0.083)	Data 0.000 (0.003)	Loss 0.1638 (0.1360)	Prec@1 95.000 (95.248)	Prec@5 100.000 (99.980)
2019-05-08 21:46:34 - INFO - TRAINING - Epoch: [19][150/500]	Time 0.076 (0.083)	Data 0.000 (0.002)	Loss 0.1999 (0.1375)	Prec@1 91.000 (95.179)	Prec@5 100.000 (99.987)
2019-05-08 21:46:38 - INFO - TRAINING - Epoch: [19][200/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.1537 (0.1404)	Prec@1 94.000 (95.109)	Prec@5 100.000 (99.985)
2019-05-08 21:46:42 - INFO - TRAINING - Epoch: [19][250/500]	Time 0.077 (0.082)	Data 0.000 (0.002)	Loss 0.2105 (0.1409)	Prec@1 94.000 (95.104)	Prec@5 100.000 (99.984)
2019-05-08 21:46:46 - INFO - TRAINING - Epoch: [19][300/500]	Time 0.070 (0.082)	Data 0.000 (0.002)	Loss 0.1412 (0.1415)	Prec@1 95.000 (95.120)	Prec@5 100.000 (99.983)
2019-05-08 21:46:50 - INFO - TRAINING - Epoch: [19][350/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.1438 (0.1423)	Prec@1 94.000 (95.085)	Prec@5 100.000 (99.980)
2019-05-08 21:46:54 - INFO - TRAINING - Epoch: [19][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.1285 (0.1415)	Prec@1 93.000 (95.095)	Prec@5 100.000 (99.983)
2019-05-08 21:46:58 - INFO - TRAINING - Epoch: [19][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.1278 (0.1419)	Prec@1 94.000 (95.091)	Prec@5 100.000 (99.976)
2019-05-08 21:47:02 - INFO - EVALUATING - Epoch: [19][0/100]	Time 0.304 (0.304)	Data 0.279 (0.279)	Loss 0.3266 (0.3266)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-05-08 21:47:04 - INFO - EVALUATING - Epoch: [19][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.1621 (0.3455)	Prec@1 95.000 (90.412)	Prec@5 99.000 (99.451)
2019-05-08 21:47:05 - INFO - 
 Epoch: 20	Training Loss 0.1428 	Training Prec@1 95.090 	Training Prec@5 99.964 	Validation Loss 0.3455 	Validation Prec@1 90.080 	Validation Prec@5 99.560 	
2019-05-08 21:47:05 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:47:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:47:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:47:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:47:06 - INFO - TRAINING - Epoch: [20][0/500]	Time 0.288 (0.288)	Data 0.224 (0.224)	Loss 0.2368 (0.2368)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-08 21:47:10 - INFO - TRAINING - Epoch: [20][50/500]	Time 0.086 (0.085)	Data 0.000 (0.005)	Loss 0.1003 (0.1176)	Prec@1 96.000 (96.020)	Prec@5 100.000 (99.941)
2019-05-08 21:47:14 - INFO - TRAINING - Epoch: [20][100/500]	Time 0.085 (0.083)	Data 0.000 (0.003)	Loss 0.0725 (0.1185)	Prec@1 98.000 (96.000)	Prec@5 100.000 (99.931)
2019-05-08 21:47:18 - INFO - TRAINING - Epoch: [20][150/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.1255 (0.1177)	Prec@1 97.000 (96.066)	Prec@5 100.000 (99.934)
2019-05-08 21:47:22 - INFO - TRAINING - Epoch: [20][200/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.1425 (0.1192)	Prec@1 95.000 (96.040)	Prec@5 100.000 (99.940)
2019-05-08 21:47:26 - INFO - TRAINING - Epoch: [20][250/500]	Time 0.084 (0.081)	Data 0.000 (0.002)	Loss 0.1499 (0.1209)	Prec@1 96.000 (95.948)	Prec@5 100.000 (99.940)
2019-05-08 21:47:30 - INFO - TRAINING - Epoch: [20][300/500]	Time 0.085 (0.081)	Data 0.000 (0.002)	Loss 0.1292 (0.1223)	Prec@1 94.000 (95.857)	Prec@5 100.000 (99.944)
2019-05-08 21:47:34 - INFO - TRAINING - Epoch: [20][350/500]	Time 0.071 (0.081)	Data 0.000 (0.001)	Loss 0.0669 (0.1260)	Prec@1 97.000 (95.661)	Prec@5 100.000 (99.952)
2019-05-08 21:47:38 - INFO - TRAINING - Epoch: [20][400/500]	Time 0.081 (0.081)	Data 0.000 (0.001)	Loss 0.0774 (0.1260)	Prec@1 98.000 (95.663)	Prec@5 100.000 (99.955)
2019-05-08 21:47:42 - INFO - TRAINING - Epoch: [20][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.1872 (0.1269)	Prec@1 94.000 (95.630)	Prec@5 100.000 (99.960)
2019-05-08 21:47:47 - INFO - EVALUATING - Epoch: [20][0/100]	Time 0.304 (0.304)	Data 0.278 (0.278)	Loss 0.3141 (0.3141)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-08 21:47:48 - INFO - EVALUATING - Epoch: [20][50/100]	Time 0.035 (0.033)	Data 0.000 (0.006)	Loss 0.3074 (0.4241)	Prec@1 91.000 (87.882)	Prec@5 100.000 (99.353)
2019-05-08 21:47:49 - INFO - 
 Epoch: 21	Training Loss 0.1292 	Training Prec@1 95.514 	Training Prec@5 99.954 	Validation Loss 0.4143 	Validation Prec@1 87.930 	Validation Prec@5 99.500 	
2019-05-08 21:47:49 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:47:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:47:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:47:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:47:50 - INFO - TRAINING - Epoch: [21][0/500]	Time 0.286 (0.286)	Data 0.244 (0.244)	Loss 0.1407 (0.1407)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 21:47:54 - INFO - TRAINING - Epoch: [21][50/500]	Time 0.087 (0.085)	Data 0.000 (0.006)	Loss 0.1738 (0.1118)	Prec@1 93.000 (96.137)	Prec@5 100.000 (99.961)
2019-05-08 21:47:58 - INFO - TRAINING - Epoch: [21][100/500]	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 0.1294 (0.1149)	Prec@1 96.000 (96.069)	Prec@5 100.000 (99.970)
2019-05-08 21:48:02 - INFO - TRAINING - Epoch: [21][150/500]	Time 0.084 (0.085)	Data 0.000 (0.002)	Loss 0.1039 (0.1166)	Prec@1 97.000 (95.980)	Prec@5 100.000 (99.967)
2019-05-08 21:48:06 - INFO - TRAINING - Epoch: [21][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.1015 (0.1184)	Prec@1 97.000 (95.851)	Prec@5 100.000 (99.970)
2019-05-08 21:48:10 - INFO - TRAINING - Epoch: [21][250/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.1951 (0.1204)	Prec@1 90.000 (95.821)	Prec@5 100.000 (99.976)
2019-05-08 21:48:14 - INFO - TRAINING - Epoch: [21][300/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.1584 (0.1244)	Prec@1 93.000 (95.648)	Prec@5 100.000 (99.977)
2019-05-08 21:48:19 - INFO - TRAINING - Epoch: [21][350/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.1085 (0.1288)	Prec@1 97.000 (95.530)	Prec@5 100.000 (99.974)
2019-05-08 21:48:23 - INFO - TRAINING - Epoch: [21][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.1763 (0.1284)	Prec@1 95.000 (95.511)	Prec@5 100.000 (99.973)
2019-05-08 21:48:27 - INFO - TRAINING - Epoch: [21][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.1967 (0.1280)	Prec@1 92.000 (95.508)	Prec@5 100.000 (99.971)
2019-05-08 21:48:31 - INFO - EVALUATING - Epoch: [21][0/100]	Time 0.313 (0.313)	Data 0.275 (0.275)	Loss 0.3376 (0.3376)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-08 21:48:33 - INFO - EVALUATING - Epoch: [21][50/100]	Time 0.026 (0.033)	Data 0.000 (0.006)	Loss 0.2609 (0.3388)	Prec@1 93.000 (90.255)	Prec@5 100.000 (99.588)
2019-05-08 21:48:34 - INFO - 
 Epoch: 22	Training Loss 0.1293 	Training Prec@1 95.476 	Training Prec@5 99.964 	Validation Loss 0.3377 	Validation Prec@1 90.160 	Validation Prec@5 99.660 	
2019-05-08 21:48:34 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:48:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:48:34 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:48:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:48:34 - INFO - TRAINING - Epoch: [22][0/500]	Time 0.249 (0.249)	Data 0.194 (0.194)	Loss 0.0870 (0.0870)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-08 21:48:39 - INFO - TRAINING - Epoch: [22][50/500]	Time 0.073 (0.086)	Data 0.000 (0.005)	Loss 0.0944 (0.0996)	Prec@1 95.000 (96.608)	Prec@5 100.000 (100.000)
2019-05-08 21:48:43 - INFO - TRAINING - Epoch: [22][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0654 (0.1091)	Prec@1 99.000 (96.248)	Prec@5 100.000 (100.000)
2019-05-08 21:48:47 - INFO - TRAINING - Epoch: [22][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.1421 (0.1082)	Prec@1 94.000 (96.272)	Prec@5 100.000 (100.000)
2019-05-08 21:48:51 - INFO - TRAINING - Epoch: [22][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0784 (0.1101)	Prec@1 96.000 (96.149)	Prec@5 100.000 (99.980)
2019-05-08 21:48:55 - INFO - TRAINING - Epoch: [22][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.1121 (0.1128)	Prec@1 97.000 (95.996)	Prec@5 100.000 (99.976)
2019-05-08 21:48:59 - INFO - TRAINING - Epoch: [22][300/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.1734 (0.1145)	Prec@1 95.000 (95.967)	Prec@5 100.000 (99.973)
2019-05-08 21:49:03 - INFO - TRAINING - Epoch: [22][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.1197 (0.1154)	Prec@1 95.000 (95.923)	Prec@5 100.000 (99.974)
2019-05-08 21:49:08 - INFO - TRAINING - Epoch: [22][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0978 (0.1150)	Prec@1 97.000 (95.945)	Prec@5 100.000 (99.978)
2019-05-08 21:49:12 - INFO - TRAINING - Epoch: [22][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.1105 (0.1154)	Prec@1 97.000 (95.953)	Prec@5 100.000 (99.978)
2019-05-08 21:49:16 - INFO - EVALUATING - Epoch: [22][0/100]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.1612 (0.1612)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 21:49:17 - INFO - EVALUATING - Epoch: [22][50/100]	Time 0.031 (0.032)	Data 0.000 (0.005)	Loss 0.2620 (0.3353)	Prec@1 93.000 (90.137)	Prec@5 99.000 (99.588)
2019-05-08 21:49:19 - INFO - 
 Epoch: 23	Training Loss 0.1170 	Training Prec@1 95.936 	Training Prec@5 99.976 	Validation Loss 0.3352 	Validation Prec@1 89.850 	Validation Prec@5 99.720 	
2019-05-08 21:49:19 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:49:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:49:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:49:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:49:19 - INFO - TRAINING - Epoch: [23][0/500]	Time 0.250 (0.250)	Data 0.193 (0.193)	Loss 0.1084 (0.1084)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-08 21:49:23 - INFO - TRAINING - Epoch: [23][50/500]	Time 0.087 (0.083)	Data 0.000 (0.005)	Loss 0.0888 (0.0951)	Prec@1 98.000 (96.863)	Prec@5 99.000 (99.941)
2019-05-08 21:49:27 - INFO - TRAINING - Epoch: [23][100/500]	Time 0.071 (0.082)	Data 0.000 (0.003)	Loss 0.1034 (0.1040)	Prec@1 97.000 (96.535)	Prec@5 100.000 (99.970)
2019-05-08 21:49:31 - INFO - TRAINING - Epoch: [23][150/500]	Time 0.080 (0.081)	Data 0.000 (0.002)	Loss 0.1556 (0.1019)	Prec@1 94.000 (96.596)	Prec@5 100.000 (99.980)
2019-05-08 21:49:35 - INFO - TRAINING - Epoch: [23][200/500]	Time 0.087 (0.081)	Data 0.000 (0.002)	Loss 0.0974 (0.1000)	Prec@1 96.000 (96.647)	Prec@5 100.000 (99.975)
2019-05-08 21:49:39 - INFO - TRAINING - Epoch: [23][250/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.1017 (0.1004)	Prec@1 96.000 (96.602)	Prec@5 100.000 (99.980)
2019-05-08 21:49:44 - INFO - TRAINING - Epoch: [23][300/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.1723 (0.1004)	Prec@1 96.000 (96.588)	Prec@5 100.000 (99.983)
2019-05-08 21:49:48 - INFO - TRAINING - Epoch: [23][350/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.1408 (0.0997)	Prec@1 95.000 (96.630)	Prec@5 100.000 (99.983)
2019-05-08 21:49:52 - INFO - TRAINING - Epoch: [23][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.1933 (0.1019)	Prec@1 90.000 (96.529)	Prec@5 100.000 (99.975)
2019-05-08 21:49:56 - INFO - TRAINING - Epoch: [23][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.1553 (0.1023)	Prec@1 95.000 (96.503)	Prec@5 100.000 (99.978)
2019-05-08 21:50:00 - INFO - EVALUATING - Epoch: [23][0/100]	Time 0.293 (0.293)	Data 0.267 (0.267)	Loss 0.2713 (0.2713)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-08 21:50:01 - INFO - EVALUATING - Epoch: [23][50/100]	Time 0.026 (0.032)	Data 0.000 (0.006)	Loss 0.2831 (0.3342)	Prec@1 93.000 (90.451)	Prec@5 100.000 (99.510)
2019-05-08 21:50:03 - INFO - 
 Epoch: 24	Training Loss 0.1029 	Training Prec@1 96.504 	Training Prec@5 99.974 	Validation Loss 0.3284 	Validation Prec@1 90.570 	Validation Prec@5 99.640 	
2019-05-08 21:50:03 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:50:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:50:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:50:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:50:03 - INFO - TRAINING - Epoch: [24][0/500]	Time 0.259 (0.259)	Data 0.196 (0.196)	Loss 0.1336 (0.1336)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-08 21:50:07 - INFO - TRAINING - Epoch: [24][50/500]	Time 0.074 (0.084)	Data 0.000 (0.005)	Loss 0.0942 (0.0910)	Prec@1 96.000 (96.941)	Prec@5 100.000 (99.941)
2019-05-08 21:50:11 - INFO - TRAINING - Epoch: [24][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.2051 (0.0870)	Prec@1 91.000 (97.000)	Prec@5 100.000 (99.970)
2019-05-08 21:50:15 - INFO - TRAINING - Epoch: [24][150/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0654 (0.0862)	Prec@1 97.000 (97.119)	Prec@5 100.000 (99.974)
2019-05-08 21:50:20 - INFO - TRAINING - Epoch: [24][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.1521 (0.0880)	Prec@1 96.000 (97.055)	Prec@5 99.000 (99.975)
2019-05-08 21:50:24 - INFO - TRAINING - Epoch: [24][250/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.1543 (0.0900)	Prec@1 95.000 (96.988)	Prec@5 100.000 (99.968)
2019-05-08 21:50:28 - INFO - TRAINING - Epoch: [24][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0673 (0.0933)	Prec@1 98.000 (96.837)	Prec@5 100.000 (99.967)
2019-05-08 21:50:32 - INFO - TRAINING - Epoch: [24][350/500]	Time 0.069 (0.083)	Data 0.000 (0.001)	Loss 0.1325 (0.0950)	Prec@1 96.000 (96.729)	Prec@5 100.000 (99.969)
2019-05-08 21:50:36 - INFO - TRAINING - Epoch: [24][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.1557 (0.0958)	Prec@1 96.000 (96.723)	Prec@5 100.000 (99.970)
2019-05-08 21:50:40 - INFO - TRAINING - Epoch: [24][450/500]	Time 0.058 (0.083)	Data 0.000 (0.001)	Loss 0.0817 (0.0959)	Prec@1 97.000 (96.692)	Prec@5 100.000 (99.971)
2019-05-08 21:50:45 - INFO - EVALUATING - Epoch: [24][0/100]	Time 0.324 (0.324)	Data 0.278 (0.278)	Loss 0.3691 (0.3691)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-05-08 21:50:46 - INFO - EVALUATING - Epoch: [24][50/100]	Time 0.031 (0.032)	Data 0.000 (0.006)	Loss 0.2841 (0.3611)	Prec@1 93.000 (90.412)	Prec@5 99.000 (99.412)
2019-05-08 21:50:47 - INFO - 
 Epoch: 25	Training Loss 0.0968 	Training Prec@1 96.668 	Training Prec@5 99.972 	Validation Loss 0.3599 	Validation Prec@1 90.120 	Validation Prec@5 99.510 	
2019-05-08 21:50:47 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:50:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:50:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:50:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:50:48 - INFO - TRAINING - Epoch: [25][0/500]	Time 0.248 (0.248)	Data 0.190 (0.190)	Loss 0.1208 (0.1208)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 21:50:52 - INFO - TRAINING - Epoch: [25][50/500]	Time 0.085 (0.083)	Data 0.000 (0.005)	Loss 0.0443 (0.0716)	Prec@1 98.000 (97.647)	Prec@5 100.000 (100.000)
2019-05-08 21:50:56 - INFO - TRAINING - Epoch: [25][100/500]	Time 0.086 (0.082)	Data 0.000 (0.003)	Loss 0.1297 (0.0825)	Prec@1 98.000 (97.327)	Prec@5 100.000 (100.000)
2019-05-08 21:51:00 - INFO - TRAINING - Epoch: [25][150/500]	Time 0.072 (0.082)	Data 0.000 (0.002)	Loss 0.1624 (0.0840)	Prec@1 95.000 (97.212)	Prec@5 100.000 (99.993)
2019-05-08 21:51:04 - INFO - TRAINING - Epoch: [25][200/500]	Time 0.070 (0.081)	Data 0.000 (0.002)	Loss 0.1068 (0.0876)	Prec@1 96.000 (97.070)	Prec@5 100.000 (99.990)
2019-05-08 21:51:08 - INFO - TRAINING - Epoch: [25][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.1654 (0.0887)	Prec@1 93.000 (96.964)	Prec@5 100.000 (99.988)
2019-05-08 21:51:12 - INFO - TRAINING - Epoch: [25][300/500]	Time 0.082 (0.081)	Data 0.000 (0.002)	Loss 0.1314 (0.0915)	Prec@1 96.000 (96.920)	Prec@5 100.000 (99.990)
2019-05-08 21:51:16 - INFO - TRAINING - Epoch: [25][350/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0344 (0.0916)	Prec@1 99.000 (96.909)	Prec@5 100.000 (99.991)
2019-05-08 21:51:20 - INFO - TRAINING - Epoch: [25][400/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.1077 (0.0931)	Prec@1 96.000 (96.845)	Prec@5 100.000 (99.993)
2019-05-08 21:51:24 - INFO - TRAINING - Epoch: [25][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0929 (0.0937)	Prec@1 98.000 (96.809)	Prec@5 100.000 (99.993)
2019-05-08 21:51:29 - INFO - EVALUATING - Epoch: [25][0/100]	Time 0.281 (0.281)	Data 0.255 (0.255)	Loss 0.3310 (0.3310)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-05-08 21:51:30 - INFO - EVALUATING - Epoch: [25][50/100]	Time 0.029 (0.032)	Data 0.000 (0.005)	Loss 0.2130 (0.3956)	Prec@1 94.000 (88.980)	Prec@5 100.000 (99.451)
2019-05-08 21:51:31 - INFO - 
 Epoch: 26	Training Loss 0.0941 	Training Prec@1 96.806 	Training Prec@5 99.992 	Validation Loss 0.3797 	Validation Prec@1 89.250 	Validation Prec@5 99.630 	
2019-05-08 21:51:31 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:51:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:51:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:51:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:51:32 - INFO - TRAINING - Epoch: [26][0/500]	Time 0.245 (0.245)	Data 0.177 (0.177)	Loss 0.0725 (0.0725)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 21:51:36 - INFO - TRAINING - Epoch: [26][50/500]	Time 0.080 (0.086)	Data 0.000 (0.004)	Loss 0.0752 (0.0851)	Prec@1 98.000 (97.098)	Prec@5 100.000 (99.980)
2019-05-08 21:51:40 - INFO - TRAINING - Epoch: [26][100/500]	Time 0.069 (0.084)	Data 0.000 (0.003)	Loss 0.0408 (0.0782)	Prec@1 99.000 (97.327)	Prec@5 100.000 (99.990)
2019-05-08 21:51:44 - INFO - TRAINING - Epoch: [26][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0763 (0.0799)	Prec@1 97.000 (97.245)	Prec@5 100.000 (99.987)
2019-05-08 21:51:48 - INFO - TRAINING - Epoch: [26][200/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0709 (0.0795)	Prec@1 98.000 (97.338)	Prec@5 100.000 (99.990)
2019-05-08 21:51:52 - INFO - TRAINING - Epoch: [26][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0722 (0.0803)	Prec@1 98.000 (97.323)	Prec@5 100.000 (99.992)
2019-05-08 21:51:56 - INFO - TRAINING - Epoch: [26][300/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0900 (0.0824)	Prec@1 95.000 (97.236)	Prec@5 100.000 (99.993)
2019-05-08 21:52:00 - INFO - TRAINING - Epoch: [26][350/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0752 (0.0822)	Prec@1 98.000 (97.222)	Prec@5 100.000 (99.994)
2019-05-08 21:52:05 - INFO - TRAINING - Epoch: [26][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0982 (0.0822)	Prec@1 95.000 (97.192)	Prec@5 100.000 (99.995)
2019-05-08 21:52:09 - INFO - TRAINING - Epoch: [26][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0799 (0.0835)	Prec@1 97.000 (97.151)	Prec@5 100.000 (99.991)
2019-05-08 21:52:13 - INFO - EVALUATING - Epoch: [26][0/100]	Time 0.295 (0.295)	Data 0.269 (0.269)	Loss 0.1807 (0.1807)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 21:52:14 - INFO - EVALUATING - Epoch: [26][50/100]	Time 0.033 (0.033)	Data 0.000 (0.006)	Loss 0.2443 (0.3510)	Prec@1 92.000 (90.510)	Prec@5 99.000 (99.490)
2019-05-08 21:52:16 - INFO - 
 Epoch: 27	Training Loss 0.0840 	Training Prec@1 97.142 	Training Prec@5 99.990 	Validation Loss 0.3551 	Validation Prec@1 90.350 	Validation Prec@5 99.610 	
2019-05-08 21:52:16 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:52:16 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:52:16 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:52:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:52:16 - INFO - TRAINING - Epoch: [27][0/500]	Time 0.295 (0.295)	Data 0.229 (0.229)	Loss 0.0683 (0.0683)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-08 21:52:20 - INFO - TRAINING - Epoch: [27][50/500]	Time 0.081 (0.085)	Data 0.000 (0.005)	Loss 0.1258 (0.0705)	Prec@1 97.000 (97.529)	Prec@5 100.000 (100.000)
2019-05-08 21:52:24 - INFO - TRAINING - Epoch: [27][100/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.1326 (0.0784)	Prec@1 95.000 (97.218)	Prec@5 100.000 (100.000)
2019-05-08 21:52:29 - INFO - TRAINING - Epoch: [27][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0617 (0.0783)	Prec@1 96.000 (97.272)	Prec@5 100.000 (100.000)
2019-05-08 21:52:33 - INFO - TRAINING - Epoch: [27][200/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0641 (0.0792)	Prec@1 99.000 (97.214)	Prec@5 100.000 (100.000)
2019-05-08 21:52:37 - INFO - TRAINING - Epoch: [27][250/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.1032 (0.0809)	Prec@1 96.000 (97.199)	Prec@5 100.000 (99.992)
2019-05-08 21:52:41 - INFO - TRAINING - Epoch: [27][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0400 (0.0795)	Prec@1 99.000 (97.322)	Prec@5 100.000 (99.990)
2019-05-08 21:52:45 - INFO - TRAINING - Epoch: [27][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0999 (0.0794)	Prec@1 96.000 (97.322)	Prec@5 100.000 (99.989)
2019-05-08 21:52:49 - INFO - TRAINING - Epoch: [27][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0366 (0.0801)	Prec@1 99.000 (97.327)	Prec@5 100.000 (99.990)
2019-05-08 21:52:53 - INFO - TRAINING - Epoch: [27][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.2015 (0.0810)	Prec@1 93.000 (97.286)	Prec@5 100.000 (99.989)
2019-05-08 21:52:58 - INFO - EVALUATING - Epoch: [27][0/100]	Time 0.290 (0.290)	Data 0.265 (0.265)	Loss 0.2157 (0.2157)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 21:52:59 - INFO - EVALUATING - Epoch: [27][50/100]	Time 0.039 (0.032)	Data 0.000 (0.005)	Loss 0.1585 (0.3450)	Prec@1 94.000 (90.627)	Prec@5 100.000 (99.569)
2019-05-08 21:53:00 - INFO - 
 Epoch: 28	Training Loss 0.0809 	Training Prec@1 97.282 	Training Prec@5 99.988 	Validation Loss 0.3550 	Validation Prec@1 90.540 	Validation Prec@5 99.630 	
2019-05-08 21:53:00 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:53:00 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:53:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:53:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:53:01 - INFO - TRAINING - Epoch: [28][0/500]	Time 0.251 (0.251)	Data 0.193 (0.193)	Loss 0.0452 (0.0452)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 21:53:05 - INFO - TRAINING - Epoch: [28][50/500]	Time 0.072 (0.083)	Data 0.000 (0.005)	Loss 0.0643 (0.0664)	Prec@1 98.000 (97.686)	Prec@5 100.000 (100.000)
2019-05-08 21:53:09 - INFO - TRAINING - Epoch: [28][100/500]	Time 0.083 (0.082)	Data 0.000 (0.003)	Loss 0.0780 (0.0709)	Prec@1 97.000 (97.594)	Prec@5 100.000 (99.980)
2019-05-08 21:53:13 - INFO - TRAINING - Epoch: [28][150/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.1353 (0.0726)	Prec@1 94.000 (97.490)	Prec@5 100.000 (99.987)
2019-05-08 21:53:17 - INFO - TRAINING - Epoch: [28][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0598 (0.0756)	Prec@1 99.000 (97.438)	Prec@5 100.000 (99.990)
2019-05-08 21:53:21 - INFO - TRAINING - Epoch: [28][250/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0462 (0.0751)	Prec@1 99.000 (97.446)	Prec@5 100.000 (99.992)
2019-05-08 21:53:25 - INFO - TRAINING - Epoch: [28][300/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0656 (0.0755)	Prec@1 97.000 (97.429)	Prec@5 100.000 (99.993)
2019-05-08 21:53:29 - INFO - TRAINING - Epoch: [28][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0310 (0.0752)	Prec@1 99.000 (97.410)	Prec@5 100.000 (99.994)
2019-05-08 21:53:33 - INFO - TRAINING - Epoch: [28][400/500]	Time 0.073 (0.082)	Data 0.000 (0.001)	Loss 0.1047 (0.0761)	Prec@1 98.000 (97.389)	Prec@5 100.000 (99.993)
2019-05-08 21:53:37 - INFO - TRAINING - Epoch: [28][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.1013 (0.0771)	Prec@1 97.000 (97.359)	Prec@5 100.000 (99.989)
2019-05-08 21:53:42 - INFO - EVALUATING - Epoch: [28][0/100]	Time 0.284 (0.284)	Data 0.259 (0.259)	Loss 0.3210 (0.3210)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-08 21:53:43 - INFO - EVALUATING - Epoch: [28][50/100]	Time 0.026 (0.033)	Data 0.001 (0.005)	Loss 0.2304 (0.4174)	Prec@1 95.000 (89.333)	Prec@5 99.000 (99.471)
2019-05-08 21:53:45 - INFO - 
 Epoch: 29	Training Loss 0.0772 	Training Prec@1 97.330 	Training Prec@5 99.990 	Validation Loss 0.4139 	Validation Prec@1 89.440 	Validation Prec@5 99.570 	
2019-05-08 21:53:45 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:53:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:53:45 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:53:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:53:45 - INFO - TRAINING - Epoch: [29][0/500]	Time 0.246 (0.246)	Data 0.202 (0.202)	Loss 0.0416 (0.0416)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 21:53:49 - INFO - TRAINING - Epoch: [29][50/500]	Time 0.082 (0.086)	Data 0.000 (0.005)	Loss 0.0954 (0.0592)	Prec@1 95.000 (97.882)	Prec@5 100.000 (100.000)
2019-05-08 21:53:53 - INFO - TRAINING - Epoch: [29][100/500]	Time 0.085 (0.084)	Data 0.000 (0.003)	Loss 0.0934 (0.0571)	Prec@1 96.000 (98.129)	Prec@5 100.000 (100.000)
2019-05-08 21:53:57 - INFO - TRAINING - Epoch: [29][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0143 (0.0595)	Prec@1 100.000 (97.980)	Prec@5 100.000 (100.000)
2019-05-08 21:54:01 - INFO - TRAINING - Epoch: [29][200/500]	Time 0.096 (0.084)	Data 0.000 (0.002)	Loss 0.0680 (0.0634)	Prec@1 95.000 (97.861)	Prec@5 100.000 (100.000)
2019-05-08 21:54:06 - INFO - TRAINING - Epoch: [29][250/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.1178 (0.0649)	Prec@1 95.000 (97.789)	Prec@5 100.000 (100.000)
2019-05-08 21:54:10 - INFO - TRAINING - Epoch: [29][300/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0903 (0.0680)	Prec@1 98.000 (97.678)	Prec@5 100.000 (100.000)
2019-05-08 21:54:14 - INFO - TRAINING - Epoch: [29][350/500]	Time 0.047 (0.083)	Data 0.000 (0.001)	Loss 0.0819 (0.0694)	Prec@1 98.000 (97.615)	Prec@5 100.000 (99.997)
2019-05-08 21:54:18 - INFO - TRAINING - Epoch: [29][400/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0493 (0.0707)	Prec@1 98.000 (97.574)	Prec@5 100.000 (99.998)
2019-05-08 21:54:22 - INFO - TRAINING - Epoch: [29][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0741 (0.0699)	Prec@1 98.000 (97.612)	Prec@5 100.000 (99.998)
2019-05-08 21:54:26 - INFO - EVALUATING - Epoch: [29][0/100]	Time 0.302 (0.302)	Data 0.265 (0.265)	Loss 0.2618 (0.2618)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 21:54:28 - INFO - EVALUATING - Epoch: [29][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.2378 (0.3356)	Prec@1 94.000 (90.588)	Prec@5 100.000 (99.647)
2019-05-08 21:54:29 - INFO - 
 Epoch: 30	Training Loss 0.0699 	Training Prec@1 97.598 	Training Prec@5 99.998 	Validation Loss 0.3332 	Validation Prec@1 90.810 	Validation Prec@5 99.710 	
2019-05-08 21:54:29 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:54:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:54:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:54:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:54:29 - INFO - TRAINING - Epoch: [30][0/500]	Time 0.242 (0.242)	Data 0.177 (0.177)	Loss 0.0367 (0.0367)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 21:54:34 - INFO - TRAINING - Epoch: [30][50/500]	Time 0.077 (0.085)	Data 0.000 (0.004)	Loss 0.0438 (0.0588)	Prec@1 99.000 (98.020)	Prec@5 100.000 (100.000)
2019-05-08 21:54:38 - INFO - TRAINING - Epoch: [30][100/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.0546 (0.0607)	Prec@1 97.000 (97.950)	Prec@5 100.000 (100.000)
2019-05-08 21:54:42 - INFO - TRAINING - Epoch: [30][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0935 (0.0648)	Prec@1 97.000 (97.841)	Prec@5 100.000 (100.000)
2019-05-08 21:54:46 - INFO - TRAINING - Epoch: [30][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0875 (0.0648)	Prec@1 98.000 (97.856)	Prec@5 100.000 (99.995)
2019-05-08 21:54:50 - INFO - TRAINING - Epoch: [30][250/500]	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 0.0185 (0.0653)	Prec@1 100.000 (97.817)	Prec@5 100.000 (99.996)
2019-05-08 21:54:54 - INFO - TRAINING - Epoch: [30][300/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.1208 (0.0676)	Prec@1 98.000 (97.797)	Prec@5 100.000 (99.990)
2019-05-08 21:54:58 - INFO - TRAINING - Epoch: [30][350/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.1094 (0.0671)	Prec@1 96.000 (97.801)	Prec@5 100.000 (99.991)
2019-05-08 21:55:02 - INFO - TRAINING - Epoch: [30][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0291 (0.0681)	Prec@1 100.000 (97.761)	Prec@5 100.000 (99.990)
2019-05-08 21:55:07 - INFO - TRAINING - Epoch: [30][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0373 (0.0675)	Prec@1 99.000 (97.789)	Prec@5 100.000 (99.991)
2019-05-08 21:55:11 - INFO - EVALUATING - Epoch: [30][0/100]	Time 0.299 (0.299)	Data 0.274 (0.274)	Loss 0.3615 (0.3615)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 21:55:12 - INFO - EVALUATING - Epoch: [30][50/100]	Time 0.026 (0.033)	Data 0.001 (0.006)	Loss 0.2720 (0.3785)	Prec@1 93.000 (90.647)	Prec@5 100.000 (99.510)
2019-05-08 21:55:13 - INFO - 
 Epoch: 31	Training Loss 0.0673 	Training Prec@1 97.782 	Training Prec@5 99.990 	Validation Loss 0.3761 	Validation Prec@1 90.390 	Validation Prec@5 99.620 	
2019-05-08 21:55:14 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:55:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:55:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:55:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:55:14 - INFO - TRAINING - Epoch: [31][0/500]	Time 0.260 (0.260)	Data 0.220 (0.220)	Loss 0.0346 (0.0346)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 21:55:18 - INFO - TRAINING - Epoch: [31][50/500]	Time 0.078 (0.084)	Data 0.000 (0.005)	Loss 0.0312 (0.0563)	Prec@1 100.000 (97.961)	Prec@5 100.000 (100.000)
2019-05-08 21:55:22 - INFO - TRAINING - Epoch: [31][100/500]	Time 0.083 (0.082)	Data 0.000 (0.003)	Loss 0.0218 (0.0558)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 21:55:26 - INFO - TRAINING - Epoch: [31][150/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0883 (0.0608)	Prec@1 97.000 (97.868)	Prec@5 100.000 (100.000)
2019-05-08 21:55:30 - INFO - TRAINING - Epoch: [31][200/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0323 (0.0641)	Prec@1 98.000 (97.711)	Prec@5 100.000 (100.000)
2019-05-08 21:55:34 - INFO - TRAINING - Epoch: [31][250/500]	Time 0.070 (0.082)	Data 0.000 (0.002)	Loss 0.0606 (0.0630)	Prec@1 98.000 (97.801)	Prec@5 100.000 (100.000)
2019-05-08 21:55:38 - INFO - TRAINING - Epoch: [31][300/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0276 (0.0631)	Prec@1 100.000 (97.794)	Prec@5 100.000 (100.000)
2019-05-08 21:55:43 - INFO - TRAINING - Epoch: [31][350/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0450 (0.0642)	Prec@1 99.000 (97.752)	Prec@5 100.000 (99.997)
2019-05-08 21:55:47 - INFO - TRAINING - Epoch: [31][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.1122 (0.0632)	Prec@1 96.000 (97.783)	Prec@5 100.000 (99.998)
2019-05-08 21:55:51 - INFO - TRAINING - Epoch: [31][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.1757 (0.0629)	Prec@1 93.000 (97.812)	Prec@5 100.000 (99.998)
2019-05-08 21:55:55 - INFO - EVALUATING - Epoch: [31][0/100]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.2257 (0.2257)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 21:55:56 - INFO - EVALUATING - Epoch: [31][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.3451 (0.3655)	Prec@1 93.000 (90.961)	Prec@5 99.000 (99.353)
2019-05-08 21:55:58 - INFO - 
 Epoch: 32	Training Loss 0.0628 	Training Prec@1 97.812 	Training Prec@5 99.998 	Validation Loss 0.3620 	Validation Prec@1 90.860 	Validation Prec@5 99.500 	
2019-05-08 21:55:58 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:55:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:55:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:55:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:55:58 - INFO - TRAINING - Epoch: [32][0/500]	Time 0.258 (0.258)	Data 0.215 (0.215)	Loss 0.0422 (0.0422)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 21:56:02 - INFO - TRAINING - Epoch: [32][50/500]	Time 0.086 (0.085)	Data 0.000 (0.005)	Loss 0.0273 (0.0554)	Prec@1 99.000 (98.000)	Prec@5 100.000 (99.980)
2019-05-08 21:56:06 - INFO - TRAINING - Epoch: [32][100/500]	Time 0.085 (0.084)	Data 0.000 (0.003)	Loss 0.1216 (0.0553)	Prec@1 95.000 (98.089)	Prec@5 100.000 (99.990)
2019-05-08 21:56:10 - INFO - TRAINING - Epoch: [32][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0487 (0.0569)	Prec@1 99.000 (98.079)	Prec@5 100.000 (99.987)
2019-05-08 21:56:15 - INFO - TRAINING - Epoch: [32][200/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0302 (0.0571)	Prec@1 99.000 (98.050)	Prec@5 100.000 (99.990)
2019-05-08 21:56:19 - INFO - TRAINING - Epoch: [32][250/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0463 (0.0579)	Prec@1 97.000 (98.020)	Prec@5 100.000 (99.992)
2019-05-08 21:56:23 - INFO - TRAINING - Epoch: [32][300/500]	Time 0.076 (0.083)	Data 0.000 (0.002)	Loss 0.0517 (0.0582)	Prec@1 97.000 (97.963)	Prec@5 100.000 (99.993)
2019-05-08 21:56:27 - INFO - TRAINING - Epoch: [32][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0493 (0.0590)	Prec@1 99.000 (97.960)	Prec@5 100.000 (99.994)
2019-05-08 21:56:31 - INFO - TRAINING - Epoch: [32][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0949 (0.0608)	Prec@1 97.000 (97.920)	Prec@5 100.000 (99.995)
2019-05-08 21:56:35 - INFO - TRAINING - Epoch: [32][450/500]	Time 0.081 (0.082)	Data 0.001 (0.001)	Loss 0.0605 (0.0603)	Prec@1 98.000 (97.949)	Prec@5 100.000 (99.996)
2019-05-08 21:56:39 - INFO - EVALUATING - Epoch: [32][0/100]	Time 0.287 (0.287)	Data 0.260 (0.260)	Loss 0.1712 (0.1712)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 21:56:40 - INFO - EVALUATING - Epoch: [32][50/100]	Time 0.027 (0.032)	Data 0.000 (0.005)	Loss 0.1520 (0.3412)	Prec@1 94.000 (91.196)	Prec@5 100.000 (99.490)
2019-05-08 21:56:42 - INFO - 
 Epoch: 33	Training Loss 0.0601 	Training Prec@1 97.958 	Training Prec@5 99.996 	Validation Loss 0.3313 	Validation Prec@1 91.500 	Validation Prec@5 99.580 	
2019-05-08 21:56:42 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:56:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:56:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:56:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:56:42 - INFO - TRAINING - Epoch: [33][0/500]	Time 0.247 (0.247)	Data 0.204 (0.204)	Loss 0.0705 (0.0705)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-08 21:56:46 - INFO - TRAINING - Epoch: [33][50/500]	Time 0.083 (0.086)	Data 0.000 (0.005)	Loss 0.0475 (0.0507)	Prec@1 99.000 (98.314)	Prec@5 100.000 (100.000)
2019-05-08 21:56:50 - INFO - TRAINING - Epoch: [33][100/500]	Time 0.077 (0.084)	Data 0.000 (0.003)	Loss 0.0500 (0.0515)	Prec@1 98.000 (98.376)	Prec@5 100.000 (100.000)
2019-05-08 21:56:55 - INFO - TRAINING - Epoch: [33][150/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0676 (0.0508)	Prec@1 98.000 (98.411)	Prec@5 100.000 (100.000)
2019-05-08 21:56:59 - INFO - TRAINING - Epoch: [33][200/500]	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 0.0325 (0.0516)	Prec@1 98.000 (98.323)	Prec@5 100.000 (100.000)
2019-05-08 21:57:03 - INFO - TRAINING - Epoch: [33][250/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.1196 (0.0519)	Prec@1 97.000 (98.303)	Prec@5 100.000 (100.000)
2019-05-08 21:57:07 - INFO - TRAINING - Epoch: [33][300/500]	Time 0.063 (0.084)	Data 0.000 (0.002)	Loss 0.0488 (0.0519)	Prec@1 97.000 (98.282)	Prec@5 100.000 (100.000)
2019-05-08 21:57:11 - INFO - TRAINING - Epoch: [33][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0134 (0.0509)	Prec@1 100.000 (98.350)	Prec@5 100.000 (99.997)
2019-05-08 21:57:15 - INFO - TRAINING - Epoch: [33][400/500]	Time 0.072 (0.083)	Data 0.000 (0.001)	Loss 0.0156 (0.0517)	Prec@1 100.000 (98.339)	Prec@5 100.000 (99.998)
2019-05-08 21:57:19 - INFO - TRAINING - Epoch: [33][450/500]	Time 0.076 (0.083)	Data 0.000 (0.001)	Loss 0.0879 (0.0520)	Prec@1 96.000 (98.315)	Prec@5 100.000 (99.998)
2019-05-08 21:57:24 - INFO - EVALUATING - Epoch: [33][0/100]	Time 0.283 (0.283)	Data 0.256 (0.256)	Loss 0.4131 (0.4131)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-05-08 21:57:25 - INFO - EVALUATING - Epoch: [33][50/100]	Time 0.041 (0.032)	Data 0.000 (0.005)	Loss 0.2598 (0.3699)	Prec@1 93.000 (90.902)	Prec@5 100.000 (99.471)
2019-05-08 21:57:26 - INFO - 
 Epoch: 34	Training Loss 0.0532 	Training Prec@1 98.266 	Training Prec@5 99.998 	Validation Loss 0.3552 	Validation Prec@1 90.740 	Validation Prec@5 99.570 	
2019-05-08 21:57:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:57:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:57:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:57:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:57:27 - INFO - TRAINING - Epoch: [34][0/500]	Time 0.249 (0.249)	Data 0.188 (0.188)	Loss 0.0297 (0.0297)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 21:57:31 - INFO - TRAINING - Epoch: [34][50/500]	Time 0.045 (0.086)	Data 0.000 (0.004)	Loss 0.0180 (0.0446)	Prec@1 100.000 (98.627)	Prec@5 100.000 (100.000)
2019-05-08 21:57:35 - INFO - TRAINING - Epoch: [34][100/500]	Time 0.069 (0.084)	Data 0.000 (0.003)	Loss 0.0476 (0.0465)	Prec@1 99.000 (98.525)	Prec@5 100.000 (100.000)
2019-05-08 21:57:39 - INFO - TRAINING - Epoch: [34][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0715 (0.0479)	Prec@1 98.000 (98.424)	Prec@5 100.000 (100.000)
2019-05-08 21:57:43 - INFO - TRAINING - Epoch: [34][200/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0467 (0.0488)	Prec@1 98.000 (98.413)	Prec@5 100.000 (99.995)
2019-05-08 21:57:47 - INFO - TRAINING - Epoch: [34][250/500]	Time 0.055 (0.083)	Data 0.000 (0.002)	Loss 0.0319 (0.0483)	Prec@1 99.000 (98.422)	Prec@5 100.000 (99.992)
2019-05-08 21:57:51 - INFO - TRAINING - Epoch: [34][300/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0362 (0.0476)	Prec@1 98.000 (98.432)	Prec@5 100.000 (99.993)
2019-05-08 21:57:55 - INFO - TRAINING - Epoch: [34][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0508 (0.0472)	Prec@1 99.000 (98.430)	Prec@5 100.000 (99.994)
2019-05-08 21:58:00 - INFO - TRAINING - Epoch: [34][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0447 (0.0484)	Prec@1 99.000 (98.394)	Prec@5 100.000 (99.995)
2019-05-08 21:58:04 - INFO - TRAINING - Epoch: [34][450/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0343 (0.0495)	Prec@1 99.000 (98.355)	Prec@5 100.000 (99.996)
2019-05-08 21:58:08 - INFO - EVALUATING - Epoch: [34][0/100]	Time 0.289 (0.289)	Data 0.265 (0.265)	Loss 0.2336 (0.2336)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 21:58:09 - INFO - EVALUATING - Epoch: [34][50/100]	Time 0.024 (0.033)	Data 0.001 (0.006)	Loss 0.1502 (0.3583)	Prec@1 94.000 (91.000)	Prec@5 100.000 (99.451)
2019-05-08 21:58:11 - INFO - 
 Epoch: 35	Training Loss 0.0496 	Training Prec@1 98.328 	Training Prec@5 99.996 	Validation Loss 0.3325 	Validation Prec@1 91.360 	Validation Prec@5 99.550 	
2019-05-08 21:58:11 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:58:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:58:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:58:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:58:11 - INFO - TRAINING - Epoch: [35][0/500]	Time 0.255 (0.255)	Data 0.189 (0.189)	Loss 0.0124 (0.0124)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 21:58:15 - INFO - TRAINING - Epoch: [35][50/500]	Time 0.085 (0.085)	Data 0.000 (0.005)	Loss 0.0297 (0.0404)	Prec@1 98.000 (98.745)	Prec@5 100.000 (100.000)
2019-05-08 21:58:19 - INFO - TRAINING - Epoch: [35][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0306 (0.0406)	Prec@1 99.000 (98.752)	Prec@5 100.000 (100.000)
2019-05-08 21:58:23 - INFO - TRAINING - Epoch: [35][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0519 (0.0404)	Prec@1 98.000 (98.762)	Prec@5 100.000 (100.000)
2019-05-08 21:58:27 - INFO - TRAINING - Epoch: [35][200/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0143 (0.0428)	Prec@1 100.000 (98.662)	Prec@5 100.000 (100.000)
2019-05-08 21:58:32 - INFO - TRAINING - Epoch: [35][250/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0780 (0.0422)	Prec@1 97.000 (98.633)	Prec@5 100.000 (100.000)
2019-05-08 21:58:36 - INFO - TRAINING - Epoch: [35][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0242 (0.0429)	Prec@1 99.000 (98.605)	Prec@5 100.000 (100.000)
2019-05-08 21:58:40 - INFO - TRAINING - Epoch: [35][350/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0533 (0.0432)	Prec@1 96.000 (98.601)	Prec@5 100.000 (99.997)
2019-05-08 21:58:44 - INFO - TRAINING - Epoch: [35][400/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0342 (0.0449)	Prec@1 98.000 (98.551)	Prec@5 100.000 (99.998)
2019-05-08 21:58:48 - INFO - TRAINING - Epoch: [35][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0507 (0.0458)	Prec@1 99.000 (98.519)	Prec@5 100.000 (99.998)
2019-05-08 21:58:52 - INFO - EVALUATING - Epoch: [35][0/100]	Time 0.305 (0.305)	Data 0.280 (0.280)	Loss 0.1881 (0.1881)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-08 21:58:54 - INFO - EVALUATING - Epoch: [35][50/100]	Time 0.022 (0.031)	Data 0.000 (0.006)	Loss 0.1684 (0.3401)	Prec@1 95.000 (91.569)	Prec@5 100.000 (99.510)
2019-05-08 21:58:55 - INFO - 
 Epoch: 36	Training Loss 0.0464 	Training Prec@1 98.494 	Training Prec@5 99.998 	Validation Loss 0.3406 	Validation Prec@1 91.460 	Validation Prec@5 99.680 	
2019-05-08 21:58:55 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:58:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:58:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:58:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:58:55 - INFO - TRAINING - Epoch: [36][0/500]	Time 0.254 (0.254)	Data 0.190 (0.190)	Loss 0.0425 (0.0425)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 21:58:59 - INFO - TRAINING - Epoch: [36][50/500]	Time 0.083 (0.081)	Data 0.000 (0.004)	Loss 0.0474 (0.0378)	Prec@1 99.000 (98.843)	Prec@5 100.000 (100.000)
2019-05-08 21:59:03 - INFO - TRAINING - Epoch: [36][100/500]	Time 0.089 (0.082)	Data 0.000 (0.003)	Loss 0.0112 (0.0403)	Prec@1 100.000 (98.723)	Prec@5 100.000 (100.000)
2019-05-08 21:59:08 - INFO - TRAINING - Epoch: [36][150/500]	Time 0.078 (0.082)	Data 0.000 (0.002)	Loss 0.0218 (0.0416)	Prec@1 100.000 (98.728)	Prec@5 100.000 (100.000)
2019-05-08 21:59:12 - INFO - TRAINING - Epoch: [36][200/500]	Time 0.054 (0.082)	Data 0.001 (0.002)	Loss 0.0134 (0.0432)	Prec@1 100.000 (98.667)	Prec@5 100.000 (100.000)
2019-05-08 21:59:16 - INFO - TRAINING - Epoch: [36][250/500]	Time 0.071 (0.082)	Data 0.000 (0.002)	Loss 0.0361 (0.0433)	Prec@1 99.000 (98.629)	Prec@5 100.000 (100.000)
2019-05-08 21:59:20 - INFO - TRAINING - Epoch: [36][300/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0547 (0.0442)	Prec@1 98.000 (98.591)	Prec@5 100.000 (99.997)
2019-05-08 21:59:24 - INFO - TRAINING - Epoch: [36][350/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0934 (0.0461)	Prec@1 97.000 (98.533)	Prec@5 100.000 (99.994)
2019-05-08 21:59:28 - INFO - TRAINING - Epoch: [36][400/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0740 (0.0459)	Prec@1 98.000 (98.516)	Prec@5 100.000 (99.995)
2019-05-08 21:59:32 - INFO - TRAINING - Epoch: [36][450/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0580 (0.0447)	Prec@1 98.000 (98.550)	Prec@5 100.000 (99.996)
2019-05-08 21:59:37 - INFO - EVALUATING - Epoch: [36][0/100]	Time 0.310 (0.310)	Data 0.260 (0.260)	Loss 0.2474 (0.2474)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 21:59:38 - INFO - EVALUATING - Epoch: [36][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.2436 (0.3450)	Prec@1 92.000 (91.549)	Prec@5 100.000 (99.529)
2019-05-08 21:59:39 - INFO - 
 Epoch: 37	Training Loss 0.0442 	Training Prec@1 98.578 	Training Prec@5 99.996 	Validation Loss 0.3409 	Validation Prec@1 91.500 	Validation Prec@5 99.630 	
2019-05-08 21:59:39 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 21:59:39 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 21:59:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 21:59:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 21:59:40 - INFO - TRAINING - Epoch: [37][0/500]	Time 0.257 (0.257)	Data 0.194 (0.194)	Loss 0.0496 (0.0496)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 21:59:44 - INFO - TRAINING - Epoch: [37][50/500]	Time 0.080 (0.086)	Data 0.000 (0.005)	Loss 0.0433 (0.0351)	Prec@1 99.000 (98.784)	Prec@5 100.000 (100.000)
2019-05-08 21:59:48 - INFO - TRAINING - Epoch: [37][100/500]	Time 0.078 (0.083)	Data 0.000 (0.003)	Loss 0.0427 (0.0364)	Prec@1 98.000 (98.743)	Prec@5 100.000 (100.000)
2019-05-08 21:59:52 - INFO - TRAINING - Epoch: [37][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0180 (0.0372)	Prec@1 100.000 (98.735)	Prec@5 100.000 (100.000)
2019-05-08 21:59:56 - INFO - TRAINING - Epoch: [37][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0214 (0.0363)	Prec@1 100.000 (98.781)	Prec@5 100.000 (100.000)
2019-05-08 22:00:00 - INFO - TRAINING - Epoch: [37][250/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0184 (0.0376)	Prec@1 100.000 (98.725)	Prec@5 100.000 (100.000)
2019-05-08 22:00:04 - INFO - TRAINING - Epoch: [37][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0358 (0.0390)	Prec@1 98.000 (98.658)	Prec@5 100.000 (100.000)
2019-05-08 22:00:09 - INFO - TRAINING - Epoch: [37][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.1022 (0.0407)	Prec@1 96.000 (98.604)	Prec@5 100.000 (100.000)
2019-05-08 22:00:13 - INFO - TRAINING - Epoch: [37][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0584 (0.0425)	Prec@1 98.000 (98.544)	Prec@5 100.000 (100.000)
2019-05-08 22:00:17 - INFO - TRAINING - Epoch: [37][450/500]	Time 0.054 (0.083)	Data 0.001 (0.001)	Loss 0.0535 (0.0425)	Prec@1 98.000 (98.561)	Prec@5 100.000 (100.000)
2019-05-08 22:00:21 - INFO - EVALUATING - Epoch: [37][0/100]	Time 0.322 (0.322)	Data 0.269 (0.269)	Loss 0.2458 (0.2458)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 22:00:22 - INFO - EVALUATING - Epoch: [37][50/100]	Time 0.028 (0.033)	Data 0.000 (0.006)	Loss 0.1417 (0.3793)	Prec@1 94.000 (91.118)	Prec@5 100.000 (99.529)
2019-05-08 22:00:24 - INFO - 
 Epoch: 38	Training Loss 0.0426 	Training Prec@1 98.566 	Training Prec@5 99.996 	Validation Loss 0.3727 	Validation Prec@1 90.760 	Validation Prec@5 99.620 	
2019-05-08 22:00:24 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:00:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:00:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:00:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:00:24 - INFO - TRAINING - Epoch: [38][0/500]	Time 0.266 (0.266)	Data 0.199 (0.199)	Loss 0.0422 (0.0422)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:00:28 - INFO - TRAINING - Epoch: [38][50/500]	Time 0.086 (0.086)	Data 0.000 (0.005)	Loss 0.0088 (0.0427)	Prec@1 100.000 (98.588)	Prec@5 100.000 (100.000)
2019-05-08 22:00:32 - INFO - TRAINING - Epoch: [38][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.0250 (0.0393)	Prec@1 99.000 (98.634)	Prec@5 100.000 (100.000)
2019-05-08 22:00:36 - INFO - TRAINING - Epoch: [38][150/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0122 (0.0378)	Prec@1 100.000 (98.748)	Prec@5 100.000 (100.000)
2019-05-08 22:00:40 - INFO - TRAINING - Epoch: [38][200/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0118 (0.0382)	Prec@1 100.000 (98.726)	Prec@5 100.000 (100.000)
2019-05-08 22:00:44 - INFO - TRAINING - Epoch: [38][250/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0632 (0.0386)	Prec@1 98.000 (98.721)	Prec@5 100.000 (100.000)
2019-05-08 22:00:48 - INFO - TRAINING - Epoch: [38][300/500]	Time 0.090 (0.082)	Data 0.000 (0.002)	Loss 0.1501 (0.0388)	Prec@1 95.000 (98.711)	Prec@5 100.000 (100.000)
2019-05-08 22:00:52 - INFO - TRAINING - Epoch: [38][350/500]	Time 0.091 (0.082)	Data 0.000 (0.001)	Loss 0.0349 (0.0397)	Prec@1 99.000 (98.664)	Prec@5 100.000 (100.000)
2019-05-08 22:00:57 - INFO - TRAINING - Epoch: [38][400/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0225 (0.0413)	Prec@1 99.000 (98.601)	Prec@5 100.000 (100.000)
2019-05-08 22:01:01 - INFO - TRAINING - Epoch: [38][450/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0968 (0.0417)	Prec@1 95.000 (98.601)	Prec@5 100.000 (100.000)
2019-05-08 22:01:06 - INFO - EVALUATING - Epoch: [38][0/100]	Time 0.801 (0.801)	Data 0.244 (0.244)	Loss 0.2641 (0.2641)	Prec@1 94.000 (94.000)	Prec@5 98.000 (98.000)
2019-05-08 22:01:07 - INFO - EVALUATING - Epoch: [38][50/100]	Time 0.025 (0.044)	Data 0.000 (0.006)	Loss 0.1624 (0.3494)	Prec@1 94.000 (91.235)	Prec@5 100.000 (99.529)
2019-05-08 22:01:09 - INFO - 
 Epoch: 39	Training Loss 0.0421 	Training Prec@1 98.574 	Training Prec@5 100.000 	Validation Loss 0.3302 	Validation Prec@1 91.360 	Validation Prec@5 99.660 	
2019-05-08 22:01:09 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:01:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:01:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:01:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:01:09 - INFO - TRAINING - Epoch: [39][0/500]	Time 0.261 (0.261)	Data 0.220 (0.220)	Loss 0.0250 (0.0250)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:01:13 - INFO - TRAINING - Epoch: [39][50/500]	Time 0.084 (0.088)	Data 0.000 (0.005)	Loss 0.0106 (0.0428)	Prec@1 100.000 (98.627)	Prec@5 100.000 (100.000)
2019-05-08 22:01:18 - INFO - TRAINING - Epoch: [39][100/500]	Time 0.085 (0.086)	Data 0.000 (0.003)	Loss 0.0237 (0.0400)	Prec@1 99.000 (98.812)	Prec@5 100.000 (100.000)
2019-05-08 22:01:22 - INFO - TRAINING - Epoch: [39][150/500]	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 0.0566 (0.0377)	Prec@1 99.000 (98.848)	Prec@5 100.000 (100.000)
2019-05-08 22:01:26 - INFO - TRAINING - Epoch: [39][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0587 (0.0376)	Prec@1 97.000 (98.826)	Prec@5 100.000 (100.000)
2019-05-08 22:01:30 - INFO - TRAINING - Epoch: [39][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0175 (0.0376)	Prec@1 100.000 (98.805)	Prec@5 100.000 (100.000)
2019-05-08 22:01:34 - INFO - TRAINING - Epoch: [39][300/500]	Time 0.074 (0.084)	Data 0.001 (0.002)	Loss 0.0238 (0.0377)	Prec@1 99.000 (98.784)	Prec@5 100.000 (100.000)
2019-05-08 22:01:38 - INFO - TRAINING - Epoch: [39][350/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0234 (0.0390)	Prec@1 99.000 (98.738)	Prec@5 100.000 (100.000)
2019-05-08 22:01:42 - INFO - TRAINING - Epoch: [39][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0382 (0.0387)	Prec@1 98.000 (98.738)	Prec@5 100.000 (100.000)
2019-05-08 22:01:46 - INFO - TRAINING - Epoch: [39][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0111 (0.0394)	Prec@1 100.000 (98.736)	Prec@5 100.000 (100.000)
2019-05-08 22:01:51 - INFO - EVALUATING - Epoch: [39][0/100]	Time 0.328 (0.328)	Data 0.284 (0.284)	Loss 0.2837 (0.2837)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:01:52 - INFO - EVALUATING - Epoch: [39][50/100]	Time 0.025 (0.033)	Data 0.000 (0.006)	Loss 0.2164 (0.3817)	Prec@1 93.000 (91.059)	Prec@5 99.000 (99.471)
2019-05-08 22:01:53 - INFO - 
 Epoch: 40	Training Loss 0.0404 	Training Prec@1 98.702 	Training Prec@5 100.000 	Validation Loss 0.3656 	Validation Prec@1 91.240 	Validation Prec@5 99.520 	
2019-05-08 22:01:54 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:01:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:01:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:01:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:01:54 - INFO - TRAINING - Epoch: [40][0/500]	Time 0.294 (0.294)	Data 0.223 (0.223)	Loss 0.0124 (0.0124)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:01:58 - INFO - TRAINING - Epoch: [40][50/500]	Time 0.083 (0.086)	Data 0.000 (0.005)	Loss 0.0444 (0.0364)	Prec@1 98.000 (98.863)	Prec@5 100.000 (99.980)
2019-05-08 22:02:02 - INFO - TRAINING - Epoch: [40][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0222 (0.0300)	Prec@1 99.000 (99.149)	Prec@5 100.000 (99.990)
2019-05-08 22:02:06 - INFO - TRAINING - Epoch: [40][150/500]	Time 0.051 (0.084)	Data 0.001 (0.002)	Loss 0.0133 (0.0318)	Prec@1 100.000 (98.993)	Prec@5 100.000 (99.993)
2019-05-08 22:02:10 - INFO - TRAINING - Epoch: [40][200/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0769 (0.0321)	Prec@1 98.000 (98.980)	Prec@5 100.000 (99.995)
2019-05-08 22:02:14 - INFO - TRAINING - Epoch: [40][250/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0153 (0.0337)	Prec@1 100.000 (98.873)	Prec@5 100.000 (99.996)
2019-05-08 22:02:19 - INFO - TRAINING - Epoch: [40][300/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0395 (0.0342)	Prec@1 98.000 (98.850)	Prec@5 100.000 (99.997)
2019-05-08 22:02:23 - INFO - TRAINING - Epoch: [40][350/500]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.0377 (0.0343)	Prec@1 97.000 (98.832)	Prec@5 100.000 (99.997)
2019-05-08 22:02:27 - INFO - TRAINING - Epoch: [40][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0190 (0.0347)	Prec@1 99.000 (98.800)	Prec@5 100.000 (99.998)
2019-05-08 22:02:31 - INFO - TRAINING - Epoch: [40][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0252 (0.0347)	Prec@1 99.000 (98.807)	Prec@5 100.000 (99.998)
2019-05-08 22:02:35 - INFO - EVALUATING - Epoch: [40][0/100]	Time 0.280 (0.280)	Data 0.253 (0.253)	Loss 0.3143 (0.3143)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-08 22:02:37 - INFO - EVALUATING - Epoch: [40][50/100]	Time 0.030 (0.033)	Data 0.000 (0.005)	Loss 0.2575 (0.3808)	Prec@1 93.000 (91.255)	Prec@5 100.000 (99.431)
2019-05-08 22:02:38 - INFO - 
 Epoch: 41	Training Loss 0.0359 	Training Prec@1 98.756 	Training Prec@5 99.998 	Validation Loss 0.3696 	Validation Prec@1 91.320 	Validation Prec@5 99.530 	
2019-05-08 22:02:38 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:02:38 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:02:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:02:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:02:39 - INFO - TRAINING - Epoch: [41][0/500]	Time 0.262 (0.262)	Data 0.202 (0.202)	Loss 0.0331 (0.0331)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:02:43 - INFO - TRAINING - Epoch: [41][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0266 (0.0323)	Prec@1 99.000 (98.902)	Prec@5 100.000 (100.000)
2019-05-08 22:02:47 - INFO - TRAINING - Epoch: [41][100/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.0101 (0.0306)	Prec@1 100.000 (98.970)	Prec@5 100.000 (100.000)
2019-05-08 22:02:51 - INFO - TRAINING - Epoch: [41][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0332 (0.0330)	Prec@1 99.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-08 22:02:55 - INFO - TRAINING - Epoch: [41][200/500]	Time 0.074 (0.082)	Data 0.000 (0.002)	Loss 0.0185 (0.0361)	Prec@1 99.000 (98.796)	Prec@5 100.000 (100.000)
2019-05-08 22:02:59 - INFO - TRAINING - Epoch: [41][250/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.1111 (0.0356)	Prec@1 95.000 (98.769)	Prec@5 100.000 (100.000)
2019-05-08 22:03:03 - INFO - TRAINING - Epoch: [41][300/500]	Time 0.051 (0.082)	Data 0.001 (0.002)	Loss 0.0524 (0.0365)	Prec@1 99.000 (98.734)	Prec@5 100.000 (100.000)
2019-05-08 22:03:07 - INFO - TRAINING - Epoch: [41][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0139 (0.0359)	Prec@1 100.000 (98.761)	Prec@5 100.000 (100.000)
2019-05-08 22:03:11 - INFO - TRAINING - Epoch: [41][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0714 (0.0361)	Prec@1 98.000 (98.761)	Prec@5 100.000 (100.000)
2019-05-08 22:03:15 - INFO - TRAINING - Epoch: [41][450/500]	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 0.0834 (0.0356)	Prec@1 97.000 (98.776)	Prec@5 100.000 (100.000)
2019-05-08 22:03:19 - INFO - EVALUATING - Epoch: [41][0/100]	Time 0.276 (0.276)	Data 0.252 (0.252)	Loss 0.2958 (0.2958)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:03:21 - INFO - EVALUATING - Epoch: [41][50/100]	Time 0.036 (0.032)	Data 0.000 (0.005)	Loss 0.2875 (0.3547)	Prec@1 92.000 (91.490)	Prec@5 100.000 (99.451)
2019-05-08 22:03:22 - INFO - 
 Epoch: 42	Training Loss 0.0359 	Training Prec@1 98.758 	Training Prec@5 100.000 	Validation Loss 0.3523 	Validation Prec@1 91.320 	Validation Prec@5 99.560 	
2019-05-08 22:03:22 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:03:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:03:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:03:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:03:22 - INFO - TRAINING - Epoch: [42][0/500]	Time 0.262 (0.262)	Data 0.204 (0.204)	Loss 0.0278 (0.0278)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:03:26 - INFO - TRAINING - Epoch: [42][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.0633 (0.0441)	Prec@1 97.000 (98.588)	Prec@5 100.000 (100.000)
2019-05-08 22:03:30 - INFO - TRAINING - Epoch: [42][100/500]	Time 0.081 (0.082)	Data 0.000 (0.003)	Loss 0.0263 (0.0391)	Prec@1 100.000 (98.772)	Prec@5 100.000 (100.000)
2019-05-08 22:03:34 - INFO - TRAINING - Epoch: [42][150/500]	Time 0.082 (0.081)	Data 0.000 (0.002)	Loss 0.0148 (0.0362)	Prec@1 99.000 (98.834)	Prec@5 100.000 (100.000)
2019-05-08 22:03:38 - INFO - TRAINING - Epoch: [42][200/500]	Time 0.084 (0.081)	Data 0.000 (0.002)	Loss 0.0113 (0.0340)	Prec@1 100.000 (98.905)	Prec@5 100.000 (100.000)
2019-05-08 22:03:43 - INFO - TRAINING - Epoch: [42][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0236 (0.0330)	Prec@1 99.000 (98.932)	Prec@5 100.000 (100.000)
2019-05-08 22:03:47 - INFO - TRAINING - Epoch: [42][300/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0693 (0.0343)	Prec@1 98.000 (98.904)	Prec@5 100.000 (100.000)
2019-05-08 22:03:51 - INFO - TRAINING - Epoch: [42][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0384 (0.0348)	Prec@1 99.000 (98.880)	Prec@5 100.000 (100.000)
2019-05-08 22:03:55 - INFO - TRAINING - Epoch: [42][400/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0802 (0.0355)	Prec@1 97.000 (98.838)	Prec@5 100.000 (100.000)
2019-05-08 22:03:59 - INFO - TRAINING - Epoch: [42][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0289 (0.0364)	Prec@1 99.000 (98.803)	Prec@5 100.000 (100.000)
2019-05-08 22:04:03 - INFO - EVALUATING - Epoch: [42][0/100]	Time 0.280 (0.280)	Data 0.254 (0.254)	Loss 0.2186 (0.2186)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:04:05 - INFO - EVALUATING - Epoch: [42][50/100]	Time 0.028 (0.031)	Data 0.000 (0.005)	Loss 0.1320 (0.3485)	Prec@1 96.000 (91.824)	Prec@5 100.000 (99.490)
2019-05-08 22:04:06 - INFO - 
 Epoch: 43	Training Loss 0.0364 	Training Prec@1 98.818 	Training Prec@5 100.000 	Validation Loss 0.3468 	Validation Prec@1 91.710 	Validation Prec@5 99.610 	
2019-05-08 22:04:06 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:04:06 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:04:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:04:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:04:06 - INFO - TRAINING - Epoch: [43][0/500]	Time 0.264 (0.264)	Data 0.221 (0.221)	Loss 0.0458 (0.0458)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:04:11 - INFO - TRAINING - Epoch: [43][50/500]	Time 0.087 (0.086)	Data 0.000 (0.005)	Loss 0.0896 (0.0385)	Prec@1 98.000 (98.941)	Prec@5 100.000 (100.000)
2019-05-08 22:04:15 - INFO - TRAINING - Epoch: [43][100/500]	Time 0.070 (0.084)	Data 0.000 (0.003)	Loss 0.0287 (0.0345)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:04:19 - INFO - TRAINING - Epoch: [43][150/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0840 (0.0338)	Prec@1 97.000 (99.026)	Prec@5 100.000 (100.000)
2019-05-08 22:04:23 - INFO - TRAINING - Epoch: [43][200/500]	Time 0.071 (0.083)	Data 0.000 (0.002)	Loss 0.0460 (0.0339)	Prec@1 98.000 (98.995)	Prec@5 100.000 (100.000)
2019-05-08 22:04:27 - INFO - TRAINING - Epoch: [43][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0108 (0.0352)	Prec@1 100.000 (98.928)	Prec@5 100.000 (100.000)
2019-05-08 22:04:31 - INFO - TRAINING - Epoch: [43][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0418 (0.0355)	Prec@1 98.000 (98.897)	Prec@5 100.000 (100.000)
2019-05-08 22:04:35 - INFO - TRAINING - Epoch: [43][350/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0294 (0.0353)	Prec@1 99.000 (98.897)	Prec@5 100.000 (100.000)
2019-05-08 22:04:39 - INFO - TRAINING - Epoch: [43][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0259 (0.0347)	Prec@1 99.000 (98.898)	Prec@5 100.000 (100.000)
2019-05-08 22:04:43 - INFO - TRAINING - Epoch: [43][450/500]	Time 0.047 (0.083)	Data 0.000 (0.001)	Loss 0.0237 (0.0340)	Prec@1 99.000 (98.920)	Prec@5 100.000 (100.000)
2019-05-08 22:04:48 - INFO - EVALUATING - Epoch: [43][0/100]	Time 0.229 (0.229)	Data 0.186 (0.186)	Loss 0.2561 (0.2561)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-05-08 22:04:49 - INFO - EVALUATING - Epoch: [43][50/100]	Time 0.022 (0.031)	Data 0.000 (0.004)	Loss 0.1855 (0.3537)	Prec@1 95.000 (91.804)	Prec@5 100.000 (99.392)
2019-05-08 22:04:50 - INFO - 
 Epoch: 44	Training Loss 0.0337 	Training Prec@1 98.914 	Training Prec@5 100.000 	Validation Loss 0.3571 	Validation Prec@1 91.560 	Validation Prec@5 99.560 	
2019-05-08 22:04:50 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:04:50 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:04:50 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:04:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:04:51 - INFO - TRAINING - Epoch: [44][0/500]	Time 0.233 (0.233)	Data 0.178 (0.178)	Loss 0.0288 (0.0288)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:04:55 - INFO - TRAINING - Epoch: [44][50/500]	Time 0.085 (0.086)	Data 0.000 (0.004)	Loss 0.0316 (0.0339)	Prec@1 99.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-08 22:04:59 - INFO - TRAINING - Epoch: [44][100/500]	Time 0.082 (0.083)	Data 0.000 (0.003)	Loss 0.0208 (0.0387)	Prec@1 99.000 (98.822)	Prec@5 100.000 (100.000)
2019-05-08 22:05:03 - INFO - TRAINING - Epoch: [44][150/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0127 (0.0357)	Prec@1 100.000 (98.947)	Prec@5 100.000 (100.000)
2019-05-08 22:05:07 - INFO - TRAINING - Epoch: [44][200/500]	Time 0.093 (0.082)	Data 0.000 (0.002)	Loss 0.0313 (0.0330)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:05:11 - INFO - TRAINING - Epoch: [44][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0059 (0.0327)	Prec@1 100.000 (98.992)	Prec@5 100.000 (100.000)
2019-05-08 22:05:15 - INFO - TRAINING - Epoch: [44][300/500]	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 0.0185 (0.0326)	Prec@1 99.000 (98.987)	Prec@5 100.000 (100.000)
2019-05-08 22:05:20 - INFO - TRAINING - Epoch: [44][350/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0063 (0.0324)	Prec@1 100.000 (98.986)	Prec@5 100.000 (100.000)
2019-05-08 22:05:23 - INFO - TRAINING - Epoch: [44][400/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0200 (0.0325)	Prec@1 99.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-08 22:05:28 - INFO - TRAINING - Epoch: [44][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0738 (0.0332)	Prec@1 97.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-08 22:05:32 - INFO - EVALUATING - Epoch: [44][0/100]	Time 0.297 (0.297)	Data 0.272 (0.272)	Loss 0.2892 (0.2892)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:05:33 - INFO - EVALUATING - Epoch: [44][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1512 (0.3660)	Prec@1 96.000 (91.765)	Prec@5 100.000 (99.451)
2019-05-08 22:05:35 - INFO - 
 Epoch: 45	Training Loss 0.0331 	Training Prec@1 98.964 	Training Prec@5 100.000 	Validation Loss 0.3450 	Validation Prec@1 91.820 	Validation Prec@5 99.630 	
2019-05-08 22:05:35 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:05:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:05:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:05:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:05:35 - INFO - TRAINING - Epoch: [45][0/500]	Time 0.252 (0.252)	Data 0.190 (0.190)	Loss 0.0636 (0.0636)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:05:39 - INFO - TRAINING - Epoch: [45][50/500]	Time 0.079 (0.086)	Data 0.000 (0.005)	Loss 0.0296 (0.0292)	Prec@1 99.000 (98.941)	Prec@5 100.000 (100.000)
2019-05-08 22:05:43 - INFO - TRAINING - Epoch: [45][100/500]	Time 0.077 (0.084)	Data 0.000 (0.003)	Loss 0.0131 (0.0266)	Prec@1 100.000 (99.059)	Prec@5 100.000 (100.000)
2019-05-08 22:05:48 - INFO - TRAINING - Epoch: [45][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0274 (0.0272)	Prec@1 99.000 (99.046)	Prec@5 100.000 (100.000)
2019-05-08 22:05:52 - INFO - TRAINING - Epoch: [45][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0104 (0.0258)	Prec@1 100.000 (99.129)	Prec@5 100.000 (100.000)
2019-05-08 22:05:56 - INFO - TRAINING - Epoch: [45][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0705 (0.0259)	Prec@1 97.000 (99.131)	Prec@5 100.000 (100.000)
2019-05-08 22:06:00 - INFO - TRAINING - Epoch: [45][300/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0361 (0.0260)	Prec@1 98.000 (99.133)	Prec@5 100.000 (100.000)
2019-05-08 22:06:04 - INFO - TRAINING - Epoch: [45][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0991 (0.0261)	Prec@1 99.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-08 22:06:08 - INFO - TRAINING - Epoch: [45][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0044 (0.0263)	Prec@1 100.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-08 22:06:12 - INFO - TRAINING - Epoch: [45][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0125 (0.0259)	Prec@1 100.000 (99.153)	Prec@5 100.000 (100.000)
2019-05-08 22:06:16 - INFO - EVALUATING - Epoch: [45][0/100]	Time 0.324 (0.324)	Data 0.276 (0.276)	Loss 0.4036 (0.4036)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:06:18 - INFO - EVALUATING - Epoch: [45][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.4632 (0.3843)	Prec@1 92.000 (91.118)	Prec@5 100.000 (99.569)
2019-05-08 22:06:19 - INFO - 
 Epoch: 46	Training Loss 0.0266 	Training Prec@1 99.104 	Training Prec@5 100.000 	Validation Loss 0.3779 	Validation Prec@1 91.350 	Validation Prec@5 99.680 	
2019-05-08 22:06:19 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:06:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:06:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:06:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:06:19 - INFO - TRAINING - Epoch: [46][0/500]	Time 0.264 (0.264)	Data 0.222 (0.222)	Loss 0.0430 (0.0430)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:06:24 - INFO - TRAINING - Epoch: [46][50/500]	Time 0.080 (0.086)	Data 0.000 (0.005)	Loss 0.0227 (0.0210)	Prec@1 99.000 (99.431)	Prec@5 100.000 (100.000)
2019-05-08 22:06:28 - INFO - TRAINING - Epoch: [46][100/500]	Time 0.088 (0.085)	Data 0.000 (0.003)	Loss 0.0316 (0.0222)	Prec@1 98.000 (99.386)	Prec@5 100.000 (100.000)
2019-05-08 22:06:32 - INFO - TRAINING - Epoch: [46][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0025 (0.0228)	Prec@1 100.000 (99.325)	Prec@5 100.000 (100.000)
2019-05-08 22:06:36 - INFO - TRAINING - Epoch: [46][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0128 (0.0234)	Prec@1 99.000 (99.284)	Prec@5 100.000 (100.000)
2019-05-08 22:06:40 - INFO - TRAINING - Epoch: [46][250/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0863 (0.0234)	Prec@1 98.000 (99.287)	Prec@5 100.000 (100.000)
2019-05-08 22:06:44 - INFO - TRAINING - Epoch: [46][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0193 (0.0237)	Prec@1 99.000 (99.262)	Prec@5 100.000 (100.000)
2019-05-08 22:06:49 - INFO - TRAINING - Epoch: [46][350/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0090 (0.0233)	Prec@1 100.000 (99.274)	Prec@5 100.000 (100.000)
2019-05-08 22:06:53 - INFO - TRAINING - Epoch: [46][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0248 (0.0230)	Prec@1 99.000 (99.264)	Prec@5 100.000 (100.000)
2019-05-08 22:06:57 - INFO - TRAINING - Epoch: [46][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0077 (0.0235)	Prec@1 100.000 (99.244)	Prec@5 100.000 (100.000)
2019-05-08 22:07:01 - INFO - EVALUATING - Epoch: [46][0/100]	Time 0.326 (0.326)	Data 0.278 (0.278)	Loss 0.1671 (0.1671)	Prec@1 96.000 (96.000)	Prec@5 99.000 (99.000)
2019-05-08 22:07:03 - INFO - EVALUATING - Epoch: [46][50/100]	Time 0.025 (0.033)	Data 0.000 (0.006)	Loss 0.1578 (0.3917)	Prec@1 96.000 (91.529)	Prec@5 100.000 (99.275)
2019-05-08 22:07:04 - INFO - 
 Epoch: 47	Training Loss 0.0243 	Training Prec@1 99.216 	Training Prec@5 100.000 	Validation Loss 0.3776 	Validation Prec@1 91.740 	Validation Prec@5 99.450 	
2019-05-08 22:07:04 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:07:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:07:04 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:07:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:07:04 - INFO - TRAINING - Epoch: [47][0/500]	Time 0.256 (0.256)	Data 0.200 (0.200)	Loss 0.0340 (0.0340)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:07:08 - INFO - TRAINING - Epoch: [47][50/500]	Time 0.086 (0.087)	Data 0.000 (0.005)	Loss 0.0253 (0.0221)	Prec@1 99.000 (99.353)	Prec@5 100.000 (100.000)
2019-05-08 22:07:13 - INFO - TRAINING - Epoch: [47][100/500]	Time 0.069 (0.084)	Data 0.000 (0.003)	Loss 0.0080 (0.0242)	Prec@1 100.000 (99.238)	Prec@5 100.000 (100.000)
2019-05-08 22:07:17 - INFO - TRAINING - Epoch: [47][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0597 (0.0257)	Prec@1 98.000 (99.172)	Prec@5 100.000 (100.000)
2019-05-08 22:07:21 - INFO - TRAINING - Epoch: [47][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0376 (0.0257)	Prec@1 97.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-08 22:07:25 - INFO - TRAINING - Epoch: [47][250/500]	Time 0.070 (0.083)	Data 0.000 (0.002)	Loss 0.0102 (0.0265)	Prec@1 99.000 (99.120)	Prec@5 100.000 (100.000)
2019-05-08 22:07:29 - INFO - TRAINING - Epoch: [47][300/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0202 (0.0294)	Prec@1 100.000 (99.033)	Prec@5 100.000 (100.000)
2019-05-08 22:07:33 - INFO - TRAINING - Epoch: [47][350/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0058 (0.0300)	Prec@1 100.000 (99.014)	Prec@5 100.000 (100.000)
2019-05-08 22:07:37 - INFO - TRAINING - Epoch: [47][400/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0150 (0.0296)	Prec@1 99.000 (99.027)	Prec@5 100.000 (100.000)
2019-05-08 22:07:41 - INFO - TRAINING - Epoch: [47][450/500]	Time 0.078 (0.082)	Data 0.000 (0.001)	Loss 0.0389 (0.0300)	Prec@1 98.000 (99.004)	Prec@5 100.000 (100.000)
2019-05-08 22:07:45 - INFO - EVALUATING - Epoch: [47][0/100]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.4759 (0.4759)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-08 22:07:47 - INFO - EVALUATING - Epoch: [47][50/100]	Time 0.026 (0.031)	Data 0.001 (0.005)	Loss 0.2932 (0.4158)	Prec@1 90.000 (90.627)	Prec@5 100.000 (99.431)
2019-05-08 22:07:48 - INFO - 
 Epoch: 48	Training Loss 0.0300 	Training Prec@1 98.998 	Training Prec@5 100.000 	Validation Loss 0.3867 	Validation Prec@1 90.900 	Validation Prec@5 99.600 	
2019-05-08 22:07:48 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:07:48 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:07:48 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:07:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:07:48 - INFO - TRAINING - Epoch: [48][0/500]	Time 0.231 (0.231)	Data 0.189 (0.189)	Loss 0.0111 (0.0111)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:07:53 - INFO - TRAINING - Epoch: [48][50/500]	Time 0.085 (0.086)	Data 0.000 (0.005)	Loss 0.0135 (0.0261)	Prec@1 100.000 (99.275)	Prec@5 100.000 (100.000)
2019-05-08 22:07:57 - INFO - TRAINING - Epoch: [48][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0047 (0.0238)	Prec@1 100.000 (99.287)	Prec@5 100.000 (100.000)
2019-05-08 22:08:01 - INFO - TRAINING - Epoch: [48][150/500]	Time 0.078 (0.084)	Data 0.000 (0.002)	Loss 0.0083 (0.0219)	Prec@1 100.000 (99.331)	Prec@5 100.000 (100.000)
2019-05-08 22:08:05 - INFO - TRAINING - Epoch: [48][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0420 (0.0226)	Prec@1 99.000 (99.303)	Prec@5 100.000 (100.000)
2019-05-08 22:08:09 - INFO - TRAINING - Epoch: [48][250/500]	Time 0.071 (0.083)	Data 0.000 (0.002)	Loss 0.0773 (0.0234)	Prec@1 97.000 (99.271)	Prec@5 100.000 (100.000)
2019-05-08 22:08:13 - INFO - TRAINING - Epoch: [48][300/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0206 (0.0235)	Prec@1 99.000 (99.252)	Prec@5 100.000 (100.000)
2019-05-08 22:08:17 - INFO - TRAINING - Epoch: [48][350/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0062 (0.0231)	Prec@1 100.000 (99.265)	Prec@5 100.000 (100.000)
2019-05-08 22:08:21 - INFO - TRAINING - Epoch: [48][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0151 (0.0227)	Prec@1 100.000 (99.277)	Prec@5 100.000 (100.000)
2019-05-08 22:08:25 - INFO - TRAINING - Epoch: [48][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0570 (0.0228)	Prec@1 98.000 (99.282)	Prec@5 100.000 (100.000)
2019-05-08 22:08:30 - INFO - EVALUATING - Epoch: [48][0/100]	Time 0.281 (0.281)	Data 0.256 (0.256)	Loss 0.5050 (0.5050)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:08:31 - INFO - EVALUATING - Epoch: [48][50/100]	Time 0.035 (0.032)	Data 0.000 (0.005)	Loss 0.2256 (0.4124)	Prec@1 93.000 (91.157)	Prec@5 100.000 (99.549)
2019-05-08 22:08:32 - INFO - 
 Epoch: 49	Training Loss 0.0239 	Training Prec@1 99.234 	Training Prec@5 100.000 	Validation Loss 0.3939 	Validation Prec@1 91.270 	Validation Prec@5 99.600 	
2019-05-08 22:08:32 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:08:32 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:08:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:08:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:08:33 - INFO - TRAINING - Epoch: [49][0/500]	Time 0.256 (0.256)	Data 0.213 (0.213)	Loss 0.0446 (0.0446)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:08:37 - INFO - TRAINING - Epoch: [49][50/500]	Time 0.087 (0.087)	Data 0.000 (0.005)	Loss 0.0244 (0.0288)	Prec@1 99.000 (98.941)	Prec@5 100.000 (100.000)
2019-05-08 22:08:41 - INFO - TRAINING - Epoch: [49][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0142 (0.0275)	Prec@1 100.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-08 22:08:45 - INFO - TRAINING - Epoch: [49][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0063 (0.0264)	Prec@1 100.000 (99.113)	Prec@5 100.000 (100.000)
2019-05-08 22:08:49 - INFO - TRAINING - Epoch: [49][200/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0124 (0.0261)	Prec@1 100.000 (99.164)	Prec@5 100.000 (100.000)
2019-05-08 22:08:53 - INFO - TRAINING - Epoch: [49][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0238 (0.0264)	Prec@1 99.000 (99.143)	Prec@5 100.000 (100.000)
2019-05-08 22:08:57 - INFO - TRAINING - Epoch: [49][300/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0137 (0.0265)	Prec@1 100.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-08 22:09:01 - INFO - TRAINING - Epoch: [49][350/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0248 (0.0266)	Prec@1 99.000 (99.145)	Prec@5 100.000 (99.997)
2019-05-08 22:09:06 - INFO - TRAINING - Epoch: [49][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0244 (0.0268)	Prec@1 99.000 (99.137)	Prec@5 100.000 (99.998)
2019-05-08 22:09:10 - INFO - TRAINING - Epoch: [49][450/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0107 (0.0269)	Prec@1 100.000 (99.135)	Prec@5 100.000 (99.998)
2019-05-08 22:09:14 - INFO - EVALUATING - Epoch: [49][0/100]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.3581 (0.3581)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:09:15 - INFO - EVALUATING - Epoch: [49][50/100]	Time 0.026 (0.033)	Data 0.000 (0.006)	Loss 0.1901 (0.3414)	Prec@1 93.000 (92.137)	Prec@5 100.000 (99.569)
2019-05-08 22:09:17 - INFO - 
 Epoch: 50	Training Loss 0.0266 	Training Prec@1 99.144 	Training Prec@5 99.998 	Validation Loss 0.3291 	Validation Prec@1 92.390 	Validation Prec@5 99.700 	
2019-05-08 22:09:17 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:09:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:09:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:09:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:09:17 - INFO - TRAINING - Epoch: [50][0/500]	Time 0.255 (0.255)	Data 0.192 (0.192)	Loss 0.0342 (0.0342)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:09:21 - INFO - TRAINING - Epoch: [50][50/500]	Time 0.082 (0.087)	Data 0.000 (0.004)	Loss 0.0120 (0.0229)	Prec@1 100.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-08 22:09:25 - INFO - TRAINING - Epoch: [50][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0571 (0.0221)	Prec@1 97.000 (99.218)	Prec@5 100.000 (100.000)
2019-05-08 22:09:29 - INFO - TRAINING - Epoch: [50][150/500]	Time 0.053 (0.083)	Data 0.000 (0.002)	Loss 0.0087 (0.0201)	Prec@1 100.000 (99.285)	Prec@5 100.000 (100.000)
2019-05-08 22:09:33 - INFO - TRAINING - Epoch: [50][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0115 (0.0191)	Prec@1 100.000 (99.323)	Prec@5 100.000 (100.000)
2019-05-08 22:09:38 - INFO - TRAINING - Epoch: [50][250/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0038 (0.0189)	Prec@1 100.000 (99.327)	Prec@5 100.000 (100.000)
2019-05-08 22:09:42 - INFO - TRAINING - Epoch: [50][300/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0125 (0.0192)	Prec@1 99.000 (99.332)	Prec@5 100.000 (100.000)
2019-05-08 22:09:46 - INFO - TRAINING - Epoch: [50][350/500]	Time 0.076 (0.082)	Data 0.000 (0.001)	Loss 0.0659 (0.0198)	Prec@1 97.000 (99.299)	Prec@5 100.000 (100.000)
2019-05-08 22:09:50 - INFO - TRAINING - Epoch: [50][400/500]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.0404 (0.0205)	Prec@1 99.000 (99.279)	Prec@5 100.000 (100.000)
2019-05-08 22:09:54 - INFO - TRAINING - Epoch: [50][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0111 (0.0211)	Prec@1 100.000 (99.259)	Prec@5 100.000 (100.000)
2019-05-08 22:09:58 - INFO - EVALUATING - Epoch: [50][0/100]	Time 0.340 (0.340)	Data 0.315 (0.315)	Loss 0.2199 (0.2199)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 22:10:00 - INFO - EVALUATING - Epoch: [50][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.1997 (0.3861)	Prec@1 95.000 (91.745)	Prec@5 100.000 (99.510)
2019-05-08 22:10:01 - INFO - 
 Epoch: 51	Training Loss 0.0226 	Training Prec@1 99.212 	Training Prec@5 100.000 	Validation Loss 0.3712 	Validation Prec@1 91.520 	Validation Prec@5 99.620 	
2019-05-08 22:10:01 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:10:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:10:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:10:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:10:01 - INFO - TRAINING - Epoch: [51][0/500]	Time 0.246 (0.246)	Data 0.185 (0.185)	Loss 0.0191 (0.0191)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:10:05 - INFO - TRAINING - Epoch: [51][50/500]	Time 0.087 (0.084)	Data 0.000 (0.004)	Loss 0.0309 (0.0226)	Prec@1 99.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-08 22:10:10 - INFO - TRAINING - Epoch: [51][100/500]	Time 0.079 (0.084)	Data 0.000 (0.003)	Loss 0.0023 (0.0215)	Prec@1 100.000 (99.257)	Prec@5 100.000 (100.000)
2019-05-08 22:10:14 - INFO - TRAINING - Epoch: [51][150/500]	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 0.0105 (0.0217)	Prec@1 100.000 (99.272)	Prec@5 100.000 (100.000)
2019-05-08 22:10:18 - INFO - TRAINING - Epoch: [51][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0034 (0.0231)	Prec@1 100.000 (99.249)	Prec@5 100.000 (100.000)
2019-05-08 22:10:22 - INFO - TRAINING - Epoch: [51][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0105 (0.0230)	Prec@1 100.000 (99.263)	Prec@5 100.000 (99.996)
2019-05-08 22:10:26 - INFO - TRAINING - Epoch: [51][300/500]	Time 0.062 (0.083)	Data 0.000 (0.001)	Loss 0.0213 (0.0225)	Prec@1 99.000 (99.289)	Prec@5 100.000 (99.997)
2019-05-08 22:10:30 - INFO - TRAINING - Epoch: [51][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0050 (0.0219)	Prec@1 100.000 (99.313)	Prec@5 100.000 (99.997)
2019-05-08 22:10:34 - INFO - TRAINING - Epoch: [51][400/500]	Time 0.095 (0.083)	Data 0.000 (0.001)	Loss 0.0164 (0.0219)	Prec@1 99.000 (99.309)	Prec@5 100.000 (99.998)
2019-05-08 22:10:38 - INFO - TRAINING - Epoch: [51][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0120 (0.0221)	Prec@1 100.000 (99.306)	Prec@5 100.000 (99.998)
2019-05-08 22:10:43 - INFO - EVALUATING - Epoch: [51][0/100]	Time 0.292 (0.292)	Data 0.255 (0.255)	Loss 0.4319 (0.4319)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:10:44 - INFO - EVALUATING - Epoch: [51][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.2586 (0.3916)	Prec@1 93.000 (91.196)	Prec@5 100.000 (99.667)
2019-05-08 22:10:45 - INFO - 
 Epoch: 52	Training Loss 0.0223 	Training Prec@1 99.304 	Training Prec@5 99.998 	Validation Loss 0.3851 	Validation Prec@1 91.400 	Validation Prec@5 99.690 	
2019-05-08 22:10:46 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:10:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:10:46 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:10:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:10:46 - INFO - TRAINING - Epoch: [52][0/500]	Time 0.287 (0.287)	Data 0.224 (0.224)	Loss 0.0183 (0.0183)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:10:50 - INFO - TRAINING - Epoch: [52][50/500]	Time 0.078 (0.087)	Data 0.000 (0.005)	Loss 0.0241 (0.0236)	Prec@1 99.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-08 22:10:54 - INFO - TRAINING - Epoch: [52][100/500]	Time 0.084 (0.085)	Data 0.000 (0.003)	Loss 0.0121 (0.0253)	Prec@1 99.000 (99.069)	Prec@5 100.000 (100.000)
2019-05-08 22:10:58 - INFO - TRAINING - Epoch: [52][150/500]	Time 0.076 (0.084)	Data 0.000 (0.002)	Loss 0.0151 (0.0247)	Prec@1 100.000 (99.093)	Prec@5 100.000 (100.000)
2019-05-08 22:11:02 - INFO - TRAINING - Epoch: [52][200/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0046 (0.0248)	Prec@1 100.000 (99.095)	Prec@5 100.000 (100.000)
2019-05-08 22:11:06 - INFO - TRAINING - Epoch: [52][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0081 (0.0245)	Prec@1 100.000 (99.096)	Prec@5 100.000 (100.000)
2019-05-08 22:11:11 - INFO - TRAINING - Epoch: [52][300/500]	Time 0.099 (0.083)	Data 0.000 (0.002)	Loss 0.0039 (0.0239)	Prec@1 100.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-08 22:11:15 - INFO - TRAINING - Epoch: [52][350/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0099 (0.0228)	Prec@1 100.000 (99.199)	Prec@5 100.000 (100.000)
2019-05-08 22:11:19 - INFO - TRAINING - Epoch: [52][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0222 (0.0232)	Prec@1 100.000 (99.195)	Prec@5 100.000 (100.000)
2019-05-08 22:11:23 - INFO - TRAINING - Epoch: [52][450/500]	Time 0.078 (0.082)	Data 0.000 (0.001)	Loss 0.0090 (0.0226)	Prec@1 100.000 (99.224)	Prec@5 100.000 (100.000)
2019-05-08 22:11:27 - INFO - EVALUATING - Epoch: [52][0/100]	Time 0.302 (0.302)	Data 0.276 (0.276)	Loss 0.3034 (0.3034)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:11:28 - INFO - EVALUATING - Epoch: [52][50/100]	Time 0.029 (0.033)	Data 0.000 (0.006)	Loss 0.2078 (0.3579)	Prec@1 95.000 (92.157)	Prec@5 100.000 (99.529)
2019-05-08 22:11:30 - INFO - 
 Epoch: 53	Training Loss 0.0224 	Training Prec@1 99.222 	Training Prec@5 100.000 	Validation Loss 0.3423 	Validation Prec@1 92.090 	Validation Prec@5 99.670 	
2019-05-08 22:11:30 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:11:30 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:11:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:11:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:11:30 - INFO - TRAINING - Epoch: [53][0/500]	Time 0.287 (0.287)	Data 0.227 (0.227)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:11:34 - INFO - TRAINING - Epoch: [53][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.0031 (0.0233)	Prec@1 100.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-08 22:11:38 - INFO - TRAINING - Epoch: [53][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0181 (0.0228)	Prec@1 99.000 (99.228)	Prec@5 100.000 (100.000)
2019-05-08 22:11:43 - INFO - TRAINING - Epoch: [53][150/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0092 (0.0218)	Prec@1 100.000 (99.265)	Prec@5 100.000 (100.000)
2019-05-08 22:11:47 - INFO - TRAINING - Epoch: [53][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0146 (0.0221)	Prec@1 100.000 (99.294)	Prec@5 100.000 (100.000)
2019-05-08 22:11:51 - INFO - TRAINING - Epoch: [53][250/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0079 (0.0236)	Prec@1 100.000 (99.219)	Prec@5 100.000 (100.000)
2019-05-08 22:11:55 - INFO - TRAINING - Epoch: [53][300/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0746 (0.0241)	Prec@1 97.000 (99.183)	Prec@5 100.000 (100.000)
2019-05-08 22:11:59 - INFO - TRAINING - Epoch: [53][350/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0080 (0.0241)	Prec@1 100.000 (99.188)	Prec@5 100.000 (100.000)
2019-05-08 22:12:03 - INFO - TRAINING - Epoch: [53][400/500]	Time 0.092 (0.082)	Data 0.001 (0.001)	Loss 0.0221 (0.0240)	Prec@1 100.000 (99.190)	Prec@5 100.000 (100.000)
2019-05-08 22:12:07 - INFO - TRAINING - Epoch: [53][450/500]	Time 0.091 (0.082)	Data 0.000 (0.001)	Loss 0.0200 (0.0241)	Prec@1 98.000 (99.171)	Prec@5 100.000 (100.000)
2019-05-08 22:12:11 - INFO - EVALUATING - Epoch: [53][0/100]	Time 0.297 (0.297)	Data 0.271 (0.271)	Loss 0.3131 (0.3131)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:12:13 - INFO - EVALUATING - Epoch: [53][50/100]	Time 0.035 (0.032)	Data 0.000 (0.006)	Loss 0.1666 (0.3697)	Prec@1 92.000 (91.686)	Prec@5 100.000 (99.510)
2019-05-08 22:12:14 - INFO - 
 Epoch: 54	Training Loss 0.0242 	Training Prec@1 99.182 	Training Prec@5 100.000 	Validation Loss 0.3535 	Validation Prec@1 91.890 	Validation Prec@5 99.660 	
2019-05-08 22:12:14 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:12:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:12:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:12:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:12:15 - INFO - TRAINING - Epoch: [54][0/500]	Time 0.260 (0.260)	Data 0.195 (0.195)	Loss 0.0369 (0.0369)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:12:19 - INFO - TRAINING - Epoch: [54][50/500]	Time 0.090 (0.086)	Data 0.000 (0.005)	Loss 0.0060 (0.0173)	Prec@1 100.000 (99.431)	Prec@5 100.000 (100.000)
2019-05-08 22:12:23 - INFO - TRAINING - Epoch: [54][100/500]	Time 0.081 (0.085)	Data 0.000 (0.003)	Loss 0.0144 (0.0147)	Prec@1 99.000 (99.535)	Prec@5 100.000 (100.000)
2019-05-08 22:12:27 - INFO - TRAINING - Epoch: [54][150/500]	Time 0.072 (0.084)	Data 0.000 (0.002)	Loss 0.0282 (0.0142)	Prec@1 99.000 (99.570)	Prec@5 100.000 (100.000)
2019-05-08 22:12:31 - INFO - TRAINING - Epoch: [54][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0053 (0.0146)	Prec@1 100.000 (99.547)	Prec@5 100.000 (100.000)
2019-05-08 22:12:35 - INFO - TRAINING - Epoch: [54][250/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0275 (0.0151)	Prec@1 99.000 (99.534)	Prec@5 100.000 (100.000)
2019-05-08 22:12:39 - INFO - TRAINING - Epoch: [54][300/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0371 (0.0155)	Prec@1 99.000 (99.512)	Prec@5 100.000 (100.000)
2019-05-08 22:12:44 - INFO - TRAINING - Epoch: [54][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0592 (0.0169)	Prec@1 97.000 (99.462)	Prec@5 100.000 (100.000)
2019-05-08 22:12:48 - INFO - TRAINING - Epoch: [54][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0327 (0.0187)	Prec@1 99.000 (99.406)	Prec@5 100.000 (100.000)
2019-05-08 22:12:52 - INFO - TRAINING - Epoch: [54][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0188 (0.0191)	Prec@1 99.000 (99.392)	Prec@5 100.000 (100.000)
2019-05-08 22:12:56 - INFO - EVALUATING - Epoch: [54][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.3738 (0.3738)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-05-08 22:12:57 - INFO - EVALUATING - Epoch: [54][50/100]	Time 0.036 (0.033)	Data 0.000 (0.005)	Loss 0.1995 (0.3843)	Prec@1 93.000 (91.725)	Prec@5 100.000 (99.431)
2019-05-08 22:12:59 - INFO - 
 Epoch: 55	Training Loss 0.0201 	Training Prec@1 99.354 	Training Prec@5 100.000 	Validation Loss 0.3541 	Validation Prec@1 91.890 	Validation Prec@5 99.620 	
2019-05-08 22:12:59 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:12:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:12:59 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:12:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:12:59 - INFO - TRAINING - Epoch: [55][0/500]	Time 0.262 (0.262)	Data 0.198 (0.198)	Loss 0.0269 (0.0269)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:13:03 - INFO - TRAINING - Epoch: [55][50/500]	Time 0.081 (0.083)	Data 0.000 (0.005)	Loss 0.0314 (0.0219)	Prec@1 98.000 (99.353)	Prec@5 100.000 (100.000)
2019-05-08 22:13:07 - INFO - TRAINING - Epoch: [55][100/500]	Time 0.080 (0.083)	Data 0.000 (0.003)	Loss 0.0076 (0.0210)	Prec@1 100.000 (99.376)	Prec@5 100.000 (100.000)
2019-05-08 22:13:11 - INFO - TRAINING - Epoch: [55][150/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0099 (0.0201)	Prec@1 100.000 (99.377)	Prec@5 100.000 (100.000)
2019-05-08 22:13:15 - INFO - TRAINING - Epoch: [55][200/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0192 (0.0209)	Prec@1 100.000 (99.313)	Prec@5 100.000 (100.000)
2019-05-08 22:13:19 - INFO - TRAINING - Epoch: [55][250/500]	Time 0.078 (0.082)	Data 0.000 (0.002)	Loss 0.0391 (0.0209)	Prec@1 99.000 (99.299)	Prec@5 100.000 (100.000)
2019-05-08 22:13:23 - INFO - TRAINING - Epoch: [55][300/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0463 (0.0217)	Prec@1 99.000 (99.279)	Prec@5 100.000 (100.000)
2019-05-08 22:13:28 - INFO - TRAINING - Epoch: [55][350/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0027 (0.0224)	Prec@1 100.000 (99.242)	Prec@5 100.000 (100.000)
2019-05-08 22:13:32 - INFO - TRAINING - Epoch: [55][400/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.0171 (0.0222)	Prec@1 99.000 (99.259)	Prec@5 100.000 (100.000)
2019-05-08 22:13:36 - INFO - TRAINING - Epoch: [55][450/500]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.0141 (0.0220)	Prec@1 99.000 (99.273)	Prec@5 100.000 (100.000)
2019-05-08 22:13:40 - INFO - EVALUATING - Epoch: [55][0/100]	Time 0.296 (0.296)	Data 0.266 (0.266)	Loss 0.3066 (0.3066)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:13:41 - INFO - EVALUATING - Epoch: [55][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.1062 (0.3642)	Prec@1 96.000 (92.157)	Prec@5 100.000 (99.333)
2019-05-08 22:13:43 - INFO - 
 Epoch: 56	Training Loss 0.0224 	Training Prec@1 99.260 	Training Prec@5 100.000 	Validation Loss 0.3501 	Validation Prec@1 91.990 	Validation Prec@5 99.530 	
2019-05-08 22:13:43 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:13:43 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:13:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:13:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:13:43 - INFO - TRAINING - Epoch: [56][0/500]	Time 0.257 (0.257)	Data 0.196 (0.196)	Loss 0.0346 (0.0346)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:13:47 - INFO - TRAINING - Epoch: [56][50/500]	Time 0.080 (0.087)	Data 0.000 (0.005)	Loss 0.0099 (0.0144)	Prec@1 100.000 (99.588)	Prec@5 100.000 (100.000)
2019-05-08 22:13:52 - INFO - TRAINING - Epoch: [56][100/500]	Time 0.078 (0.085)	Data 0.000 (0.003)	Loss 0.0129 (0.0154)	Prec@1 100.000 (99.604)	Prec@5 100.000 (100.000)
2019-05-08 22:13:55 - INFO - TRAINING - Epoch: [56][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0209 (0.0161)	Prec@1 99.000 (99.523)	Prec@5 100.000 (100.000)
2019-05-08 22:13:59 - INFO - TRAINING - Epoch: [56][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0679 (0.0165)	Prec@1 98.000 (99.483)	Prec@5 100.000 (100.000)
2019-05-08 22:14:03 - INFO - TRAINING - Epoch: [56][250/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0387 (0.0165)	Prec@1 99.000 (99.482)	Prec@5 100.000 (100.000)
2019-05-08 22:14:08 - INFO - TRAINING - Epoch: [56][300/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0142 (0.0159)	Prec@1 99.000 (99.502)	Prec@5 100.000 (100.000)
2019-05-08 22:14:12 - INFO - TRAINING - Epoch: [56][350/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0185 (0.0155)	Prec@1 99.000 (99.530)	Prec@5 100.000 (100.000)
2019-05-08 22:14:16 - INFO - TRAINING - Epoch: [56][400/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0075 (0.0156)	Prec@1 100.000 (99.536)	Prec@5 100.000 (100.000)
2019-05-08 22:14:20 - INFO - TRAINING - Epoch: [56][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0027 (0.0156)	Prec@1 100.000 (99.532)	Prec@5 100.000 (100.000)
2019-05-08 22:14:24 - INFO - EVALUATING - Epoch: [56][0/100]	Time 0.326 (0.326)	Data 0.301 (0.301)	Loss 0.2610 (0.2610)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:14:25 - INFO - EVALUATING - Epoch: [56][50/100]	Time 0.038 (0.032)	Data 0.000 (0.006)	Loss 0.2449 (0.3969)	Prec@1 94.000 (92.118)	Prec@5 100.000 (99.510)
2019-05-08 22:14:27 - INFO - 
 Epoch: 57	Training Loss 0.0157 	Training Prec@1 99.522 	Training Prec@5 100.000 	Validation Loss 0.3630 	Validation Prec@1 92.420 	Validation Prec@5 99.680 	
2019-05-08 22:14:27 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:14:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:14:27 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:14:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:14:27 - INFO - TRAINING - Epoch: [57][0/500]	Time 0.256 (0.256)	Data 0.191 (0.191)	Loss 0.0043 (0.0043)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:14:31 - INFO - TRAINING - Epoch: [57][50/500]	Time 0.082 (0.084)	Data 0.000 (0.004)	Loss 0.0432 (0.0217)	Prec@1 99.000 (99.314)	Prec@5 100.000 (100.000)
2019-05-08 22:14:35 - INFO - TRAINING - Epoch: [57][100/500]	Time 0.078 (0.084)	Data 0.000 (0.002)	Loss 0.0090 (0.0166)	Prec@1 100.000 (99.495)	Prec@5 100.000 (100.000)
2019-05-08 22:14:40 - INFO - TRAINING - Epoch: [57][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0091 (0.0145)	Prec@1 100.000 (99.576)	Prec@5 100.000 (100.000)
2019-05-08 22:14:44 - INFO - TRAINING - Epoch: [57][200/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0098 (0.0139)	Prec@1 100.000 (99.582)	Prec@5 100.000 (100.000)
2019-05-08 22:14:48 - INFO - TRAINING - Epoch: [57][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0224 (0.0148)	Prec@1 99.000 (99.554)	Prec@5 100.000 (100.000)
2019-05-08 22:14:52 - INFO - TRAINING - Epoch: [57][300/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0171 (0.0145)	Prec@1 100.000 (99.571)	Prec@5 100.000 (100.000)
2019-05-08 22:14:56 - INFO - TRAINING - Epoch: [57][350/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0057 (0.0143)	Prec@1 100.000 (99.564)	Prec@5 100.000 (100.000)
2019-05-08 22:15:00 - INFO - TRAINING - Epoch: [57][400/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0125 (0.0147)	Prec@1 100.000 (99.551)	Prec@5 100.000 (100.000)
2019-05-08 22:15:04 - INFO - TRAINING - Epoch: [57][450/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.0815 (0.0159)	Prec@1 97.000 (99.501)	Prec@5 100.000 (100.000)
2019-05-08 22:15:08 - INFO - EVALUATING - Epoch: [57][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.4133 (0.4133)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-08 22:15:10 - INFO - EVALUATING - Epoch: [57][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.1413 (0.4045)	Prec@1 95.000 (91.647)	Prec@5 100.000 (99.392)
2019-05-08 22:15:11 - INFO - 
 Epoch: 58	Training Loss 0.0166 	Training Prec@1 99.478 	Training Prec@5 100.000 	Validation Loss 0.3713 	Validation Prec@1 91.790 	Validation Prec@5 99.580 	
2019-05-08 22:15:11 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:15:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:15:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:15:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:15:12 - INFO - TRAINING - Epoch: [58][0/500]	Time 0.244 (0.244)	Data 0.188 (0.188)	Loss 0.0057 (0.0057)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:15:16 - INFO - TRAINING - Epoch: [58][50/500]	Time 0.078 (0.087)	Data 0.000 (0.004)	Loss 0.0127 (0.0133)	Prec@1 99.000 (99.451)	Prec@5 100.000 (100.000)
2019-05-08 22:15:20 - INFO - TRAINING - Epoch: [58][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0319 (0.0167)	Prec@1 99.000 (99.366)	Prec@5 100.000 (100.000)
2019-05-08 22:15:24 - INFO - TRAINING - Epoch: [58][150/500]	Time 0.077 (0.084)	Data 0.000 (0.002)	Loss 0.0625 (0.0188)	Prec@1 99.000 (99.358)	Prec@5 100.000 (100.000)
2019-05-08 22:15:28 - INFO - TRAINING - Epoch: [58][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0282 (0.0188)	Prec@1 99.000 (99.378)	Prec@5 100.000 (100.000)
2019-05-08 22:15:32 - INFO - TRAINING - Epoch: [58][250/500]	Time 0.077 (0.084)	Data 0.000 (0.002)	Loss 0.0018 (0.0187)	Prec@1 100.000 (99.390)	Prec@5 100.000 (100.000)
2019-05-08 22:15:37 - INFO - TRAINING - Epoch: [58][300/500]	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 0.0071 (0.0192)	Prec@1 100.000 (99.362)	Prec@5 100.000 (100.000)
2019-05-08 22:15:41 - INFO - TRAINING - Epoch: [58][350/500]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.0074 (0.0198)	Prec@1 100.000 (99.350)	Prec@5 100.000 (100.000)
2019-05-08 22:15:45 - INFO - TRAINING - Epoch: [58][400/500]	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 0.0053 (0.0208)	Prec@1 100.000 (99.329)	Prec@5 100.000 (100.000)
2019-05-08 22:15:49 - INFO - TRAINING - Epoch: [58][450/500]	Time 0.057 (0.084)	Data 0.001 (0.001)	Loss 0.0058 (0.0207)	Prec@1 100.000 (99.335)	Prec@5 100.000 (100.000)
2019-05-08 22:15:53 - INFO - EVALUATING - Epoch: [58][0/100]	Time 0.330 (0.330)	Data 0.279 (0.279)	Loss 0.3775 (0.3775)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:15:55 - INFO - EVALUATING - Epoch: [58][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1231 (0.4082)	Prec@1 94.000 (91.020)	Prec@5 100.000 (99.451)
2019-05-08 22:15:56 - INFO - 
 Epoch: 59	Training Loss 0.0209 	Training Prec@1 99.324 	Training Prec@5 100.000 	Validation Loss 0.3885 	Validation Prec@1 91.340 	Validation Prec@5 99.600 	
2019-05-08 22:15:56 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:15:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:15:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:15:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:15:57 - INFO - TRAINING - Epoch: [59][0/500]	Time 0.272 (0.272)	Data 0.229 (0.229)	Loss 0.0082 (0.0082)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:16:01 - INFO - TRAINING - Epoch: [59][50/500]	Time 0.083 (0.083)	Data 0.000 (0.006)	Loss 0.0021 (0.0121)	Prec@1 100.000 (99.667)	Prec@5 100.000 (100.000)
2019-05-08 22:16:05 - INFO - TRAINING - Epoch: [59][100/500]	Time 0.075 (0.083)	Data 0.000 (0.003)	Loss 0.0312 (0.0154)	Prec@1 99.000 (99.564)	Prec@5 100.000 (100.000)
2019-05-08 22:16:09 - INFO - TRAINING - Epoch: [59][150/500]	Time 0.044 (0.083)	Data 0.000 (0.002)	Loss 0.0866 (0.0178)	Prec@1 96.000 (99.397)	Prec@5 100.000 (100.000)
2019-05-08 22:16:13 - INFO - TRAINING - Epoch: [59][200/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0116 (0.0180)	Prec@1 100.000 (99.388)	Prec@5 100.000 (100.000)
2019-05-08 22:16:17 - INFO - TRAINING - Epoch: [59][250/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0100 (0.0175)	Prec@1 100.000 (99.430)	Prec@5 100.000 (100.000)
2019-05-08 22:16:21 - INFO - TRAINING - Epoch: [59][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0478 (0.0173)	Prec@1 99.000 (99.449)	Prec@5 100.000 (100.000)
2019-05-08 22:16:25 - INFO - TRAINING - Epoch: [59][350/500]	Time 0.071 (0.082)	Data 0.000 (0.002)	Loss 0.0038 (0.0182)	Prec@1 100.000 (99.419)	Prec@5 100.000 (100.000)
2019-05-08 22:16:29 - INFO - TRAINING - Epoch: [59][400/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0266 (0.0189)	Prec@1 99.000 (99.387)	Prec@5 100.000 (100.000)
2019-05-08 22:16:33 - INFO - TRAINING - Epoch: [59][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0058 (0.0193)	Prec@1 100.000 (99.370)	Prec@5 100.000 (100.000)
2019-05-08 22:16:38 - INFO - EVALUATING - Epoch: [59][0/100]	Time 0.296 (0.296)	Data 0.270 (0.270)	Loss 0.1875 (0.1875)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:16:39 - INFO - EVALUATING - Epoch: [59][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.0296 (0.4105)	Prec@1 99.000 (91.059)	Prec@5 100.000 (99.373)
2019-05-08 22:16:40 - INFO - 
 Epoch: 60	Training Loss 0.0193 	Training Prec@1 99.372 	Training Prec@5 100.000 	Validation Loss 0.3795 	Validation Prec@1 91.490 	Validation Prec@5 99.560 	
2019-05-08 22:16:41 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:16:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:16:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:16:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:16:41 - INFO - TRAINING - Epoch: [60][0/500]	Time 0.242 (0.242)	Data 0.182 (0.182)	Loss 0.0056 (0.0056)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:16:45 - INFO - TRAINING - Epoch: [60][50/500]	Time 0.082 (0.086)	Data 0.000 (0.004)	Loss 0.0028 (0.0143)	Prec@1 100.000 (99.490)	Prec@5 100.000 (100.000)
2019-05-08 22:16:49 - INFO - TRAINING - Epoch: [60][100/500]	Time 0.079 (0.085)	Data 0.000 (0.003)	Loss 0.0167 (0.0171)	Prec@1 100.000 (99.426)	Prec@5 100.000 (100.000)
2019-05-08 22:16:53 - INFO - TRAINING - Epoch: [60][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0026 (0.0169)	Prec@1 100.000 (99.444)	Prec@5 100.000 (100.000)
2019-05-08 22:16:57 - INFO - TRAINING - Epoch: [60][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0072 (0.0177)	Prec@1 100.000 (99.453)	Prec@5 100.000 (100.000)
2019-05-08 22:17:02 - INFO - TRAINING - Epoch: [60][250/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0032 (0.0167)	Prec@1 100.000 (99.486)	Prec@5 100.000 (100.000)
2019-05-08 22:17:06 - INFO - TRAINING - Epoch: [60][300/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0052 (0.0163)	Prec@1 100.000 (99.482)	Prec@5 100.000 (100.000)
2019-05-08 22:17:10 - INFO - TRAINING - Epoch: [60][350/500]	Time 0.076 (0.083)	Data 0.000 (0.001)	Loss 0.0150 (0.0171)	Prec@1 100.000 (99.462)	Prec@5 100.000 (100.000)
2019-05-08 22:17:14 - INFO - TRAINING - Epoch: [60][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0053 (0.0172)	Prec@1 100.000 (99.456)	Prec@5 100.000 (100.000)
2019-05-08 22:17:18 - INFO - TRAINING - Epoch: [60][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0136 (0.0171)	Prec@1 99.000 (99.463)	Prec@5 100.000 (100.000)
2019-05-08 22:17:22 - INFO - EVALUATING - Epoch: [60][0/100]	Time 0.286 (0.286)	Data 0.261 (0.261)	Loss 0.2964 (0.2964)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:17:24 - INFO - EVALUATING - Epoch: [60][50/100]	Time 0.024 (0.032)	Data 0.000 (0.005)	Loss 0.1328 (0.3642)	Prec@1 98.000 (92.255)	Prec@5 100.000 (99.412)
2019-05-08 22:17:25 - INFO - 
 Epoch: 61	Training Loss 0.0173 	Training Prec@1 99.456 	Training Prec@5 100.000 	Validation Loss 0.3490 	Validation Prec@1 92.100 	Validation Prec@5 99.560 	
2019-05-08 22:17:25 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:17:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:17:25 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:17:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:17:25 - INFO - TRAINING - Epoch: [61][0/500]	Time 0.253 (0.253)	Data 0.195 (0.195)	Loss 0.0059 (0.0059)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:17:29 - INFO - TRAINING - Epoch: [61][50/500]	Time 0.079 (0.085)	Data 0.000 (0.005)	Loss 0.0198 (0.0142)	Prec@1 99.000 (99.471)	Prec@5 100.000 (100.000)
2019-05-08 22:17:34 - INFO - TRAINING - Epoch: [61][100/500]	Time 0.087 (0.084)	Data 0.000 (0.003)	Loss 0.0103 (0.0140)	Prec@1 100.000 (99.525)	Prec@5 100.000 (100.000)
2019-05-08 22:17:38 - INFO - TRAINING - Epoch: [61][150/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0207 (0.0138)	Prec@1 99.000 (99.556)	Prec@5 100.000 (100.000)
2019-05-08 22:17:42 - INFO - TRAINING - Epoch: [61][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0347 (0.0144)	Prec@1 97.000 (99.512)	Prec@5 100.000 (100.000)
2019-05-08 22:17:46 - INFO - TRAINING - Epoch: [61][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0079 (0.0147)	Prec@1 100.000 (99.502)	Prec@5 100.000 (100.000)
2019-05-08 22:17:50 - INFO - TRAINING - Epoch: [61][300/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0020 (0.0155)	Prec@1 100.000 (99.482)	Prec@5 100.000 (100.000)
2019-05-08 22:17:54 - INFO - TRAINING - Epoch: [61][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0022 (0.0161)	Prec@1 100.000 (99.476)	Prec@5 100.000 (100.000)
2019-05-08 22:17:58 - INFO - TRAINING - Epoch: [61][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0162 (0.0167)	Prec@1 100.000 (99.454)	Prec@5 100.000 (100.000)
2019-05-08 22:18:02 - INFO - TRAINING - Epoch: [61][450/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0029 (0.0166)	Prec@1 100.000 (99.452)	Prec@5 100.000 (100.000)
2019-05-08 22:18:07 - INFO - EVALUATING - Epoch: [61][0/100]	Time 0.282 (0.282)	Data 0.257 (0.257)	Loss 0.2945 (0.2945)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:18:08 - INFO - EVALUATING - Epoch: [61][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.0977 (0.3672)	Prec@1 95.000 (92.353)	Prec@5 100.000 (99.510)
2019-05-08 22:18:09 - INFO - 
 Epoch: 62	Training Loss 0.0165 	Training Prec@1 99.454 	Training Prec@5 100.000 	Validation Loss 0.3537 	Validation Prec@1 92.300 	Validation Prec@5 99.680 	
2019-05-08 22:18:09 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:18:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:18:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:18:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:18:10 - INFO - TRAINING - Epoch: [62][0/500]	Time 0.266 (0.266)	Data 0.223 (0.223)	Loss 0.0314 (0.0314)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:18:14 - INFO - TRAINING - Epoch: [62][50/500]	Time 0.085 (0.084)	Data 0.000 (0.005)	Loss 0.0058 (0.0148)	Prec@1 100.000 (99.588)	Prec@5 100.000 (100.000)
2019-05-08 22:18:18 - INFO - TRAINING - Epoch: [62][100/500]	Time 0.091 (0.083)	Data 0.000 (0.003)	Loss 0.0174 (0.0162)	Prec@1 99.000 (99.515)	Prec@5 100.000 (100.000)
2019-05-08 22:18:22 - INFO - TRAINING - Epoch: [62][150/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0260 (0.0193)	Prec@1 99.000 (99.430)	Prec@5 100.000 (100.000)
2019-05-08 22:18:26 - INFO - TRAINING - Epoch: [62][200/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0031 (0.0185)	Prec@1 100.000 (99.463)	Prec@5 100.000 (100.000)
2019-05-08 22:18:30 - INFO - TRAINING - Epoch: [62][250/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0203 (0.0185)	Prec@1 100.000 (99.466)	Prec@5 100.000 (100.000)
2019-05-08 22:18:34 - INFO - TRAINING - Epoch: [62][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0054 (0.0183)	Prec@1 100.000 (99.465)	Prec@5 100.000 (100.000)
2019-05-08 22:18:38 - INFO - TRAINING - Epoch: [62][350/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0074 (0.0181)	Prec@1 100.000 (99.470)	Prec@5 100.000 (100.000)
2019-05-08 22:18:42 - INFO - TRAINING - Epoch: [62][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0179 (0.0175)	Prec@1 99.000 (99.489)	Prec@5 100.000 (100.000)
2019-05-08 22:18:46 - INFO - TRAINING - Epoch: [62][450/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0070 (0.0174)	Prec@1 100.000 (99.486)	Prec@5 100.000 (100.000)
2019-05-08 22:18:51 - INFO - EVALUATING - Epoch: [62][0/100]	Time 0.297 (0.297)	Data 0.272 (0.272)	Loss 0.3631 (0.3631)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:18:52 - INFO - EVALUATING - Epoch: [62][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1784 (0.3822)	Prec@1 95.000 (91.961)	Prec@5 100.000 (99.549)
2019-05-08 22:18:53 - INFO - 
 Epoch: 63	Training Loss 0.0172 	Training Prec@1 99.490 	Training Prec@5 100.000 	Validation Loss 0.3738 	Validation Prec@1 92.000 	Validation Prec@5 99.640 	
2019-05-08 22:18:53 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:18:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:18:53 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:18:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:18:54 - INFO - TRAINING - Epoch: [63][0/500]	Time 0.252 (0.252)	Data 0.187 (0.187)	Loss 0.0129 (0.0129)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:18:58 - INFO - TRAINING - Epoch: [63][50/500]	Time 0.056 (0.085)	Data 0.003 (0.005)	Loss 0.0116 (0.0126)	Prec@1 99.000 (99.569)	Prec@5 100.000 (100.000)
2019-05-08 22:19:02 - INFO - TRAINING - Epoch: [63][100/500]	Time 0.077 (0.083)	Data 0.000 (0.003)	Loss 0.0241 (0.0137)	Prec@1 99.000 (99.564)	Prec@5 100.000 (100.000)
2019-05-08 22:19:06 - INFO - TRAINING - Epoch: [63][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0020 (0.0130)	Prec@1 100.000 (99.596)	Prec@5 100.000 (100.000)
2019-05-08 22:19:10 - INFO - TRAINING - Epoch: [63][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0127 (0.0138)	Prec@1 99.000 (99.562)	Prec@5 100.000 (100.000)
2019-05-08 22:19:14 - INFO - TRAINING - Epoch: [63][250/500]	Time 0.094 (0.083)	Data 0.000 (0.002)	Loss 0.0023 (0.0140)	Prec@1 100.000 (99.546)	Prec@5 100.000 (100.000)
2019-05-08 22:19:18 - INFO - TRAINING - Epoch: [63][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0051 (0.0150)	Prec@1 100.000 (99.492)	Prec@5 100.000 (100.000)
2019-05-08 22:19:23 - INFO - TRAINING - Epoch: [63][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0579 (0.0149)	Prec@1 98.000 (99.493)	Prec@5 100.000 (100.000)
2019-05-08 22:19:27 - INFO - TRAINING - Epoch: [63][400/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0054 (0.0152)	Prec@1 100.000 (99.474)	Prec@5 100.000 (100.000)
2019-05-08 22:19:31 - INFO - TRAINING - Epoch: [63][450/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0038 (0.0152)	Prec@1 100.000 (99.481)	Prec@5 100.000 (100.000)
2019-05-08 22:19:35 - INFO - EVALUATING - Epoch: [63][0/100]	Time 0.319 (0.319)	Data 0.276 (0.276)	Loss 0.3834 (0.3834)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:19:36 - INFO - EVALUATING - Epoch: [63][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.0613 (0.3625)	Prec@1 98.000 (92.333)	Prec@5 100.000 (99.549)
2019-05-08 22:19:38 - INFO - 
 Epoch: 64	Training Loss 0.0149 	Training Prec@1 99.494 	Training Prec@5 100.000 	Validation Loss 0.3450 	Validation Prec@1 92.510 	Validation Prec@5 99.710 	
2019-05-08 22:19:38 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:19:38 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:19:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:19:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:19:38 - INFO - TRAINING - Epoch: [64][0/500]	Time 0.254 (0.254)	Data 0.205 (0.205)	Loss 0.0457 (0.0457)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:19:42 - INFO - TRAINING - Epoch: [64][50/500]	Time 0.094 (0.085)	Data 0.000 (0.005)	Loss 0.0108 (0.0123)	Prec@1 100.000 (99.627)	Prec@5 100.000 (100.000)
2019-05-08 22:19:46 - INFO - TRAINING - Epoch: [64][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0042 (0.0130)	Prec@1 100.000 (99.604)	Prec@5 100.000 (100.000)
2019-05-08 22:19:50 - INFO - TRAINING - Epoch: [64][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0412 (0.0129)	Prec@1 99.000 (99.609)	Prec@5 100.000 (100.000)
2019-05-08 22:19:55 - INFO - TRAINING - Epoch: [64][200/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0012 (0.0129)	Prec@1 100.000 (99.612)	Prec@5 100.000 (100.000)
2019-05-08 22:19:59 - INFO - TRAINING - Epoch: [64][250/500]	Time 0.073 (0.082)	Data 0.000 (0.002)	Loss 0.0057 (0.0125)	Prec@1 100.000 (99.602)	Prec@5 100.000 (100.000)
2019-05-08 22:20:03 - INFO - TRAINING - Epoch: [64][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0300 (0.0133)	Prec@1 99.000 (99.568)	Prec@5 100.000 (100.000)
2019-05-08 22:20:07 - INFO - TRAINING - Epoch: [64][350/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0016 (0.0132)	Prec@1 100.000 (99.576)	Prec@5 100.000 (100.000)
2019-05-08 22:20:11 - INFO - TRAINING - Epoch: [64][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0267 (0.0136)	Prec@1 99.000 (99.559)	Prec@5 100.000 (100.000)
2019-05-08 22:20:15 - INFO - TRAINING - Epoch: [64][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0198 (0.0138)	Prec@1 99.000 (99.545)	Prec@5 100.000 (100.000)
2019-05-08 22:20:19 - INFO - EVALUATING - Epoch: [64][0/100]	Time 0.276 (0.276)	Data 0.251 (0.251)	Loss 0.3768 (0.3768)	Prec@1 95.000 (95.000)	Prec@5 99.000 (99.000)
2019-05-08 22:20:21 - INFO - EVALUATING - Epoch: [64][50/100]	Time 0.037 (0.032)	Data 0.000 (0.005)	Loss 0.2577 (0.3817)	Prec@1 94.000 (92.471)	Prec@5 100.000 (99.412)
2019-05-08 22:20:22 - INFO - 
 Epoch: 65	Training Loss 0.0143 	Training Prec@1 99.524 	Training Prec@5 100.000 	Validation Loss 0.3650 	Validation Prec@1 92.480 	Validation Prec@5 99.580 	
2019-05-08 22:20:22 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:20:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:20:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:20:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:20:22 - INFO - TRAINING - Epoch: [65][0/500]	Time 0.258 (0.258)	Data 0.210 (0.210)	Loss 0.0164 (0.0164)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:20:26 - INFO - TRAINING - Epoch: [65][50/500]	Time 0.085 (0.087)	Data 0.000 (0.005)	Loss 0.0373 (0.0143)	Prec@1 99.000 (99.549)	Prec@5 100.000 (100.000)
2019-05-08 22:20:31 - INFO - TRAINING - Epoch: [65][100/500]	Time 0.077 (0.084)	Data 0.000 (0.003)	Loss 0.0200 (0.0134)	Prec@1 100.000 (99.604)	Prec@5 100.000 (100.000)
2019-05-08 22:20:35 - INFO - TRAINING - Epoch: [65][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0506 (0.0153)	Prec@1 99.000 (99.530)	Prec@5 100.000 (100.000)
2019-05-08 22:20:39 - INFO - TRAINING - Epoch: [65][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0116 (0.0162)	Prec@1 100.000 (99.502)	Prec@5 100.000 (100.000)
2019-05-08 22:20:43 - INFO - TRAINING - Epoch: [65][250/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0278 (0.0158)	Prec@1 99.000 (99.506)	Prec@5 100.000 (100.000)
2019-05-08 22:20:47 - INFO - TRAINING - Epoch: [65][300/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0311 (0.0153)	Prec@1 99.000 (99.515)	Prec@5 100.000 (100.000)
2019-05-08 22:20:51 - INFO - TRAINING - Epoch: [65][350/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0295 (0.0160)	Prec@1 99.000 (99.493)	Prec@5 100.000 (100.000)
2019-05-08 22:20:55 - INFO - TRAINING - Epoch: [65][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0043 (0.0160)	Prec@1 100.000 (99.489)	Prec@5 100.000 (100.000)
2019-05-08 22:20:59 - INFO - TRAINING - Epoch: [65][450/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0009 (0.0162)	Prec@1 100.000 (99.486)	Prec@5 100.000 (100.000)
2019-05-08 22:21:04 - INFO - EVALUATING - Epoch: [65][0/100]	Time 0.362 (0.362)	Data 0.337 (0.337)	Loss 0.2564 (0.2564)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 22:21:05 - INFO - EVALUATING - Epoch: [65][50/100]	Time 0.025 (0.033)	Data 0.000 (0.007)	Loss 0.1513 (0.3762)	Prec@1 95.000 (92.235)	Prec@5 100.000 (99.412)
2019-05-08 22:21:06 - INFO - 
 Epoch: 66	Training Loss 0.0166 	Training Prec@1 99.474 	Training Prec@5 100.000 	Validation Loss 0.3671 	Validation Prec@1 91.890 	Validation Prec@5 99.590 	
2019-05-08 22:21:07 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:21:07 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:21:07 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:21:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:21:07 - INFO - TRAINING - Epoch: [66][0/500]	Time 0.250 (0.250)	Data 0.191 (0.191)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:21:11 - INFO - TRAINING - Epoch: [66][50/500]	Time 0.084 (0.085)	Data 0.000 (0.005)	Loss 0.0026 (0.0101)	Prec@1 100.000 (99.725)	Prec@5 100.000 (100.000)
2019-05-08 22:21:15 - INFO - TRAINING - Epoch: [66][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0036 (0.0100)	Prec@1 100.000 (99.713)	Prec@5 100.000 (100.000)
2019-05-08 22:21:19 - INFO - TRAINING - Epoch: [66][150/500]	Time 0.092 (0.084)	Data 0.000 (0.002)	Loss 0.0062 (0.0105)	Prec@1 100.000 (99.656)	Prec@5 100.000 (100.000)
2019-05-08 22:21:23 - INFO - TRAINING - Epoch: [66][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0047 (0.0102)	Prec@1 100.000 (99.672)	Prec@5 100.000 (100.000)
2019-05-08 22:21:28 - INFO - TRAINING - Epoch: [66][250/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0233 (0.0112)	Prec@1 98.000 (99.629)	Prec@5 100.000 (100.000)
2019-05-08 22:21:32 - INFO - TRAINING - Epoch: [66][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0086 (0.0112)	Prec@1 100.000 (99.628)	Prec@5 100.000 (100.000)
2019-05-08 22:21:36 - INFO - TRAINING - Epoch: [66][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0132 (0.0115)	Prec@1 100.000 (99.621)	Prec@5 100.000 (100.000)
2019-05-08 22:21:40 - INFO - TRAINING - Epoch: [66][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0139 (0.0117)	Prec@1 99.000 (99.618)	Prec@5 100.000 (100.000)
2019-05-08 22:21:44 - INFO - TRAINING - Epoch: [66][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0011 (0.0118)	Prec@1 100.000 (99.619)	Prec@5 100.000 (100.000)
2019-05-08 22:21:49 - INFO - EVALUATING - Epoch: [66][0/100]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.2939 (0.2939)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:21:50 - INFO - EVALUATING - Epoch: [66][50/100]	Time 0.030 (0.032)	Data 0.000 (0.005)	Loss 0.2604 (0.3754)	Prec@1 93.000 (92.196)	Prec@5 100.000 (99.588)
2019-05-08 22:21:51 - INFO - 
 Epoch: 67	Training Loss 0.0125 	Training Prec@1 99.592 	Training Prec@5 100.000 	Validation Loss 0.3702 	Validation Prec@1 92.190 	Validation Prec@5 99.620 	
2019-05-08 22:21:51 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:21:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:21:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:21:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:21:52 - INFO - TRAINING - Epoch: [67][0/500]	Time 0.239 (0.239)	Data 0.194 (0.194)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:21:56 - INFO - TRAINING - Epoch: [67][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.0126 (0.0114)	Prec@1 100.000 (99.725)	Prec@5 100.000 (100.000)
2019-05-08 22:22:00 - INFO - TRAINING - Epoch: [67][100/500]	Time 0.090 (0.084)	Data 0.000 (0.003)	Loss 0.0081 (0.0117)	Prec@1 100.000 (99.693)	Prec@5 100.000 (100.000)
2019-05-08 22:22:04 - INFO - TRAINING - Epoch: [67][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0050 (0.0131)	Prec@1 100.000 (99.616)	Prec@5 100.000 (100.000)
2019-05-08 22:22:08 - INFO - TRAINING - Epoch: [67][200/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0019 (0.0143)	Prec@1 100.000 (99.582)	Prec@5 100.000 (100.000)
2019-05-08 22:22:12 - INFO - TRAINING - Epoch: [67][250/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0359 (0.0146)	Prec@1 99.000 (99.582)	Prec@5 100.000 (100.000)
2019-05-08 22:22:16 - INFO - TRAINING - Epoch: [67][300/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0109 (0.0147)	Prec@1 100.000 (99.575)	Prec@5 100.000 (100.000)
2019-05-08 22:22:20 - INFO - TRAINING - Epoch: [67][350/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0023 (0.0145)	Prec@1 100.000 (99.578)	Prec@5 100.000 (100.000)
2019-05-08 22:22:24 - INFO - TRAINING - Epoch: [67][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0219 (0.0145)	Prec@1 99.000 (99.571)	Prec@5 100.000 (100.000)
2019-05-08 22:22:28 - INFO - TRAINING - Epoch: [67][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0112 (0.0145)	Prec@1 100.000 (99.581)	Prec@5 100.000 (100.000)
2019-05-08 22:22:33 - INFO - EVALUATING - Epoch: [67][0/100]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.2857 (0.2857)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:22:34 - INFO - EVALUATING - Epoch: [67][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.1399 (0.3935)	Prec@1 97.000 (91.745)	Prec@5 100.000 (99.588)
2019-05-08 22:22:36 - INFO - 
 Epoch: 68	Training Loss 0.0145 	Training Prec@1 99.580 	Training Prec@5 100.000 	Validation Loss 0.3768 	Validation Prec@1 91.950 	Validation Prec@5 99.660 	
2019-05-08 22:22:36 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:22:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:22:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:22:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:22:36 - INFO - TRAINING - Epoch: [68][0/500]	Time 0.243 (0.243)	Data 0.187 (0.187)	Loss 0.0072 (0.0072)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:22:40 - INFO - TRAINING - Epoch: [68][50/500]	Time 0.084 (0.086)	Data 0.000 (0.004)	Loss 0.0025 (0.0148)	Prec@1 100.000 (99.569)	Prec@5 100.000 (100.000)
2019-05-08 22:22:44 - INFO - TRAINING - Epoch: [68][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.0210 (0.0147)	Prec@1 99.000 (99.535)	Prec@5 100.000 (100.000)
2019-05-08 22:22:48 - INFO - TRAINING - Epoch: [68][150/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0020 (0.0161)	Prec@1 100.000 (99.510)	Prec@5 100.000 (100.000)
2019-05-08 22:22:53 - INFO - TRAINING - Epoch: [68][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0038 (0.0165)	Prec@1 100.000 (99.498)	Prec@5 100.000 (100.000)
2019-05-08 22:22:57 - INFO - TRAINING - Epoch: [68][250/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0057 (0.0162)	Prec@1 100.000 (99.486)	Prec@5 100.000 (100.000)
2019-05-08 22:23:01 - INFO - TRAINING - Epoch: [68][300/500]	Time 0.071 (0.084)	Data 0.000 (0.002)	Loss 0.0027 (0.0164)	Prec@1 100.000 (99.495)	Prec@5 100.000 (100.000)
2019-05-08 22:23:05 - INFO - TRAINING - Epoch: [68][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0124 (0.0177)	Prec@1 99.000 (99.439)	Prec@5 100.000 (100.000)
2019-05-08 22:23:09 - INFO - TRAINING - Epoch: [68][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0034 (0.0175)	Prec@1 100.000 (99.449)	Prec@5 100.000 (100.000)
2019-05-08 22:23:13 - INFO - TRAINING - Epoch: [68][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0283 (0.0168)	Prec@1 99.000 (99.479)	Prec@5 100.000 (100.000)
2019-05-08 22:23:17 - INFO - EVALUATING - Epoch: [68][0/100]	Time 0.311 (0.311)	Data 0.276 (0.276)	Loss 0.3244 (0.3244)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:23:19 - INFO - EVALUATING - Epoch: [68][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.2206 (0.3624)	Prec@1 95.000 (92.078)	Prec@5 100.000 (99.490)
2019-05-08 22:23:20 - INFO - 
 Epoch: 69	Training Loss 0.0164 	Training Prec@1 99.482 	Training Prec@5 100.000 	Validation Loss 0.3451 	Validation Prec@1 92.460 	Validation Prec@5 99.570 	
2019-05-08 22:23:20 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:23:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:23:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:23:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:23:21 - INFO - TRAINING - Epoch: [69][0/500]	Time 0.260 (0.260)	Data 0.220 (0.220)	Loss 0.0107 (0.0107)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:23:25 - INFO - TRAINING - Epoch: [69][50/500]	Time 0.084 (0.087)	Data 0.000 (0.005)	Loss 0.0162 (0.0087)	Prec@1 99.000 (99.784)	Prec@5 100.000 (100.000)
2019-05-08 22:23:29 - INFO - TRAINING - Epoch: [69][100/500]	Time 0.079 (0.086)	Data 0.000 (0.003)	Loss 0.0009 (0.0092)	Prec@1 100.000 (99.752)	Prec@5 100.000 (100.000)
2019-05-08 22:23:33 - INFO - TRAINING - Epoch: [69][150/500]	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 0.0008 (0.0095)	Prec@1 100.000 (99.735)	Prec@5 100.000 (100.000)
2019-05-08 22:23:37 - INFO - TRAINING - Epoch: [69][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0014 (0.0089)	Prec@1 100.000 (99.771)	Prec@5 100.000 (100.000)
2019-05-08 22:23:41 - INFO - TRAINING - Epoch: [69][250/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0192 (0.0091)	Prec@1 99.000 (99.757)	Prec@5 100.000 (100.000)
2019-05-08 22:23:45 - INFO - TRAINING - Epoch: [69][300/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0097)	Prec@1 100.000 (99.731)	Prec@5 100.000 (100.000)
2019-05-08 22:23:49 - INFO - TRAINING - Epoch: [69][350/500]	Time 0.069 (0.083)	Data 0.000 (0.002)	Loss 0.0060 (0.0099)	Prec@1 100.000 (99.726)	Prec@5 100.000 (100.000)
2019-05-08 22:23:54 - INFO - TRAINING - Epoch: [69][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0083 (0.0101)	Prec@1 100.000 (99.723)	Prec@5 100.000 (100.000)
2019-05-08 22:23:57 - INFO - TRAINING - Epoch: [69][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0130 (0.0105)	Prec@1 99.000 (99.710)	Prec@5 100.000 (100.000)
2019-05-08 22:24:02 - INFO - EVALUATING - Epoch: [69][0/100]	Time 0.313 (0.313)	Data 0.265 (0.265)	Loss 0.5417 (0.5417)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-08 22:24:03 - INFO - EVALUATING - Epoch: [69][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.3262 (0.4043)	Prec@1 92.000 (92.353)	Prec@5 100.000 (99.529)
2019-05-08 22:24:05 - INFO - 
 Epoch: 70	Training Loss 0.0105 	Training Prec@1 99.702 	Training Prec@5 100.000 	Validation Loss 0.3788 	Validation Prec@1 92.570 	Validation Prec@5 99.630 	
2019-05-08 22:24:05 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:24:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:24:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:24:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:24:05 - INFO - TRAINING - Epoch: [70][0/500]	Time 0.266 (0.266)	Data 0.200 (0.200)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:24:09 - INFO - TRAINING - Epoch: [70][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0026 (0.0104)	Prec@1 100.000 (99.569)	Prec@5 100.000 (100.000)
2019-05-08 22:24:13 - INFO - TRAINING - Epoch: [70][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0021 (0.0104)	Prec@1 100.000 (99.554)	Prec@5 100.000 (100.000)
2019-05-08 22:24:18 - INFO - TRAINING - Epoch: [70][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0017 (0.0100)	Prec@1 100.000 (99.649)	Prec@5 100.000 (100.000)
2019-05-08 22:24:22 - INFO - TRAINING - Epoch: [70][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0095)	Prec@1 100.000 (99.677)	Prec@5 100.000 (100.000)
2019-05-08 22:24:26 - INFO - TRAINING - Epoch: [70][250/500]	Time 0.094 (0.083)	Data 0.000 (0.002)	Loss 0.0135 (0.0095)	Prec@1 99.000 (99.669)	Prec@5 100.000 (100.000)
2019-05-08 22:24:30 - INFO - TRAINING - Epoch: [70][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0078 (0.0101)	Prec@1 100.000 (99.648)	Prec@5 100.000 (100.000)
2019-05-08 22:24:34 - INFO - TRAINING - Epoch: [70][350/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0064 (0.0103)	Prec@1 100.000 (99.638)	Prec@5 100.000 (100.000)
2019-05-08 22:24:38 - INFO - TRAINING - Epoch: [70][400/500]	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 0.0225 (0.0105)	Prec@1 99.000 (99.633)	Prec@5 100.000 (100.000)
2019-05-08 22:24:42 - INFO - TRAINING - Epoch: [70][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0025 (0.0106)	Prec@1 100.000 (99.630)	Prec@5 100.000 (100.000)
2019-05-08 22:24:46 - INFO - EVALUATING - Epoch: [70][0/100]	Time 0.319 (0.319)	Data 0.292 (0.292)	Loss 0.4911 (0.4911)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:24:48 - INFO - EVALUATING - Epoch: [70][50/100]	Time 0.037 (0.033)	Data 0.000 (0.006)	Loss 0.2274 (0.4759)	Prec@1 94.000 (91.353)	Prec@5 100.000 (99.510)
2019-05-08 22:24:49 - INFO - 
 Epoch: 71	Training Loss 0.0109 	Training Prec@1 99.622 	Training Prec@5 100.000 	Validation Loss 0.4463 	Validation Prec@1 91.820 	Validation Prec@5 99.650 	
2019-05-08 22:24:49 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:24:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:24:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:24:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:24:49 - INFO - TRAINING - Epoch: [71][0/500]	Time 0.259 (0.259)	Data 0.200 (0.200)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:24:54 - INFO - TRAINING - Epoch: [71][50/500]	Time 0.079 (0.087)	Data 0.000 (0.005)	Loss 0.0116 (0.0082)	Prec@1 99.000 (99.745)	Prec@5 100.000 (100.000)
2019-05-08 22:24:58 - INFO - TRAINING - Epoch: [71][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0175 (0.0093)	Prec@1 99.000 (99.683)	Prec@5 100.000 (100.000)
2019-05-08 22:25:02 - INFO - TRAINING - Epoch: [71][150/500]	Time 0.093 (0.084)	Data 0.000 (0.002)	Loss 0.0037 (0.0094)	Prec@1 100.000 (99.682)	Prec@5 100.000 (100.000)
2019-05-08 22:25:06 - INFO - TRAINING - Epoch: [71][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0023 (0.0095)	Prec@1 100.000 (99.692)	Prec@5 100.000 (100.000)
2019-05-08 22:25:10 - INFO - TRAINING - Epoch: [71][250/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0048 (0.0096)	Prec@1 100.000 (99.685)	Prec@5 100.000 (100.000)
2019-05-08 22:25:14 - INFO - TRAINING - Epoch: [71][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0049 (0.0093)	Prec@1 100.000 (99.698)	Prec@5 100.000 (100.000)
2019-05-08 22:25:18 - INFO - TRAINING - Epoch: [71][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0010 (0.0101)	Prec@1 100.000 (99.667)	Prec@5 100.000 (100.000)
2019-05-08 22:25:23 - INFO - TRAINING - Epoch: [71][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0209 (0.0110)	Prec@1 98.000 (99.641)	Prec@5 100.000 (100.000)
2019-05-08 22:25:27 - INFO - TRAINING - Epoch: [71][450/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0091 (0.0118)	Prec@1 100.000 (99.623)	Prec@5 100.000 (100.000)
2019-05-08 22:25:31 - INFO - EVALUATING - Epoch: [71][0/100]	Time 0.299 (0.299)	Data 0.273 (0.273)	Loss 0.4167 (0.4167)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:25:32 - INFO - EVALUATING - Epoch: [71][50/100]	Time 0.043 (0.033)	Data 0.000 (0.006)	Loss 0.1736 (0.3840)	Prec@1 95.000 (92.000)	Prec@5 100.000 (99.608)
2019-05-08 22:25:34 - INFO - 
 Epoch: 72	Training Loss 0.0126 	Training Prec@1 99.600 	Training Prec@5 100.000 	Validation Loss 0.3599 	Validation Prec@1 92.380 	Validation Prec@5 99.660 	
2019-05-08 22:25:34 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:25:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:25:34 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:25:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:25:34 - INFO - TRAINING - Epoch: [72][0/500]	Time 0.231 (0.231)	Data 0.177 (0.177)	Loss 0.0149 (0.0149)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:25:38 - INFO - TRAINING - Epoch: [72][50/500]	Time 0.090 (0.083)	Data 0.000 (0.004)	Loss 0.0055 (0.0083)	Prec@1 100.000 (99.765)	Prec@5 100.000 (100.000)
2019-05-08 22:25:42 - INFO - TRAINING - Epoch: [72][100/500]	Time 0.085 (0.082)	Data 0.000 (0.003)	Loss 0.0212 (0.0110)	Prec@1 99.000 (99.663)	Prec@5 100.000 (100.000)
2019-05-08 22:25:46 - INFO - TRAINING - Epoch: [72][150/500]	Time 0.072 (0.082)	Data 0.000 (0.002)	Loss 0.0198 (0.0108)	Prec@1 99.000 (99.689)	Prec@5 100.000 (100.000)
2019-05-08 22:25:50 - INFO - TRAINING - Epoch: [72][200/500]	Time 0.078 (0.081)	Data 0.000 (0.002)	Loss 0.0062 (0.0106)	Prec@1 100.000 (99.692)	Prec@5 100.000 (100.000)
2019-05-08 22:25:54 - INFO - TRAINING - Epoch: [72][250/500]	Time 0.079 (0.081)	Data 0.000 (0.002)	Loss 0.0407 (0.0111)	Prec@1 98.000 (99.673)	Prec@5 100.000 (100.000)
2019-05-08 22:25:58 - INFO - TRAINING - Epoch: [72][300/500]	Time 0.075 (0.081)	Data 0.000 (0.001)	Loss 0.0082 (0.0117)	Prec@1 100.000 (99.661)	Prec@5 100.000 (100.000)
2019-05-08 22:26:02 - INFO - TRAINING - Epoch: [72][350/500]	Time 0.087 (0.081)	Data 0.000 (0.001)	Loss 0.0055 (0.0120)	Prec@1 100.000 (99.647)	Prec@5 100.000 (100.000)
2019-05-08 22:26:06 - INFO - TRAINING - Epoch: [72][400/500]	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 0.0015 (0.0120)	Prec@1 100.000 (99.641)	Prec@5 100.000 (100.000)
2019-05-08 22:26:11 - INFO - TRAINING - Epoch: [72][450/500]	Time 0.054 (0.081)	Data 0.000 (0.001)	Loss 0.0054 (0.0120)	Prec@1 100.000 (99.634)	Prec@5 100.000 (100.000)
2019-05-08 22:26:15 - INFO - EVALUATING - Epoch: [72][0/100]	Time 0.317 (0.317)	Data 0.272 (0.272)	Loss 0.4153 (0.4153)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 22:26:16 - INFO - EVALUATING - Epoch: [72][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1448 (0.4124)	Prec@1 96.000 (91.902)	Prec@5 100.000 (99.686)
2019-05-08 22:26:17 - INFO - 
 Epoch: 73	Training Loss 0.0122 	Training Prec@1 99.626 	Training Prec@5 100.000 	Validation Loss 0.3994 	Validation Prec@1 91.710 	Validation Prec@5 99.730 	
2019-05-08 22:26:18 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:26:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:26:18 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:26:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:26:18 - INFO - TRAINING - Epoch: [73][0/500]	Time 0.253 (0.253)	Data 0.210 (0.210)	Loss 0.0224 (0.0224)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:26:22 - INFO - TRAINING - Epoch: [73][50/500]	Time 0.078 (0.085)	Data 0.000 (0.005)	Loss 0.0041 (0.0116)	Prec@1 100.000 (99.627)	Prec@5 100.000 (100.000)
2019-05-08 22:26:26 - INFO - TRAINING - Epoch: [73][100/500]	Time 0.080 (0.085)	Data 0.000 (0.003)	Loss 0.0032 (0.0109)	Prec@1 100.000 (99.653)	Prec@5 100.000 (100.000)
2019-05-08 22:26:30 - INFO - TRAINING - Epoch: [73][150/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0047 (0.0106)	Prec@1 100.000 (99.682)	Prec@5 100.000 (100.000)
2019-05-08 22:26:34 - INFO - TRAINING - Epoch: [73][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0114 (0.0102)	Prec@1 99.000 (99.697)	Prec@5 100.000 (100.000)
2019-05-08 22:26:38 - INFO - TRAINING - Epoch: [73][250/500]	Time 0.074 (0.082)	Data 0.000 (0.002)	Loss 0.0022 (0.0105)	Prec@1 100.000 (99.681)	Prec@5 100.000 (100.000)
2019-05-08 22:26:42 - INFO - TRAINING - Epoch: [73][300/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0202 (0.0103)	Prec@1 99.000 (99.698)	Prec@5 100.000 (100.000)
2019-05-08 22:26:46 - INFO - TRAINING - Epoch: [73][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0159 (0.0106)	Prec@1 99.000 (99.689)	Prec@5 100.000 (100.000)
2019-05-08 22:26:51 - INFO - TRAINING - Epoch: [73][400/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0103 (0.0105)	Prec@1 100.000 (99.688)	Prec@5 100.000 (100.000)
2019-05-08 22:26:55 - INFO - TRAINING - Epoch: [73][450/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0066 (0.0111)	Prec@1 100.000 (99.663)	Prec@5 100.000 (100.000)
2019-05-08 22:26:59 - INFO - EVALUATING - Epoch: [73][0/100]	Time 0.301 (0.301)	Data 0.273 (0.273)	Loss 0.3724 (0.3724)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-08 22:27:00 - INFO - EVALUATING - Epoch: [73][50/100]	Time 0.025 (0.033)	Data 0.000 (0.006)	Loss 0.3415 (0.4082)	Prec@1 93.000 (92.039)	Prec@5 100.000 (99.471)
2019-05-08 22:27:02 - INFO - 
 Epoch: 74	Training Loss 0.0110 	Training Prec@1 99.674 	Training Prec@5 100.000 	Validation Loss 0.3821 	Validation Prec@1 92.360 	Validation Prec@5 99.600 	
2019-05-08 22:27:02 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:27:02 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:27:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:27:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:27:02 - INFO - TRAINING - Epoch: [74][0/500]	Time 0.255 (0.255)	Data 0.214 (0.214)	Loss 0.0070 (0.0070)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:27:06 - INFO - TRAINING - Epoch: [74][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.0007 (0.0103)	Prec@1 100.000 (99.686)	Prec@5 100.000 (100.000)
2019-05-08 22:27:10 - INFO - TRAINING - Epoch: [74][100/500]	Time 0.081 (0.083)	Data 0.000 (0.003)	Loss 0.0058 (0.0106)	Prec@1 100.000 (99.644)	Prec@5 100.000 (100.000)
2019-05-08 22:27:14 - INFO - TRAINING - Epoch: [74][150/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0186 (0.0112)	Prec@1 99.000 (99.636)	Prec@5 100.000 (100.000)
2019-05-08 22:27:18 - INFO - TRAINING - Epoch: [74][200/500]	Time 0.069 (0.082)	Data 0.000 (0.002)	Loss 0.0040 (0.0110)	Prec@1 100.000 (99.652)	Prec@5 100.000 (100.000)
2019-05-08 22:27:22 - INFO - TRAINING - Epoch: [74][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0131 (0.0105)	Prec@1 99.000 (99.673)	Prec@5 100.000 (100.000)
2019-05-08 22:27:27 - INFO - TRAINING - Epoch: [74][300/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0006 (0.0105)	Prec@1 100.000 (99.691)	Prec@5 100.000 (100.000)
2019-05-08 22:27:31 - INFO - TRAINING - Epoch: [74][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0139 (0.0103)	Prec@1 99.000 (99.692)	Prec@5 100.000 (100.000)
2019-05-08 22:27:35 - INFO - TRAINING - Epoch: [74][400/500]	Time 0.065 (0.082)	Data 0.000 (0.001)	Loss 0.0507 (0.0099)	Prec@1 98.000 (99.701)	Prec@5 100.000 (100.000)
2019-05-08 22:27:39 - INFO - TRAINING - Epoch: [74][450/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0096)	Prec@1 100.000 (99.716)	Prec@5 100.000 (100.000)
2019-05-08 22:27:43 - INFO - EVALUATING - Epoch: [74][0/100]	Time 0.327 (0.327)	Data 0.286 (0.286)	Loss 0.3755 (0.3755)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-08 22:27:45 - INFO - EVALUATING - Epoch: [74][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.3387 (0.4042)	Prec@1 95.000 (92.039)	Prec@5 100.000 (99.294)
2019-05-08 22:27:46 - INFO - 
 Epoch: 75	Training Loss 0.0099 	Training Prec@1 99.698 	Training Prec@5 100.000 	Validation Loss 0.3832 	Validation Prec@1 92.400 	Validation Prec@5 99.540 	
2019-05-08 22:27:46 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:27:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:27:46 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:27:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:27:46 - INFO - TRAINING - Epoch: [75][0/500]	Time 0.281 (0.281)	Data 0.214 (0.214)	Loss 0.0231 (0.0231)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-08 22:27:50 - INFO - TRAINING - Epoch: [75][50/500]	Time 0.086 (0.084)	Data 0.000 (0.004)	Loss 0.0084 (0.0093)	Prec@1 100.000 (99.706)	Prec@5 100.000 (100.000)
2019-05-08 22:27:55 - INFO - TRAINING - Epoch: [75][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0055 (0.0088)	Prec@1 100.000 (99.713)	Prec@5 100.000 (100.000)
2019-05-08 22:27:59 - INFO - TRAINING - Epoch: [75][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0117 (0.0093)	Prec@1 100.000 (99.695)	Prec@5 100.000 (100.000)
2019-05-08 22:28:03 - INFO - TRAINING - Epoch: [75][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0139 (0.0093)	Prec@1 99.000 (99.692)	Prec@5 100.000 (100.000)
2019-05-08 22:28:07 - INFO - TRAINING - Epoch: [75][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0078 (0.0096)	Prec@1 100.000 (99.677)	Prec@5 100.000 (100.000)
2019-05-08 22:28:11 - INFO - TRAINING - Epoch: [75][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0071 (0.0097)	Prec@1 100.000 (99.688)	Prec@5 100.000 (100.000)
2019-05-08 22:28:15 - INFO - TRAINING - Epoch: [75][350/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0089 (0.0101)	Prec@1 99.000 (99.658)	Prec@5 100.000 (100.000)
2019-05-08 22:28:19 - INFO - TRAINING - Epoch: [75][400/500]	Time 0.072 (0.083)	Data 0.000 (0.001)	Loss 0.0052 (0.0103)	Prec@1 100.000 (99.658)	Prec@5 100.000 (100.000)
2019-05-08 22:28:23 - INFO - TRAINING - Epoch: [75][450/500]	Time 0.077 (0.082)	Data 0.000 (0.001)	Loss 0.0019 (0.0106)	Prec@1 100.000 (99.647)	Prec@5 100.000 (100.000)
2019-05-08 22:28:27 - INFO - EVALUATING - Epoch: [75][0/100]	Time 0.322 (0.322)	Data 0.270 (0.270)	Loss 0.4041 (0.4041)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:28:29 - INFO - EVALUATING - Epoch: [75][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.2040 (0.3857)	Prec@1 93.000 (91.863)	Prec@5 100.000 (99.569)
2019-05-08 22:28:30 - INFO - 
 Epoch: 76	Training Loss 0.0106 	Training Prec@1 99.652 	Training Prec@5 100.000 	Validation Loss 0.3644 	Validation Prec@1 92.200 	Validation Prec@5 99.660 	
2019-05-08 22:28:30 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:28:30 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:28:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:28:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:28:31 - INFO - TRAINING - Epoch: [76][0/500]	Time 0.295 (0.295)	Data 0.229 (0.229)	Loss 0.0035 (0.0035)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:28:35 - INFO - TRAINING - Epoch: [76][50/500]	Time 0.081 (0.085)	Data 0.000 (0.005)	Loss 0.0015 (0.0081)	Prec@1 100.000 (99.765)	Prec@5 100.000 (100.000)
2019-05-08 22:28:39 - INFO - TRAINING - Epoch: [76][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0213 (0.0088)	Prec@1 99.000 (99.713)	Prec@5 100.000 (100.000)
2019-05-08 22:28:43 - INFO - TRAINING - Epoch: [76][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0021 (0.0093)	Prec@1 100.000 (99.715)	Prec@5 100.000 (100.000)
2019-05-08 22:28:47 - INFO - TRAINING - Epoch: [76][200/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0078 (0.0101)	Prec@1 100.000 (99.692)	Prec@5 100.000 (100.000)
2019-05-08 22:28:51 - INFO - TRAINING - Epoch: [76][250/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0093 (0.0107)	Prec@1 100.000 (99.665)	Prec@5 100.000 (100.000)
2019-05-08 22:28:55 - INFO - TRAINING - Epoch: [76][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0089 (0.0109)	Prec@1 100.000 (99.668)	Prec@5 100.000 (100.000)
2019-05-08 22:28:59 - INFO - TRAINING - Epoch: [76][350/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0150 (0.0106)	Prec@1 99.000 (99.675)	Prec@5 100.000 (100.000)
2019-05-08 22:29:03 - INFO - TRAINING - Epoch: [76][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0047 (0.0104)	Prec@1 100.000 (99.676)	Prec@5 100.000 (100.000)
2019-05-08 22:29:07 - INFO - TRAINING - Epoch: [76][450/500]	Time 0.069 (0.082)	Data 0.000 (0.001)	Loss 0.0245 (0.0104)	Prec@1 99.000 (99.676)	Prec@5 100.000 (100.000)
2019-05-08 22:29:12 - INFO - EVALUATING - Epoch: [76][0/100]	Time 0.301 (0.301)	Data 0.276 (0.276)	Loss 0.4278 (0.4278)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:29:13 - INFO - EVALUATING - Epoch: [76][50/100]	Time 0.029 (0.033)	Data 0.001 (0.006)	Loss 0.1156 (0.4266)	Prec@1 97.000 (91.706)	Prec@5 100.000 (99.529)
2019-05-08 22:29:14 - INFO - 
 Epoch: 77	Training Loss 0.0103 	Training Prec@1 99.682 	Training Prec@5 100.000 	Validation Loss 0.4066 	Validation Prec@1 91.880 	Validation Prec@5 99.670 	
2019-05-08 22:29:14 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:29:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:29:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:29:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:29:15 - INFO - TRAINING - Epoch: [77][0/500]	Time 0.258 (0.258)	Data 0.201 (0.201)	Loss 0.0038 (0.0038)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:29:19 - INFO - TRAINING - Epoch: [77][50/500]	Time 0.080 (0.086)	Data 0.000 (0.005)	Loss 0.0009 (0.0089)	Prec@1 100.000 (99.686)	Prec@5 100.000 (100.000)
2019-05-08 22:29:23 - INFO - TRAINING - Epoch: [77][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0408 (0.0120)	Prec@1 98.000 (99.535)	Prec@5 100.000 (100.000)
2019-05-08 22:29:27 - INFO - TRAINING - Epoch: [77][150/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0133 (0.0121)	Prec@1 99.000 (99.576)	Prec@5 100.000 (100.000)
2019-05-08 22:29:31 - INFO - TRAINING - Epoch: [77][200/500]	Time 0.095 (0.084)	Data 0.000 (0.002)	Loss 0.0049 (0.0121)	Prec@1 100.000 (99.587)	Prec@5 100.000 (100.000)
2019-05-08 22:29:35 - INFO - TRAINING - Epoch: [77][250/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.0020 (0.0116)	Prec@1 100.000 (99.602)	Prec@5 100.000 (100.000)
2019-05-08 22:29:40 - INFO - TRAINING - Epoch: [77][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0167 (0.0117)	Prec@1 99.000 (99.601)	Prec@5 100.000 (100.000)
2019-05-08 22:29:44 - INFO - TRAINING - Epoch: [77][350/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0525 (0.0117)	Prec@1 99.000 (99.604)	Prec@5 100.000 (100.000)
2019-05-08 22:29:48 - INFO - TRAINING - Epoch: [77][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0082 (0.0116)	Prec@1 100.000 (99.606)	Prec@5 100.000 (100.000)
2019-05-08 22:29:52 - INFO - TRAINING - Epoch: [77][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0254 (0.0119)	Prec@1 99.000 (99.588)	Prec@5 100.000 (100.000)
2019-05-08 22:29:56 - INFO - EVALUATING - Epoch: [77][0/100]	Time 0.308 (0.308)	Data 0.283 (0.283)	Loss 0.3879 (0.3879)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:29:58 - INFO - EVALUATING - Epoch: [77][50/100]	Time 0.037 (0.033)	Data 0.000 (0.006)	Loss 0.1589 (0.4341)	Prec@1 95.000 (92.059)	Prec@5 100.000 (99.373)
2019-05-08 22:29:59 - INFO - 
 Epoch: 78	Training Loss 0.0120 	Training Prec@1 99.588 	Training Prec@5 100.000 	Validation Loss 0.3956 	Validation Prec@1 92.270 	Validation Prec@5 99.610 	
2019-05-08 22:29:59 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:29:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:29:59 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:29:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:30:00 - INFO - TRAINING - Epoch: [78][0/500]	Time 0.268 (0.268)	Data 0.198 (0.198)	Loss 0.0534 (0.0534)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 22:30:04 - INFO - TRAINING - Epoch: [78][50/500]	Time 0.084 (0.084)	Data 0.000 (0.004)	Loss 0.0288 (0.0098)	Prec@1 99.000 (99.667)	Prec@5 100.000 (100.000)
2019-05-08 22:30:08 - INFO - TRAINING - Epoch: [78][100/500]	Time 0.085 (0.083)	Data 0.000 (0.003)	Loss 0.0034 (0.0111)	Prec@1 100.000 (99.604)	Prec@5 100.000 (100.000)
2019-05-08 22:30:12 - INFO - TRAINING - Epoch: [78][150/500]	Time 0.091 (0.082)	Data 0.000 (0.002)	Loss 0.0388 (0.0119)	Prec@1 97.000 (99.609)	Prec@5 100.000 (100.000)
2019-05-08 22:30:16 - INFO - TRAINING - Epoch: [78][200/500]	Time 0.087 (0.081)	Data 0.000 (0.002)	Loss 0.0056 (0.0127)	Prec@1 100.000 (99.582)	Prec@5 100.000 (100.000)
2019-05-08 22:30:20 - INFO - TRAINING - Epoch: [78][250/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0112 (0.0119)	Prec@1 100.000 (99.618)	Prec@5 100.000 (100.000)
2019-05-08 22:30:24 - INFO - TRAINING - Epoch: [78][300/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0009 (0.0118)	Prec@1 100.000 (99.628)	Prec@5 100.000 (100.000)
2019-05-08 22:30:28 - INFO - TRAINING - Epoch: [78][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0046 (0.0117)	Prec@1 100.000 (99.632)	Prec@5 100.000 (100.000)
2019-05-08 22:30:32 - INFO - TRAINING - Epoch: [78][400/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0127 (0.0118)	Prec@1 100.000 (99.628)	Prec@5 100.000 (100.000)
2019-05-08 22:30:36 - INFO - TRAINING - Epoch: [78][450/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0018 (0.0115)	Prec@1 100.000 (99.632)	Prec@5 100.000 (100.000)
2019-05-08 22:30:41 - INFO - EVALUATING - Epoch: [78][0/100]	Time 0.300 (0.300)	Data 0.275 (0.275)	Loss 0.4759 (0.4759)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:30:42 - INFO - EVALUATING - Epoch: [78][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.1636 (0.4272)	Prec@1 96.000 (92.078)	Prec@5 100.000 (99.588)
2019-05-08 22:30:44 - INFO - 
 Epoch: 79	Training Loss 0.0112 	Training Prec@1 99.644 	Training Prec@5 100.000 	Validation Loss 0.4087 	Validation Prec@1 92.340 	Validation Prec@5 99.670 	
2019-05-08 22:30:44 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:30:44 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:30:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:30:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:30:44 - INFO - TRAINING - Epoch: [79][0/500]	Time 0.274 (0.274)	Data 0.221 (0.221)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:30:48 - INFO - TRAINING - Epoch: [79][50/500]	Time 0.086 (0.086)	Data 0.000 (0.005)	Loss 0.0081 (0.0090)	Prec@1 100.000 (99.706)	Prec@5 100.000 (100.000)
2019-05-08 22:30:52 - INFO - TRAINING - Epoch: [79][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0061 (0.0079)	Prec@1 100.000 (99.743)	Prec@5 100.000 (100.000)
2019-05-08 22:30:56 - INFO - TRAINING - Epoch: [79][150/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0007 (0.0078)	Prec@1 100.000 (99.775)	Prec@5 100.000 (100.000)
2019-05-08 22:31:00 - INFO - TRAINING - Epoch: [79][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0325 (0.0079)	Prec@1 99.000 (99.766)	Prec@5 100.000 (100.000)
2019-05-08 22:31:04 - INFO - TRAINING - Epoch: [79][250/500]	Time 0.069 (0.082)	Data 0.000 (0.002)	Loss 0.0037 (0.0096)	Prec@1 100.000 (99.717)	Prec@5 100.000 (100.000)
2019-05-08 22:31:08 - INFO - TRAINING - Epoch: [79][300/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0022 (0.0094)	Prec@1 100.000 (99.724)	Prec@5 100.000 (100.000)
2019-05-08 22:31:13 - INFO - TRAINING - Epoch: [79][350/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0014 (0.0093)	Prec@1 100.000 (99.721)	Prec@5 100.000 (100.000)
2019-05-08 22:31:17 - INFO - TRAINING - Epoch: [79][400/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0028 (0.0092)	Prec@1 100.000 (99.728)	Prec@5 100.000 (100.000)
2019-05-08 22:31:21 - INFO - TRAINING - Epoch: [79][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0042 (0.0097)	Prec@1 100.000 (99.707)	Prec@5 100.000 (100.000)
2019-05-08 22:31:25 - INFO - EVALUATING - Epoch: [79][0/100]	Time 0.296 (0.296)	Data 0.271 (0.271)	Loss 0.3934 (0.3934)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:31:27 - INFO - EVALUATING - Epoch: [79][50/100]	Time 0.027 (0.034)	Data 0.000 (0.006)	Loss 0.1895 (0.4117)	Prec@1 94.000 (91.961)	Prec@5 100.000 (99.353)
2019-05-08 22:31:28 - INFO - 
 Epoch: 80	Training Loss 0.0095 	Training Prec@1 99.718 	Training Prec@5 100.000 	Validation Loss 0.3754 	Validation Prec@1 92.330 	Validation Prec@5 99.570 	
2019-05-08 22:31:28 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:31:28 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:31:28 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:31:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:31:28 - INFO - TRAINING - Epoch: [80][0/500]	Time 0.286 (0.286)	Data 0.219 (0.219)	Loss 0.0027 (0.0027)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:31:32 - INFO - TRAINING - Epoch: [80][50/500]	Time 0.088 (0.086)	Data 0.000 (0.005)	Loss 0.0056 (0.0063)	Prec@1 100.000 (99.824)	Prec@5 100.000 (100.000)
2019-05-08 22:31:36 - INFO - TRAINING - Epoch: [80][100/500]	Time 0.092 (0.083)	Data 0.000 (0.003)	Loss 0.0007 (0.0077)	Prec@1 100.000 (99.752)	Prec@5 100.000 (100.000)
2019-05-08 22:31:41 - INFO - TRAINING - Epoch: [80][150/500]	Time 0.073 (0.083)	Data 0.000 (0.002)	Loss 0.0407 (0.0072)	Prec@1 98.000 (99.788)	Prec@5 100.000 (100.000)
2019-05-08 22:31:45 - INFO - TRAINING - Epoch: [80][200/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0034 (0.0075)	Prec@1 100.000 (99.791)	Prec@5 100.000 (100.000)
2019-05-08 22:31:49 - INFO - TRAINING - Epoch: [80][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0246 (0.0076)	Prec@1 99.000 (99.769)	Prec@5 100.000 (100.000)
2019-05-08 22:31:53 - INFO - TRAINING - Epoch: [80][300/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0276 (0.0081)	Prec@1 98.000 (99.748)	Prec@5 100.000 (100.000)
2019-05-08 22:31:57 - INFO - TRAINING - Epoch: [80][350/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0081 (0.0085)	Prec@1 100.000 (99.749)	Prec@5 100.000 (100.000)
2019-05-08 22:32:01 - INFO - TRAINING - Epoch: [80][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0076 (0.0090)	Prec@1 100.000 (99.723)	Prec@5 100.000 (100.000)
2019-05-08 22:32:05 - INFO - TRAINING - Epoch: [80][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0114 (0.0096)	Prec@1 100.000 (99.701)	Prec@5 100.000 (100.000)
2019-05-08 22:32:10 - INFO - EVALUATING - Epoch: [80][0/100]	Time 0.292 (0.292)	Data 0.265 (0.265)	Loss 0.3959 (0.3959)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:32:11 - INFO - EVALUATING - Epoch: [80][50/100]	Time 0.029 (0.032)	Data 0.000 (0.006)	Loss 0.2607 (0.4292)	Prec@1 95.000 (92.078)	Prec@5 100.000 (99.569)
2019-05-08 22:32:12 - INFO - 
 Epoch: 81	Training Loss 0.0095 	Training Prec@1 99.704 	Training Prec@5 100.000 	Validation Loss 0.3946 	Validation Prec@1 92.580 	Validation Prec@5 99.650 	
2019-05-08 22:32:13 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:32:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:32:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:32:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:32:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:32:13 - INFO - TRAINING - Epoch: [81][0/500]	Time 0.266 (0.266)	Data 0.195 (0.195)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:32:17 - INFO - TRAINING - Epoch: [81][50/500]	Time 0.082 (0.081)	Data 0.000 (0.004)	Loss 0.0016 (0.0062)	Prec@1 100.000 (99.863)	Prec@5 100.000 (100.000)
2019-05-08 22:32:21 - INFO - TRAINING - Epoch: [81][100/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0070)	Prec@1 100.000 (99.822)	Prec@5 100.000 (100.000)
2019-05-08 22:32:25 - INFO - TRAINING - Epoch: [81][150/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0031 (0.0061)	Prec@1 100.000 (99.848)	Prec@5 100.000 (100.000)
2019-05-08 22:32:29 - INFO - TRAINING - Epoch: [81][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0044 (0.0061)	Prec@1 100.000 (99.861)	Prec@5 100.000 (100.000)
2019-05-08 22:32:33 - INFO - TRAINING - Epoch: [81][250/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0010 (0.0056)	Prec@1 100.000 (99.865)	Prec@5 100.000 (100.000)
2019-05-08 22:32:37 - INFO - TRAINING - Epoch: [81][300/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0193 (0.0053)	Prec@1 99.000 (99.867)	Prec@5 100.000 (100.000)
2019-05-08 22:32:41 - INFO - TRAINING - Epoch: [81][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0050)	Prec@1 100.000 (99.875)	Prec@5 100.000 (100.000)
2019-05-08 22:32:45 - INFO - TRAINING - Epoch: [81][400/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0030 (0.0047)	Prec@1 100.000 (99.883)	Prec@5 100.000 (100.000)
2019-05-08 22:32:49 - INFO - TRAINING - Epoch: [81][450/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0037 (0.0047)	Prec@1 100.000 (99.880)	Prec@5 100.000 (100.000)
2019-05-08 22:32:54 - INFO - EVALUATING - Epoch: [81][0/100]	Time 0.296 (0.296)	Data 0.271 (0.271)	Loss 0.3509 (0.3509)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-08 22:32:55 - INFO - EVALUATING - Epoch: [81][50/100]	Time 0.024 (0.032)	Data 0.000 (0.006)	Loss 0.2025 (0.3737)	Prec@1 95.000 (92.725)	Prec@5 100.000 (99.549)
2019-05-08 22:32:56 - INFO - 
 Epoch: 82	Training Loss 0.0047 	Training Prec@1 99.874 	Training Prec@5 100.000 	Validation Loss 0.3446 	Validation Prec@1 93.160 	Validation Prec@5 99.680 	
2019-05-08 22:32:57 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:32:57 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:32:57 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:32:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:32:57 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:32:57 - INFO - TRAINING - Epoch: [82][0/500]	Time 0.256 (0.256)	Data 0.197 (0.197)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:33:01 - INFO - TRAINING - Epoch: [82][50/500]	Time 0.082 (0.082)	Data 0.000 (0.005)	Loss 0.0005 (0.0041)	Prec@1 100.000 (99.902)	Prec@5 100.000 (100.000)
2019-05-08 22:33:05 - INFO - TRAINING - Epoch: [82][100/500]	Time 0.086 (0.081)	Data 0.000 (0.003)	Loss 0.0059 (0.0036)	Prec@1 100.000 (99.921)	Prec@5 100.000 (100.000)
2019-05-08 22:33:09 - INFO - TRAINING - Epoch: [82][150/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0039 (0.0035)	Prec@1 100.000 (99.914)	Prec@5 100.000 (100.000)
2019-05-08 22:33:13 - INFO - TRAINING - Epoch: [82][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0033 (0.0035)	Prec@1 100.000 (99.915)	Prec@5 100.000 (100.000)
2019-05-08 22:33:17 - INFO - TRAINING - Epoch: [82][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0035)	Prec@1 100.000 (99.924)	Prec@5 100.000 (100.000)
2019-05-08 22:33:21 - INFO - TRAINING - Epoch: [82][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0061 (0.0034)	Prec@1 100.000 (99.930)	Prec@5 100.000 (100.000)
2019-05-08 22:33:26 - INFO - TRAINING - Epoch: [82][350/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0050 (0.0034)	Prec@1 100.000 (99.923)	Prec@5 100.000 (100.000)
2019-05-08 22:33:30 - INFO - TRAINING - Epoch: [82][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0038 (0.0032)	Prec@1 100.000 (99.925)	Prec@5 100.000 (100.000)
2019-05-08 22:33:34 - INFO - TRAINING - Epoch: [82][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0031)	Prec@1 100.000 (99.931)	Prec@5 100.000 (100.000)
2019-05-08 22:33:38 - INFO - EVALUATING - Epoch: [82][0/100]	Time 0.303 (0.303)	Data 0.278 (0.278)	Loss 0.3732 (0.3732)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:33:40 - INFO - EVALUATING - Epoch: [82][50/100]	Time 0.023 (0.033)	Data 0.001 (0.006)	Loss 0.1899 (0.3716)	Prec@1 95.000 (92.725)	Prec@5 100.000 (99.569)
2019-05-08 22:33:41 - INFO - 
 Epoch: 83	Training Loss 0.0030 	Training Prec@1 99.934 	Training Prec@5 100.000 	Validation Loss 0.3470 	Validation Prec@1 93.070 	Validation Prec@5 99.690 	
2019-05-08 22:33:41 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:33:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:33:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:33:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:33:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:33:41 - INFO - TRAINING - Epoch: [83][0/500]	Time 0.249 (0.249)	Data 0.182 (0.182)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:33:46 - INFO - TRAINING - Epoch: [83][50/500]	Time 0.080 (0.086)	Data 0.000 (0.004)	Loss 0.0002 (0.0024)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 22:33:50 - INFO - TRAINING - Epoch: [83][100/500]	Time 0.085 (0.084)	Data 0.000 (0.003)	Loss 0.0012 (0.0031)	Prec@1 100.000 (99.950)	Prec@5 100.000 (100.000)
2019-05-08 22:33:54 - INFO - TRAINING - Epoch: [83][150/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0018 (0.0031)	Prec@1 100.000 (99.927)	Prec@5 100.000 (100.000)
2019-05-08 22:33:58 - INFO - TRAINING - Epoch: [83][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0007 (0.0031)	Prec@1 100.000 (99.925)	Prec@5 100.000 (100.000)
2019-05-08 22:34:02 - INFO - TRAINING - Epoch: [83][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0030)	Prec@1 100.000 (99.928)	Prec@5 100.000 (100.000)
2019-05-08 22:34:06 - INFO - TRAINING - Epoch: [83][300/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0028)	Prec@1 100.000 (99.934)	Prec@5 100.000 (100.000)
2019-05-08 22:34:10 - INFO - TRAINING - Epoch: [83][350/500]	Time 0.072 (0.082)	Data 0.000 (0.001)	Loss 0.0020 (0.0027)	Prec@1 100.000 (99.940)	Prec@5 100.000 (100.000)
2019-05-08 22:34:14 - INFO - TRAINING - Epoch: [83][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0008 (0.0026)	Prec@1 100.000 (99.948)	Prec@5 100.000 (100.000)
2019-05-08 22:34:18 - INFO - TRAINING - Epoch: [83][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0018 (0.0026)	Prec@1 100.000 (99.945)	Prec@5 100.000 (100.000)
2019-05-08 22:34:23 - INFO - EVALUATING - Epoch: [83][0/100]	Time 0.296 (0.296)	Data 0.270 (0.270)	Loss 0.3459 (0.3459)	Prec@1 95.000 (95.000)	Prec@5 99.000 (99.000)
2019-05-08 22:34:24 - INFO - EVALUATING - Epoch: [83][50/100]	Time 0.032 (0.033)	Data 0.001 (0.006)	Loss 0.1616 (0.3689)	Prec@1 96.000 (92.804)	Prec@5 100.000 (99.608)
2019-05-08 22:34:25 - INFO - 
 Epoch: 84	Training Loss 0.0026 	Training Prec@1 99.946 	Training Prec@5 100.000 	Validation Loss 0.3429 	Validation Prec@1 93.140 	Validation Prec@5 99.670 	
2019-05-08 22:34:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:34:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:34:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:34:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:34:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:34:26 - INFO - TRAINING - Epoch: [84][0/500]	Time 0.260 (0.260)	Data 0.216 (0.216)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:34:30 - INFO - TRAINING - Epoch: [84][50/500]	Time 0.085 (0.085)	Data 0.000 (0.005)	Loss 0.0004 (0.0015)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 22:34:34 - INFO - TRAINING - Epoch: [84][100/500]	Time 0.070 (0.084)	Data 0.000 (0.003)	Loss 0.0004 (0.0015)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:34:38 - INFO - TRAINING - Epoch: [84][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0017)	Prec@1 100.000 (99.967)	Prec@5 100.000 (100.000)
2019-05-08 22:34:43 - INFO - TRAINING - Epoch: [84][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0036 (0.0017)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:34:47 - INFO - TRAINING - Epoch: [84][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0017)	Prec@1 100.000 (99.964)	Prec@5 100.000 (100.000)
2019-05-08 22:34:51 - INFO - TRAINING - Epoch: [84][300/500]	Time 0.092 (0.084)	Data 0.000 (0.002)	Loss 0.0013 (0.0018)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:34:55 - INFO - TRAINING - Epoch: [84][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0021 (0.0018)	Prec@1 100.000 (99.957)	Prec@5 100.000 (100.000)
2019-05-08 22:34:59 - INFO - TRAINING - Epoch: [84][400/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0019)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:35:03 - INFO - TRAINING - Epoch: [84][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0009 (0.0018)	Prec@1 100.000 (99.962)	Prec@5 100.000 (100.000)
2019-05-08 22:35:07 - INFO - EVALUATING - Epoch: [84][0/100]	Time 0.334 (0.334)	Data 0.290 (0.290)	Loss 0.3524 (0.3524)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:35:09 - INFO - EVALUATING - Epoch: [84][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.2072 (0.3616)	Prec@1 95.000 (92.627)	Prec@5 100.000 (99.588)
2019-05-08 22:35:10 - INFO - 
 Epoch: 85	Training Loss 0.0019 	Training Prec@1 99.958 	Training Prec@5 100.000 	Validation Loss 0.3384 	Validation Prec@1 93.040 	Validation Prec@5 99.710 	
2019-05-08 22:35:10 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:35:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:35:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:35:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:35:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:35:11 - INFO - TRAINING - Epoch: [85][0/500]	Time 0.290 (0.290)	Data 0.225 (0.225)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:35:15 - INFO - TRAINING - Epoch: [85][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.0023 (0.0017)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:35:19 - INFO - TRAINING - Epoch: [85][100/500]	Time 0.093 (0.083)	Data 0.000 (0.003)	Loss 0.0005 (0.0020)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:35:23 - INFO - TRAINING - Epoch: [85][150/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0025 (0.0018)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:35:27 - INFO - TRAINING - Epoch: [85][200/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0019)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:35:31 - INFO - TRAINING - Epoch: [85][250/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0019)	Prec@1 100.000 (99.964)	Prec@5 100.000 (100.000)
2019-05-08 22:35:35 - INFO - TRAINING - Epoch: [85][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0020)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:35:39 - INFO - TRAINING - Epoch: [85][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0007 (0.0019)	Prec@1 100.000 (99.966)	Prec@5 100.000 (100.000)
2019-05-08 22:35:44 - INFO - TRAINING - Epoch: [85][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0019)	Prec@1 100.000 (99.968)	Prec@5 100.000 (100.000)
2019-05-08 22:35:48 - INFO - TRAINING - Epoch: [85][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0021)	Prec@1 100.000 (99.962)	Prec@5 100.000 (100.000)
2019-05-08 22:35:52 - INFO - EVALUATING - Epoch: [85][0/100]	Time 0.299 (0.299)	Data 0.273 (0.273)	Loss 0.3508 (0.3508)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:35:53 - INFO - EVALUATING - Epoch: [85][50/100]	Time 0.026 (0.033)	Data 0.000 (0.006)	Loss 0.2382 (0.3700)	Prec@1 95.000 (92.941)	Prec@5 100.000 (99.549)
2019-05-08 22:35:55 - INFO - 
 Epoch: 86	Training Loss 0.0020 	Training Prec@1 99.964 	Training Prec@5 100.000 	Validation Loss 0.3445 	Validation Prec@1 93.350 	Validation Prec@5 99.670 	
2019-05-08 22:35:55 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:35:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:35:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:35:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:35:55 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:35:55 - INFO - TRAINING - Epoch: [86][0/500]	Time 0.253 (0.253)	Data 0.211 (0.211)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:35:59 - INFO - TRAINING - Epoch: [86][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0011 (0.0015)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:36:03 - INFO - TRAINING - Epoch: [86][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.0052 (0.0015)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:36:08 - INFO - TRAINING - Epoch: [86][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0022 (0.0016)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:36:12 - INFO - TRAINING - Epoch: [86][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0016)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:36:16 - INFO - TRAINING - Epoch: [86][250/500]	Time 0.068 (0.083)	Data 0.001 (0.002)	Loss 0.0004 (0.0016)	Prec@1 100.000 (99.976)	Prec@5 100.000 (100.000)
2019-05-08 22:36:20 - INFO - TRAINING - Epoch: [86][300/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0016)	Prec@1 100.000 (99.973)	Prec@5 100.000 (100.000)
2019-05-08 22:36:24 - INFO - TRAINING - Epoch: [86][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0017)	Prec@1 100.000 (99.969)	Prec@5 100.000 (100.000)
2019-05-08 22:36:28 - INFO - TRAINING - Epoch: [86][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0009 (0.0016)	Prec@1 100.000 (99.968)	Prec@5 100.000 (100.000)
2019-05-08 22:36:32 - INFO - TRAINING - Epoch: [86][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0015)	Prec@1 100.000 (99.971)	Prec@5 100.000 (100.000)
2019-05-08 22:36:37 - INFO - EVALUATING - Epoch: [86][0/100]	Time 0.295 (0.295)	Data 0.269 (0.269)	Loss 0.3651 (0.3651)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-08 22:36:38 - INFO - EVALUATING - Epoch: [86][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.2347 (0.3667)	Prec@1 95.000 (92.784)	Prec@5 100.000 (99.569)
2019-05-08 22:36:39 - INFO - 
 Epoch: 87	Training Loss 0.0015 	Training Prec@1 99.972 	Training Prec@5 100.000 	Validation Loss 0.3431 	Validation Prec@1 93.240 	Validation Prec@5 99.700 	
2019-05-08 22:36:40 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:36:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:36:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:36:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:36:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:36:40 - INFO - TRAINING - Epoch: [87][0/500]	Time 0.252 (0.252)	Data 0.209 (0.209)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:36:44 - INFO - TRAINING - Epoch: [87][50/500]	Time 0.092 (0.087)	Data 0.000 (0.005)	Loss 0.0004 (0.0021)	Prec@1 100.000 (99.922)	Prec@5 100.000 (100.000)
2019-05-08 22:36:48 - INFO - TRAINING - Epoch: [87][100/500]	Time 0.081 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0020)	Prec@1 100.000 (99.941)	Prec@5 100.000 (100.000)
2019-05-08 22:36:52 - INFO - TRAINING - Epoch: [87][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0017)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:36:57 - INFO - TRAINING - Epoch: [87][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0019)	Prec@1 100.000 (99.955)	Prec@5 100.000 (100.000)
2019-05-08 22:37:01 - INFO - TRAINING - Epoch: [87][250/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0017)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:37:05 - INFO - TRAINING - Epoch: [87][300/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0017)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:37:09 - INFO - TRAINING - Epoch: [87][350/500]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.0017 (0.0017)	Prec@1 100.000 (99.954)	Prec@5 100.000 (100.000)
2019-05-08 22:37:13 - INFO - TRAINING - Epoch: [87][400/500]	Time 0.076 (0.083)	Data 0.000 (0.001)	Loss 0.0150 (0.0018)	Prec@1 99.000 (99.955)	Prec@5 100.000 (100.000)
2019-05-08 22:37:17 - INFO - TRAINING - Epoch: [87][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0008 (0.0018)	Prec@1 100.000 (99.956)	Prec@5 100.000 (100.000)
2019-05-08 22:37:21 - INFO - EVALUATING - Epoch: [87][0/100]	Time 0.293 (0.293)	Data 0.266 (0.266)	Loss 0.3626 (0.3626)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:37:23 - INFO - EVALUATING - Epoch: [87][50/100]	Time 0.022 (0.033)	Data 0.000 (0.005)	Loss 0.1801 (0.3679)	Prec@1 95.000 (92.784)	Prec@5 100.000 (99.569)
2019-05-08 22:37:24 - INFO - 
 Epoch: 88	Training Loss 0.0017 	Training Prec@1 99.960 	Training Prec@5 100.000 	Validation Loss 0.3442 	Validation Prec@1 93.180 	Validation Prec@5 99.710 	
2019-05-08 22:37:24 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:37:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:37:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:37:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:37:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:37:25 - INFO - TRAINING - Epoch: [88][0/500]	Time 0.266 (0.266)	Data 0.221 (0.221)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:37:29 - INFO - TRAINING - Epoch: [88][50/500]	Time 0.084 (0.086)	Data 0.000 (0.005)	Loss 0.0066 (0.0015)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 22:37:33 - INFO - TRAINING - Epoch: [88][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0005 (0.0014)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:37:37 - INFO - TRAINING - Epoch: [88][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0012)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:37:41 - INFO - TRAINING - Epoch: [88][200/500]	Time 0.052 (0.083)	Data 0.001 (0.002)	Loss 0.0007 (0.0014)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:37:45 - INFO - TRAINING - Epoch: [88][250/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0015)	Prec@1 100.000 (99.976)	Prec@5 100.000 (100.000)
2019-05-08 22:37:49 - INFO - TRAINING - Epoch: [88][300/500]	Time 0.071 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0016)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:37:53 - INFO - TRAINING - Epoch: [88][350/500]	Time 0.077 (0.081)	Data 0.000 (0.002)	Loss 0.0011 (0.0015)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:37:57 - INFO - TRAINING - Epoch: [88][400/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0008 (0.0015)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:38:01 - INFO - TRAINING - Epoch: [88][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0007 (0.0016)	Prec@1 100.000 (99.971)	Prec@5 100.000 (100.000)
2019-05-08 22:38:06 - INFO - EVALUATING - Epoch: [88][0/100]	Time 0.309 (0.309)	Data 0.268 (0.268)	Loss 0.3853 (0.3853)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-08 22:38:07 - INFO - EVALUATING - Epoch: [88][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1228 (0.3626)	Prec@1 97.000 (92.980)	Prec@5 100.000 (99.510)
2019-05-08 22:38:08 - INFO - 
 Epoch: 89	Training Loss 0.0016 	Training Prec@1 99.972 	Training Prec@5 100.000 	Validation Loss 0.3388 	Validation Prec@1 93.430 	Validation Prec@5 99.650 	
2019-05-08 22:38:08 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:38:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:38:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:38:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:38:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:38:09 - INFO - TRAINING - Epoch: [89][0/500]	Time 0.258 (0.258)	Data 0.214 (0.214)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:38:13 - INFO - TRAINING - Epoch: [89][50/500]	Time 0.069 (0.085)	Data 0.000 (0.005)	Loss 0.0005 (0.0011)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:38:17 - INFO - TRAINING - Epoch: [89][100/500]	Time 0.075 (0.084)	Data 0.000 (0.003)	Loss 0.0014 (0.0011)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:38:21 - INFO - TRAINING - Epoch: [89][150/500]	Time 0.052 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0010)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:38:25 - INFO - TRAINING - Epoch: [89][200/500]	Time 0.092 (0.082)	Data 0.000 (0.002)	Loss 0.0011 (0.0010)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:38:29 - INFO - TRAINING - Epoch: [89][250/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0010)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:38:33 - INFO - TRAINING - Epoch: [89][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0007 (0.0011)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:38:37 - INFO - TRAINING - Epoch: [89][350/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0009 (0.0012)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 22:38:41 - INFO - TRAINING - Epoch: [89][400/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0012)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:38:45 - INFO - TRAINING - Epoch: [89][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0007 (0.0013)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:38:50 - INFO - EVALUATING - Epoch: [89][0/100]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.4402 (0.4402)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:38:51 - INFO - EVALUATING - Epoch: [89][50/100]	Time 0.036 (0.032)	Data 0.000 (0.005)	Loss 0.1788 (0.3716)	Prec@1 95.000 (93.059)	Prec@5 100.000 (99.569)
2019-05-08 22:38:52 - INFO - 
 Epoch: 90	Training Loss 0.0013 	Training Prec@1 99.980 	Training Prec@5 100.000 	Validation Loss 0.3453 	Validation Prec@1 93.530 	Validation Prec@5 99.700 	
2019-05-08 22:38:53 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:38:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:38:53 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:38:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:38:53 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:38:53 - INFO - TRAINING - Epoch: [90][0/500]	Time 0.280 (0.280)	Data 0.238 (0.238)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:38:57 - INFO - TRAINING - Epoch: [90][50/500]	Time 0.082 (0.086)	Data 0.000 (0.006)	Loss 0.0004 (0.0011)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 22:39:01 - INFO - TRAINING - Epoch: [90][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0007 (0.0014)	Prec@1 100.000 (99.950)	Prec@5 100.000 (100.000)
2019-05-08 22:39:05 - INFO - TRAINING - Epoch: [90][150/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0019 (0.0013)	Prec@1 100.000 (99.967)	Prec@5 100.000 (100.000)
2019-05-08 22:39:09 - INFO - TRAINING - Epoch: [90][200/500]	Time 0.091 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0014)	Prec@1 100.000 (99.965)	Prec@5 100.000 (100.000)
2019-05-08 22:39:13 - INFO - TRAINING - Epoch: [90][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0013)	Prec@1 100.000 (99.968)	Prec@5 100.000 (100.000)
2019-05-08 22:39:17 - INFO - TRAINING - Epoch: [90][300/500]	Time 0.091 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0013)	Prec@1 100.000 (99.967)	Prec@5 100.000 (100.000)
2019-05-08 22:39:22 - INFO - TRAINING - Epoch: [90][350/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0013)	Prec@1 100.000 (99.963)	Prec@5 100.000 (100.000)
2019-05-08 22:39:26 - INFO - TRAINING - Epoch: [90][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0013)	Prec@1 100.000 (99.965)	Prec@5 100.000 (100.000)
2019-05-08 22:39:30 - INFO - TRAINING - Epoch: [90][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0092 (0.0015)	Prec@1 99.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:39:34 - INFO - EVALUATING - Epoch: [90][0/100]	Time 0.327 (0.327)	Data 0.280 (0.280)	Loss 0.4080 (0.4080)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:39:35 - INFO - EVALUATING - Epoch: [90][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1403 (0.3646)	Prec@1 95.000 (93.059)	Prec@5 100.000 (99.569)
2019-05-08 22:39:37 - INFO - 
 Epoch: 91	Training Loss 0.0015 	Training Prec@1 99.960 	Training Prec@5 100.000 	Validation Loss 0.3480 	Validation Prec@1 93.350 	Validation Prec@5 99.680 	
2019-05-08 22:39:37 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:39:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:39:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:39:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:39:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:39:37 - INFO - TRAINING - Epoch: [91][0/500]	Time 0.332 (0.332)	Data 0.261 (0.261)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:39:41 - INFO - TRAINING - Epoch: [91][50/500]	Time 0.078 (0.087)	Data 0.000 (0.005)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:39:46 - INFO - TRAINING - Epoch: [91][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0024 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:39:50 - INFO - TRAINING - Epoch: [91][150/500]	Time 0.086 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0013)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:39:54 - INFO - TRAINING - Epoch: [91][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0012)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:39:58 - INFO - TRAINING - Epoch: [91][250/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0012)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:40:02 - INFO - TRAINING - Epoch: [91][300/500]	Time 0.070 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0012)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:40:06 - INFO - TRAINING - Epoch: [91][350/500]	Time 0.070 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0013)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:40:10 - INFO - TRAINING - Epoch: [91][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0013)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:40:14 - INFO - TRAINING - Epoch: [91][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0009 (0.0013)	Prec@1 100.000 (99.978)	Prec@5 100.000 (100.000)
2019-05-08 22:40:18 - INFO - EVALUATING - Epoch: [91][0/100]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.3743 (0.3743)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:40:20 - INFO - EVALUATING - Epoch: [91][50/100]	Time 0.029 (0.033)	Data 0.000 (0.006)	Loss 0.1911 (0.3694)	Prec@1 96.000 (92.980)	Prec@5 100.000 (99.529)
2019-05-08 22:40:21 - INFO - 
 Epoch: 92	Training Loss 0.0013 	Training Prec@1 99.980 	Training Prec@5 100.000 	Validation Loss 0.3446 	Validation Prec@1 93.340 	Validation Prec@5 99.690 	
2019-05-08 22:40:21 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:40:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:40:21 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:40:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:40:21 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:40:22 - INFO - TRAINING - Epoch: [92][0/500]	Time 0.264 (0.264)	Data 0.201 (0.201)	Loss 0.0034 (0.0034)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:40:26 - INFO - TRAINING - Epoch: [92][50/500]	Time 0.091 (0.084)	Data 0.000 (0.005)	Loss 0.0006 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:40:30 - INFO - TRAINING - Epoch: [92][100/500]	Time 0.080 (0.084)	Data 0.000 (0.003)	Loss 0.0007 (0.0013)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:40:34 - INFO - TRAINING - Epoch: [92][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0012)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:40:38 - INFO - TRAINING - Epoch: [92][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0011)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 22:40:42 - INFO - TRAINING - Epoch: [92][250/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0011)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:40:46 - INFO - TRAINING - Epoch: [92][300/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0019 (0.0010)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:40:51 - INFO - TRAINING - Epoch: [92][350/500]	Time 0.080 (0.084)	Data 0.000 (0.001)	Loss 0.0003 (0.0010)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:40:55 - INFO - TRAINING - Epoch: [92][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0010)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:40:59 - INFO - TRAINING - Epoch: [92][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:41:03 - INFO - EVALUATING - Epoch: [92][0/100]	Time 0.279 (0.279)	Data 0.255 (0.255)	Loss 0.4074 (0.4074)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:41:05 - INFO - EVALUATING - Epoch: [92][50/100]	Time 0.040 (0.033)	Data 0.000 (0.005)	Loss 0.1468 (0.3717)	Prec@1 96.000 (92.941)	Prec@5 100.000 (99.569)
2019-05-08 22:41:06 - INFO - 
 Epoch: 93	Training Loss 0.0010 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3450 	Validation Prec@1 93.370 	Validation Prec@5 99.690 	
2019-05-08 22:41:06 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:41:06 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:41:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:41:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:41:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:41:06 - INFO - TRAINING - Epoch: [93][0/500]	Time 0.256 (0.256)	Data 0.199 (0.199)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:41:11 - INFO - TRAINING - Epoch: [93][50/500]	Time 0.081 (0.088)	Data 0.000 (0.005)	Loss 0.0004 (0.0014)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 22:41:15 - INFO - TRAINING - Epoch: [93][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0004 (0.0011)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:41:19 - INFO - TRAINING - Epoch: [93][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0011)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:41:23 - INFO - TRAINING - Epoch: [93][200/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0012)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:41:27 - INFO - TRAINING - Epoch: [93][250/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0147 (0.0016)	Prec@1 99.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 22:41:31 - INFO - TRAINING - Epoch: [93][300/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0031 (0.0017)	Prec@1 100.000 (99.957)	Prec@5 100.000 (100.000)
2019-05-08 22:41:35 - INFO - TRAINING - Epoch: [93][350/500]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0016)	Prec@1 100.000 (99.957)	Prec@5 100.000 (100.000)
2019-05-08 22:41:39 - INFO - TRAINING - Epoch: [93][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0209 (0.0016)	Prec@1 99.000 (99.955)	Prec@5 100.000 (100.000)
2019-05-08 22:41:44 - INFO - TRAINING - Epoch: [93][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0016)	Prec@1 100.000 (99.956)	Prec@5 100.000 (100.000)
2019-05-08 22:41:48 - INFO - EVALUATING - Epoch: [93][0/100]	Time 0.290 (0.290)	Data 0.265 (0.265)	Loss 0.4610 (0.4610)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:41:49 - INFO - EVALUATING - Epoch: [93][50/100]	Time 0.025 (0.032)	Data 0.001 (0.005)	Loss 0.1277 (0.3662)	Prec@1 96.000 (92.882)	Prec@5 100.000 (99.569)
2019-05-08 22:41:51 - INFO - 
 Epoch: 94	Training Loss 0.0016 	Training Prec@1 99.960 	Training Prec@5 100.000 	Validation Loss 0.3455 	Validation Prec@1 93.260 	Validation Prec@5 99.680 	
2019-05-08 22:41:51 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:41:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:41:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:41:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:41:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:41:51 - INFO - TRAINING - Epoch: [94][0/500]	Time 0.246 (0.246)	Data 0.182 (0.182)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:41:55 - INFO - TRAINING - Epoch: [94][50/500]	Time 0.086 (0.085)	Data 0.000 (0.004)	Loss 0.0003 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:41:59 - INFO - TRAINING - Epoch: [94][100/500]	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 0.0003 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:42:03 - INFO - TRAINING - Epoch: [94][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0011)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:42:08 - INFO - TRAINING - Epoch: [94][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0011)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:42:12 - INFO - TRAINING - Epoch: [94][250/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0010)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 22:42:16 - INFO - TRAINING - Epoch: [94][300/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0011)	Prec@1 100.000 (99.977)	Prec@5 100.000 (100.000)
2019-05-08 22:42:20 - INFO - TRAINING - Epoch: [94][350/500]	Time 0.073 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0011)	Prec@1 100.000 (99.977)	Prec@5 100.000 (100.000)
2019-05-08 22:42:24 - INFO - TRAINING - Epoch: [94][400/500]	Time 0.075 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:42:28 - INFO - TRAINING - Epoch: [94][450/500]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.0010 (0.0012)	Prec@1 100.000 (99.978)	Prec@5 100.000 (100.000)
2019-05-08 22:42:32 - INFO - EVALUATING - Epoch: [94][0/100]	Time 0.297 (0.297)	Data 0.271 (0.271)	Loss 0.4013 (0.4013)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:42:34 - INFO - EVALUATING - Epoch: [94][50/100]	Time 0.029 (0.032)	Data 0.000 (0.006)	Loss 0.1149 (0.3689)	Prec@1 96.000 (93.235)	Prec@5 100.000 (99.588)
2019-05-08 22:42:35 - INFO - 
 Epoch: 95	Training Loss 0.0012 	Training Prec@1 99.976 	Training Prec@5 100.000 	Validation Loss 0.3463 	Validation Prec@1 93.510 	Validation Prec@5 99.720 	
2019-05-08 22:42:35 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:42:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:42:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:42:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:42:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:42:35 - INFO - TRAINING - Epoch: [95][0/500]	Time 0.261 (0.261)	Data 0.220 (0.220)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:42:39 - INFO - TRAINING - Epoch: [95][50/500]	Time 0.089 (0.084)	Data 0.000 (0.005)	Loss 0.0003 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:42:44 - INFO - TRAINING - Epoch: [95][100/500]	Time 0.078 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:42:48 - INFO - TRAINING - Epoch: [95][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0024 (0.0009)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:42:52 - INFO - TRAINING - Epoch: [95][200/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0008)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:42:56 - INFO - TRAINING - Epoch: [95][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 22:43:00 - INFO - TRAINING - Epoch: [95][300/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0008)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:43:04 - INFO - TRAINING - Epoch: [95][350/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 22:43:08 - INFO - TRAINING - Epoch: [95][400/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0009 (0.0009)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:43:13 - INFO - TRAINING - Epoch: [95][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.982)	Prec@5 100.000 (100.000)
2019-05-08 22:43:17 - INFO - EVALUATING - Epoch: [95][0/100]	Time 0.292 (0.292)	Data 0.265 (0.265)	Loss 0.4614 (0.4614)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:18 - INFO - EVALUATING - Epoch: [95][50/100]	Time 0.026 (0.033)	Data 0.001 (0.005)	Loss 0.1489 (0.3685)	Prec@1 96.000 (93.196)	Prec@5 100.000 (99.569)
2019-05-08 22:43:20 - INFO - 
 Epoch: 96	Training Loss 0.0009 	Training Prec@1 99.984 	Training Prec@5 100.000 	Validation Loss 0.3461 	Validation Prec@1 93.510 	Validation Prec@5 99.700 	
2019-05-08 22:43:20 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:43:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:43:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:43:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:43:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:43:20 - INFO - TRAINING - Epoch: [96][0/500]	Time 0.290 (0.290)	Data 0.227 (0.227)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:24 - INFO - TRAINING - Epoch: [96][50/500]	Time 0.076 (0.084)	Data 0.000 (0.005)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:28 - INFO - TRAINING - Epoch: [96][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.0008 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:32 - INFO - TRAINING - Epoch: [96][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0032 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:36 - INFO - TRAINING - Epoch: [96][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:43:40 - INFO - TRAINING - Epoch: [96][250/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:43:44 - INFO - TRAINING - Epoch: [96][300/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0024 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:43:49 - INFO - TRAINING - Epoch: [96][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0008)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:43:53 - INFO - TRAINING - Epoch: [96][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0009)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:43:57 - INFO - TRAINING - Epoch: [96][450/500]	Time 0.074 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0009)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:44:01 - INFO - EVALUATING - Epoch: [96][0/100]	Time 0.308 (0.308)	Data 0.268 (0.268)	Loss 0.4844 (0.4844)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:03 - INFO - EVALUATING - Epoch: [96][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1346 (0.3662)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.549)
2019-05-08 22:44:04 - INFO - 
 Epoch: 97	Training Loss 0.0009 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3471 	Validation Prec@1 93.300 	Validation Prec@5 99.680 	
2019-05-08 22:44:04 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:44:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:44:04 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:44:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:44:04 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:44:04 - INFO - TRAINING - Epoch: [97][0/500]	Time 0.250 (0.250)	Data 0.209 (0.209)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:08 - INFO - TRAINING - Epoch: [97][50/500]	Time 0.079 (0.086)	Data 0.000 (0.005)	Loss 0.0003 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:13 - INFO - TRAINING - Epoch: [97][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:17 - INFO - TRAINING - Epoch: [97][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:21 - INFO - TRAINING - Epoch: [97][200/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:25 - INFO - TRAINING - Epoch: [97][250/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:29 - INFO - TRAINING - Epoch: [97][300/500]	Time 0.076 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:44:33 - INFO - TRAINING - Epoch: [97][350/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0008)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:44:37 - INFO - TRAINING - Epoch: [97][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0029 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:44:41 - INFO - TRAINING - Epoch: [97][450/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0009 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:44:46 - INFO - EVALUATING - Epoch: [97][0/100]	Time 0.284 (0.284)	Data 0.258 (0.258)	Loss 0.4170 (0.4170)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:47 - INFO - EVALUATING - Epoch: [97][50/100]	Time 0.026 (0.033)	Data 0.001 (0.005)	Loss 0.1646 (0.3721)	Prec@1 96.000 (93.333)	Prec@5 100.000 (99.471)
2019-05-08 22:44:48 - INFO - 
 Epoch: 98	Training Loss 0.0007 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3465 	Validation Prec@1 93.620 	Validation Prec@5 99.640 	
2019-05-08 22:44:49 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:44:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:44:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:44:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:44:49 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:44:49 - INFO - TRAINING - Epoch: [98][0/500]	Time 0.258 (0.258)	Data 0.192 (0.192)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:53 - INFO - TRAINING - Epoch: [98][50/500]	Time 0.081 (0.086)	Data 0.000 (0.005)	Loss 0.0020 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:44:57 - INFO - TRAINING - Epoch: [98][100/500]	Time 0.070 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0010)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:45:01 - INFO - TRAINING - Epoch: [98][150/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0009 (0.0009)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:45:05 - INFO - TRAINING - Epoch: [98][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:45:09 - INFO - TRAINING - Epoch: [98][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0058 (0.0009)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:45:13 - INFO - TRAINING - Epoch: [98][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:45:18 - INFO - TRAINING - Epoch: [98][350/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0030 (0.0009)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:45:22 - INFO - TRAINING - Epoch: [98][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:45:26 - INFO - TRAINING - Epoch: [98][450/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0009)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:45:30 - INFO - EVALUATING - Epoch: [98][0/100]	Time 0.292 (0.292)	Data 0.267 (0.267)	Loss 0.4569 (0.4569)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:45:31 - INFO - EVALUATING - Epoch: [98][50/100]	Time 0.037 (0.033)	Data 0.000 (0.006)	Loss 0.1288 (0.3661)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.588)
2019-05-08 22:45:33 - INFO - 
 Epoch: 99	Training Loss 0.0009 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3447 	Validation Prec@1 93.550 	Validation Prec@5 99.710 	
2019-05-08 22:45:33 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:45:33 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:45:33 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:45:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:45:33 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:45:33 - INFO - TRAINING - Epoch: [99][0/500]	Time 0.256 (0.256)	Data 0.191 (0.191)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:45:37 - INFO - TRAINING - Epoch: [99][50/500]	Time 0.075 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0010)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:45:41 - INFO - TRAINING - Epoch: [99][100/500]	Time 0.082 (0.083)	Data 0.000 (0.003)	Loss 0.0058 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:45:45 - INFO - TRAINING - Epoch: [99][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:45:50 - INFO - TRAINING - Epoch: [99][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0032 (0.0010)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:45:54 - INFO - TRAINING - Epoch: [99][250/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.972)	Prec@5 100.000 (100.000)
2019-05-08 22:45:58 - INFO - TRAINING - Epoch: [99][300/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0012)	Prec@1 100.000 (99.973)	Prec@5 100.000 (100.000)
2019-05-08 22:46:02 - INFO - TRAINING - Epoch: [99][350/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:46:06 - INFO - TRAINING - Epoch: [99][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0011)	Prec@1 100.000 (99.978)	Prec@5 100.000 (100.000)
2019-05-08 22:46:10 - INFO - TRAINING - Epoch: [99][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0020 (0.0011)	Prec@1 100.000 (99.978)	Prec@5 100.000 (100.000)
2019-05-08 22:46:14 - INFO - EVALUATING - Epoch: [99][0/100]	Time 0.317 (0.317)	Data 0.270 (0.270)	Loss 0.4593 (0.4593)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-08 22:46:16 - INFO - EVALUATING - Epoch: [99][50/100]	Time 0.027 (0.033)	Data 0.000 (0.006)	Loss 0.1358 (0.3700)	Prec@1 96.000 (92.980)	Prec@5 100.000 (99.608)
2019-05-08 22:46:17 - INFO - 
 Epoch: 100	Training Loss 0.0010 	Training Prec@1 99.980 	Training Prec@5 100.000 	Validation Loss 0.3425 	Validation Prec@1 93.370 	Validation Prec@5 99.730 	
2019-05-08 22:46:17 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:46:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:46:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:46:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:46:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:46:18 - INFO - TRAINING - Epoch: [100][0/500]	Time 0.268 (0.268)	Data 0.200 (0.200)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:46:22 - INFO - TRAINING - Epoch: [100][50/500]	Time 0.071 (0.083)	Data 0.000 (0.005)	Loss 0.0003 (0.0009)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:46:26 - INFO - TRAINING - Epoch: [100][100/500]	Time 0.087 (0.083)	Data 0.000 (0.003)	Loss 0.0003 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:46:30 - INFO - TRAINING - Epoch: [100][150/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0005 (0.0010)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:46:34 - INFO - TRAINING - Epoch: [100][200/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:46:38 - INFO - TRAINING - Epoch: [100][250/500]	Time 0.076 (0.081)	Data 0.000 (0.002)	Loss 0.0006 (0.0010)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:46:42 - INFO - TRAINING - Epoch: [100][300/500]	Time 0.082 (0.081)	Data 0.000 (0.002)	Loss 0.0004 (0.0009)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:46:46 - INFO - TRAINING - Epoch: [100][350/500]	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 0.0003 (0.0009)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:46:50 - INFO - TRAINING - Epoch: [100][400/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0051 (0.0010)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:46:54 - INFO - TRAINING - Epoch: [100][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0009)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:46:59 - INFO - EVALUATING - Epoch: [100][0/100]	Time 0.322 (0.322)	Data 0.285 (0.285)	Loss 0.4612 (0.4612)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:00 - INFO - EVALUATING - Epoch: [100][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1331 (0.3706)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.608)
2019-05-08 22:47:01 - INFO - 
 Epoch: 101	Training Loss 0.0009 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3455 	Validation Prec@1 93.510 	Validation Prec@5 99.730 	
2019-05-08 22:47:01 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:47:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:47:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:47:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:47:01 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:47:02 - INFO - TRAINING - Epoch: [101][0/500]	Time 0.259 (0.259)	Data 0.199 (0.199)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:06 - INFO - TRAINING - Epoch: [101][50/500]	Time 0.081 (0.083)	Data 0.000 (0.005)	Loss 0.0016 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:47:10 - INFO - TRAINING - Epoch: [101][100/500]	Time 0.090 (0.082)	Data 0.000 (0.003)	Loss 0.0007 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:47:14 - INFO - TRAINING - Epoch: [101][150/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:47:18 - INFO - TRAINING - Epoch: [101][200/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0008 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:47:22 - INFO - TRAINING - Epoch: [101][250/500]	Time 0.072 (0.082)	Data 0.000 (0.002)	Loss 0.0005 (0.0007)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:47:26 - INFO - TRAINING - Epoch: [101][300/500]	Time 0.081 (0.081)	Data 0.000 (0.002)	Loss 0.0008 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:47:30 - INFO - TRAINING - Epoch: [101][350/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0007)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:47:34 - INFO - TRAINING - Epoch: [101][400/500]	Time 0.069 (0.081)	Data 0.000 (0.001)	Loss 0.0005 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:47:38 - INFO - TRAINING - Epoch: [101][450/500]	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 0.0012 (0.0007)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:47:42 - INFO - EVALUATING - Epoch: [101][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.4159 (0.4159)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:44 - INFO - EVALUATING - Epoch: [101][50/100]	Time 0.022 (0.032)	Data 0.000 (0.005)	Loss 0.1217 (0.3653)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.608)
2019-05-08 22:47:45 - INFO - 
 Epoch: 102	Training Loss 0.0007 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3430 	Validation Prec@1 93.440 	Validation Prec@5 99.720 	
2019-05-08 22:47:45 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:47:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:47:45 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:47:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:47:45 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:47:45 - INFO - TRAINING - Epoch: [102][0/500]	Time 0.253 (0.253)	Data 0.211 (0.211)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:50 - INFO - TRAINING - Epoch: [102][50/500]	Time 0.073 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:54 - INFO - TRAINING - Epoch: [102][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:47:58 - INFO - TRAINING - Epoch: [102][150/500]	Time 0.094 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:48:02 - INFO - TRAINING - Epoch: [102][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0013 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:48:06 - INFO - TRAINING - Epoch: [102][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:48:10 - INFO - TRAINING - Epoch: [102][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:48:15 - INFO - TRAINING - Epoch: [102][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:48:19 - INFO - TRAINING - Epoch: [102][400/500]	Time 0.070 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:48:23 - INFO - TRAINING - Epoch: [102][450/500]	Time 0.071 (0.083)	Data 0.000 (0.001)	Loss 0.0011 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:48:27 - INFO - EVALUATING - Epoch: [102][0/100]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.4163 (0.4163)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:48:28 - INFO - EVALUATING - Epoch: [102][50/100]	Time 0.027 (0.033)	Data 0.001 (0.005)	Loss 0.1371 (0.3702)	Prec@1 97.000 (93.255)	Prec@5 100.000 (99.588)
2019-05-08 22:48:30 - INFO - 
 Epoch: 103	Training Loss 0.0007 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3452 	Validation Prec@1 93.610 	Validation Prec@5 99.720 	
2019-05-08 22:48:30 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:48:30 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:48:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:48:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:48:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:48:30 - INFO - TRAINING - Epoch: [103][0/500]	Time 0.261 (0.261)	Data 0.221 (0.221)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:48:34 - INFO - TRAINING - Epoch: [103][50/500]	Time 0.077 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0012)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:48:38 - INFO - TRAINING - Epoch: [103][100/500]	Time 0.071 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:48:43 - INFO - TRAINING - Epoch: [103][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:48:47 - INFO - TRAINING - Epoch: [103][200/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:48:51 - INFO - TRAINING - Epoch: [103][250/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:48:55 - INFO - TRAINING - Epoch: [103][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0008 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:48:59 - INFO - TRAINING - Epoch: [103][350/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:49:03 - INFO - TRAINING - Epoch: [103][400/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:49:07 - INFO - TRAINING - Epoch: [103][450/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:49:12 - INFO - EVALUATING - Epoch: [103][0/100]	Time 0.279 (0.279)	Data 0.254 (0.254)	Loss 0.4322 (0.4322)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 22:49:13 - INFO - EVALUATING - Epoch: [103][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.1339 (0.3709)	Prec@1 97.000 (93.039)	Prec@5 100.000 (99.569)
2019-05-08 22:49:15 - INFO - 
 Epoch: 104	Training Loss 0.0006 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3471 	Validation Prec@1 93.460 	Validation Prec@5 99.710 	
2019-05-08 22:49:15 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:49:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:49:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:49:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:49:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:49:15 - INFO - TRAINING - Epoch: [104][0/500]	Time 0.251 (0.251)	Data 0.187 (0.187)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:49:19 - INFO - TRAINING - Epoch: [104][50/500]	Time 0.088 (0.085)	Data 0.000 (0.005)	Loss 0.0046 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:49:23 - INFO - TRAINING - Epoch: [104][100/500]	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 0.0000 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:49:27 - INFO - TRAINING - Epoch: [104][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0008)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:49:31 - INFO - TRAINING - Epoch: [104][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:49:35 - INFO - TRAINING - Epoch: [104][250/500]	Time 0.075 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:49:39 - INFO - TRAINING - Epoch: [104][300/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0016 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:49:43 - INFO - TRAINING - Epoch: [104][350/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0009 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:49:48 - INFO - TRAINING - Epoch: [104][400/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:49:52 - INFO - TRAINING - Epoch: [104][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:49:56 - INFO - EVALUATING - Epoch: [104][0/100]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.3906 (0.3906)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:49:57 - INFO - EVALUATING - Epoch: [104][50/100]	Time 0.026 (0.033)	Data 0.000 (0.005)	Loss 0.1079 (0.3699)	Prec@1 97.000 (93.098)	Prec@5 100.000 (99.588)
2019-05-08 22:49:59 - INFO - 
 Epoch: 105	Training Loss 0.0006 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3447 	Validation Prec@1 93.520 	Validation Prec@5 99.720 	
2019-05-08 22:49:59 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:49:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:49:59 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:49:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:49:59 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:49:59 - INFO - TRAINING - Epoch: [105][0/500]	Time 0.265 (0.265)	Data 0.199 (0.199)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:03 - INFO - TRAINING - Epoch: [105][50/500]	Time 0.078 (0.086)	Data 0.000 (0.005)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:07 - INFO - TRAINING - Epoch: [105][100/500]	Time 0.088 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:12 - INFO - TRAINING - Epoch: [105][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:50:16 - INFO - TRAINING - Epoch: [105][200/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:50:20 - INFO - TRAINING - Epoch: [105][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:50:24 - INFO - TRAINING - Epoch: [105][300/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:50:28 - INFO - TRAINING - Epoch: [105][350/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0007 (0.0007)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:50:32 - INFO - TRAINING - Epoch: [105][400/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0008)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:50:36 - INFO - TRAINING - Epoch: [105][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0008)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:50:41 - INFO - EVALUATING - Epoch: [105][0/100]	Time 0.333 (0.333)	Data 0.287 (0.287)	Loss 0.3859 (0.3859)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:42 - INFO - EVALUATING - Epoch: [105][50/100]	Time 0.029 (0.033)	Data 0.001 (0.006)	Loss 0.1098 (0.3731)	Prec@1 97.000 (92.667)	Prec@5 100.000 (99.588)
2019-05-08 22:50:43 - INFO - 
 Epoch: 106	Training Loss 0.0008 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3472 	Validation Prec@1 93.270 	Validation Prec@5 99.700 	
2019-05-08 22:50:44 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:50:44 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:50:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:50:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:50:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:50:44 - INFO - TRAINING - Epoch: [106][0/500]	Time 0.260 (0.260)	Data 0.217 (0.217)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:48 - INFO - TRAINING - Epoch: [106][50/500]	Time 0.077 (0.085)	Data 0.000 (0.005)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:52 - INFO - TRAINING - Epoch: [106][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:50:56 - INFO - TRAINING - Epoch: [106][150/500]	Time 0.092 (0.084)	Data 0.000 (0.002)	Loss 0.0010 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:51:00 - INFO - TRAINING - Epoch: [106][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:51:04 - INFO - TRAINING - Epoch: [106][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0012 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:51:09 - INFO - TRAINING - Epoch: [106][300/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:51:13 - INFO - TRAINING - Epoch: [106][350/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:51:17 - INFO - TRAINING - Epoch: [106][400/500]	Time 0.045 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:51:21 - INFO - TRAINING - Epoch: [106][450/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:51:25 - INFO - EVALUATING - Epoch: [106][0/100]	Time 0.295 (0.295)	Data 0.270 (0.270)	Loss 0.4265 (0.4265)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:51:27 - INFO - EVALUATING - Epoch: [106][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.1130 (0.3674)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.608)
2019-05-08 22:51:28 - INFO - 
 Epoch: 107	Training Loss 0.0008 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3440 	Validation Prec@1 93.500 	Validation Prec@5 99.720 	
2019-05-08 22:51:28 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:51:28 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:51:28 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:51:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:51:28 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:51:28 - INFO - TRAINING - Epoch: [107][0/500]	Time 0.247 (0.247)	Data 0.203 (0.203)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:51:33 - INFO - TRAINING - Epoch: [107][50/500]	Time 0.085 (0.087)	Data 0.000 (0.005)	Loss 0.0004 (0.0009)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:51:37 - INFO - TRAINING - Epoch: [107][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0000 (0.0009)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:51:41 - INFO - TRAINING - Epoch: [107][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:51:45 - INFO - TRAINING - Epoch: [107][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:51:49 - INFO - TRAINING - Epoch: [107][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:51:53 - INFO - TRAINING - Epoch: [107][300/500]	Time 0.094 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:51:57 - INFO - TRAINING - Epoch: [107][350/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:52:02 - INFO - TRAINING - Epoch: [107][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0018 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:52:06 - INFO - TRAINING - Epoch: [107][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:52:10 - INFO - EVALUATING - Epoch: [107][0/100]	Time 0.277 (0.277)	Data 0.251 (0.251)	Loss 0.4067 (0.4067)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:52:11 - INFO - EVALUATING - Epoch: [107][50/100]	Time 0.025 (0.033)	Data 0.000 (0.005)	Loss 0.0860 (0.3740)	Prec@1 97.000 (93.039)	Prec@5 100.000 (99.569)
2019-05-08 22:52:13 - INFO - 
 Epoch: 108	Training Loss 0.0007 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3433 	Validation Prec@1 93.480 	Validation Prec@5 99.700 	
2019-05-08 22:52:13 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:52:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:52:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:52:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:52:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:52:13 - INFO - TRAINING - Epoch: [108][0/500]	Time 0.261 (0.261)	Data 0.201 (0.201)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:52:17 - INFO - TRAINING - Epoch: [108][50/500]	Time 0.083 (0.084)	Data 0.000 (0.005)	Loss 0.0002 (0.0014)	Prec@1 100.000 (99.941)	Prec@5 100.000 (100.000)
2019-05-08 22:52:21 - INFO - TRAINING - Epoch: [108][100/500]	Time 0.084 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0015)	Prec@1 100.000 (99.950)	Prec@5 100.000 (100.000)
2019-05-08 22:52:25 - INFO - TRAINING - Epoch: [108][150/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.967)	Prec@5 100.000 (100.000)
2019-05-08 22:52:29 - INFO - TRAINING - Epoch: [108][200/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0010)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:52:33 - INFO - TRAINING - Epoch: [108][250/500]	Time 0.069 (0.082)	Data 0.000 (0.002)	Loss 0.0006 (0.0009)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:52:38 - INFO - TRAINING - Epoch: [108][300/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0012 (0.0009)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:52:42 - INFO - TRAINING - Epoch: [108][350/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0028 (0.0008)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 22:52:46 - INFO - TRAINING - Epoch: [108][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:52:50 - INFO - TRAINING - Epoch: [108][450/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0028 (0.0008)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:52:55 - INFO - EVALUATING - Epoch: [108][0/100]	Time 0.299 (0.299)	Data 0.273 (0.273)	Loss 0.3898 (0.3898)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 22:52:56 - INFO - EVALUATING - Epoch: [108][50/100]	Time 0.024 (0.033)	Data 0.001 (0.006)	Loss 0.1126 (0.3714)	Prec@1 97.000 (92.824)	Prec@5 100.000 (99.608)
2019-05-08 22:52:57 - INFO - 
 Epoch: 109	Training Loss 0.0008 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3449 	Validation Prec@1 93.380 	Validation Prec@5 99.730 	
2019-05-08 22:52:57 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:52:57 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:52:57 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:52:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:52:57 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:52:58 - INFO - TRAINING - Epoch: [109][0/500]	Time 0.286 (0.286)	Data 0.224 (0.224)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:02 - INFO - TRAINING - Epoch: [109][50/500]	Time 0.085 (0.084)	Data 0.000 (0.005)	Loss 0.0008 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:06 - INFO - TRAINING - Epoch: [109][100/500]	Time 0.085 (0.082)	Data 0.000 (0.003)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:53:10 - INFO - TRAINING - Epoch: [109][150/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:53:14 - INFO - TRAINING - Epoch: [109][200/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0007 (0.0007)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:53:18 - INFO - TRAINING - Epoch: [109][250/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:53:22 - INFO - TRAINING - Epoch: [109][300/500]	Time 0.086 (0.081)	Data 0.000 (0.002)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:53:26 - INFO - TRAINING - Epoch: [109][350/500]	Time 0.077 (0.081)	Data 0.000 (0.001)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:53:30 - INFO - TRAINING - Epoch: [109][400/500]	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 0.0007 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:53:34 - INFO - TRAINING - Epoch: [109][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:53:39 - INFO - EVALUATING - Epoch: [109][0/100]	Time 0.285 (0.285)	Data 0.260 (0.260)	Loss 0.3709 (0.3709)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:40 - INFO - EVALUATING - Epoch: [109][50/100]	Time 0.028 (0.032)	Data 0.000 (0.005)	Loss 0.1232 (0.3722)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.608)
2019-05-08 22:53:41 - INFO - 
 Epoch: 110	Training Loss 0.0008 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3458 	Validation Prec@1 93.550 	Validation Prec@5 99.720 	
2019-05-08 22:53:41 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:53:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:53:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:53:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:53:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:53:42 - INFO - TRAINING - Epoch: [110][0/500]	Time 0.263 (0.263)	Data 0.221 (0.221)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:46 - INFO - TRAINING - Epoch: [110][50/500]	Time 0.083 (0.084)	Data 0.000 (0.005)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:50 - INFO - TRAINING - Epoch: [110][100/500]	Time 0.082 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:54 - INFO - TRAINING - Epoch: [110][150/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:53:58 - INFO - TRAINING - Epoch: [110][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:54:02 - INFO - TRAINING - Epoch: [110][250/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:54:06 - INFO - TRAINING - Epoch: [110][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:54:10 - INFO - TRAINING - Epoch: [110][350/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:54:14 - INFO - TRAINING - Epoch: [110][400/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.0011 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:54:18 - INFO - TRAINING - Epoch: [110][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:54:23 - INFO - EVALUATING - Epoch: [110][0/100]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.3891 (0.3891)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:54:24 - INFO - EVALUATING - Epoch: [110][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.1204 (0.3708)	Prec@1 96.000 (93.157)	Prec@5 100.000 (99.608)
2019-05-08 22:54:26 - INFO - 
 Epoch: 111	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3464 	Validation Prec@1 93.550 	Validation Prec@5 99.730 	
2019-05-08 22:54:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:54:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:54:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:54:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:54:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:54:26 - INFO - TRAINING - Epoch: [111][0/500]	Time 0.263 (0.263)	Data 0.195 (0.195)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:54:30 - INFO - TRAINING - Epoch: [111][50/500]	Time 0.055 (0.083)	Data 0.000 (0.004)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:54:34 - INFO - TRAINING - Epoch: [111][100/500]	Time 0.088 (0.082)	Data 0.000 (0.003)	Loss 0.0022 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:54:38 - INFO - TRAINING - Epoch: [111][150/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:54:42 - INFO - TRAINING - Epoch: [111][200/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0023 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:54:46 - INFO - TRAINING - Epoch: [111][250/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:54:50 - INFO - TRAINING - Epoch: [111][300/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:54:54 - INFO - TRAINING - Epoch: [111][350/500]	Time 0.077 (0.081)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 22:54:58 - INFO - TRAINING - Epoch: [111][400/500]	Time 0.089 (0.081)	Data 0.000 (0.001)	Loss 0.0006 (0.0007)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:55:03 - INFO - TRAINING - Epoch: [111][450/500]	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:55:07 - INFO - EVALUATING - Epoch: [111][0/100]	Time 0.284 (0.284)	Data 0.258 (0.258)	Loss 0.3716 (0.3716)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:08 - INFO - EVALUATING - Epoch: [111][50/100]	Time 0.033 (0.032)	Data 0.000 (0.005)	Loss 0.1367 (0.3662)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.608)
2019-05-08 22:55:10 - INFO - 
 Epoch: 112	Training Loss 0.0007 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3446 	Validation Prec@1 93.520 	Validation Prec@5 99.720 	
2019-05-08 22:55:10 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:55:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:55:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:55:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:55:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:55:10 - INFO - TRAINING - Epoch: [112][0/500]	Time 0.278 (0.278)	Data 0.234 (0.234)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:14 - INFO - TRAINING - Epoch: [112][50/500]	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:18 - INFO - TRAINING - Epoch: [112][100/500]	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:22 - INFO - TRAINING - Epoch: [112][150/500]	Time 0.048 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:26 - INFO - TRAINING - Epoch: [112][200/500]	Time 0.071 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:55:31 - INFO - TRAINING - Epoch: [112][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:55:35 - INFO - TRAINING - Epoch: [112][300/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:55:39 - INFO - TRAINING - Epoch: [112][350/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:55:43 - INFO - TRAINING - Epoch: [112][400/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:55:47 - INFO - TRAINING - Epoch: [112][450/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0011 (0.0007)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 22:55:51 - INFO - EVALUATING - Epoch: [112][0/100]	Time 0.297 (0.297)	Data 0.271 (0.271)	Loss 0.4159 (0.4159)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:53 - INFO - EVALUATING - Epoch: [112][50/100]	Time 0.027 (0.033)	Data 0.001 (0.006)	Loss 0.1326 (0.3735)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.588)
2019-05-08 22:55:54 - INFO - 
 Epoch: 113	Training Loss 0.0007 	Training Prec@1 99.986 	Training Prec@5 100.000 	Validation Loss 0.3499 	Validation Prec@1 93.450 	Validation Prec@5 99.720 	
2019-05-08 22:55:54 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:55:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:55:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:55:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:55:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:55:54 - INFO - TRAINING - Epoch: [113][0/500]	Time 0.269 (0.269)	Data 0.200 (0.200)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:55:59 - INFO - TRAINING - Epoch: [113][50/500]	Time 0.087 (0.086)	Data 0.000 (0.004)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:56:04 - INFO - TRAINING - Epoch: [113][100/500]	Time 0.088 (0.101)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:56:08 - INFO - TRAINING - Epoch: [113][150/500]	Time 0.089 (0.094)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:56:13 - INFO - TRAINING - Epoch: [113][200/500]	Time 0.078 (0.091)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:56:17 - INFO - TRAINING - Epoch: [113][250/500]	Time 0.083 (0.090)	Data 0.000 (0.001)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 22:56:21 - INFO - TRAINING - Epoch: [113][300/500]	Time 0.086 (0.091)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:56:26 - INFO - TRAINING - Epoch: [113][350/500]	Time 0.082 (0.091)	Data 0.000 (0.001)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:56:30 - INFO - TRAINING - Epoch: [113][400/500]	Time 0.081 (0.090)	Data 0.000 (0.001)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:56:34 - INFO - TRAINING - Epoch: [113][450/500]	Time 0.047 (0.089)	Data 0.000 (0.001)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:56:39 - INFO - EVALUATING - Epoch: [113][0/100]	Time 0.303 (0.303)	Data 0.278 (0.278)	Loss 0.4266 (0.4266)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:56:40 - INFO - EVALUATING - Epoch: [113][50/100]	Time 0.022 (0.032)	Data 0.000 (0.006)	Loss 0.1873 (0.3672)	Prec@1 96.000 (92.941)	Prec@5 100.000 (99.608)
2019-05-08 22:56:41 - INFO - 
 Epoch: 114	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3447 	Validation Prec@1 93.430 	Validation Prec@5 99.750 	
2019-05-08 22:56:42 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:56:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:56:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:56:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:56:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:56:42 - INFO - TRAINING - Epoch: [114][0/500]	Time 0.243 (0.243)	Data 0.182 (0.182)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:56:46 - INFO - TRAINING - Epoch: [114][50/500]	Time 0.085 (0.086)	Data 0.000 (0.004)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:56:50 - INFO - TRAINING - Epoch: [114][100/500]	Time 0.087 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:56:54 - INFO - TRAINING - Epoch: [114][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:56:58 - INFO - TRAINING - Epoch: [114][200/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0006)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 22:57:03 - INFO - TRAINING - Epoch: [114][250/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0012 (0.0007)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 22:57:07 - INFO - TRAINING - Epoch: [114][300/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:57:11 - INFO - TRAINING - Epoch: [114][350/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 22:57:15 - INFO - TRAINING - Epoch: [114][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0006)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 22:57:19 - INFO - TRAINING - Epoch: [114][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0006)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 22:57:23 - INFO - EVALUATING - Epoch: [114][0/100]	Time 0.286 (0.286)	Data 0.261 (0.261)	Loss 0.4092 (0.4092)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:57:25 - INFO - EVALUATING - Epoch: [114][50/100]	Time 0.027 (0.032)	Data 0.001 (0.005)	Loss 0.1827 (0.3724)	Prec@1 96.000 (92.941)	Prec@5 100.000 (99.608)
2019-05-08 22:57:26 - INFO - 
 Epoch: 115	Training Loss 0.0006 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3479 	Validation Prec@1 93.520 	Validation Prec@5 99.700 	
2019-05-08 22:57:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:57:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:57:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:57:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:57:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:57:26 - INFO - TRAINING - Epoch: [115][0/500]	Time 0.262 (0.262)	Data 0.197 (0.197)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:57:31 - INFO - TRAINING - Epoch: [115][50/500]	Time 0.091 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:57:35 - INFO - TRAINING - Epoch: [115][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:57:39 - INFO - TRAINING - Epoch: [115][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:57:43 - INFO - TRAINING - Epoch: [115][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 22:57:47 - INFO - TRAINING - Epoch: [115][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 22:57:51 - INFO - TRAINING - Epoch: [115][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:57:55 - INFO - TRAINING - Epoch: [115][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0006)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 22:58:00 - INFO - TRAINING - Epoch: [115][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:58:04 - INFO - TRAINING - Epoch: [115][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:58:08 - INFO - EVALUATING - Epoch: [115][0/100]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.3972 (0.3972)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:09 - INFO - EVALUATING - Epoch: [115][50/100]	Time 0.035 (0.033)	Data 0.001 (0.005)	Loss 0.1423 (0.3733)	Prec@1 96.000 (92.922)	Prec@5 100.000 (99.588)
2019-05-08 22:58:11 - INFO - 
 Epoch: 116	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3500 	Validation Prec@1 93.370 	Validation Prec@5 99.710 	
2019-05-08 22:58:11 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:58:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:58:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:58:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:58:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:58:11 - INFO - TRAINING - Epoch: [116][0/500]	Time 0.253 (0.253)	Data 0.210 (0.210)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:15 - INFO - TRAINING - Epoch: [116][50/500]	Time 0.079 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:19 - INFO - TRAINING - Epoch: [116][100/500]	Time 0.081 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:24 - INFO - TRAINING - Epoch: [116][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0025 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:28 - INFO - TRAINING - Epoch: [116][200/500]	Time 0.053 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:32 - INFO - TRAINING - Epoch: [116][250/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:36 - INFO - TRAINING - Epoch: [116][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:58:40 - INFO - TRAINING - Epoch: [116][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 22:58:44 - INFO - TRAINING - Epoch: [116][400/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0006)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 22:58:48 - INFO - TRAINING - Epoch: [116][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 22:58:52 - INFO - EVALUATING - Epoch: [116][0/100]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.3525 (0.3525)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 22:58:54 - INFO - EVALUATING - Epoch: [116][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.1164 (0.3735)	Prec@1 97.000 (93.275)	Prec@5 100.000 (99.529)
2019-05-08 22:58:55 - INFO - 
 Epoch: 117	Training Loss 0.0007 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3495 	Validation Prec@1 93.590 	Validation Prec@5 99.680 	
2019-05-08 22:58:55 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:58:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:58:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:58:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:58:55 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:58:56 - INFO - TRAINING - Epoch: [117][0/500]	Time 0.257 (0.257)	Data 0.216 (0.216)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:59:00 - INFO - TRAINING - Epoch: [117][50/500]	Time 0.085 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:59:04 - INFO - TRAINING - Epoch: [117][100/500]	Time 0.079 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 22:59:08 - INFO - TRAINING - Epoch: [117][150/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.974)	Prec@5 100.000 (100.000)
2019-05-08 22:59:12 - INFO - TRAINING - Epoch: [117][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0008)	Prec@1 100.000 (99.975)	Prec@5 100.000 (100.000)
2019-05-08 22:59:16 - INFO - TRAINING - Epoch: [117][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0008)	Prec@1 100.000 (99.976)	Prec@5 100.000 (100.000)
2019-05-08 22:59:20 - INFO - TRAINING - Epoch: [117][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:59:25 - INFO - TRAINING - Epoch: [117][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0016 (0.0007)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 22:59:29 - INFO - TRAINING - Epoch: [117][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 22:59:33 - INFO - TRAINING - Epoch: [117][450/500]	Time 0.068 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 22:59:37 - INFO - EVALUATING - Epoch: [117][0/100]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.3904 (0.3904)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 22:59:39 - INFO - EVALUATING - Epoch: [117][50/100]	Time 0.025 (0.032)	Data 0.000 (0.005)	Loss 0.1315 (0.3748)	Prec@1 97.000 (93.235)	Prec@5 100.000 (99.588)
2019-05-08 22:59:40 - INFO - 
 Epoch: 118	Training Loss 0.0006 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3515 	Validation Prec@1 93.550 	Validation Prec@5 99.710 	
2019-05-08 22:59:40 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 22:59:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 22:59:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 22:59:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 22:59:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 22:59:40 - INFO - TRAINING - Epoch: [118][0/500]	Time 0.255 (0.255)	Data 0.212 (0.212)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 22:59:44 - INFO - TRAINING - Epoch: [118][50/500]	Time 0.088 (0.083)	Data 0.000 (0.005)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 22:59:48 - INFO - TRAINING - Epoch: [118][100/500]	Time 0.078 (0.082)	Data 0.000 (0.003)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 22:59:53 - INFO - TRAINING - Epoch: [118][150/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 22:59:57 - INFO - TRAINING - Epoch: [118][200/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:00:01 - INFO - TRAINING - Epoch: [118][250/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0010 (0.0006)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:00:05 - INFO - TRAINING - Epoch: [118][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:00:09 - INFO - TRAINING - Epoch: [118][350/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:00:13 - INFO - TRAINING - Epoch: [118][400/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:00:18 - INFO - TRAINING - Epoch: [118][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:00:22 - INFO - EVALUATING - Epoch: [118][0/100]	Time 0.338 (0.338)	Data 0.291 (0.291)	Loss 0.3921 (0.3921)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:00:23 - INFO - EVALUATING - Epoch: [118][50/100]	Time 0.031 (0.033)	Data 0.000 (0.006)	Loss 0.1664 (0.3746)	Prec@1 96.000 (92.961)	Prec@5 100.000 (99.569)
2019-05-08 23:00:25 - INFO - 
 Epoch: 119	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3489 	Validation Prec@1 93.440 	Validation Prec@5 99.670 	
2019-05-08 23:00:25 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:00:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:00:25 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:00:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:00:25 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:00:25 - INFO - TRAINING - Epoch: [119][0/500]	Time 0.266 (0.266)	Data 0.198 (0.198)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:00:29 - INFO - TRAINING - Epoch: [119][50/500]	Time 0.083 (0.084)	Data 0.000 (0.004)	Loss 0.0001 (0.0015)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 23:00:33 - INFO - TRAINING - Epoch: [119][100/500]	Time 0.087 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 23:00:37 - INFO - TRAINING - Epoch: [119][150/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0012)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 23:00:42 - INFO - TRAINING - Epoch: [119][200/500]	Time 0.076 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0010)	Prec@1 100.000 (99.970)	Prec@5 100.000 (100.000)
2019-05-08 23:00:46 - INFO - TRAINING - Epoch: [119][250/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0009)	Prec@1 100.000 (99.976)	Prec@5 100.000 (100.000)
2019-05-08 23:00:50 - INFO - TRAINING - Epoch: [119][300/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:00:54 - INFO - TRAINING - Epoch: [119][350/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0007)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 23:00:58 - INFO - TRAINING - Epoch: [119][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0007)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 23:01:02 - INFO - TRAINING - Epoch: [119][450/500]	Time 0.076 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:01:06 - INFO - EVALUATING - Epoch: [119][0/100]	Time 0.330 (0.330)	Data 0.285 (0.285)	Loss 0.3756 (0.3756)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:08 - INFO - EVALUATING - Epoch: [119][50/100]	Time 0.024 (0.033)	Data 0.000 (0.006)	Loss 0.1787 (0.3728)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.588)
2019-05-08 23:01:09 - INFO - 
 Epoch: 120	Training Loss 0.0007 	Training Prec@1 99.988 	Training Prec@5 100.000 	Validation Loss 0.3469 	Validation Prec@1 93.450 	Validation Prec@5 99.710 	
2019-05-08 23:01:09 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:01:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:01:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:01:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:01:09 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:01:10 - INFO - TRAINING - Epoch: [120][0/500]	Time 0.253 (0.253)	Data 0.208 (0.208)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:14 - INFO - TRAINING - Epoch: [120][50/500]	Time 0.079 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:18 - INFO - TRAINING - Epoch: [120][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:22 - INFO - TRAINING - Epoch: [120][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:26 - INFO - TRAINING - Epoch: [120][200/500]	Time 0.073 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:01:30 - INFO - TRAINING - Epoch: [120][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:01:34 - INFO - TRAINING - Epoch: [120][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:01:39 - INFO - TRAINING - Epoch: [120][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0019 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:01:43 - INFO - TRAINING - Epoch: [120][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:01:47 - INFO - TRAINING - Epoch: [120][450/500]	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 0.0010 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:01:51 - INFO - EVALUATING - Epoch: [120][0/100]	Time 0.313 (0.313)	Data 0.285 (0.285)	Loss 0.3632 (0.3632)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:53 - INFO - EVALUATING - Epoch: [120][50/100]	Time 0.033 (0.033)	Data 0.000 (0.006)	Loss 0.1419 (0.3769)	Prec@1 96.000 (93.176)	Prec@5 100.000 (99.569)
2019-05-08 23:01:54 - INFO - 
 Epoch: 121	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3512 	Validation Prec@1 93.580 	Validation Prec@5 99.710 	
2019-05-08 23:01:54 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:01:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:01:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:01:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:01:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:01:54 - INFO - TRAINING - Epoch: [121][0/500]	Time 0.272 (0.272)	Data 0.206 (0.206)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:01:59 - INFO - TRAINING - Epoch: [121][50/500]	Time 0.086 (0.087)	Data 0.000 (0.005)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:03 - INFO - TRAINING - Epoch: [121][100/500]	Time 0.085 (0.083)	Data 0.000 (0.003)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:07 - INFO - TRAINING - Epoch: [121][150/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:11 - INFO - TRAINING - Epoch: [121][200/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:15 - INFO - TRAINING - Epoch: [121][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:19 - INFO - TRAINING - Epoch: [121][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:23 - INFO - TRAINING - Epoch: [121][350/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:02:27 - INFO - TRAINING - Epoch: [121][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0054 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:02:32 - INFO - TRAINING - Epoch: [121][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:02:36 - INFO - EVALUATING - Epoch: [121][0/100]	Time 0.329 (0.329)	Data 0.288 (0.288)	Loss 0.4023 (0.4023)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:37 - INFO - EVALUATING - Epoch: [121][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1502 (0.3758)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.608)
2019-05-08 23:02:39 - INFO - 
 Epoch: 122	Training Loss 0.0006 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3515 	Validation Prec@1 93.510 	Validation Prec@5 99.700 	
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:02:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:02:39 - INFO - TRAINING - Epoch: [122][0/500]	Time 0.266 (0.266)	Data 0.194 (0.194)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:43 - INFO - TRAINING - Epoch: [122][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:47 - INFO - TRAINING - Epoch: [122][100/500]	Time 0.088 (0.084)	Data 0.000 (0.003)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:52 - INFO - TRAINING - Epoch: [122][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:02:56 - INFO - TRAINING - Epoch: [122][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:00 - INFO - TRAINING - Epoch: [122][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:04 - INFO - TRAINING - Epoch: [122][300/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.0000 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:03:08 - INFO - TRAINING - Epoch: [122][350/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:03:12 - INFO - TRAINING - Epoch: [122][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:03:16 - INFO - TRAINING - Epoch: [122][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:03:20 - INFO - EVALUATING - Epoch: [122][0/100]	Time 0.283 (0.283)	Data 0.258 (0.258)	Loss 0.4105 (0.4105)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:22 - INFO - EVALUATING - Epoch: [122][50/100]	Time 0.027 (0.032)	Data 0.001 (0.005)	Loss 0.1427 (0.3801)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.608)
2019-05-08 23:03:23 - INFO - 
 Epoch: 123	Training Loss 0.0005 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3565 	Validation Prec@1 93.470 	Validation Prec@5 99.710 	
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:03:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:03:24 - INFO - TRAINING - Epoch: [123][0/500]	Time 0.258 (0.258)	Data 0.214 (0.214)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:28 - INFO - TRAINING - Epoch: [123][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:32 - INFO - TRAINING - Epoch: [123][100/500]	Time 0.078 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:03:36 - INFO - TRAINING - Epoch: [123][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:03:40 - INFO - TRAINING - Epoch: [123][200/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:03:44 - INFO - TRAINING - Epoch: [123][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:03:48 - INFO - TRAINING - Epoch: [123][300/500]	Time 0.070 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:03:52 - INFO - TRAINING - Epoch: [123][350/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:03:56 - INFO - TRAINING - Epoch: [123][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:04:01 - INFO - TRAINING - Epoch: [123][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:04:05 - INFO - EVALUATING - Epoch: [123][0/100]	Time 0.282 (0.282)	Data 0.256 (0.256)	Loss 0.4022 (0.4022)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:06 - INFO - EVALUATING - Epoch: [123][50/100]	Time 0.026 (0.032)	Data 0.000 (0.005)	Loss 0.1338 (0.3778)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.529)
2019-05-08 23:04:08 - INFO - 
 Epoch: 124	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3542 	Validation Prec@1 93.400 	Validation Prec@5 99.660 	
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:04:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:04:08 - INFO - TRAINING - Epoch: [124][0/500]	Time 0.263 (0.263)	Data 0.218 (0.218)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:12 - INFO - TRAINING - Epoch: [124][50/500]	Time 0.077 (0.083)	Data 0.000 (0.005)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:16 - INFO - TRAINING - Epoch: [124][100/500]	Time 0.092 (0.082)	Data 0.000 (0.003)	Loss 0.0012 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:20 - INFO - TRAINING - Epoch: [124][150/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:04:24 - INFO - TRAINING - Epoch: [124][200/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0013 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:04:28 - INFO - TRAINING - Epoch: [124][250/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0006)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:04:33 - INFO - TRAINING - Epoch: [124][300/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0010 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:04:37 - INFO - TRAINING - Epoch: [124][350/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:04:41 - INFO - TRAINING - Epoch: [124][400/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:04:45 - INFO - TRAINING - Epoch: [124][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:04:49 - INFO - EVALUATING - Epoch: [124][0/100]	Time 0.291 (0.291)	Data 0.259 (0.259)	Loss 0.3888 (0.3888)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:51 - INFO - EVALUATING - Epoch: [124][50/100]	Time 0.023 (0.032)	Data 0.000 (0.005)	Loss 0.1446 (0.3724)	Prec@1 96.000 (93.216)	Prec@5 100.000 (99.588)
2019-05-08 23:04:52 - INFO - 
 Epoch: 125	Training Loss 0.0006 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3494 	Validation Prec@1 93.580 	Validation Prec@5 99.690 	
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:04:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:04:52 - INFO - TRAINING - Epoch: [125][0/500]	Time 0.252 (0.252)	Data 0.186 (0.186)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:04:57 - INFO - TRAINING - Epoch: [125][50/500]	Time 0.088 (0.086)	Data 0.000 (0.004)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:01 - INFO - TRAINING - Epoch: [125][100/500]	Time 0.080 (0.083)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:05 - INFO - TRAINING - Epoch: [125][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:09 - INFO - TRAINING - Epoch: [125][200/500]	Time 0.077 (0.082)	Data 0.000 (0.002)	Loss 0.0011 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:13 - INFO - TRAINING - Epoch: [125][250/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:05:17 - INFO - TRAINING - Epoch: [125][300/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:05:21 - INFO - TRAINING - Epoch: [125][350/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0000 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:05:25 - INFO - TRAINING - Epoch: [125][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:05:29 - INFO - TRAINING - Epoch: [125][450/500]	Time 0.076 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:05:33 - INFO - EVALUATING - Epoch: [125][0/100]	Time 0.296 (0.296)	Data 0.268 (0.268)	Loss 0.4068 (0.4068)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:35 - INFO - EVALUATING - Epoch: [125][50/100]	Time 0.028 (0.032)	Data 0.000 (0.006)	Loss 0.1568 (0.3761)	Prec@1 96.000 (93.157)	Prec@5 100.000 (99.569)
2019-05-08 23:05:36 - INFO - 
 Epoch: 126	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3524 	Validation Prec@1 93.570 	Validation Prec@5 99.690 	
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:05:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:05:37 - INFO - TRAINING - Epoch: [126][0/500]	Time 0.248 (0.248)	Data 0.188 (0.188)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:41 - INFO - TRAINING - Epoch: [126][50/500]	Time 0.084 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:05:45 - INFO - TRAINING - Epoch: [126][100/500]	Time 0.080 (0.083)	Data 0.000 (0.003)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:05:49 - INFO - TRAINING - Epoch: [126][150/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:05:53 - INFO - TRAINING - Epoch: [126][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0011 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:05:57 - INFO - TRAINING - Epoch: [126][250/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:06:01 - INFO - TRAINING - Epoch: [126][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:06:05 - INFO - TRAINING - Epoch: [126][350/500]	Time 0.075 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:06:09 - INFO - TRAINING - Epoch: [126][400/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:06:13 - INFO - TRAINING - Epoch: [126][450/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:06:18 - INFO - EVALUATING - Epoch: [126][0/100]	Time 0.284 (0.284)	Data 0.258 (0.258)	Loss 0.4237 (0.4237)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:06:19 - INFO - EVALUATING - Epoch: [126][50/100]	Time 0.033 (0.032)	Data 0.000 (0.005)	Loss 0.1657 (0.3759)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.549)
2019-05-08 23:06:21 - INFO - 
 Epoch: 127	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3506 	Validation Prec@1 93.510 	Validation Prec@5 99.670 	
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:06:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:06:21 - INFO - TRAINING - Epoch: [127][0/500]	Time 0.225 (0.225)	Data 0.182 (0.182)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:06:25 - INFO - TRAINING - Epoch: [127][50/500]	Time 0.079 (0.085)	Data 0.000 (0.004)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:06:29 - INFO - TRAINING - Epoch: [127][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0015 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:06:34 - INFO - TRAINING - Epoch: [127][150/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:06:38 - INFO - TRAINING - Epoch: [127][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:06:42 - INFO - TRAINING - Epoch: [127][250/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:06:46 - INFO - TRAINING - Epoch: [127][300/500]	Time 0.048 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:06:50 - INFO - TRAINING - Epoch: [127][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:06:54 - INFO - TRAINING - Epoch: [127][400/500]	Time 0.072 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:06:58 - INFO - TRAINING - Epoch: [127][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:07:02 - INFO - EVALUATING - Epoch: [127][0/100]	Time 0.292 (0.292)	Data 0.267 (0.267)	Loss 0.3900 (0.3900)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:04 - INFO - EVALUATING - Epoch: [127][50/100]	Time 0.027 (0.033)	Data 0.001 (0.006)	Loss 0.1511 (0.3715)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.549)
2019-05-08 23:07:05 - INFO - 
 Epoch: 128	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3463 	Validation Prec@1 93.590 	Validation Prec@5 99.680 	
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:07:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:07:06 - INFO - TRAINING - Epoch: [128][0/500]	Time 0.273 (0.273)	Data 0.209 (0.209)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:10 - INFO - TRAINING - Epoch: [128][50/500]	Time 0.082 (0.086)	Data 0.000 (0.005)	Loss 0.0003 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:14 - INFO - TRAINING - Epoch: [128][100/500]	Time 0.079 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:18 - INFO - TRAINING - Epoch: [128][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:22 - INFO - TRAINING - Epoch: [128][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0007 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:26 - INFO - TRAINING - Epoch: [128][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:30 - INFO - TRAINING - Epoch: [128][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:34 - INFO - TRAINING - Epoch: [128][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:39 - INFO - TRAINING - Epoch: [128][400/500]	Time 0.041 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:07:43 - INFO - TRAINING - Epoch: [128][450/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:07:47 - INFO - EVALUATING - Epoch: [128][0/100]	Time 0.301 (0.301)	Data 0.275 (0.275)	Loss 0.3766 (0.3766)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:48 - INFO - EVALUATING - Epoch: [128][50/100]	Time 0.034 (0.032)	Data 0.000 (0.006)	Loss 0.1480 (0.3725)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.588)
2019-05-08 23:07:50 - INFO - 
 Epoch: 129	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3483 	Validation Prec@1 93.520 	Validation Prec@5 99.690 	
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:07:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:07:50 - INFO - TRAINING - Epoch: [129][0/500]	Time 0.249 (0.249)	Data 0.206 (0.206)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:07:54 - INFO - TRAINING - Epoch: [129][50/500]	Time 0.083 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.961)	Prec@5 100.000 (100.000)
2019-05-08 23:07:58 - INFO - TRAINING - Epoch: [129][100/500]	Time 0.081 (0.084)	Data 0.000 (0.003)	Loss 0.0000 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:08:02 - INFO - TRAINING - Epoch: [129][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:08:06 - INFO - TRAINING - Epoch: [129][200/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:08:10 - INFO - TRAINING - Epoch: [129][250/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:08:14 - INFO - TRAINING - Epoch: [129][300/500]	Time 0.093 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:08:18 - INFO - TRAINING - Epoch: [129][350/500]	Time 0.084 (0.081)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:08:23 - INFO - TRAINING - Epoch: [129][400/500]	Time 0.082 (0.081)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:08:27 - INFO - TRAINING - Epoch: [129][450/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:08:31 - INFO - EVALUATING - Epoch: [129][0/100]	Time 0.285 (0.285)	Data 0.260 (0.260)	Loss 0.3801 (0.3801)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:08:32 - INFO - EVALUATING - Epoch: [129][50/100]	Time 0.026 (0.033)	Data 0.001 (0.005)	Loss 0.1477 (0.3710)	Prec@1 95.000 (93.000)	Prec@5 100.000 (99.608)
2019-05-08 23:08:34 - INFO - 
 Epoch: 130	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3460 	Validation Prec@1 93.460 	Validation Prec@5 99.710 	
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:08:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:08:34 - INFO - TRAINING - Epoch: [130][0/500]	Time 0.240 (0.240)	Data 0.182 (0.182)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:08:38 - INFO - TRAINING - Epoch: [130][50/500]	Time 0.086 (0.086)	Data 0.000 (0.004)	Loss 0.0030 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:08:42 - INFO - TRAINING - Epoch: [130][100/500]	Time 0.073 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 23:08:46 - INFO - TRAINING - Epoch: [130][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0013)	Prec@1 100.000 (99.960)	Prec@5 100.000 (100.000)
2019-05-08 23:08:51 - INFO - TRAINING - Epoch: [130][200/500]	Time 0.067 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0011)	Prec@1 100.000 (99.965)	Prec@5 100.000 (100.000)
2019-05-08 23:08:55 - INFO - TRAINING - Epoch: [130][250/500]	Time 0.091 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0009)	Prec@1 100.000 (99.972)	Prec@5 100.000 (100.000)
2019-05-08 23:08:59 - INFO - TRAINING - Epoch: [130][300/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.977)	Prec@5 100.000 (100.000)
2019-05-08 23:09:03 - INFO - TRAINING - Epoch: [130][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0005 (0.0008)	Prec@1 100.000 (99.977)	Prec@5 100.000 (100.000)
2019-05-08 23:09:07 - INFO - TRAINING - Epoch: [130][400/500]	Time 0.082 (0.082)	Data 0.002 (0.001)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.978)	Prec@5 100.000 (100.000)
2019-05-08 23:09:11 - INFO - TRAINING - Epoch: [130][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:09:15 - INFO - EVALUATING - Epoch: [130][0/100]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.3893 (0.3893)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:09:17 - INFO - EVALUATING - Epoch: [130][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.1521 (0.3727)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.549)
2019-05-08 23:09:18 - INFO - 
 Epoch: 131	Training Loss 0.0008 	Training Prec@1 99.980 	Training Prec@5 100.000 	Validation Loss 0.3465 	Validation Prec@1 93.450 	Validation Prec@5 99.680 	
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:09:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:09:19 - INFO - TRAINING - Epoch: [131][0/500]	Time 0.249 (0.249)	Data 0.194 (0.194)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:09:23 - INFO - TRAINING - Epoch: [131][50/500]	Time 0.079 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:09:27 - INFO - TRAINING - Epoch: [131][100/500]	Time 0.087 (0.083)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:09:31 - INFO - TRAINING - Epoch: [131][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0014 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:09:35 - INFO - TRAINING - Epoch: [131][200/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0007)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:09:39 - INFO - TRAINING - Epoch: [131][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 23:09:43 - INFO - TRAINING - Epoch: [131][300/500]	Time 0.095 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:09:47 - INFO - TRAINING - Epoch: [131][350/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:09:51 - INFO - TRAINING - Epoch: [131][400/500]	Time 0.049 (0.083)	Data 0.002 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:09:56 - INFO - TRAINING - Epoch: [131][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:10:00 - INFO - EVALUATING - Epoch: [131][0/100]	Time 0.327 (0.327)	Data 0.282 (0.282)	Loss 0.4073 (0.4073)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:10:01 - INFO - EVALUATING - Epoch: [131][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1676 (0.3757)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.529)
2019-05-08 23:10:03 - INFO - 
 Epoch: 132	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3501 	Validation Prec@1 93.480 	Validation Prec@5 99.680 	
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:10:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:10:03 - INFO - TRAINING - Epoch: [132][0/500]	Time 0.259 (0.259)	Data 0.192 (0.192)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:10:07 - INFO - TRAINING - Epoch: [132][50/500]	Time 0.085 (0.086)	Data 0.000 (0.005)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:10:11 - INFO - TRAINING - Epoch: [132][100/500]	Time 0.081 (0.083)	Data 0.000 (0.003)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:10:15 - INFO - TRAINING - Epoch: [132][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:10:19 - INFO - TRAINING - Epoch: [132][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:10:24 - INFO - TRAINING - Epoch: [132][250/500]	Time 0.091 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:10:28 - INFO - TRAINING - Epoch: [132][300/500]	Time 0.069 (0.083)	Data 0.000 (0.002)	Loss 0.0012 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:10:32 - INFO - TRAINING - Epoch: [132][350/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:10:36 - INFO - TRAINING - Epoch: [132][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:10:40 - INFO - TRAINING - Epoch: [132][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:10:44 - INFO - EVALUATING - Epoch: [132][0/100]	Time 0.322 (0.322)	Data 0.280 (0.280)	Loss 0.3646 (0.3646)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:10:46 - INFO - EVALUATING - Epoch: [132][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1476 (0.3723)	Prec@1 96.000 (93.176)	Prec@5 100.000 (99.569)
2019-05-08 23:10:47 - INFO - 
 Epoch: 133	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3470 	Validation Prec@1 93.570 	Validation Prec@5 99.700 	
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:10:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:10:47 - INFO - TRAINING - Epoch: [133][0/500]	Time 0.249 (0.249)	Data 0.196 (0.196)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:10:52 - INFO - TRAINING - Epoch: [133][50/500]	Time 0.086 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:10:56 - INFO - TRAINING - Epoch: [133][100/500]	Time 0.080 (0.085)	Data 0.000 (0.003)	Loss 0.0016 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:00 - INFO - TRAINING - Epoch: [133][150/500]	Time 0.072 (0.083)	Data 0.000 (0.002)	Loss 0.0009 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:04 - INFO - TRAINING - Epoch: [133][200/500]	Time 0.072 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:08 - INFO - TRAINING - Epoch: [133][250/500]	Time 0.067 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:12 - INFO - TRAINING - Epoch: [133][300/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:16 - INFO - TRAINING - Epoch: [133][350/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:20 - INFO - TRAINING - Epoch: [133][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:11:24 - INFO - TRAINING - Epoch: [133][450/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:11:28 - INFO - EVALUATING - Epoch: [133][0/100]	Time 0.274 (0.274)	Data 0.249 (0.249)	Loss 0.3988 (0.3988)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:30 - INFO - EVALUATING - Epoch: [133][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.1489 (0.3764)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.549)
2019-05-08 23:11:31 - INFO - 
 Epoch: 134	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3508 	Validation Prec@1 93.470 	Validation Prec@5 99.680 	
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:11:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:11:32 - INFO - TRAINING - Epoch: [134][0/500]	Time 0.249 (0.249)	Data 0.192 (0.192)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:36 - INFO - TRAINING - Epoch: [134][50/500]	Time 0.092 (0.088)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:11:40 - INFO - TRAINING - Epoch: [134][100/500]	Time 0.049 (0.083)	Data 0.000 (0.003)	Loss 0.0002 (0.0010)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:11:44 - INFO - TRAINING - Epoch: [134][150/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0009)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:11:48 - INFO - TRAINING - Epoch: [134][200/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:11:52 - INFO - TRAINING - Epoch: [134][250/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0007)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:11:56 - INFO - TRAINING - Epoch: [134][300/500]	Time 0.092 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:12:00 - INFO - TRAINING - Epoch: [134][350/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0007)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:12:04 - INFO - TRAINING - Epoch: [134][400/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:12:08 - INFO - TRAINING - Epoch: [134][450/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0005 (0.0006)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:12:12 - INFO - EVALUATING - Epoch: [134][0/100]	Time 0.286 (0.286)	Data 0.259 (0.259)	Loss 0.4182 (0.4182)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:12:14 - INFO - EVALUATING - Epoch: [134][50/100]	Time 0.024 (0.032)	Data 0.001 (0.005)	Loss 0.1484 (0.3766)	Prec@1 96.000 (93.000)	Prec@5 100.000 (99.569)
2019-05-08 23:12:15 - INFO - 
 Epoch: 135	Training Loss 0.0006 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3533 	Validation Prec@1 93.420 	Validation Prec@5 99.690 	
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:12:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:12:16 - INFO - TRAINING - Epoch: [135][0/500]	Time 0.267 (0.267)	Data 0.224 (0.224)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:12:20 - INFO - TRAINING - Epoch: [135][50/500]	Time 0.085 (0.087)	Data 0.000 (0.005)	Loss 0.0011 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:12:24 - INFO - TRAINING - Epoch: [135][100/500]	Time 0.084 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:12:28 - INFO - TRAINING - Epoch: [135][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:12:32 - INFO - TRAINING - Epoch: [135][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:12:36 - INFO - TRAINING - Epoch: [135][250/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:12:40 - INFO - TRAINING - Epoch: [135][300/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:12:45 - INFO - TRAINING - Epoch: [135][350/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:12:49 - INFO - TRAINING - Epoch: [135][400/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:12:53 - INFO - TRAINING - Epoch: [135][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:12:57 - INFO - EVALUATING - Epoch: [135][0/100]	Time 0.317 (0.317)	Data 0.275 (0.275)	Loss 0.4010 (0.4010)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:12:58 - INFO - EVALUATING - Epoch: [135][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1618 (0.3746)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.549)
2019-05-08 23:13:00 - INFO - 
 Epoch: 136	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3500 	Validation Prec@1 93.510 	Validation Prec@5 99.680 	
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:13:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:13:00 - INFO - TRAINING - Epoch: [136][0/500]	Time 0.274 (0.274)	Data 0.208 (0.208)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:13:04 - INFO - TRAINING - Epoch: [136][50/500]	Time 0.088 (0.086)	Data 0.000 (0.005)	Loss 0.0004 (0.0019)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:13:08 - INFO - TRAINING - Epoch: [136][100/500]	Time 0.073 (0.083)	Data 0.000 (0.003)	Loss 0.0016 (0.0011)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:13:12 - INFO - TRAINING - Epoch: [136][150/500]	Time 0.090 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0009)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:13:17 - INFO - TRAINING - Epoch: [136][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:13:21 - INFO - TRAINING - Epoch: [136][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0007)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:13:25 - INFO - TRAINING - Epoch: [136][300/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:13:29 - INFO - TRAINING - Epoch: [136][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:13:33 - INFO - TRAINING - Epoch: [136][400/500]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:13:37 - INFO - TRAINING - Epoch: [136][450/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:13:41 - INFO - EVALUATING - Epoch: [136][0/100]	Time 0.306 (0.306)	Data 0.280 (0.280)	Loss 0.3605 (0.3605)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:13:43 - INFO - EVALUATING - Epoch: [136][50/100]	Time 0.034 (0.032)	Data 0.000 (0.006)	Loss 0.1303 (0.3720)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.529)
2019-05-08 23:13:44 - INFO - 
 Epoch: 137	Training Loss 0.0006 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3478 	Validation Prec@1 93.500 	Validation Prec@5 99.680 	
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:13:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:13:45 - INFO - TRAINING - Epoch: [137][0/500]	Time 0.257 (0.257)	Data 0.213 (0.213)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:13:49 - INFO - TRAINING - Epoch: [137][50/500]	Time 0.088 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:13:53 - INFO - TRAINING - Epoch: [137][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:13:57 - INFO - TRAINING - Epoch: [137][150/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0020 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:14:01 - INFO - TRAINING - Epoch: [137][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:14:05 - INFO - TRAINING - Epoch: [137][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:14:09 - INFO - TRAINING - Epoch: [137][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:14:13 - INFO - TRAINING - Epoch: [137][350/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:14:17 - INFO - TRAINING - Epoch: [137][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:14:21 - INFO - TRAINING - Epoch: [137][450/500]	Time 0.074 (0.082)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:14:26 - INFO - EVALUATING - Epoch: [137][0/100]	Time 0.321 (0.321)	Data 0.272 (0.272)	Loss 0.4069 (0.4069)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:14:27 - INFO - EVALUATING - Epoch: [137][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1561 (0.3789)	Prec@1 96.000 (92.941)	Prec@5 100.000 (99.588)
2019-05-08 23:14:29 - INFO - 
 Epoch: 138	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3532 	Validation Prec@1 93.440 	Validation Prec@5 99.730 	
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:14:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:14:29 - INFO - TRAINING - Epoch: [138][0/500]	Time 0.255 (0.255)	Data 0.208 (0.208)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:14:33 - INFO - TRAINING - Epoch: [138][50/500]	Time 0.081 (0.087)	Data 0.000 (0.005)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:14:37 - INFO - TRAINING - Epoch: [138][100/500]	Time 0.077 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:14:41 - INFO - TRAINING - Epoch: [138][150/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:14:45 - INFO - TRAINING - Epoch: [138][200/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:14:50 - INFO - TRAINING - Epoch: [138][250/500]	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:14:54 - INFO - TRAINING - Epoch: [138][300/500]	Time 0.078 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:14:58 - INFO - TRAINING - Epoch: [138][350/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:15:02 - INFO - TRAINING - Epoch: [138][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:15:06 - INFO - TRAINING - Epoch: [138][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0012 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:15:11 - INFO - EVALUATING - Epoch: [138][0/100]	Time 0.329 (0.329)	Data 0.291 (0.291)	Loss 0.3798 (0.3798)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:12 - INFO - EVALUATING - Epoch: [138][50/100]	Time 0.034 (0.033)	Data 0.000 (0.006)	Loss 0.1467 (0.3708)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.549)
2019-05-08 23:15:13 - INFO - 
 Epoch: 139	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3459 	Validation Prec@1 93.500 	Validation Prec@5 99.690 	
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:15:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:15:14 - INFO - TRAINING - Epoch: [139][0/500]	Time 0.258 (0.258)	Data 0.212 (0.212)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:18 - INFO - TRAINING - Epoch: [139][50/500]	Time 0.083 (0.083)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:22 - INFO - TRAINING - Epoch: [139][100/500]	Time 0.082 (0.083)	Data 0.000 (0.003)	Loss 0.0007 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:26 - INFO - TRAINING - Epoch: [139][150/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:30 - INFO - TRAINING - Epoch: [139][200/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:34 - INFO - TRAINING - Epoch: [139][250/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:15:38 - INFO - TRAINING - Epoch: [139][300/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:15:42 - INFO - TRAINING - Epoch: [139][350/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:15:46 - INFO - TRAINING - Epoch: [139][400/500]	Time 0.070 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:15:51 - INFO - TRAINING - Epoch: [139][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:15:55 - INFO - EVALUATING - Epoch: [139][0/100]	Time 0.319 (0.319)	Data 0.277 (0.277)	Loss 0.3782 (0.3782)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:15:56 - INFO - EVALUATING - Epoch: [139][50/100]	Time 0.030 (0.032)	Data 0.000 (0.006)	Loss 0.1434 (0.3771)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.549)
2019-05-08 23:15:58 - INFO - 
 Epoch: 140	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3510 	Validation Prec@1 93.520 	Validation Prec@5 99.690 	
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:15:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:15:58 - INFO - TRAINING - Epoch: [140][0/500]	Time 0.276 (0.276)	Data 0.215 (0.215)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:02 - INFO - TRAINING - Epoch: [140][50/500]	Time 0.074 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:06 - INFO - TRAINING - Epoch: [140][100/500]	Time 0.077 (0.083)	Data 0.001 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:10 - INFO - TRAINING - Epoch: [140][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0010 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:14 - INFO - TRAINING - Epoch: [140][200/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:19 - INFO - TRAINING - Epoch: [140][250/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0006 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:23 - INFO - TRAINING - Epoch: [140][300/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:27 - INFO - TRAINING - Epoch: [140][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:31 - INFO - TRAINING - Epoch: [140][400/500]	Time 0.073 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:35 - INFO - TRAINING - Epoch: [140][450/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:39 - INFO - EVALUATING - Epoch: [140][0/100]	Time 0.330 (0.330)	Data 0.283 (0.283)	Loss 0.4204 (0.4204)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:41 - INFO - EVALUATING - Epoch: [140][50/100]	Time 0.041 (0.034)	Data 0.000 (0.006)	Loss 0.1676 (0.3752)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.549)
2019-05-08 23:16:42 - INFO - 
 Epoch: 141	Training Loss 0.0004 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3505 	Validation Prec@1 93.590 	Validation Prec@5 99.700 	
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:16:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:16:42 - INFO - TRAINING - Epoch: [141][0/500]	Time 0.261 (0.261)	Data 0.201 (0.201)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:46 - INFO - TRAINING - Epoch: [141][50/500]	Time 0.083 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:51 - INFO - TRAINING - Epoch: [141][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:55 - INFO - TRAINING - Epoch: [141][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:16:59 - INFO - TRAINING - Epoch: [141][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0008 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:17:03 - INFO - TRAINING - Epoch: [141][250/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:17:07 - INFO - TRAINING - Epoch: [141][300/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:17:11 - INFO - TRAINING - Epoch: [141][350/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:17:16 - INFO - TRAINING - Epoch: [141][400/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:17:20 - INFO - TRAINING - Epoch: [141][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:17:24 - INFO - EVALUATING - Epoch: [141][0/100]	Time 0.315 (0.315)	Data 0.268 (0.268)	Loss 0.4088 (0.4088)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:17:25 - INFO - EVALUATING - Epoch: [141][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1592 (0.3789)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.569)
2019-05-08 23:17:27 - INFO - 
 Epoch: 142	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3519 	Validation Prec@1 93.510 	Validation Prec@5 99.680 	
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:17:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:17:27 - INFO - TRAINING - Epoch: [142][0/500]	Time 0.283 (0.283)	Data 0.227 (0.227)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:17:31 - INFO - TRAINING - Epoch: [142][50/500]	Time 0.080 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:17:35 - INFO - TRAINING - Epoch: [142][100/500]	Time 0.089 (0.084)	Data 0.000 (0.003)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:17:40 - INFO - TRAINING - Epoch: [142][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:17:44 - INFO - TRAINING - Epoch: [142][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:17:48 - INFO - TRAINING - Epoch: [142][250/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0012 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:17:52 - INFO - TRAINING - Epoch: [142][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:17:56 - INFO - TRAINING - Epoch: [142][350/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:18:00 - INFO - TRAINING - Epoch: [142][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 23:18:04 - INFO - TRAINING - Epoch: [142][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:18:09 - INFO - EVALUATING - Epoch: [142][0/100]	Time 0.287 (0.287)	Data 0.260 (0.260)	Loss 0.4323 (0.4323)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:10 - INFO - EVALUATING - Epoch: [142][50/100]	Time 0.026 (0.032)	Data 0.001 (0.005)	Loss 0.1539 (0.3798)	Prec@1 96.000 (92.980)	Prec@5 100.000 (99.529)
2019-05-08 23:18:12 - INFO - 
 Epoch: 143	Training Loss 0.0005 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3540 	Validation Prec@1 93.460 	Validation Prec@5 99.670 	
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:18:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:18:12 - INFO - TRAINING - Epoch: [143][0/500]	Time 0.266 (0.266)	Data 0.198 (0.198)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:16 - INFO - TRAINING - Epoch: [143][50/500]	Time 0.073 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:20 - INFO - TRAINING - Epoch: [143][100/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:24 - INFO - TRAINING - Epoch: [143][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:29 - INFO - TRAINING - Epoch: [143][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0011 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:33 - INFO - TRAINING - Epoch: [143][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:37 - INFO - TRAINING - Epoch: [143][300/500]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:41 - INFO - TRAINING - Epoch: [143][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:45 - INFO - TRAINING - Epoch: [143][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:49 - INFO - TRAINING - Epoch: [143][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:54 - INFO - EVALUATING - Epoch: [143][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.3844 (0.3844)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:18:55 - INFO - EVALUATING - Epoch: [143][50/100]	Time 0.027 (0.032)	Data 0.000 (0.005)	Loss 0.1391 (0.3765)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.569)
2019-05-08 23:18:56 - INFO - 
 Epoch: 144	Training Loss 0.0004 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3503 	Validation Prec@1 93.510 	Validation Prec@5 99.680 	
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:18:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:18:57 - INFO - TRAINING - Epoch: [144][0/500]	Time 0.254 (0.254)	Data 0.213 (0.213)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:01 - INFO - TRAINING - Epoch: [144][50/500]	Time 0.086 (0.084)	Data 0.000 (0.005)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:05 - INFO - TRAINING - Epoch: [144][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:09 - INFO - TRAINING - Epoch: [144][150/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:19:13 - INFO - TRAINING - Epoch: [144][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0109 (0.0004)	Prec@1 99.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:19:17 - INFO - TRAINING - Epoch: [144][250/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0019 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:19:22 - INFO - TRAINING - Epoch: [144][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:19:26 - INFO - TRAINING - Epoch: [144][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:19:30 - INFO - TRAINING - Epoch: [144][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:19:34 - INFO - TRAINING - Epoch: [144][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:19:38 - INFO - EVALUATING - Epoch: [144][0/100]	Time 0.289 (0.289)	Data 0.264 (0.264)	Loss 0.3930 (0.3930)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:40 - INFO - EVALUATING - Epoch: [144][50/100]	Time 0.027 (0.033)	Data 0.001 (0.005)	Loss 0.1583 (0.3719)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.608)
2019-05-08 23:19:41 - INFO - 
 Epoch: 145	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3466 	Validation Prec@1 93.590 	Validation Prec@5 99.730 	
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:19:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:19:42 - INFO - TRAINING - Epoch: [145][0/500]	Time 0.261 (0.261)	Data 0.199 (0.199)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:46 - INFO - TRAINING - Epoch: [145][50/500]	Time 0.080 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:50 - INFO - TRAINING - Epoch: [145][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:54 - INFO - TRAINING - Epoch: [145][150/500]	Time 0.078 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:19:58 - INFO - TRAINING - Epoch: [145][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:02 - INFO - TRAINING - Epoch: [145][250/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:06 - INFO - TRAINING - Epoch: [145][300/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:11 - INFO - TRAINING - Epoch: [145][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:15 - INFO - TRAINING - Epoch: [145][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:19 - INFO - TRAINING - Epoch: [145][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:20:23 - INFO - EVALUATING - Epoch: [145][0/100]	Time 0.289 (0.289)	Data 0.264 (0.264)	Loss 0.3831 (0.3831)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:25 - INFO - EVALUATING - Epoch: [145][50/100]	Time 0.026 (0.032)	Data 0.000 (0.005)	Loss 0.1504 (0.3737)	Prec@1 96.000 (93.176)	Prec@5 100.000 (99.569)
2019-05-08 23:20:26 - INFO - 
 Epoch: 146	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3482 	Validation Prec@1 93.570 	Validation Prec@5 99.710 	
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:20:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:20:26 - INFO - TRAINING - Epoch: [146][0/500]	Time 0.274 (0.274)	Data 0.199 (0.199)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:30 - INFO - TRAINING - Epoch: [146][50/500]	Time 0.086 (0.083)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:34 - INFO - TRAINING - Epoch: [146][100/500]	Time 0.073 (0.081)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:38 - INFO - TRAINING - Epoch: [146][150/500]	Time 0.086 (0.081)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:43 - INFO - TRAINING - Epoch: [146][200/500]	Time 0.072 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:47 - INFO - TRAINING - Epoch: [146][250/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:51 - INFO - TRAINING - Epoch: [146][300/500]	Time 0.066 (0.082)	Data 0.001 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:55 - INFO - TRAINING - Epoch: [146][350/500]	Time 0.072 (0.082)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:20:59 - INFO - TRAINING - Epoch: [146][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:21:03 - INFO - TRAINING - Epoch: [146][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:21:07 - INFO - EVALUATING - Epoch: [146][0/100]	Time 0.294 (0.294)	Data 0.269 (0.269)	Loss 0.4209 (0.4209)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:09 - INFO - EVALUATING - Epoch: [146][50/100]	Time 0.034 (0.033)	Data 0.000 (0.006)	Loss 0.1489 (0.3713)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.569)
2019-05-08 23:21:10 - INFO - 
 Epoch: 147	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3461 	Validation Prec@1 93.480 	Validation Prec@5 99.710 	
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:21:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:21:11 - INFO - TRAINING - Epoch: [147][0/500]	Time 0.264 (0.264)	Data 0.223 (0.223)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:15 - INFO - TRAINING - Epoch: [147][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:19 - INFO - TRAINING - Epoch: [147][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0004 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:23 - INFO - TRAINING - Epoch: [147][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:27 - INFO - TRAINING - Epoch: [147][200/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:31 - INFO - TRAINING - Epoch: [147][250/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0008 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:35 - INFO - TRAINING - Epoch: [147][300/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:21:40 - INFO - TRAINING - Epoch: [147][350/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:21:44 - INFO - TRAINING - Epoch: [147][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:21:48 - INFO - TRAINING - Epoch: [147][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:21:52 - INFO - EVALUATING - Epoch: [147][0/100]	Time 0.311 (0.311)	Data 0.264 (0.264)	Loss 0.3914 (0.3914)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:53 - INFO - EVALUATING - Epoch: [147][50/100]	Time 0.044 (0.033)	Data 0.000 (0.005)	Loss 0.1559 (0.3709)	Prec@1 96.000 (92.961)	Prec@5 100.000 (99.549)
2019-05-08 23:21:55 - INFO - 
 Epoch: 148	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3446 	Validation Prec@1 93.480 	Validation Prec@5 99.690 	
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:21:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:21:55 - INFO - TRAINING - Epoch: [148][0/500]	Time 0.258 (0.258)	Data 0.215 (0.215)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:21:59 - INFO - TRAINING - Epoch: [148][50/500]	Time 0.081 (0.084)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:03 - INFO - TRAINING - Epoch: [148][100/500]	Time 0.085 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:08 - INFO - TRAINING - Epoch: [148][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:12 - INFO - TRAINING - Epoch: [148][200/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0012 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:16 - INFO - TRAINING - Epoch: [148][250/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:20 - INFO - TRAINING - Epoch: [148][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:24 - INFO - TRAINING - Epoch: [148][350/500]	Time 0.071 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:22:28 - INFO - TRAINING - Epoch: [148][400/500]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:22:32 - INFO - TRAINING - Epoch: [148][450/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0008 (0.0003)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:22:37 - INFO - EVALUATING - Epoch: [148][0/100]	Time 0.281 (0.281)	Data 0.256 (0.256)	Loss 0.3957 (0.3957)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:38 - INFO - EVALUATING - Epoch: [148][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.1638 (0.3774)	Prec@1 96.000 (92.961)	Prec@5 100.000 (99.549)
2019-05-08 23:22:39 - INFO - 
 Epoch: 149	Training Loss 0.0003 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3506 	Validation Prec@1 93.480 	Validation Prec@5 99.680 	
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:22:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:22:40 - INFO - TRAINING - Epoch: [149][0/500]	Time 0.267 (0.267)	Data 0.224 (0.224)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:44 - INFO - TRAINING - Epoch: [149][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:48 - INFO - TRAINING - Epoch: [149][100/500]	Time 0.084 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:22:52 - INFO - TRAINING - Epoch: [149][150/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0015 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:22:56 - INFO - TRAINING - Epoch: [149][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0167 (0.0005)	Prec@1 99.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:23:00 - INFO - TRAINING - Epoch: [149][250/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.0008 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:23:04 - INFO - TRAINING - Epoch: [149][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:23:09 - INFO - TRAINING - Epoch: [149][350/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0007 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:23:13 - INFO - TRAINING - Epoch: [149][400/500]	Time 0.075 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:23:17 - INFO - TRAINING - Epoch: [149][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:23:21 - INFO - EVALUATING - Epoch: [149][0/100]	Time 0.299 (0.299)	Data 0.271 (0.271)	Loss 0.4097 (0.4097)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:23 - INFO - EVALUATING - Epoch: [149][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1510 (0.3793)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.588)
2019-05-08 23:23:24 - INFO - 
 Epoch: 150	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3510 	Validation Prec@1 93.580 	Validation Prec@5 99.700 	
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:23:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:23:25 - INFO - TRAINING - Epoch: [150][0/500]	Time 0.259 (0.259)	Data 0.195 (0.195)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:29 - INFO - TRAINING - Epoch: [150][50/500]	Time 0.084 (0.083)	Data 0.000 (0.004)	Loss 0.0001 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:33 - INFO - TRAINING - Epoch: [150][100/500]	Time 0.079 (0.083)	Data 0.000 (0.003)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:37 - INFO - TRAINING - Epoch: [150][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:41 - INFO - TRAINING - Epoch: [150][200/500]	Time 0.048 (0.082)	Data 0.001 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:45 - INFO - TRAINING - Epoch: [150][250/500]	Time 0.086 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:49 - INFO - TRAINING - Epoch: [150][300/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0035 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:23:53 - INFO - TRAINING - Epoch: [150][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:23:57 - INFO - TRAINING - Epoch: [150][400/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:24:01 - INFO - TRAINING - Epoch: [150][450/500]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.0005 (0.0005)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:24:06 - INFO - EVALUATING - Epoch: [150][0/100]	Time 0.283 (0.283)	Data 0.258 (0.258)	Loss 0.3782 (0.3782)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:07 - INFO - EVALUATING - Epoch: [150][50/100]	Time 0.026 (0.032)	Data 0.000 (0.005)	Loss 0.1461 (0.3741)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.588)
2019-05-08 23:24:08 - INFO - 
 Epoch: 151	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3468 	Validation Prec@1 93.500 	Validation Prec@5 99.710 	
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:24:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:24:09 - INFO - TRAINING - Epoch: [151][0/500]	Time 0.257 (0.257)	Data 0.204 (0.204)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:13 - INFO - TRAINING - Epoch: [151][50/500]	Time 0.082 (0.087)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:17 - INFO - TRAINING - Epoch: [151][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0038 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:21 - INFO - TRAINING - Epoch: [151][150/500]	Time 0.077 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:26 - INFO - TRAINING - Epoch: [151][200/500]	Time 0.092 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:24:30 - INFO - TRAINING - Epoch: [151][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:24:34 - INFO - TRAINING - Epoch: [151][300/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:24:38 - INFO - TRAINING - Epoch: [151][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:24:42 - INFO - TRAINING - Epoch: [151][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:24:46 - INFO - TRAINING - Epoch: [151][450/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:24:51 - INFO - EVALUATING - Epoch: [151][0/100]	Time 0.337 (0.337)	Data 0.290 (0.290)	Loss 0.3959 (0.3959)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:52 - INFO - EVALUATING - Epoch: [151][50/100]	Time 0.023 (0.034)	Data 0.000 (0.006)	Loss 0.1350 (0.3693)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.569)
2019-05-08 23:24:53 - INFO - 
 Epoch: 152	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3446 	Validation Prec@1 93.480 	Validation Prec@5 99.720 	
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:24:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:24:54 - INFO - TRAINING - Epoch: [152][0/500]	Time 0.264 (0.264)	Data 0.204 (0.204)	Loss 0.0191 (0.0191)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-08 23:24:58 - INFO - TRAINING - Epoch: [152][50/500]	Time 0.088 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:25:02 - INFO - TRAINING - Epoch: [152][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:25:06 - INFO - TRAINING - Epoch: [152][150/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:25:10 - INFO - TRAINING - Epoch: [152][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:25:15 - INFO - TRAINING - Epoch: [152][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:25:19 - INFO - TRAINING - Epoch: [152][300/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:25:23 - INFO - TRAINING - Epoch: [152][350/500]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.0010 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:25:27 - INFO - TRAINING - Epoch: [152][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:25:31 - INFO - TRAINING - Epoch: [152][450/500]	Time 0.075 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:25:35 - INFO - EVALUATING - Epoch: [152][0/100]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.3993 (0.3993)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:36 - INFO - EVALUATING - Epoch: [152][50/100]	Time 0.026 (0.033)	Data 0.001 (0.005)	Loss 0.1612 (0.3719)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.549)
2019-05-08 23:25:38 - INFO - 
 Epoch: 153	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3451 	Validation Prec@1 93.550 	Validation Prec@5 99.690 	
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:25:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:25:38 - INFO - TRAINING - Epoch: [153][0/500]	Time 0.259 (0.259)	Data 0.209 (0.209)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:42 - INFO - TRAINING - Epoch: [153][50/500]	Time 0.065 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:47 - INFO - TRAINING - Epoch: [153][100/500]	Time 0.089 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:51 - INFO - TRAINING - Epoch: [153][150/500]	Time 0.079 (0.084)	Data 0.000 (0.002)	Loss 0.0007 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:55 - INFO - TRAINING - Epoch: [153][200/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:25:59 - INFO - TRAINING - Epoch: [153][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:03 - INFO - TRAINING - Epoch: [153][300/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:07 - INFO - TRAINING - Epoch: [153][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:12 - INFO - TRAINING - Epoch: [153][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:26:16 - INFO - TRAINING - Epoch: [153][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:26:20 - INFO - EVALUATING - Epoch: [153][0/100]	Time 0.285 (0.285)	Data 0.261 (0.261)	Loss 0.3968 (0.3968)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:21 - INFO - EVALUATING - Epoch: [153][50/100]	Time 0.035 (0.032)	Data 0.000 (0.005)	Loss 0.1484 (0.3722)	Prec@1 96.000 (92.863)	Prec@5 100.000 (99.627)
2019-05-08 23:26:23 - INFO - 
 Epoch: 154	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3465 	Validation Prec@1 93.400 	Validation Prec@5 99.750 	
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:26:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:26:23 - INFO - TRAINING - Epoch: [154][0/500]	Time 0.258 (0.258)	Data 0.198 (0.198)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:27 - INFO - TRAINING - Epoch: [154][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:31 - INFO - TRAINING - Epoch: [154][100/500]	Time 0.083 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:36 - INFO - TRAINING - Epoch: [154][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0016 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:26:40 - INFO - TRAINING - Epoch: [154][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:26:44 - INFO - TRAINING - Epoch: [154][250/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:26:48 - INFO - TRAINING - Epoch: [154][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0010 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:26:52 - INFO - TRAINING - Epoch: [154][350/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:26:56 - INFO - TRAINING - Epoch: [154][400/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:27:01 - INFO - TRAINING - Epoch: [154][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:27:05 - INFO - EVALUATING - Epoch: [154][0/100]	Time 0.295 (0.295)	Data 0.270 (0.270)	Loss 0.3895 (0.3895)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:06 - INFO - EVALUATING - Epoch: [154][50/100]	Time 0.041 (0.033)	Data 0.000 (0.006)	Loss 0.1436 (0.3737)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.549)
2019-05-08 23:27:08 - INFO - 
 Epoch: 155	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3457 	Validation Prec@1 93.570 	Validation Prec@5 99.690 	
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:27:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:27:08 - INFO - TRAINING - Epoch: [155][0/500]	Time 0.244 (0.244)	Data 0.189 (0.189)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:12 - INFO - TRAINING - Epoch: [155][50/500]	Time 0.084 (0.085)	Data 0.000 (0.004)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:16 - INFO - TRAINING - Epoch: [155][100/500]	Time 0.076 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:21 - INFO - TRAINING - Epoch: [155][150/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0038 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:25 - INFO - TRAINING - Epoch: [155][200/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:29 - INFO - TRAINING - Epoch: [155][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:33 - INFO - TRAINING - Epoch: [155][300/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:37 - INFO - TRAINING - Epoch: [155][350/500]	Time 0.068 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:41 - INFO - TRAINING - Epoch: [155][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:45 - INFO - TRAINING - Epoch: [155][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:27:50 - INFO - EVALUATING - Epoch: [155][0/100]	Time 0.286 (0.286)	Data 0.259 (0.259)	Loss 0.3988 (0.3988)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:51 - INFO - EVALUATING - Epoch: [155][50/100]	Time 0.040 (0.032)	Data 0.000 (0.005)	Loss 0.1509 (0.3759)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.627)
2019-05-08 23:27:52 - INFO - 
 Epoch: 156	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3473 	Validation Prec@1 93.530 	Validation Prec@5 99.740 	
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:27:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:27:53 - INFO - TRAINING - Epoch: [156][0/500]	Time 0.260 (0.260)	Data 0.218 (0.218)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:27:57 - INFO - TRAINING - Epoch: [156][50/500]	Time 0.070 (0.085)	Data 0.000 (0.005)	Loss 0.0007 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:01 - INFO - TRAINING - Epoch: [156][100/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:05 - INFO - TRAINING - Epoch: [156][150/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:09 - INFO - TRAINING - Epoch: [156][200/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0006)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:28:13 - INFO - TRAINING - Epoch: [156][250/500]	Time 0.082 (0.082)	Data 0.000 (0.002)	Loss 0.0010 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:28:17 - INFO - TRAINING - Epoch: [156][300/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:28:21 - INFO - TRAINING - Epoch: [156][350/500]	Time 0.083 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:28:25 - INFO - TRAINING - Epoch: [156][400/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:28:29 - INFO - TRAINING - Epoch: [156][450/500]	Time 0.091 (0.082)	Data 0.000 (0.001)	Loss 0.0007 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:28:34 - INFO - EVALUATING - Epoch: [156][0/100]	Time 0.281 (0.281)	Data 0.255 (0.255)	Loss 0.4003 (0.4003)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:35 - INFO - EVALUATING - Epoch: [156][50/100]	Time 0.023 (0.033)	Data 0.000 (0.005)	Loss 0.1550 (0.3750)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.588)
2019-05-08 23:28:37 - INFO - 
 Epoch: 157	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3485 	Validation Prec@1 93.570 	Validation Prec@5 99.700 	
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:28:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:28:37 - INFO - TRAINING - Epoch: [157][0/500]	Time 0.269 (0.269)	Data 0.228 (0.228)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:41 - INFO - TRAINING - Epoch: [157][50/500]	Time 0.084 (0.084)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:28:45 - INFO - TRAINING - Epoch: [157][100/500]	Time 0.084 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:28:49 - INFO - TRAINING - Epoch: [157][150/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:28:54 - INFO - TRAINING - Epoch: [157][200/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:28:58 - INFO - TRAINING - Epoch: [157][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 23:29:02 - INFO - TRAINING - Epoch: [157][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:29:06 - INFO - TRAINING - Epoch: [157][350/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 23:29:10 - INFO - TRAINING - Epoch: [157][400/500]	Time 0.073 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 23:29:14 - INFO - TRAINING - Epoch: [157][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:29:18 - INFO - EVALUATING - Epoch: [157][0/100]	Time 0.304 (0.304)	Data 0.263 (0.263)	Loss 0.3935 (0.3935)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:29:20 - INFO - EVALUATING - Epoch: [157][50/100]	Time 0.026 (0.032)	Data 0.001 (0.005)	Loss 0.1463 (0.3741)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.588)
2019-05-08 23:29:21 - INFO - 
 Epoch: 158	Training Loss 0.0004 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3465 	Validation Prec@1 93.550 	Validation Prec@5 99.730 	
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:29:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:29:21 - INFO - TRAINING - Epoch: [158][0/500]	Time 0.244 (0.244)	Data 0.190 (0.190)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:29:26 - INFO - TRAINING - Epoch: [158][50/500]	Time 0.078 (0.086)	Data 0.000 (0.005)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:29:30 - INFO - TRAINING - Epoch: [158][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:29:34 - INFO - TRAINING - Epoch: [158][150/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:29:38 - INFO - TRAINING - Epoch: [158][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:29:42 - INFO - TRAINING - Epoch: [158][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:29:46 - INFO - TRAINING - Epoch: [158][300/500]	Time 0.072 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:29:50 - INFO - TRAINING - Epoch: [158][350/500]	Time 0.076 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:29:54 - INFO - TRAINING - Epoch: [158][400/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:29:58 - INFO - TRAINING - Epoch: [158][450/500]	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 0.0007 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:30:03 - INFO - EVALUATING - Epoch: [158][0/100]	Time 0.310 (0.310)	Data 0.263 (0.263)	Loss 0.3588 (0.3588)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:04 - INFO - EVALUATING - Epoch: [158][50/100]	Time 0.022 (0.033)	Data 0.000 (0.005)	Loss 0.1275 (0.3777)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.529)
2019-05-08 23:30:05 - INFO - 
 Epoch: 159	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3512 	Validation Prec@1 93.530 	Validation Prec@5 99.670 	
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:30:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:30:06 - INFO - TRAINING - Epoch: [159][0/500]	Time 0.269 (0.269)	Data 0.212 (0.212)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:10 - INFO - TRAINING - Epoch: [159][50/500]	Time 0.083 (0.088)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:14 - INFO - TRAINING - Epoch: [159][100/500]	Time 0.086 (0.085)	Data 0.000 (0.003)	Loss 0.0006 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:18 - INFO - TRAINING - Epoch: [159][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:22 - INFO - TRAINING - Epoch: [159][200/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:27 - INFO - TRAINING - Epoch: [159][250/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:31 - INFO - TRAINING - Epoch: [159][300/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:30:35 - INFO - TRAINING - Epoch: [159][350/500]	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:30:39 - INFO - TRAINING - Epoch: [159][400/500]	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:30:43 - INFO - TRAINING - Epoch: [159][450/500]	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:30:48 - INFO - EVALUATING - Epoch: [159][0/100]	Time 0.293 (0.293)	Data 0.268 (0.268)	Loss 0.4007 (0.4007)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:49 - INFO - EVALUATING - Epoch: [159][50/100]	Time 0.026 (0.032)	Data 0.001 (0.006)	Loss 0.1450 (0.3746)	Prec@1 96.000 (92.980)	Prec@5 100.000 (99.608)
2019-05-08 23:30:50 - INFO - 
 Epoch: 160	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3466 	Validation Prec@1 93.520 	Validation Prec@5 99.720 	
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:30:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:30:51 - INFO - TRAINING - Epoch: [160][0/500]	Time 0.244 (0.244)	Data 0.188 (0.188)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:55 - INFO - TRAINING - Epoch: [160][50/500]	Time 0.086 (0.084)	Data 0.000 (0.005)	Loss 0.0000 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:30:59 - INFO - TRAINING - Epoch: [160][100/500]	Time 0.090 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:03 - INFO - TRAINING - Epoch: [160][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:07 - INFO - TRAINING - Epoch: [160][200/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:11 - INFO - TRAINING - Epoch: [160][250/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:16 - INFO - TRAINING - Epoch: [160][300/500]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:20 - INFO - TRAINING - Epoch: [160][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:24 - INFO - TRAINING - Epoch: [160][400/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:31:28 - INFO - TRAINING - Epoch: [160][450/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0012 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:31:32 - INFO - EVALUATING - Epoch: [160][0/100]	Time 0.243 (0.243)	Data 0.205 (0.205)	Loss 0.3607 (0.3607)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:33 - INFO - EVALUATING - Epoch: [160][50/100]	Time 0.023 (0.032)	Data 0.000 (0.004)	Loss 0.1400 (0.3775)	Prec@1 96.000 (93.216)	Prec@5 100.000 (99.549)
2019-05-08 23:31:35 - INFO - 
 Epoch: 161	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3506 	Validation Prec@1 93.660 	Validation Prec@5 99.700 	
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:31:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:31:35 - INFO - TRAINING - Epoch: [161][0/500]	Time 0.254 (0.254)	Data 0.213 (0.213)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:31:40 - INFO - TRAINING - Epoch: [161][50/500]	Time 0.088 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:31:44 - INFO - TRAINING - Epoch: [161][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:31:48 - INFO - TRAINING - Epoch: [161][150/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:31:52 - INFO - TRAINING - Epoch: [161][200/500]	Time 0.069 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:31:56 - INFO - TRAINING - Epoch: [161][250/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0010 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:32:00 - INFO - TRAINING - Epoch: [161][300/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:32:05 - INFO - TRAINING - Epoch: [161][350/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:32:09 - INFO - TRAINING - Epoch: [161][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:32:13 - INFO - TRAINING - Epoch: [161][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0031 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:32:17 - INFO - EVALUATING - Epoch: [161][0/100]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.4047 (0.4047)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:32:18 - INFO - EVALUATING - Epoch: [161][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.1316 (0.3783)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.627)
2019-05-08 23:32:20 - INFO - 
 Epoch: 162	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3516 	Validation Prec@1 93.530 	Validation Prec@5 99.740 	
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:32:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:32:20 - INFO - TRAINING - Epoch: [162][0/500]	Time 0.255 (0.255)	Data 0.190 (0.190)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:32:24 - INFO - TRAINING - Epoch: [162][50/500]	Time 0.091 (0.086)	Data 0.000 (0.005)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:32:28 - INFO - TRAINING - Epoch: [162][100/500]	Time 0.085 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:32:33 - INFO - TRAINING - Epoch: [162][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:32:36 - INFO - TRAINING - Epoch: [162][200/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0011 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:32:41 - INFO - TRAINING - Epoch: [162][250/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:32:45 - INFO - TRAINING - Epoch: [162][300/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:32:49 - INFO - TRAINING - Epoch: [162][350/500]	Time 0.060 (0.083)	Data 0.001 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:32:53 - INFO - TRAINING - Epoch: [162][400/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:32:57 - INFO - TRAINING - Epoch: [162][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:33:01 - INFO - EVALUATING - Epoch: [162][0/100]	Time 0.291 (0.291)	Data 0.263 (0.263)	Loss 0.4028 (0.4028)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:03 - INFO - EVALUATING - Epoch: [162][50/100]	Time 0.027 (0.033)	Data 0.001 (0.005)	Loss 0.1474 (0.3774)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.569)
2019-05-08 23:33:04 - INFO - 
 Epoch: 163	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3508 	Validation Prec@1 93.540 	Validation Prec@5 99.690 	
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:33:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:33:05 - INFO - TRAINING - Epoch: [163][0/500]	Time 0.258 (0.258)	Data 0.195 (0.195)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:09 - INFO - TRAINING - Epoch: [163][50/500]	Time 0.089 (0.087)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:13 - INFO - TRAINING - Epoch: [163][100/500]	Time 0.091 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:17 - INFO - TRAINING - Epoch: [163][150/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:21 - INFO - TRAINING - Epoch: [163][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:26 - INFO - TRAINING - Epoch: [163][250/500]	Time 0.089 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:30 - INFO - TRAINING - Epoch: [163][300/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:34 - INFO - TRAINING - Epoch: [163][350/500]	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:38 - INFO - TRAINING - Epoch: [163][400/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:33:42 - INFO - TRAINING - Epoch: [163][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0016 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:33:46 - INFO - EVALUATING - Epoch: [163][0/100]	Time 0.302 (0.302)	Data 0.274 (0.274)	Loss 0.3728 (0.3728)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:48 - INFO - EVALUATING - Epoch: [163][50/100]	Time 0.028 (0.032)	Data 0.000 (0.006)	Loss 0.1463 (0.3760)	Prec@1 96.000 (93.216)	Prec@5 100.000 (99.588)
2019-05-08 23:33:49 - INFO - 
 Epoch: 164	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3501 	Validation Prec@1 93.660 	Validation Prec@5 99.720 	
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:33:49 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:33:50 - INFO - TRAINING - Epoch: [164][0/500]	Time 0.254 (0.254)	Data 0.193 (0.193)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:33:54 - INFO - TRAINING - Epoch: [164][50/500]	Time 0.083 (0.086)	Data 0.000 (0.005)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:33:58 - INFO - TRAINING - Epoch: [164][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:34:02 - INFO - TRAINING - Epoch: [164][150/500]	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:34:06 - INFO - TRAINING - Epoch: [164][200/500]	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 23:34:11 - INFO - TRAINING - Epoch: [164][250/500]	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 0.0000 (0.0006)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 23:34:15 - INFO - TRAINING - Epoch: [164][300/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:34:19 - INFO - TRAINING - Epoch: [164][350/500]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:34:23 - INFO - TRAINING - Epoch: [164][400/500]	Time 0.079 (0.084)	Data 0.000 (0.001)	Loss 0.0008 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:34:27 - INFO - TRAINING - Epoch: [164][450/500]	Time 0.075 (0.084)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:34:32 - INFO - EVALUATING - Epoch: [164][0/100]	Time 0.327 (0.327)	Data 0.280 (0.280)	Loss 0.3877 (0.3877)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:34:33 - INFO - EVALUATING - Epoch: [164][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1323 (0.3737)	Prec@1 96.000 (93.196)	Prec@5 100.000 (99.608)
2019-05-08 23:34:34 - INFO - 
 Epoch: 165	Training Loss 0.0007 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3471 	Validation Prec@1 93.580 	Validation Prec@5 99.730 	
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:34:35 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:34:35 - INFO - TRAINING - Epoch: [165][0/500]	Time 0.255 (0.255)	Data 0.200 (0.200)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:34:39 - INFO - TRAINING - Epoch: [165][50/500]	Time 0.077 (0.086)	Data 0.000 (0.005)	Loss 0.0009 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:34:43 - INFO - TRAINING - Epoch: [165][100/500]	Time 0.083 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:34:47 - INFO - TRAINING - Epoch: [165][150/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:34:51 - INFO - TRAINING - Epoch: [165][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:34:56 - INFO - TRAINING - Epoch: [165][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:35:00 - INFO - TRAINING - Epoch: [165][300/500]	Time 0.075 (0.083)	Data 0.001 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:35:04 - INFO - TRAINING - Epoch: [165][350/500]	Time 0.073 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:35:08 - INFO - TRAINING - Epoch: [165][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:35:12 - INFO - TRAINING - Epoch: [165][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:35:16 - INFO - EVALUATING - Epoch: [165][0/100]	Time 0.320 (0.320)	Data 0.269 (0.269)	Loss 0.3818 (0.3818)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:35:18 - INFO - EVALUATING - Epoch: [165][50/100]	Time 0.023 (0.032)	Data 0.000 (0.006)	Loss 0.1406 (0.3759)	Prec@1 96.000 (93.157)	Prec@5 100.000 (99.588)
2019-05-08 23:35:19 - INFO - 
 Epoch: 166	Training Loss 0.0003 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3493 	Validation Prec@1 93.610 	Validation Prec@5 99.700 	
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:35:19 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:35:19 - INFO - TRAINING - Epoch: [166][0/500]	Time 0.250 (0.250)	Data 0.192 (0.192)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:35:23 - INFO - TRAINING - Epoch: [166][50/500]	Time 0.070 (0.082)	Data 0.000 (0.005)	Loss 0.0001 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:35:27 - INFO - TRAINING - Epoch: [166][100/500]	Time 0.076 (0.081)	Data 0.000 (0.003)	Loss 0.0007 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:35:31 - INFO - TRAINING - Epoch: [166][150/500]	Time 0.084 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:35:36 - INFO - TRAINING - Epoch: [166][200/500]	Time 0.084 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:35:40 - INFO - TRAINING - Epoch: [166][250/500]	Time 0.076 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:35:44 - INFO - TRAINING - Epoch: [166][300/500]	Time 0.077 (0.081)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:35:48 - INFO - TRAINING - Epoch: [166][350/500]	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:35:52 - INFO - TRAINING - Epoch: [166][400/500]	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:35:56 - INFO - TRAINING - Epoch: [166][450/500]	Time 0.089 (0.081)	Data 0.000 (0.001)	Loss 0.0012 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:36:00 - INFO - EVALUATING - Epoch: [166][0/100]	Time 0.290 (0.290)	Data 0.265 (0.265)	Loss 0.3932 (0.3932)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:01 - INFO - EVALUATING - Epoch: [166][50/100]	Time 0.027 (0.033)	Data 0.001 (0.005)	Loss 0.1433 (0.3754)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.608)
2019-05-08 23:36:03 - INFO - 
 Epoch: 167	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3485 	Validation Prec@1 93.580 	Validation Prec@5 99.730 	
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:36:03 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:36:03 - INFO - TRAINING - Epoch: [167][0/500]	Time 0.268 (0.268)	Data 0.218 (0.218)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:07 - INFO - TRAINING - Epoch: [167][50/500]	Time 0.084 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:12 - INFO - TRAINING - Epoch: [167][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:16 - INFO - TRAINING - Epoch: [167][150/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:20 - INFO - TRAINING - Epoch: [167][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:24 - INFO - TRAINING - Epoch: [167][250/500]	Time 0.052 (0.083)	Data 0.001 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:28 - INFO - TRAINING - Epoch: [167][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:32 - INFO - TRAINING - Epoch: [167][350/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0012 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:36 - INFO - TRAINING - Epoch: [167][400/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0005 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:40 - INFO - TRAINING - Epoch: [167][450/500]	Time 0.075 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:44 - INFO - EVALUATING - Epoch: [167][0/100]	Time 0.288 (0.288)	Data 0.264 (0.264)	Loss 0.3794 (0.3794)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:46 - INFO - EVALUATING - Epoch: [167][50/100]	Time 0.028 (0.032)	Data 0.000 (0.005)	Loss 0.1317 (0.3735)	Prec@1 96.000 (93.216)	Prec@5 100.000 (99.588)
2019-05-08 23:36:47 - INFO - 
 Epoch: 168	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3464 	Validation Prec@1 93.640 	Validation Prec@5 99.700 	
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:36:47 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:36:48 - INFO - TRAINING - Epoch: [168][0/500]	Time 0.273 (0.273)	Data 0.230 (0.230)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:52 - INFO - TRAINING - Epoch: [168][50/500]	Time 0.086 (0.086)	Data 0.000 (0.005)	Loss 0.0044 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:36:56 - INFO - TRAINING - Epoch: [168][100/500]	Time 0.080 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:00 - INFO - TRAINING - Epoch: [168][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0056 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:04 - INFO - TRAINING - Epoch: [168][200/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:37:08 - INFO - TRAINING - Epoch: [168][250/500]	Time 0.070 (0.083)	Data 0.000 (0.002)	Loss 0.0018 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:37:12 - INFO - TRAINING - Epoch: [168][300/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.0020 (0.0005)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:37:16 - INFO - TRAINING - Epoch: [168][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0014 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:37:21 - INFO - TRAINING - Epoch: [168][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:37:25 - INFO - TRAINING - Epoch: [168][450/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:37:29 - INFO - EVALUATING - Epoch: [168][0/100]	Time 0.303 (0.303)	Data 0.276 (0.276)	Loss 0.3840 (0.3840)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:30 - INFO - EVALUATING - Epoch: [168][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1292 (0.3765)	Prec@1 96.000 (93.196)	Prec@5 100.000 (99.608)
2019-05-08 23:37:32 - INFO - 
 Epoch: 169	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3493 	Validation Prec@1 93.580 	Validation Prec@5 99.740 	
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:37:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:37:32 - INFO - TRAINING - Epoch: [169][0/500]	Time 0.260 (0.260)	Data 0.188 (0.188)	Loss 0.0005 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:36 - INFO - TRAINING - Epoch: [169][50/500]	Time 0.079 (0.087)	Data 0.000 (0.004)	Loss 0.0017 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:41 - INFO - TRAINING - Epoch: [169][100/500]	Time 0.079 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:45 - INFO - TRAINING - Epoch: [169][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:49 - INFO - TRAINING - Epoch: [169][200/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:53 - INFO - TRAINING - Epoch: [169][250/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:37:57 - INFO - TRAINING - Epoch: [169][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:38:01 - INFO - TRAINING - Epoch: [169][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:38:05 - INFO - TRAINING - Epoch: [169][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:38:09 - INFO - TRAINING - Epoch: [169][450/500]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:38:14 - INFO - EVALUATING - Epoch: [169][0/100]	Time 0.287 (0.287)	Data 0.261 (0.261)	Loss 0.3860 (0.3860)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:38:15 - INFO - EVALUATING - Epoch: [169][50/100]	Time 0.035 (0.032)	Data 0.000 (0.005)	Loss 0.1390 (0.3768)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.529)
2019-05-08 23:38:16 - INFO - 
 Epoch: 170	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3506 	Validation Prec@1 93.530 	Validation Prec@5 99.670 	
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:38:17 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:38:17 - INFO - TRAINING - Epoch: [170][0/500]	Time 0.259 (0.259)	Data 0.214 (0.214)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:38:21 - INFO - TRAINING - Epoch: [170][50/500]	Time 0.086 (0.085)	Data 0.000 (0.005)	Loss 0.0011 (0.0005)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:38:25 - INFO - TRAINING - Epoch: [170][100/500]	Time 0.085 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:38:29 - INFO - TRAINING - Epoch: [170][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:38:33 - INFO - TRAINING - Epoch: [170][200/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 23:38:37 - INFO - TRAINING - Epoch: [170][250/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 23:38:41 - INFO - TRAINING - Epoch: [170][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0012 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:38:46 - INFO - TRAINING - Epoch: [170][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0011 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:38:50 - INFO - TRAINING - Epoch: [170][400/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:38:54 - INFO - TRAINING - Epoch: [170][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:38:58 - INFO - EVALUATING - Epoch: [170][0/100]	Time 0.332 (0.332)	Data 0.287 (0.287)	Loss 0.3957 (0.3957)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:00 - INFO - EVALUATING - Epoch: [170][50/100]	Time 0.022 (0.033)	Data 0.000 (0.006)	Loss 0.1390 (0.3718)	Prec@1 96.000 (93.176)	Prec@5 100.000 (99.608)
2019-05-08 23:39:01 - INFO - 
 Epoch: 171	Training Loss 0.0004 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3459 	Validation Prec@1 93.580 	Validation Prec@5 99.720 	
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:39:01 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:39:02 - INFO - TRAINING - Epoch: [171][0/500]	Time 0.262 (0.262)	Data 0.204 (0.204)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:06 - INFO - TRAINING - Epoch: [171][50/500]	Time 0.081 (0.087)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:10 - INFO - TRAINING - Epoch: [171][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:14 - INFO - TRAINING - Epoch: [171][150/500]	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:39:18 - INFO - TRAINING - Epoch: [171][200/500]	Time 0.093 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:39:23 - INFO - TRAINING - Epoch: [171][250/500]	Time 0.091 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:39:27 - INFO - TRAINING - Epoch: [171][300/500]	Time 0.087 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:39:31 - INFO - TRAINING - Epoch: [171][350/500]	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:39:35 - INFO - TRAINING - Epoch: [171][400/500]	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:39:39 - INFO - TRAINING - Epoch: [171][450/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:39:43 - INFO - EVALUATING - Epoch: [171][0/100]	Time 0.299 (0.299)	Data 0.273 (0.273)	Loss 0.4195 (0.4195)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:45 - INFO - EVALUATING - Epoch: [171][50/100]	Time 0.027 (0.033)	Data 0.000 (0.006)	Loss 0.1463 (0.3737)	Prec@1 96.000 (93.157)	Prec@5 100.000 (99.588)
2019-05-08 23:39:46 - INFO - 
 Epoch: 172	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3483 	Validation Prec@1 93.550 	Validation Prec@5 99.710 	
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:39:46 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:39:47 - INFO - TRAINING - Epoch: [172][0/500]	Time 0.268 (0.268)	Data 0.227 (0.227)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:51 - INFO - TRAINING - Epoch: [172][50/500]	Time 0.085 (0.085)	Data 0.000 (0.005)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:55 - INFO - TRAINING - Epoch: [172][100/500]	Time 0.089 (0.084)	Data 0.000 (0.003)	Loss 0.0012 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:39:59 - INFO - TRAINING - Epoch: [172][150/500]	Time 0.089 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:03 - INFO - TRAINING - Epoch: [172][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:07 - INFO - TRAINING - Epoch: [172][250/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:11 - INFO - TRAINING - Epoch: [172][300/500]	Time 0.081 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:40:15 - INFO - TRAINING - Epoch: [172][350/500]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:40:19 - INFO - TRAINING - Epoch: [172][400/500]	Time 0.069 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:40:23 - INFO - TRAINING - Epoch: [172][450/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0008 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:40:28 - INFO - EVALUATING - Epoch: [172][0/100]	Time 0.295 (0.295)	Data 0.269 (0.269)	Loss 0.4040 (0.4040)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:29 - INFO - EVALUATING - Epoch: [172][50/100]	Time 0.049 (0.032)	Data 0.000 (0.006)	Loss 0.1430 (0.3730)	Prec@1 96.000 (92.902)	Prec@5 100.000 (99.627)
2019-05-08 23:40:30 - INFO - 
 Epoch: 173	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3456 	Validation Prec@1 93.510 	Validation Prec@5 99.750 	
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:40:31 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:40:31 - INFO - TRAINING - Epoch: [173][0/500]	Time 0.257 (0.257)	Data 0.201 (0.201)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:35 - INFO - TRAINING - Epoch: [173][50/500]	Time 0.084 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:39 - INFO - TRAINING - Epoch: [173][100/500]	Time 0.087 (0.085)	Data 0.000 (0.003)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:43 - INFO - TRAINING - Epoch: [173][150/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:47 - INFO - TRAINING - Epoch: [173][200/500]	Time 0.072 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:51 - INFO - TRAINING - Epoch: [173][250/500]	Time 0.090 (0.082)	Data 0.000 (0.002)	Loss 0.0013 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:40:55 - INFO - TRAINING - Epoch: [173][300/500]	Time 0.073 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:41:00 - INFO - TRAINING - Epoch: [173][350/500]	Time 0.074 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:41:04 - INFO - TRAINING - Epoch: [173][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:41:08 - INFO - TRAINING - Epoch: [173][450/500]	Time 0.071 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:41:12 - INFO - EVALUATING - Epoch: [173][0/100]	Time 0.286 (0.286)	Data 0.261 (0.261)	Loss 0.4028 (0.4028)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:41:13 - INFO - EVALUATING - Epoch: [173][50/100]	Time 0.027 (0.032)	Data 0.000 (0.005)	Loss 0.1494 (0.3783)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.588)
2019-05-08 23:41:15 - INFO - 
 Epoch: 174	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3503 	Validation Prec@1 93.590 	Validation Prec@5 99.690 	
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:41:15 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:41:15 - INFO - TRAINING - Epoch: [174][0/500]	Time 0.253 (0.253)	Data 0.211 (0.211)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:41:19 - INFO - TRAINING - Epoch: [174][50/500]	Time 0.084 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0008)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:41:24 - INFO - TRAINING - Epoch: [174][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:41:28 - INFO - TRAINING - Epoch: [174][150/500]	Time 0.079 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:41:32 - INFO - TRAINING - Epoch: [174][200/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:41:36 - INFO - TRAINING - Epoch: [174][250/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:41:40 - INFO - TRAINING - Epoch: [174][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:41:44 - INFO - TRAINING - Epoch: [174][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:41:48 - INFO - TRAINING - Epoch: [174][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:41:52 - INFO - TRAINING - Epoch: [174][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:41:57 - INFO - EVALUATING - Epoch: [174][0/100]	Time 0.327 (0.327)	Data 0.300 (0.300)	Loss 0.3991 (0.3991)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:41:58 - INFO - EVALUATING - Epoch: [174][50/100]	Time 0.033 (0.033)	Data 0.000 (0.006)	Loss 0.1492 (0.3755)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.588)
2019-05-08 23:42:00 - INFO - 
 Epoch: 175	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3463 	Validation Prec@1 93.560 	Validation Prec@5 99.720 	
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:42:00 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:42:00 - INFO - TRAINING - Epoch: [175][0/500]	Time 0.262 (0.262)	Data 0.192 (0.192)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:42:04 - INFO - TRAINING - Epoch: [175][50/500]	Time 0.083 (0.086)	Data 0.000 (0.005)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:42:08 - INFO - TRAINING - Epoch: [175][100/500]	Time 0.078 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:42:13 - INFO - TRAINING - Epoch: [175][150/500]	Time 0.077 (0.085)	Data 0.000 (0.002)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:42:17 - INFO - TRAINING - Epoch: [175][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:42:21 - INFO - TRAINING - Epoch: [175][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:42:25 - INFO - TRAINING - Epoch: [175][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:42:29 - INFO - TRAINING - Epoch: [175][350/500]	Time 0.069 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0003)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:42:33 - INFO - TRAINING - Epoch: [175][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:42:37 - INFO - TRAINING - Epoch: [175][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0003)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:42:41 - INFO - EVALUATING - Epoch: [175][0/100]	Time 0.293 (0.293)	Data 0.269 (0.269)	Loss 0.4223 (0.4223)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:42:42 - INFO - EVALUATING - Epoch: [175][50/100]	Time 0.031 (0.032)	Data 0.000 (0.006)	Loss 0.1523 (0.3770)	Prec@1 96.000 (93.216)	Prec@5 100.000 (99.608)
2019-05-08 23:42:44 - INFO - 
 Epoch: 176	Training Loss 0.0003 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3510 	Validation Prec@1 93.610 	Validation Prec@5 99.720 	
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:42:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:42:44 - INFO - TRAINING - Epoch: [176][0/500]	Time 0.252 (0.252)	Data 0.211 (0.211)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:42:48 - INFO - TRAINING - Epoch: [176][50/500]	Time 0.076 (0.084)	Data 0.000 (0.005)	Loss 0.0000 (0.0005)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:42:52 - INFO - TRAINING - Epoch: [176][100/500]	Time 0.081 (0.083)	Data 0.000 (0.003)	Loss 0.0084 (0.0006)	Prec@1 99.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:42:57 - INFO - TRAINING - Epoch: [176][150/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:43:01 - INFO - TRAINING - Epoch: [176][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:43:05 - INFO - TRAINING - Epoch: [176][250/500]	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:43:09 - INFO - TRAINING - Epoch: [176][300/500]	Time 0.070 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:43:13 - INFO - TRAINING - Epoch: [176][350/500]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:43:17 - INFO - TRAINING - Epoch: [176][400/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:43:21 - INFO - TRAINING - Epoch: [176][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0019 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:43:26 - INFO - EVALUATING - Epoch: [176][0/100]	Time 0.328 (0.328)	Data 0.283 (0.283)	Loss 0.3893 (0.3893)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:27 - INFO - EVALUATING - Epoch: [176][50/100]	Time 0.029 (0.033)	Data 0.000 (0.006)	Loss 0.1384 (0.3760)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.549)
2019-05-08 23:43:28 - INFO - 
 Epoch: 177	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3494 	Validation Prec@1 93.550 	Validation Prec@5 99.700 	
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:43:29 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:43:29 - INFO - TRAINING - Epoch: [177][0/500]	Time 0.266 (0.266)	Data 0.209 (0.209)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:33 - INFO - TRAINING - Epoch: [177][50/500]	Time 0.084 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:37 - INFO - TRAINING - Epoch: [177][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:41 - INFO - TRAINING - Epoch: [177][150/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:45 - INFO - TRAINING - Epoch: [177][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:43:50 - INFO - TRAINING - Epoch: [177][250/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:43:54 - INFO - TRAINING - Epoch: [177][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:43:58 - INFO - TRAINING - Epoch: [177][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:44:02 - INFO - TRAINING - Epoch: [177][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:44:06 - INFO - TRAINING - Epoch: [177][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:44:10 - INFO - EVALUATING - Epoch: [177][0/100]	Time 0.300 (0.300)	Data 0.272 (0.272)	Loss 0.3927 (0.3927)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:44:12 - INFO - EVALUATING - Epoch: [177][50/100]	Time 0.031 (0.032)	Data 0.000 (0.006)	Loss 0.1369 (0.3729)	Prec@1 96.000 (93.078)	Prec@5 100.000 (99.588)
2019-05-08 23:44:13 - INFO - 
 Epoch: 178	Training Loss 0.0004 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3461 	Validation Prec@1 93.530 	Validation Prec@5 99.720 	
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:44:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:44:14 - INFO - TRAINING - Epoch: [178][0/500]	Time 0.256 (0.256)	Data 0.205 (0.205)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:44:18 - INFO - TRAINING - Epoch: [178][50/500]	Time 0.081 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:44:22 - INFO - TRAINING - Epoch: [178][100/500]	Time 0.053 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:44:26 - INFO - TRAINING - Epoch: [178][150/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:44:30 - INFO - TRAINING - Epoch: [178][200/500]	Time 0.090 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:44:34 - INFO - TRAINING - Epoch: [178][250/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:44:38 - INFO - TRAINING - Epoch: [178][300/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:44:43 - INFO - TRAINING - Epoch: [178][350/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:44:47 - INFO - TRAINING - Epoch: [178][400/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:44:51 - INFO - TRAINING - Epoch: [178][450/500]	Time 0.080 (0.083)	Data 0.001 (0.001)	Loss 0.0020 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:44:55 - INFO - EVALUATING - Epoch: [178][0/100]	Time 0.287 (0.287)	Data 0.261 (0.261)	Loss 0.3994 (0.3994)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:44:57 - INFO - EVALUATING - Epoch: [178][50/100]	Time 0.038 (0.032)	Data 0.000 (0.005)	Loss 0.1424 (0.3742)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.608)
2019-05-08 23:44:58 - INFO - 
 Epoch: 179	Training Loss 0.0005 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3481 	Validation Prec@1 93.580 	Validation Prec@5 99.720 	
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:44:58 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:44:58 - INFO - TRAINING - Epoch: [179][0/500]	Time 0.251 (0.251)	Data 0.210 (0.210)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:03 - INFO - TRAINING - Epoch: [179][50/500]	Time 0.088 (0.085)	Data 0.000 (0.005)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:07 - INFO - TRAINING - Epoch: [179][100/500]	Time 0.071 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:11 - INFO - TRAINING - Epoch: [179][150/500]	Time 0.091 (0.084)	Data 0.000 (0.002)	Loss 0.0009 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:45:15 - INFO - TRAINING - Epoch: [179][200/500]	Time 0.077 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:45:19 - INFO - TRAINING - Epoch: [179][250/500]	Time 0.087 (0.083)	Data 0.000 (0.002)	Loss 0.0015 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:45:23 - INFO - TRAINING - Epoch: [179][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:45:27 - INFO - TRAINING - Epoch: [179][350/500]	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:45:31 - INFO - TRAINING - Epoch: [179][400/500]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:45:36 - INFO - TRAINING - Epoch: [179][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0025 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:45:40 - INFO - EVALUATING - Epoch: [179][0/100]	Time 0.329 (0.329)	Data 0.288 (0.288)	Loss 0.3902 (0.3902)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:41 - INFO - EVALUATING - Epoch: [179][50/100]	Time 0.026 (0.033)	Data 0.000 (0.006)	Loss 0.1413 (0.3758)	Prec@1 96.000 (93.000)	Prec@5 100.000 (99.588)
2019-05-08 23:45:43 - INFO - 
 Epoch: 180	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3470 	Validation Prec@1 93.520 	Validation Prec@5 99.690 	
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:45:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:45:43 - INFO - TRAINING - Epoch: [180][0/500]	Time 0.272 (0.272)	Data 0.203 (0.203)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:47 - INFO - TRAINING - Epoch: [180][50/500]	Time 0.069 (0.087)	Data 0.000 (0.005)	Loss 0.0008 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:51 - INFO - TRAINING - Epoch: [180][100/500]	Time 0.084 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:45:56 - INFO - TRAINING - Epoch: [180][150/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:00 - INFO - TRAINING - Epoch: [180][200/500]	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:04 - INFO - TRAINING - Epoch: [180][250/500]	Time 0.076 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:08 - INFO - TRAINING - Epoch: [180][300/500]	Time 0.078 (0.083)	Data 0.000 (0.002)	Loss 0.0006 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:12 - INFO - TRAINING - Epoch: [180][350/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:16 - INFO - TRAINING - Epoch: [180][400/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:20 - INFO - TRAINING - Epoch: [180][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:25 - INFO - EVALUATING - Epoch: [180][0/100]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.4001 (0.4001)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:26 - INFO - EVALUATING - Epoch: [180][50/100]	Time 0.027 (0.033)	Data 0.001 (0.005)	Loss 0.1440 (0.3766)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.569)
2019-05-08 23:46:27 - INFO - 
 Epoch: 181	Training Loss 0.0003 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3475 	Validation Prec@1 93.550 	Validation Prec@5 99.700 	
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:46:28 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:46:28 - INFO - TRAINING - Epoch: [181][0/500]	Time 0.250 (0.250)	Data 0.205 (0.205)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:32 - INFO - TRAINING - Epoch: [181][50/500]	Time 0.080 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:36 - INFO - TRAINING - Epoch: [181][100/500]	Time 0.077 (0.083)	Data 0.000 (0.003)	Loss 0.0004 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:40 - INFO - TRAINING - Epoch: [181][150/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:46:44 - INFO - TRAINING - Epoch: [181][200/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:46:49 - INFO - TRAINING - Epoch: [181][250/500]	Time 0.092 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:46:53 - INFO - TRAINING - Epoch: [181][300/500]	Time 0.080 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:46:57 - INFO - TRAINING - Epoch: [181][350/500]	Time 0.073 (0.083)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:47:01 - INFO - TRAINING - Epoch: [181][400/500]	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 0.0011 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:47:05 - INFO - TRAINING - Epoch: [181][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:47:09 - INFO - EVALUATING - Epoch: [181][0/100]	Time 0.303 (0.303)	Data 0.277 (0.277)	Loss 0.3904 (0.3904)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:47:11 - INFO - EVALUATING - Epoch: [181][50/100]	Time 0.022 (0.032)	Data 0.000 (0.006)	Loss 0.1258 (0.3748)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.569)
2019-05-08 23:47:12 - INFO - 
 Epoch: 182	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3486 	Validation Prec@1 93.590 	Validation Prec@5 99.720 	
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:47:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:47:13 - INFO - TRAINING - Epoch: [182][0/500]	Time 0.262 (0.262)	Data 0.198 (0.198)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:47:17 - INFO - TRAINING - Epoch: [182][50/500]	Time 0.082 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:47:21 - INFO - TRAINING - Epoch: [182][100/500]	Time 0.068 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:47:25 - INFO - TRAINING - Epoch: [182][150/500]	Time 0.085 (0.083)	Data 0.000 (0.002)	Loss 0.0008 (0.0006)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:47:29 - INFO - TRAINING - Epoch: [182][200/500]	Time 0.084 (0.081)	Data 0.000 (0.002)	Loss 0.0000 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:47:33 - INFO - TRAINING - Epoch: [182][250/500]	Time 0.088 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:47:37 - INFO - TRAINING - Epoch: [182][300/500]	Time 0.090 (0.081)	Data 0.000 (0.002)	Loss 0.0009 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:47:41 - INFO - TRAINING - Epoch: [182][350/500]	Time 0.086 (0.082)	Data 0.000 (0.001)	Loss 0.0004 (0.0005)	Prec@1 100.000 (99.991)	Prec@5 100.000 (100.000)
2019-05-08 23:47:45 - INFO - TRAINING - Epoch: [182][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:47:49 - INFO - TRAINING - Epoch: [182][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0034 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:47:53 - INFO - EVALUATING - Epoch: [182][0/100]	Time 0.308 (0.308)	Data 0.282 (0.282)	Loss 0.3985 (0.3985)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:47:55 - INFO - EVALUATING - Epoch: [182][50/100]	Time 0.029 (0.033)	Data 0.000 (0.006)	Loss 0.1302 (0.3746)	Prec@1 96.000 (92.902)	Prec@5 100.000 (99.627)
2019-05-08 23:47:56 - INFO - 
 Epoch: 183	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3480 	Validation Prec@1 93.390 	Validation Prec@5 99.750 	
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:47:56 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:47:57 - INFO - TRAINING - Epoch: [183][0/500]	Time 0.249 (0.249)	Data 0.190 (0.190)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:01 - INFO - TRAINING - Epoch: [183][50/500]	Time 0.086 (0.087)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:05 - INFO - TRAINING - Epoch: [183][100/500]	Time 0.086 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:09 - INFO - TRAINING - Epoch: [183][150/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0009 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:13 - INFO - TRAINING - Epoch: [183][200/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:18 - INFO - TRAINING - Epoch: [183][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:22 - INFO - TRAINING - Epoch: [183][300/500]	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:26 - INFO - TRAINING - Epoch: [183][350/500]	Time 0.077 (0.084)	Data 0.000 (0.001)	Loss 0.0005 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:30 - INFO - TRAINING - Epoch: [183][400/500]	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 0.0000 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:34 - INFO - TRAINING - Epoch: [183][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:38 - INFO - EVALUATING - Epoch: [183][0/100]	Time 0.309 (0.309)	Data 0.280 (0.280)	Loss 0.3819 (0.3819)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:40 - INFO - EVALUATING - Epoch: [183][50/100]	Time 0.026 (0.033)	Data 0.001 (0.006)	Loss 0.1374 (0.3792)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.608)
2019-05-08 23:48:41 - INFO - 
 Epoch: 184	Training Loss 0.0003 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3504 	Validation Prec@1 93.540 	Validation Prec@5 99.740 	
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:48:41 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:48:42 - INFO - TRAINING - Epoch: [184][0/500]	Time 0.251 (0.251)	Data 0.198 (0.198)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:46 - INFO - TRAINING - Epoch: [184][50/500]	Time 0.085 (0.088)	Data 0.000 (0.005)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:50 - INFO - TRAINING - Epoch: [184][100/500]	Time 0.084 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:54 - INFO - TRAINING - Epoch: [184][150/500]	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:48:58 - INFO - TRAINING - Epoch: [184][200/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:02 - INFO - TRAINING - Epoch: [184][250/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:07 - INFO - TRAINING - Epoch: [184][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:11 - INFO - TRAINING - Epoch: [184][350/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:15 - INFO - TRAINING - Epoch: [184][400/500]	Time 0.069 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:19 - INFO - TRAINING - Epoch: [184][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:49:23 - INFO - EVALUATING - Epoch: [184][0/100]	Time 0.310 (0.310)	Data 0.284 (0.284)	Loss 0.4001 (0.4001)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:25 - INFO - EVALUATING - Epoch: [184][50/100]	Time 0.027 (0.033)	Data 0.000 (0.006)	Loss 0.1573 (0.3735)	Prec@1 96.000 (93.059)	Prec@5 100.000 (99.588)
2019-05-08 23:49:26 - INFO - 
 Epoch: 185	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3466 	Validation Prec@1 93.500 	Validation Prec@5 99.720 	
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:49:26 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:49:27 - INFO - TRAINING - Epoch: [185][0/500]	Time 0.268 (0.268)	Data 0.200 (0.200)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:49:31 - INFO - TRAINING - Epoch: [185][50/500]	Time 0.085 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:49:35 - INFO - TRAINING - Epoch: [185][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:49:39 - INFO - TRAINING - Epoch: [185][150/500]	Time 0.077 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:49:43 - INFO - TRAINING - Epoch: [185][200/500]	Time 0.082 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:49:47 - INFO - TRAINING - Epoch: [185][250/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0007)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:49:52 - INFO - TRAINING - Epoch: [185][300/500]	Time 0.091 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:49:56 - INFO - TRAINING - Epoch: [185][350/500]	Time 0.080 (0.084)	Data 0.000 (0.001)	Loss 0.0004 (0.0006)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:50:00 - INFO - TRAINING - Epoch: [185][400/500]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:50:04 - INFO - TRAINING - Epoch: [185][450/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:50:08 - INFO - EVALUATING - Epoch: [185][0/100]	Time 0.332 (0.332)	Data 0.286 (0.286)	Loss 0.3927 (0.3927)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:10 - INFO - EVALUATING - Epoch: [185][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1476 (0.3743)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.608)
2019-05-08 23:50:11 - INFO - 
 Epoch: 186	Training Loss 0.0005 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3489 	Validation Prec@1 93.560 	Validation Prec@5 99.710 	
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:50:11 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:50:12 - INFO - TRAINING - Epoch: [186][0/500]	Time 0.264 (0.264)	Data 0.196 (0.196)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:16 - INFO - TRAINING - Epoch: [186][50/500]	Time 0.070 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:20 - INFO - TRAINING - Epoch: [186][100/500]	Time 0.091 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:24 - INFO - TRAINING - Epoch: [186][150/500]	Time 0.092 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:28 - INFO - TRAINING - Epoch: [186][200/500]	Time 0.074 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:50:32 - INFO - TRAINING - Epoch: [186][250/500]	Time 0.079 (0.082)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:50:36 - INFO - TRAINING - Epoch: [186][300/500]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:50:40 - INFO - TRAINING - Epoch: [186][350/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:50:44 - INFO - TRAINING - Epoch: [186][400/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:50:48 - INFO - TRAINING - Epoch: [186][450/500]	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:50:53 - INFO - EVALUATING - Epoch: [186][0/100]	Time 0.285 (0.285)	Data 0.258 (0.258)	Loss 0.3741 (0.3741)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:50:54 - INFO - EVALUATING - Epoch: [186][50/100]	Time 0.025 (0.032)	Data 0.001 (0.005)	Loss 0.1421 (0.3748)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.569)
2019-05-08 23:50:55 - INFO - 
 Epoch: 187	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3469 	Validation Prec@1 93.520 	Validation Prec@5 99.710 	
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:50:56 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:50:56 - INFO - TRAINING - Epoch: [187][0/500]	Time 0.267 (0.267)	Data 0.196 (0.196)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:00 - INFO - TRAINING - Epoch: [187][50/500]	Time 0.084 (0.088)	Data 0.000 (0.005)	Loss 0.0013 (0.0007)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:51:04 - INFO - TRAINING - Epoch: [187][100/500]	Time 0.047 (0.084)	Data 0.000 (0.003)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:51:08 - INFO - TRAINING - Epoch: [187][150/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0000 (0.0006)	Prec@1 100.000 (99.987)	Prec@5 100.000 (100.000)
2019-05-08 23:51:12 - INFO - TRAINING - Epoch: [187][200/500]	Time 0.085 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.985)	Prec@5 100.000 (100.000)
2019-05-08 23:51:16 - INFO - TRAINING - Epoch: [187][250/500]	Time 0.077 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0006)	Prec@1 100.000 (99.984)	Prec@5 100.000 (100.000)
2019-05-08 23:51:20 - INFO - TRAINING - Epoch: [187][300/500]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.983)	Prec@5 100.000 (100.000)
2019-05-08 23:51:24 - INFO - TRAINING - Epoch: [187][350/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.986)	Prec@5 100.000 (100.000)
2019-05-08 23:51:28 - INFO - TRAINING - Epoch: [187][400/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.988)	Prec@5 100.000 (100.000)
2019-05-08 23:51:33 - INFO - TRAINING - Epoch: [187][450/500]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.989)	Prec@5 100.000 (100.000)
2019-05-08 23:51:37 - INFO - EVALUATING - Epoch: [187][0/100]	Time 0.299 (0.299)	Data 0.272 (0.272)	Loss 0.4038 (0.4038)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:38 - INFO - EVALUATING - Epoch: [187][50/100]	Time 0.029 (0.033)	Data 0.001 (0.006)	Loss 0.1354 (0.3759)	Prec@1 96.000 (93.157)	Prec@5 100.000 (99.588)
2019-05-08 23:51:40 - INFO - 
 Epoch: 188	Training Loss 0.0005 	Training Prec@1 99.990 	Training Prec@5 100.000 	Validation Loss 0.3505 	Validation Prec@1 93.600 	Validation Prec@5 99.700 	
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:51:40 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:51:40 - INFO - TRAINING - Epoch: [188][0/500]	Time 0.258 (0.258)	Data 0.199 (0.199)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:44 - INFO - TRAINING - Epoch: [188][50/500]	Time 0.049 (0.086)	Data 0.000 (0.005)	Loss 0.0034 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:48 - INFO - TRAINING - Epoch: [188][100/500]	Time 0.083 (0.085)	Data 0.000 (0.003)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:53 - INFO - TRAINING - Epoch: [188][150/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:51:57 - INFO - TRAINING - Epoch: [188][200/500]	Time 0.077 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:01 - INFO - TRAINING - Epoch: [188][250/500]	Time 0.073 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:05 - INFO - TRAINING - Epoch: [188][300/500]	Time 0.082 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:09 - INFO - TRAINING - Epoch: [188][350/500]	Time 0.064 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:13 - INFO - TRAINING - Epoch: [188][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:17 - INFO - TRAINING - Epoch: [188][450/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:22 - INFO - EVALUATING - Epoch: [188][0/100]	Time 0.305 (0.305)	Data 0.266 (0.266)	Loss 0.3739 (0.3739)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:23 - INFO - EVALUATING - Epoch: [188][50/100]	Time 0.024 (0.033)	Data 0.000 (0.006)	Loss 0.1353 (0.3766)	Prec@1 96.000 (93.020)	Prec@5 100.000 (99.588)
2019-05-08 23:52:25 - INFO - 
 Epoch: 189	Training Loss 0.0003 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3490 	Validation Prec@1 93.490 	Validation Prec@5 99.700 	
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:52:25 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:52:25 - INFO - TRAINING - Epoch: [189][0/500]	Time 0.263 (0.263)	Data 0.222 (0.222)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:29 - INFO - TRAINING - Epoch: [189][50/500]	Time 0.087 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:33 - INFO - TRAINING - Epoch: [189][100/500]	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:38 - INFO - TRAINING - Epoch: [189][150/500]	Time 0.087 (0.085)	Data 0.001 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:42 - INFO - TRAINING - Epoch: [189][200/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:46 - INFO - TRAINING - Epoch: [189][250/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:50 - INFO - TRAINING - Epoch: [189][300/500]	Time 0.086 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:54 - INFO - TRAINING - Epoch: [189][350/500]	Time 0.070 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:52:58 - INFO - TRAINING - Epoch: [189][400/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:02 - INFO - TRAINING - Epoch: [189][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:07 - INFO - EVALUATING - Epoch: [189][0/100]	Time 0.277 (0.277)	Data 0.252 (0.252)	Loss 0.4013 (0.4013)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:08 - INFO - EVALUATING - Epoch: [189][50/100]	Time 0.027 (0.033)	Data 0.000 (0.005)	Loss 0.1603 (0.3752)	Prec@1 96.000 (93.000)	Prec@5 100.000 (99.529)
2019-05-08 23:53:09 - INFO - 
 Epoch: 190	Training Loss 0.0003 	Training Prec@1 100.000 	Training Prec@5 100.000 	Validation Loss 0.3481 	Validation Prec@1 93.570 	Validation Prec@5 99.690 	
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:53:10 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:53:10 - INFO - TRAINING - Epoch: [190][0/500]	Time 0.248 (0.248)	Data 0.185 (0.185)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:14 - INFO - TRAINING - Epoch: [190][50/500]	Time 0.082 (0.086)	Data 0.000 (0.004)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:18 - INFO - TRAINING - Epoch: [190][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:53:22 - INFO - TRAINING - Epoch: [190][150/500]	Time 0.084 (0.085)	Data 0.000 (0.002)	Loss 0.0000 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:53:26 - INFO - TRAINING - Epoch: [190][200/500]	Time 0.079 (0.084)	Data 0.000 (0.002)	Loss 0.0006 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:53:31 - INFO - TRAINING - Epoch: [190][250/500]	Time 0.084 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:53:35 - INFO - TRAINING - Epoch: [190][300/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0006 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:53:39 - INFO - TRAINING - Epoch: [190][350/500]	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:53:43 - INFO - TRAINING - Epoch: [190][400/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:53:47 - INFO - TRAINING - Epoch: [190][450/500]	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:53:51 - INFO - EVALUATING - Epoch: [190][0/100]	Time 0.302 (0.302)	Data 0.277 (0.277)	Loss 0.4163 (0.4163)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:52 - INFO - EVALUATING - Epoch: [190][50/100]	Time 0.026 (0.033)	Data 0.001 (0.006)	Loss 0.1497 (0.3732)	Prec@1 96.000 (93.196)	Prec@5 100.000 (99.627)
2019-05-08 23:53:54 - INFO - 
 Epoch: 191	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3469 	Validation Prec@1 93.600 	Validation Prec@5 99.720 	
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:53:54 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:53:54 - INFO - TRAINING - Epoch: [191][0/500]	Time 0.257 (0.257)	Data 0.204 (0.204)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:53:59 - INFO - TRAINING - Epoch: [191][50/500]	Time 0.081 (0.087)	Data 0.000 (0.005)	Loss 0.0014 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:03 - INFO - TRAINING - Epoch: [191][100/500]	Time 0.083 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:54:07 - INFO - TRAINING - Epoch: [191][150/500]	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:54:11 - INFO - TRAINING - Epoch: [191][200/500]	Time 0.093 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:54:15 - INFO - TRAINING - Epoch: [191][250/500]	Time 0.072 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:54:19 - INFO - TRAINING - Epoch: [191][300/500]	Time 0.085 (0.084)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:54:23 - INFO - TRAINING - Epoch: [191][350/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0008 (0.0005)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:54:28 - INFO - TRAINING - Epoch: [191][400/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:54:32 - INFO - TRAINING - Epoch: [191][450/500]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:54:36 - INFO - EVALUATING - Epoch: [191][0/100]	Time 0.322 (0.322)	Data 0.273 (0.273)	Loss 0.4156 (0.4156)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:37 - INFO - EVALUATING - Epoch: [191][50/100]	Time 0.026 (0.032)	Data 0.000 (0.006)	Loss 0.1478 (0.3788)	Prec@1 96.000 (93.039)	Prec@5 100.000 (99.588)
2019-05-08 23:54:39 - INFO - 
 Epoch: 192	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3509 	Validation Prec@1 93.580 	Validation Prec@5 99.710 	
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:54:39 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:54:39 - INFO - TRAINING - Epoch: [192][0/500]	Time 0.281 (0.281)	Data 0.221 (0.221)	Loss 0.0002 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:43 - INFO - TRAINING - Epoch: [192][50/500]	Time 0.086 (0.086)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:47 - INFO - TRAINING - Epoch: [192][100/500]	Time 0.080 (0.085)	Data 0.000 (0.003)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:51 - INFO - TRAINING - Epoch: [192][150/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:55 - INFO - TRAINING - Epoch: [192][200/500]	Time 0.077 (0.082)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:54:59 - INFO - TRAINING - Epoch: [192][250/500]	Time 0.080 (0.081)	Data 0.000 (0.002)	Loss 0.0006 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:03 - INFO - TRAINING - Epoch: [192][300/500]	Time 0.081 (0.081)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:08 - INFO - TRAINING - Epoch: [192][350/500]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:12 - INFO - TRAINING - Epoch: [192][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:16 - INFO - TRAINING - Epoch: [192][450/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:20 - INFO - EVALUATING - Epoch: [192][0/100]	Time 0.301 (0.301)	Data 0.272 (0.272)	Loss 0.4040 (0.4040)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:22 - INFO - EVALUATING - Epoch: [192][50/100]	Time 0.023 (0.033)	Data 0.000 (0.006)	Loss 0.1378 (0.3751)	Prec@1 96.000 (92.980)	Prec@5 100.000 (99.627)
2019-05-08 23:55:23 - INFO - 
 Epoch: 193	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3466 	Validation Prec@1 93.500 	Validation Prec@5 99.740 	
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:55:23 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:55:24 - INFO - TRAINING - Epoch: [193][0/500]	Time 0.257 (0.257)	Data 0.190 (0.190)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:28 - INFO - TRAINING - Epoch: [193][50/500]	Time 0.084 (0.087)	Data 0.000 (0.005)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:32 - INFO - TRAINING - Epoch: [193][100/500]	Time 0.087 (0.084)	Data 0.000 (0.003)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:36 - INFO - TRAINING - Epoch: [193][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:40 - INFO - TRAINING - Epoch: [193][200/500]	Time 0.083 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:44 - INFO - TRAINING - Epoch: [193][250/500]	Time 0.056 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:48 - INFO - TRAINING - Epoch: [193][300/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:55:52 - INFO - TRAINING - Epoch: [193][350/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:55:56 - INFO - TRAINING - Epoch: [193][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0065 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:56:00 - INFO - TRAINING - Epoch: [193][450/500]	Time 0.071 (0.082)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:56:05 - INFO - EVALUATING - Epoch: [193][0/100]	Time 0.324 (0.324)	Data 0.281 (0.281)	Loss 0.3609 (0.3609)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:56:06 - INFO - EVALUATING - Epoch: [193][50/100]	Time 0.029 (0.033)	Data 0.001 (0.006)	Loss 0.1518 (0.3774)	Prec@1 96.000 (93.098)	Prec@5 100.000 (99.549)
2019-05-08 23:56:08 - INFO - 
 Epoch: 194	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3480 	Validation Prec@1 93.630 	Validation Prec@5 99.680 	
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:56:08 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:56:08 - INFO - TRAINING - Epoch: [194][0/500]	Time 0.242 (0.242)	Data 0.189 (0.189)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:56:12 - INFO - TRAINING - Epoch: [194][50/500]	Time 0.081 (0.083)	Data 0.000 (0.004)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:56:16 - INFO - TRAINING - Epoch: [194][100/500]	Time 0.086 (0.083)	Data 0.000 (0.003)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:56:20 - INFO - TRAINING - Epoch: [194][150/500]	Time 0.081 (0.083)	Data 0.000 (0.002)	Loss 0.0004 (0.0003)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:56:24 - INFO - TRAINING - Epoch: [194][200/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:56:29 - INFO - TRAINING - Epoch: [194][250/500]	Time 0.045 (0.083)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:56:33 - INFO - TRAINING - Epoch: [194][300/500]	Time 0.086 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:56:37 - INFO - TRAINING - Epoch: [194][350/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0003)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:56:41 - INFO - TRAINING - Epoch: [194][400/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0007 (0.0003)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:56:45 - INFO - TRAINING - Epoch: [194][450/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0003)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:56:50 - INFO - EVALUATING - Epoch: [194][0/100]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.3816 (0.3816)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:56:51 - INFO - EVALUATING - Epoch: [194][50/100]	Time 0.025 (0.033)	Data 0.000 (0.005)	Loss 0.1321 (0.3713)	Prec@1 96.000 (93.176)	Prec@5 100.000 (99.588)
2019-05-08 23:56:52 - INFO - 
 Epoch: 195	Training Loss 0.0003 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3477 	Validation Prec@1 93.580 	Validation Prec@5 99.710 	
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:56:53 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:56:53 - INFO - TRAINING - Epoch: [195][0/500]	Time 0.256 (0.256)	Data 0.197 (0.197)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:56:57 - INFO - TRAINING - Epoch: [195][50/500]	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:01 - INFO - TRAINING - Epoch: [195][100/500]	Time 0.101 (0.085)	Data 0.000 (0.003)	Loss 0.0012 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:05 - INFO - TRAINING - Epoch: [195][150/500]	Time 0.078 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:57:10 - INFO - TRAINING - Epoch: [195][200/500]	Time 0.079 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:57:14 - INFO - TRAINING - Epoch: [195][250/500]	Time 0.079 (0.084)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:57:18 - INFO - TRAINING - Epoch: [195][300/500]	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:57:22 - INFO - TRAINING - Epoch: [195][350/500]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:57:26 - INFO - TRAINING - Epoch: [195][400/500]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.0007 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:57:30 - INFO - TRAINING - Epoch: [195][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0063 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:57:34 - INFO - EVALUATING - Epoch: [195][0/100]	Time 0.280 (0.280)	Data 0.256 (0.256)	Loss 0.4099 (0.4099)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:36 - INFO - EVALUATING - Epoch: [195][50/100]	Time 0.028 (0.033)	Data 0.001 (0.005)	Loss 0.1433 (0.3737)	Prec@1 96.000 (93.255)	Prec@5 100.000 (99.588)
2019-05-08 23:57:37 - INFO - 
 Epoch: 196	Training Loss 0.0004 	Training Prec@1 99.998 	Training Prec@5 100.000 	Validation Loss 0.3480 	Validation Prec@1 93.680 	Validation Prec@5 99.720 	
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:57:37 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:57:38 - INFO - TRAINING - Epoch: [196][0/500]	Time 0.254 (0.254)	Data 0.192 (0.192)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:42 - INFO - TRAINING - Epoch: [196][50/500]	Time 0.081 (0.086)	Data 0.000 (0.005)	Loss 0.0000 (0.0002)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:46 - INFO - TRAINING - Epoch: [196][100/500]	Time 0.082 (0.085)	Data 0.000 (0.003)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:50 - INFO - TRAINING - Epoch: [196][150/500]	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 0.0002 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:54 - INFO - TRAINING - Epoch: [196][200/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:57:58 - INFO - TRAINING - Epoch: [196][250/500]	Time 0.091 (0.083)	Data 0.000 (0.002)	Loss 0.0003 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:03 - INFO - TRAINING - Epoch: [196][300/500]	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:58:07 - INFO - TRAINING - Epoch: [196][350/500]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:58:11 - INFO - TRAINING - Epoch: [196][400/500]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:58:15 - INFO - TRAINING - Epoch: [196][450/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:58:19 - INFO - EVALUATING - Epoch: [196][0/100]	Time 0.288 (0.288)	Data 0.262 (0.262)	Loss 0.3871 (0.3871)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:21 - INFO - EVALUATING - Epoch: [196][50/100]	Time 0.025 (0.033)	Data 0.001 (0.006)	Loss 0.1502 (0.3718)	Prec@1 96.000 (93.294)	Prec@5 100.000 (99.608)
2019-05-08 23:58:22 - INFO - 
 Epoch: 197	Training Loss 0.0004 	Training Prec@1 99.992 	Training Prec@5 100.000 	Validation Loss 0.3457 	Validation Prec@1 93.670 	Validation Prec@5 99.740 	
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:58:22 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:58:23 - INFO - TRAINING - Epoch: [197][0/500]	Time 0.256 (0.256)	Data 0.213 (0.213)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:27 - INFO - TRAINING - Epoch: [197][50/500]	Time 0.078 (0.086)	Data 0.000 (0.005)	Loss 0.0009 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:31 - INFO - TRAINING - Epoch: [197][100/500]	Time 0.082 (0.084)	Data 0.000 (0.003)	Loss 0.0001 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:35 - INFO - TRAINING - Epoch: [197][150/500]	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 0.0010 (0.0003)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:58:39 - INFO - TRAINING - Epoch: [197][200/500]	Time 0.079 (0.083)	Data 0.000 (0.002)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:58:43 - INFO - TRAINING - Epoch: [197][250/500]	Time 0.075 (0.083)	Data 0.000 (0.002)	Loss 0.0025 (0.0004)	Prec@1 100.000 (99.992)	Prec@5 100.000 (100.000)
2019-05-08 23:58:47 - INFO - TRAINING - Epoch: [197][300/500]	Time 0.084 (0.083)	Data 0.000 (0.002)	Loss 0.0014 (0.0004)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:58:51 - INFO - TRAINING - Epoch: [197][350/500]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.994)	Prec@5 100.000 (100.000)
2019-05-08 23:58:55 - INFO - TRAINING - Epoch: [197][400/500]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:59:00 - INFO - TRAINING - Epoch: [197][450/500]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.0002 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:59:04 - INFO - EVALUATING - Epoch: [197][0/100]	Time 0.299 (0.299)	Data 0.273 (0.273)	Loss 0.3681 (0.3681)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-08 23:59:05 - INFO - EVALUATING - Epoch: [197][50/100]	Time 0.027 (0.033)	Data 0.000 (0.006)	Loss 0.1602 (0.3797)	Prec@1 96.000 (93.118)	Prec@5 100.000 (99.588)
2019-05-08 23:59:06 - INFO - 
 Epoch: 198	Training Loss 0.0004 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3516 	Validation Prec@1 93.610 	Validation Prec@5 99.700 	
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:59:07 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:59:07 - INFO - TRAINING - Epoch: [198][0/500]	Time 0.260 (0.260)	Data 0.216 (0.216)	Loss 0.0000 (0.0000)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:59:11 - INFO - TRAINING - Epoch: [198][50/500]	Time 0.085 (0.085)	Data 0.000 (0.005)	Loss 0.0001 (0.0009)	Prec@1 100.000 (99.980)	Prec@5 100.000 (100.000)
2019-05-08 23:59:15 - INFO - TRAINING - Epoch: [198][100/500]	Time 0.087 (0.083)	Data 0.000 (0.003)	Loss 0.0001 (0.0006)	Prec@1 100.000 (99.990)	Prec@5 100.000 (100.000)
2019-05-08 23:59:19 - INFO - TRAINING - Epoch: [198][150/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.993)	Prec@5 100.000 (100.000)
2019-05-08 23:59:23 - INFO - TRAINING - Epoch: [198][200/500]	Time 0.089 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0005)	Prec@1 100.000 (99.995)	Prec@5 100.000 (100.000)
2019-05-08 23:59:27 - INFO - TRAINING - Epoch: [198][250/500]	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.996)	Prec@5 100.000 (100.000)
2019-05-08 23:59:32 - INFO - TRAINING - Epoch: [198][300/500]	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:59:36 - INFO - TRAINING - Epoch: [198][350/500]	Time 0.091 (0.082)	Data 0.000 (0.001)	Loss 0.0012 (0.0004)	Prec@1 100.000 (99.997)	Prec@5 100.000 (100.000)
2019-05-08 23:59:40 - INFO - TRAINING - Epoch: [198][400/500]	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 0.0003 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:59:44 - INFO - TRAINING - Epoch: [198][450/500]	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 0.0005 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-08 23:59:48 - INFO - EVALUATING - Epoch: [198][0/100]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.3767 (0.3767)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-08 23:59:50 - INFO - EVALUATING - Epoch: [198][50/100]	Time 0.026 (0.033)	Data 0.000 (0.005)	Loss 0.1458 (0.3724)	Prec@1 96.000 (93.000)	Prec@5 100.000 (99.608)
2019-05-08 23:59:51 - INFO - 
 Epoch: 199	Training Loss 0.0005 	Training Prec@1 99.994 	Training Prec@5 100.000 	Validation Loss 0.3466 	Validation Prec@1 93.460 	Validation Prec@5 99.730 	
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting method = SGD
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting lr = 0.001
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-08 23:59:51 - DEBUG - OPTIMIZER - setting lr = 0.0001
2019-05-08 23:59:52 - INFO - TRAINING - Epoch: [199][0/500]	Time 0.246 (0.246)	Data 0.193 (0.193)	Loss 0.0001 (0.0001)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-08 23:59:56 - INFO - TRAINING - Epoch: [199][50/500]	Time 0.083 (0.087)	Data 0.000 (0.005)	Loss 0.0002 (0.0006)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:00 - INFO - TRAINING - Epoch: [199][100/500]	Time 0.076 (0.086)	Data 0.001 (0.003)	Loss 0.0002 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:04 - INFO - TRAINING - Epoch: [199][150/500]	Time 0.085 (0.085)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:08 - INFO - TRAINING - Epoch: [199][200/500]	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 0.0028 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:12 - INFO - TRAINING - Epoch: [199][250/500]	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 0.0003 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:17 - INFO - TRAINING - Epoch: [199][300/500]	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 0.0001 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:21 - INFO - TRAINING - Epoch: [199][350/500]	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 0.0000 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:25 - INFO - TRAINING - Epoch: [199][400/500]	Time 0.069 (0.083)	Data 0.000 (0.001)	Loss 0.0005 (0.0004)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:29 - INFO - TRAINING - Epoch: [199][450/500]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.0004 (0.0004)	Prec@1 100.000 (99.998)	Prec@5 100.000 (100.000)
2019-05-09 00:00:33 - INFO - EVALUATING - Epoch: [199][0/100]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.3529 (0.3529)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-09 00:00:34 - INFO - EVALUATING - Epoch: [199][50/100]	Time 0.028 (0.033)	Data 0.001 (0.005)	Loss 0.1322 (0.3711)	Prec@1 96.000 (93.137)	Prec@5 100.000 (99.569)
2019-05-09 00:00:36 - INFO - 
 Epoch: 200	Training Loss 0.0004 	Training Prec@1 99.996 	Training Prec@5 100.000 	Validation Loss 0.3442 	Validation Prec@1 93.550 	Validation Prec@5 99.720 	
