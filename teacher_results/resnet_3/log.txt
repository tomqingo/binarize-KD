2019-05-04 16:42:01 - INFO - saving to ./results/teacher_results/resnet_3
2019-05-04 16:42:01 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='resnet', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 16:42:01 - INFO - creating model resnet_preact_quan_test
2019-05-04 16:42:01 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 16:42:01 - INFO - number of parameters: 272612
2019-05-04 16:42:04 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-04 16:42:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:42:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:42:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:42:05 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.427 (0.427)	Data 0.277 (0.277)	Loss 2.4072 (2.4072)	Prec@1 10.000 (10.000)	Prec@5 60.000 (60.000)
2019-05-04 16:42:06 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.015 (0.028)	Data 0.000 (0.006)	Loss 2.0135 (2.1033)	Prec@1 23.000 (21.196)	Prec@5 73.000 (73.804)
2019-05-04 16:42:07 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 1.7398 (2.0108)	Prec@1 37.000 (24.713)	Prec@5 92.000 (78.139)
2019-05-04 16:42:08 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.8279 (1.9478)	Prec@1 32.000 (26.887)	Prec@5 84.000 (80.523)
2019-05-04 16:42:39 - INFO - saving to ./results/teacher_results/resnet_preact_quan_test_0
2019-05-04 16:42:39 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='resnet_preact_quan_test', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 16:42:39 - INFO - creating model resnet_preact_quan_test
2019-05-04 16:42:39 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 16:42:39 - INFO - number of parameters: 272612
2019-05-04 16:42:40 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-04 16:42:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:42:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:42:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:42:40 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.298 (0.298)	Data 0.273 (0.273)	Loss 2.4493 (2.4493)	Prec@1 8.000 (8.000)	Prec@5 55.000 (55.000)
2019-05-04 16:42:41 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.023 (0.025)	Data 0.000 (0.006)	Loss 1.9647 (2.0604)	Prec@1 32.000 (22.510)	Prec@5 79.000 (77.137)
2019-05-04 16:42:42 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 1.7655 (1.9759)	Prec@1 38.000 (25.713)	Prec@5 86.000 (80.188)
2019-05-04 16:42:43 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.012 (0.022)	Data 0.000 (0.002)	Loss 1.8172 (1.9238)	Prec@1 32.000 (27.715)	Prec@5 88.000 (81.881)
2019-05-04 16:42:44 - INFO - TRAINING - Epoch: [0][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.6935 (1.8810)	Prec@1 39.000 (29.388)	Prec@5 91.000 (83.095)
2019-05-04 16:42:45 - INFO - TRAINING - Epoch: [0][250/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.7368 (1.8537)	Prec@1 30.000 (30.518)	Prec@5 85.000 (83.845)
2019-05-04 16:42:46 - INFO - TRAINING - Epoch: [0][300/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 1.7364 (1.8245)	Prec@1 35.000 (31.671)	Prec@5 88.000 (84.585)
2019-05-04 16:42:47 - INFO - TRAINING - Epoch: [0][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.6370 (1.7976)	Prec@1 48.000 (32.775)	Prec@5 84.000 (85.219)
2019-05-04 16:42:48 - INFO - TRAINING - Epoch: [0][400/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 1.5736 (1.7753)	Prec@1 44.000 (33.741)	Prec@5 88.000 (85.708)
2019-05-04 16:42:49 - INFO - TRAINING - Epoch: [0][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 1.5102 (1.7560)	Prec@1 41.000 (34.532)	Prec@5 95.000 (86.200)
2019-05-04 16:42:50 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.373 (0.373)	Data 0.359 (0.359)	Loss 1.5431 (1.5431)	Prec@1 44.000 (44.000)	Prec@5 93.000 (93.000)
2019-05-04 16:42:51 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.5179 (1.6062)	Prec@1 47.000 (42.392)	Prec@5 89.000 (89.588)
2019-05-04 16:42:51 - INFO - 
 Epoch: 1	Training Loss 1.7342 	Training Prec@1 35.416 	Training Prec@5 86.664 	Validation Loss 1.6254 	Validation Prec@1 42.060 	Validation Prec@5 89.330 	
2019-05-04 16:42:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:42:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:42:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:42:51 - INFO - TRAINING - Epoch: [1][0/500]	Time 0.279 (0.279)	Data 0.256 (0.256)	Loss 1.6051 (1.6051)	Prec@1 42.000 (42.000)	Prec@5 93.000 (93.000)
2019-05-04 16:42:52 - INFO - TRAINING - Epoch: [1][50/500]	Time 0.018 (0.024)	Data 0.000 (0.005)	Loss 1.5037 (1.5615)	Prec@1 44.000 (42.412)	Prec@5 91.000 (90.529)
2019-05-04 16:42:53 - INFO - TRAINING - Epoch: [1][100/500]	Time 0.014 (0.021)	Data 0.000 (0.003)	Loss 1.5878 (1.5430)	Prec@1 39.000 (43.772)	Prec@5 91.000 (90.851)
2019-05-04 16:42:54 - INFO - TRAINING - Epoch: [1][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 1.3708 (1.5279)	Prec@1 51.000 (44.272)	Prec@5 93.000 (91.106)
2019-05-04 16:42:55 - INFO - TRAINING - Epoch: [1][200/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.6562 (1.5241)	Prec@1 34.000 (44.274)	Prec@5 89.000 (91.333)
2019-05-04 16:42:56 - INFO - TRAINING - Epoch: [1][250/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 1.6580 (1.5116)	Prec@1 43.000 (44.797)	Prec@5 87.000 (91.506)
2019-05-04 16:42:57 - INFO - TRAINING - Epoch: [1][300/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 1.5713 (1.4983)	Prec@1 40.000 (45.289)	Prec@5 92.000 (91.631)
2019-05-04 16:42:58 - INFO - TRAINING - Epoch: [1][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.2503 (1.4875)	Prec@1 53.000 (45.746)	Prec@5 96.000 (91.775)
2019-05-04 16:42:59 - INFO - TRAINING - Epoch: [1][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 1.3014 (1.4822)	Prec@1 46.000 (45.920)	Prec@5 97.000 (91.830)
2019-05-04 16:43:00 - INFO - TRAINING - Epoch: [1][450/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 1.3563 (1.4785)	Prec@1 49.000 (46.135)	Prec@5 96.000 (91.911)
2019-05-04 16:43:01 - INFO - EVALUATING - Epoch: [1][0/100]	Time 0.367 (0.367)	Data 0.357 (0.357)	Loss 1.3054 (1.3054)	Prec@1 55.000 (55.000)	Prec@5 91.000 (91.000)
2019-05-04 16:43:02 - INFO - EVALUATING - Epoch: [1][50/100]	Time 0.005 (0.014)	Data 0.000 (0.007)	Loss 1.6234 (1.5416)	Prec@1 44.000 (44.941)	Prec@5 88.000 (89.235)
2019-05-04 16:43:02 - INFO - 
 Epoch: 2	Training Loss 1.4716 	Training Prec@1 46.446 	Training Prec@5 92.028 	Validation Loss 1.5365 	Validation Prec@1 45.150 	Validation Prec@5 89.710 	
2019-05-04 16:43:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:02 - INFO - TRAINING - Epoch: [2][0/500]	Time 0.376 (0.376)	Data 0.351 (0.351)	Loss 1.3893 (1.3893)	Prec@1 50.000 (50.000)	Prec@5 92.000 (92.000)
2019-05-04 16:43:03 - INFO - TRAINING - Epoch: [2][50/500]	Time 0.025 (0.027)	Data 0.000 (0.007)	Loss 1.3008 (1.4259)	Prec@1 54.000 (48.745)	Prec@5 91.000 (92.333)
2019-05-04 16:43:04 - INFO - TRAINING - Epoch: [2][100/500]	Time 0.023 (0.024)	Data 0.000 (0.004)	Loss 1.3775 (1.3873)	Prec@1 53.000 (49.960)	Prec@5 91.000 (93.040)
2019-05-04 16:43:05 - INFO - TRAINING - Epoch: [2][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 1.3015 (1.3854)	Prec@1 49.000 (50.079)	Prec@5 96.000 (92.967)
2019-05-04 16:43:06 - INFO - TRAINING - Epoch: [2][200/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.4666 (1.3733)	Prec@1 47.000 (50.448)	Prec@5 94.000 (93.179)
2019-05-04 16:43:07 - INFO - TRAINING - Epoch: [2][250/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 1.2600 (1.3661)	Prec@1 57.000 (50.757)	Prec@5 93.000 (93.175)
2019-05-04 16:43:08 - INFO - TRAINING - Epoch: [2][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 1.3179 (1.3588)	Prec@1 52.000 (51.070)	Prec@5 96.000 (93.369)
2019-05-04 16:43:09 - INFO - TRAINING - Epoch: [2][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 1.4656 (1.3527)	Prec@1 48.000 (51.504)	Prec@5 91.000 (93.436)
2019-05-04 16:43:10 - INFO - TRAINING - Epoch: [2][400/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 1.3025 (1.3443)	Prec@1 48.000 (51.768)	Prec@5 94.000 (93.594)
2019-05-04 16:43:11 - INFO - TRAINING - Epoch: [2][450/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 1.2670 (1.3400)	Prec@1 51.000 (51.978)	Prec@5 95.000 (93.674)
2019-05-04 16:43:13 - INFO - EVALUATING - Epoch: [2][0/100]	Time 0.365 (0.365)	Data 0.359 (0.359)	Loss 1.2549 (1.2549)	Prec@1 60.000 (60.000)	Prec@5 90.000 (90.000)
2019-05-04 16:43:13 - INFO - EVALUATING - Epoch: [2][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.4278 (1.2813)	Prec@1 52.000 (53.824)	Prec@5 91.000 (94.275)
2019-05-04 16:43:13 - INFO - 
 Epoch: 3	Training Loss 1.3364 	Training Prec@1 52.180 	Training Prec@5 93.696 	Validation Loss 1.2948 	Validation Prec@1 52.540 	Validation Prec@5 94.320 	
2019-05-04 16:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:13 - INFO - TRAINING - Epoch: [3][0/500]	Time 0.386 (0.386)	Data 0.365 (0.365)	Loss 1.2045 (1.2045)	Prec@1 62.000 (62.000)	Prec@5 93.000 (93.000)
2019-05-04 16:43:14 - INFO - TRAINING - Epoch: [3][50/500]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 1.1025 (1.2755)	Prec@1 59.000 (55.098)	Prec@5 94.000 (94.137)
2019-05-04 16:43:15 - INFO - TRAINING - Epoch: [3][100/500]	Time 0.017 (0.022)	Data 0.000 (0.004)	Loss 1.2758 (1.2628)	Prec@1 56.000 (55.545)	Prec@5 92.000 (94.129)
2019-05-04 16:43:16 - INFO - TRAINING - Epoch: [3][150/500]	Time 0.023 (0.021)	Data 0.000 (0.003)	Loss 1.2623 (1.2575)	Prec@1 50.000 (55.940)	Prec@5 96.000 (94.258)
2019-05-04 16:43:17 - INFO - TRAINING - Epoch: [3][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.1837 (1.2565)	Prec@1 61.000 (55.836)	Prec@5 94.000 (94.398)
2019-05-04 16:43:18 - INFO - TRAINING - Epoch: [3][250/500]	Time 0.028 (0.021)	Data 0.000 (0.002)	Loss 1.2978 (1.2516)	Prec@1 55.000 (55.785)	Prec@5 95.000 (94.414)
2019-05-04 16:43:19 - INFO - TRAINING - Epoch: [3][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.2874 (1.2415)	Prec@1 58.000 (56.189)	Prec@5 94.000 (94.495)
2019-05-04 16:43:20 - INFO - TRAINING - Epoch: [3][350/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 1.1095 (1.2411)	Prec@1 56.000 (55.980)	Prec@5 97.000 (94.553)
2019-05-04 16:43:21 - INFO - TRAINING - Epoch: [3][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.3523 (1.2408)	Prec@1 55.000 (55.995)	Prec@5 93.000 (94.571)
2019-05-04 16:43:22 - INFO - TRAINING - Epoch: [3][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 1.1180 (1.2382)	Prec@1 63.000 (56.182)	Prec@5 97.000 (94.543)
2019-05-04 16:43:23 - INFO - EVALUATING - Epoch: [3][0/100]	Time 0.360 (0.360)	Data 0.353 (0.353)	Loss 1.3303 (1.3303)	Prec@1 56.000 (56.000)	Prec@5 90.000 (90.000)
2019-05-04 16:43:24 - INFO - EVALUATING - Epoch: [3][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 1.4579 (1.3363)	Prec@1 51.000 (52.882)	Prec@5 92.000 (93.745)
2019-05-04 16:43:24 - INFO - 
 Epoch: 4	Training Loss 1.2323 	Training Prec@1 56.408 	Training Prec@5 94.608 	Validation Loss 1.3393 	Validation Prec@1 52.790 	Validation Prec@5 93.770 	
2019-05-04 16:43:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:24 - INFO - TRAINING - Epoch: [4][0/500]	Time 0.391 (0.391)	Data 0.359 (0.359)	Loss 1.0021 (1.0021)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-04 16:43:25 - INFO - TRAINING - Epoch: [4][50/500]	Time 0.020 (0.026)	Data 0.000 (0.007)	Loss 1.0555 (1.2139)	Prec@1 65.000 (56.471)	Prec@5 96.000 (95.039)
2019-05-04 16:43:26 - INFO - TRAINING - Epoch: [4][100/500]	Time 0.025 (0.023)	Data 0.000 (0.004)	Loss 1.1819 (1.1976)	Prec@1 54.000 (57.614)	Prec@5 95.000 (95.376)
2019-05-04 16:43:27 - INFO - TRAINING - Epoch: [4][150/500]	Time 0.025 (0.022)	Data 0.000 (0.003)	Loss 1.2097 (1.1929)	Prec@1 51.000 (57.907)	Prec@5 98.000 (95.106)
2019-05-04 16:43:28 - INFO - TRAINING - Epoch: [4][200/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 1.1915 (1.1861)	Prec@1 59.000 (58.040)	Prec@5 91.000 (95.149)
2019-05-04 16:43:29 - INFO - TRAINING - Epoch: [4][250/500]	Time 0.025 (0.021)	Data 0.000 (0.002)	Loss 1.1572 (1.1845)	Prec@1 60.000 (58.191)	Prec@5 96.000 (95.135)
2019-05-04 16:43:30 - INFO - TRAINING - Epoch: [4][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.9820 (1.1824)	Prec@1 67.000 (58.339)	Prec@5 96.000 (95.100)
2019-05-04 16:43:31 - INFO - TRAINING - Epoch: [4][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.1629 (1.1818)	Prec@1 59.000 (58.368)	Prec@5 93.000 (95.123)
2019-05-04 16:43:32 - INFO - TRAINING - Epoch: [4][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.3728 (1.1795)	Prec@1 51.000 (58.499)	Prec@5 95.000 (95.077)
2019-05-04 16:43:33 - INFO - TRAINING - Epoch: [4][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.2037 (1.1782)	Prec@1 57.000 (58.543)	Prec@5 96.000 (95.115)
2019-05-04 16:43:34 - INFO - EVALUATING - Epoch: [4][0/100]	Time 0.370 (0.370)	Data 0.361 (0.361)	Loss 1.0612 (1.0612)	Prec@1 65.000 (65.000)	Prec@5 96.000 (96.000)
2019-05-04 16:43:35 - INFO - EVALUATING - Epoch: [4][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.2276 (1.1375)	Prec@1 55.000 (59.745)	Prec@5 93.000 (95.569)
2019-05-04 16:43:35 - INFO - 
 Epoch: 5	Training Loss 1.1753 	Training Prec@1 58.592 	Training Prec@5 95.154 	Validation Loss 1.1489 	Validation Prec@1 59.160 	Validation Prec@5 95.570 	
2019-05-04 16:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:35 - INFO - TRAINING - Epoch: [5][0/500]	Time 0.405 (0.405)	Data 0.374 (0.374)	Loss 1.1636 (1.1636)	Prec@1 52.000 (52.000)	Prec@5 97.000 (97.000)
2019-05-04 16:43:36 - INFO - TRAINING - Epoch: [5][50/500]	Time 0.024 (0.027)	Data 0.000 (0.007)	Loss 0.9915 (1.1416)	Prec@1 68.000 (60.216)	Prec@5 99.000 (95.804)
2019-05-04 16:43:37 - INFO - TRAINING - Epoch: [5][100/500]	Time 0.021 (0.023)	Data 0.000 (0.004)	Loss 1.2811 (1.1418)	Prec@1 52.000 (59.980)	Prec@5 97.000 (95.604)
2019-05-04 16:43:38 - INFO - TRAINING - Epoch: [5][150/500]	Time 0.016 (0.022)	Data 0.000 (0.003)	Loss 1.1354 (1.1316)	Prec@1 59.000 (60.139)	Prec@5 95.000 (95.662)
2019-05-04 16:43:39 - INFO - TRAINING - Epoch: [5][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.8974 (1.1258)	Prec@1 71.000 (60.418)	Prec@5 99.000 (95.746)
2019-05-04 16:43:40 - INFO - TRAINING - Epoch: [5][250/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 1.1787 (1.1294)	Prec@1 56.000 (60.279)	Prec@5 97.000 (95.645)
2019-05-04 16:43:41 - INFO - TRAINING - Epoch: [5][300/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 1.2618 (1.1339)	Prec@1 59.000 (60.166)	Prec@5 95.000 (95.615)
2019-05-04 16:43:42 - INFO - TRAINING - Epoch: [5][350/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.9892 (1.1360)	Prec@1 71.000 (60.137)	Prec@5 97.000 (95.587)
2019-05-04 16:43:43 - INFO - TRAINING - Epoch: [5][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.2243 (1.1332)	Prec@1 52.000 (60.249)	Prec@5 97.000 (95.628)
2019-05-04 16:43:44 - INFO - TRAINING - Epoch: [5][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.1760 (1.1307)	Prec@1 56.000 (60.373)	Prec@5 94.000 (95.685)
2019-05-04 16:43:45 - INFO - EVALUATING - Epoch: [5][0/100]	Time 0.352 (0.352)	Data 0.344 (0.344)	Loss 1.0814 (1.0814)	Prec@1 59.000 (59.000)	Prec@5 98.000 (98.000)
2019-05-04 16:43:46 - INFO - EVALUATING - Epoch: [5][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.1380 (1.1764)	Prec@1 65.000 (58.059)	Prec@5 95.000 (95.196)
2019-05-04 16:43:46 - INFO - 
 Epoch: 6	Training Loss 1.1285 	Training Prec@1 60.452 	Training Prec@5 95.716 	Validation Loss 1.1883 	Validation Prec@1 57.700 	Validation Prec@5 95.170 	
2019-05-04 16:43:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:46 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:46 - INFO - TRAINING - Epoch: [6][0/500]	Time 0.398 (0.398)	Data 0.373 (0.373)	Loss 1.1290 (1.1290)	Prec@1 62.000 (62.000)	Prec@5 96.000 (96.000)
2019-05-04 16:43:47 - INFO - TRAINING - Epoch: [6][50/500]	Time 0.022 (0.028)	Data 0.000 (0.007)	Loss 1.4969 (1.1341)	Prec@1 46.000 (61.098)	Prec@5 90.000 (95.333)
2019-05-04 16:43:48 - INFO - TRAINING - Epoch: [6][100/500]	Time 0.022 (0.024)	Data 0.000 (0.004)	Loss 0.8832 (1.1141)	Prec@1 67.000 (61.069)	Prec@5 99.000 (95.574)
2019-05-04 16:43:49 - INFO - TRAINING - Epoch: [6][150/500]	Time 0.029 (0.022)	Data 0.000 (0.003)	Loss 1.0198 (1.1043)	Prec@1 69.000 (61.477)	Prec@5 96.000 (95.702)
2019-05-04 16:43:50 - INFO - TRAINING - Epoch: [6][200/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 1.0511 (1.0998)	Prec@1 65.000 (61.687)	Prec@5 97.000 (95.886)
2019-05-04 16:43:51 - INFO - TRAINING - Epoch: [6][250/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.9593 (1.1026)	Prec@1 68.000 (61.622)	Prec@5 98.000 (95.841)
2019-05-04 16:43:52 - INFO - TRAINING - Epoch: [6][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.9620 (1.1063)	Prec@1 68.000 (61.532)	Prec@5 96.000 (95.698)
2019-05-04 16:43:53 - INFO - TRAINING - Epoch: [6][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 1.2664 (1.1030)	Prec@1 55.000 (61.615)	Prec@5 90.000 (95.818)
2019-05-04 16:43:54 - INFO - TRAINING - Epoch: [6][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.9924 (1.0983)	Prec@1 72.000 (61.783)	Prec@5 97.000 (95.885)
2019-05-04 16:43:55 - INFO - TRAINING - Epoch: [6][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.9660 (1.0975)	Prec@1 69.000 (61.792)	Prec@5 93.000 (95.891)
2019-05-04 16:43:57 - INFO - EVALUATING - Epoch: [6][0/100]	Time 0.364 (0.364)	Data 0.357 (0.357)	Loss 1.1240 (1.1240)	Prec@1 58.000 (58.000)	Prec@5 94.000 (94.000)
2019-05-04 16:43:57 - INFO - EVALUATING - Epoch: [6][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.2758 (1.1795)	Prec@1 56.000 (59.706)	Prec@5 90.000 (94.000)
2019-05-04 16:43:57 - INFO - 
 Epoch: 7	Training Loss 1.0935 	Training Prec@1 61.936 	Training Prec@5 95.952 	Validation Loss 1.2000 	Validation Prec@1 58.770 	Validation Prec@5 93.980 	
2019-05-04 16:43:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:43:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:43:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:43:57 - INFO - TRAINING - Epoch: [7][0/500]	Time 0.376 (0.376)	Data 0.348 (0.348)	Loss 1.0276 (1.0276)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-04 16:43:58 - INFO - TRAINING - Epoch: [7][50/500]	Time 0.018 (0.027)	Data 0.000 (0.007)	Loss 1.2987 (1.1157)	Prec@1 57.000 (61.490)	Prec@5 92.000 (95.314)
2019-05-04 16:43:59 - INFO - TRAINING - Epoch: [7][100/500]	Time 0.027 (0.023)	Data 0.000 (0.004)	Loss 1.1066 (1.0858)	Prec@1 57.000 (62.455)	Prec@5 92.000 (95.812)
2019-05-04 16:44:01 - INFO - TRAINING - Epoch: [7][150/500]	Time 0.017 (0.023)	Data 0.000 (0.002)	Loss 1.1593 (1.0768)	Prec@1 57.000 (62.616)	Prec@5 97.000 (95.954)
2019-05-04 16:44:02 - INFO - TRAINING - Epoch: [7][200/500]	Time 0.026 (0.022)	Data 0.000 (0.002)	Loss 1.0797 (1.0816)	Prec@1 61.000 (62.493)	Prec@5 97.000 (95.910)
2019-05-04 16:44:03 - INFO - TRAINING - Epoch: [7][250/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.9800 (1.0761)	Prec@1 65.000 (62.745)	Prec@5 98.000 (96.024)
2019-05-04 16:44:04 - INFO - TRAINING - Epoch: [7][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9710 (1.0703)	Prec@1 71.000 (62.917)	Prec@5 97.000 (96.146)
2019-05-04 16:44:05 - INFO - TRAINING - Epoch: [7][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.1827 (1.0663)	Prec@1 67.000 (63.080)	Prec@5 93.000 (96.123)
2019-05-04 16:44:06 - INFO - TRAINING - Epoch: [7][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0981 (1.0689)	Prec@1 63.000 (63.022)	Prec@5 96.000 (96.080)
2019-05-04 16:44:07 - INFO - TRAINING - Epoch: [7][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.2783 (1.0675)	Prec@1 56.000 (63.044)	Prec@5 95.000 (96.118)
2019-05-04 16:44:08 - INFO - EVALUATING - Epoch: [7][0/100]	Time 0.284 (0.284)	Data 0.269 (0.269)	Loss 1.1546 (1.1546)	Prec@1 59.000 (59.000)	Prec@5 95.000 (95.000)
2019-05-04 16:44:08 - INFO - EVALUATING - Epoch: [7][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 1.4024 (1.3276)	Prec@1 51.000 (53.980)	Prec@5 91.000 (93.431)
2019-05-04 16:44:08 - INFO - 
 Epoch: 8	Training Loss 1.0644 	Training Prec@1 63.122 	Training Prec@5 96.158 	Validation Loss 1.3257 	Validation Prec@1 53.450 	Validation Prec@5 93.490 	
2019-05-04 16:44:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:44:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:44:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:44:09 - INFO - TRAINING - Epoch: [8][0/500]	Time 0.389 (0.389)	Data 0.362 (0.362)	Loss 1.2409 (1.2409)	Prec@1 56.000 (56.000)	Prec@5 96.000 (96.000)
2019-05-04 16:44:10 - INFO - TRAINING - Epoch: [8][50/500]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.9518 (1.0675)	Prec@1 67.000 (63.294)	Prec@5 96.000 (96.059)
2019-05-04 16:44:11 - INFO - TRAINING - Epoch: [8][100/500]	Time 0.016 (0.023)	Data 0.000 (0.004)	Loss 1.1044 (1.0675)	Prec@1 62.000 (62.980)	Prec@5 97.000 (95.950)
2019-05-04 16:44:12 - INFO - TRAINING - Epoch: [8][150/500]	Time 0.020 (0.022)	Data 0.000 (0.003)	Loss 1.1681 (1.0636)	Prec@1 55.000 (63.060)	Prec@5 94.000 (96.079)
2019-05-04 16:44:13 - INFO - TRAINING - Epoch: [8][200/500]	Time 0.027 (0.021)	Data 0.000 (0.002)	Loss 1.1663 (1.0565)	Prec@1 59.000 (63.488)	Prec@5 94.000 (96.164)
2019-05-04 16:44:14 - INFO - TRAINING - Epoch: [8][250/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.8651 (1.0507)	Prec@1 74.000 (63.649)	Prec@5 98.000 (96.203)
2019-05-04 16:44:15 - INFO - TRAINING - Epoch: [8][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.9219 (1.0453)	Prec@1 63.000 (63.741)	Prec@5 97.000 (96.219)
2019-05-04 16:44:16 - INFO - TRAINING - Epoch: [8][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.0573 (1.0476)	Prec@1 60.000 (63.621)	Prec@5 96.000 (96.191)
2019-05-04 16:44:17 - INFO - TRAINING - Epoch: [8][400/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 1.0753 (1.0472)	Prec@1 64.000 (63.678)	Prec@5 93.000 (96.237)
2019-05-04 16:44:18 - INFO - TRAINING - Epoch: [8][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 1.1960 (1.0438)	Prec@1 62.000 (63.825)	Prec@5 93.000 (96.253)
2019-05-04 16:44:19 - INFO - EVALUATING - Epoch: [8][0/100]	Time 0.377 (0.377)	Data 0.366 (0.366)	Loss 1.1932 (1.1932)	Prec@1 60.000 (60.000)	Prec@5 93.000 (93.000)
2019-05-04 16:44:19 - INFO - EVALUATING - Epoch: [8][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.1574 (1.1918)	Prec@1 60.000 (58.667)	Prec@5 95.000 (94.569)
2019-05-04 16:44:19 - INFO - 
 Epoch: 9	Training Loss 1.0463 	Training Prec@1 63.714 	Training Prec@5 96.268 	Validation Loss 1.2138 	Validation Prec@1 57.610 	Validation Prec@5 94.370 	
2019-05-04 16:44:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:44:20 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:44:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:44:20 - INFO - TRAINING - Epoch: [9][0/500]	Time 0.387 (0.387)	Data 0.367 (0.367)	Loss 0.9913 (0.9913)	Prec@1 67.000 (67.000)	Prec@5 98.000 (98.000)
2019-05-04 16:44:21 - INFO - TRAINING - Epoch: [9][50/500]	Time 0.021 (0.026)	Data 0.000 (0.007)	Loss 0.8575 (1.0489)	Prec@1 74.000 (63.196)	Prec@5 96.000 (96.451)
2019-05-04 16:44:22 - INFO - TRAINING - Epoch: [9][100/500]	Time 0.026 (0.023)	Data 0.000 (0.004)	Loss 0.9189 (1.0256)	Prec@1 71.000 (64.129)	Prec@5 95.000 (96.416)
2019-05-04 16:44:23 - INFO - TRAINING - Epoch: [9][150/500]	Time 0.021 (0.021)	Data 0.000 (0.003)	Loss 0.8636 (1.0270)	Prec@1 73.000 (64.159)	Prec@5 96.000 (96.464)
2019-05-04 16:44:24 - INFO - TRAINING - Epoch: [9][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.8496 (1.0267)	Prec@1 70.000 (64.259)	Prec@5 97.000 (96.502)
2019-05-04 16:44:25 - INFO - TRAINING - Epoch: [9][250/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 1.2091 (1.0306)	Prec@1 58.000 (64.167)	Prec@5 97.000 (96.482)
2019-05-04 16:44:26 - INFO - TRAINING - Epoch: [9][300/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 1.0886 (1.0289)	Prec@1 60.000 (64.385)	Prec@5 95.000 (96.532)
2019-05-04 16:44:27 - INFO - TRAINING - Epoch: [9][350/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 1.1036 (1.0292)	Prec@1 66.000 (64.276)	Prec@5 94.000 (96.576)
2019-05-04 16:44:28 - INFO - TRAINING - Epoch: [9][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.9981 (1.0293)	Prec@1 67.000 (64.252)	Prec@5 97.000 (96.599)
2019-05-04 16:44:29 - INFO - TRAINING - Epoch: [9][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.9014 (1.0272)	Prec@1 64.000 (64.366)	Prec@5 98.000 (96.570)
2019-05-04 16:44:30 - INFO - EVALUATING - Epoch: [9][0/100]	Time 0.381 (0.381)	Data 0.372 (0.372)	Loss 1.1778 (1.1778)	Prec@1 53.000 (53.000)	Prec@5 93.000 (93.000)
2019-05-04 16:44:30 - INFO - EVALUATING - Epoch: [9][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.0889 (1.2041)	Prec@1 62.000 (58.059)	Prec@5 96.000 (94.686)
2019-05-04 16:44:31 - INFO - 
 Epoch: 10	Training Loss 1.0270 	Training Prec@1 64.394 	Training Prec@5 96.574 	Validation Loss 1.2275 	Validation Prec@1 57.210 	Validation Prec@5 94.710 	
2019-05-04 16:44:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:44:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:44:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:44:31 - INFO - TRAINING - Epoch: [10][0/500]	Time 0.367 (0.367)	Data 0.351 (0.351)	Loss 0.9138 (0.9138)	Prec@1 67.000 (67.000)	Prec@5 98.000 (98.000)
2019-05-04 16:44:32 - INFO - TRAINING - Epoch: [10][50/500]	Time 0.031 (0.026)	Data 0.000 (0.007)	Loss 0.9797 (1.0111)	Prec@1 66.000 (64.863)	Prec@5 97.000 (96.627)
2019-05-04 16:44:33 - INFO - TRAINING - Epoch: [10][100/500]	Time 0.023 (0.023)	Data 0.000 (0.004)	Loss 1.0210 (1.0062)	Prec@1 62.000 (64.792)	Prec@5 98.000 (96.624)
2019-05-04 16:44:34 - INFO - TRAINING - Epoch: [10][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 1.1315 (1.0183)	Prec@1 55.000 (64.291)	Prec@5 94.000 (96.510)
2019-05-04 16:44:35 - INFO - TRAINING - Epoch: [10][200/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 1.0904 (1.0157)	Prec@1 62.000 (64.622)	Prec@5 97.000 (96.552)
2019-05-04 16:44:36 - INFO - TRAINING - Epoch: [10][250/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 1.0465 (1.0138)	Prec@1 66.000 (64.837)	Prec@5 98.000 (96.610)
2019-05-04 16:44:37 - INFO - TRAINING - Epoch: [10][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9617 (1.0150)	Prec@1 63.000 (64.724)	Prec@5 100.000 (96.601)
2019-05-04 16:44:38 - INFO - TRAINING - Epoch: [10][350/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 1.0914 (1.0158)	Prec@1 58.000 (64.621)	Prec@5 98.000 (96.601)
2019-05-04 16:44:39 - INFO - TRAINING - Epoch: [10][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 1.1059 (1.0163)	Prec@1 66.000 (64.706)	Prec@5 93.000 (96.606)
2019-05-04 16:44:40 - INFO - TRAINING - Epoch: [10][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.1005 (1.0185)	Prec@1 64.000 (64.678)	Prec@5 95.000 (96.588)
2019-05-04 16:44:41 - INFO - EVALUATING - Epoch: [10][0/100]	Time 0.384 (0.384)	Data 0.369 (0.369)	Loss 0.9088 (0.9088)	Prec@1 69.000 (69.000)	Prec@5 97.000 (97.000)
2019-05-04 16:44:41 - INFO - EVALUATING - Epoch: [10][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.9881 (1.0649)	Prec@1 69.000 (62.804)	Prec@5 95.000 (96.118)
2019-05-04 16:44:42 - INFO - 
 Epoch: 11	Training Loss 1.0166 	Training Prec@1 64.714 	Training Prec@5 96.562 	Validation Loss 1.0738 	Validation Prec@1 62.660 	Validation Prec@5 96.150 	
2019-05-04 16:44:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:44:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:44:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:44:42 - INFO - TRAINING - Epoch: [11][0/500]	Time 0.379 (0.379)	Data 0.359 (0.359)	Loss 0.9438 (0.9438)	Prec@1 65.000 (65.000)	Prec@5 99.000 (99.000)
2019-05-04 16:44:43 - INFO - TRAINING - Epoch: [11][50/500]	Time 0.022 (0.026)	Data 0.000 (0.007)	Loss 1.0706 (1.0264)	Prec@1 67.000 (65.314)	Prec@5 96.000 (96.471)
2019-05-04 16:44:44 - INFO - TRAINING - Epoch: [11][100/500]	Time 0.017 (0.023)	Data 0.000 (0.004)	Loss 0.8990 (1.0141)	Prec@1 67.000 (65.634)	Prec@5 97.000 (96.574)
2019-05-04 16:44:45 - INFO - TRAINING - Epoch: [11][150/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.9684 (1.0055)	Prec@1 64.000 (65.589)	Prec@5 99.000 (96.715)
2019-05-04 16:44:46 - INFO - TRAINING - Epoch: [11][200/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.8355 (1.0030)	Prec@1 70.000 (65.701)	Prec@5 99.000 (96.706)
2019-05-04 16:44:47 - INFO - TRAINING - Epoch: [11][250/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.9235 (1.0037)	Prec@1 65.000 (65.570)	Prec@5 98.000 (96.765)
2019-05-04 16:44:48 - INFO - TRAINING - Epoch: [11][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.1114 (1.0077)	Prec@1 65.000 (65.316)	Prec@5 96.000 (96.741)
2019-05-04 16:44:49 - INFO - TRAINING - Epoch: [11][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 1.0667 (1.0054)	Prec@1 62.000 (65.399)	Prec@5 94.000 (96.721)
2019-05-04 16:44:50 - INFO - TRAINING - Epoch: [11][400/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 1.1786 (1.0041)	Prec@1 63.000 (65.426)	Prec@5 94.000 (96.683)
2019-05-04 16:44:51 - INFO - TRAINING - Epoch: [11][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.0255 (1.0068)	Prec@1 63.000 (65.353)	Prec@5 96.000 (96.672)
2019-05-04 16:44:52 - INFO - EVALUATING - Epoch: [11][0/100]	Time 0.349 (0.349)	Data 0.343 (0.343)	Loss 1.2133 (1.2133)	Prec@1 56.000 (56.000)	Prec@5 92.000 (92.000)
2019-05-04 16:44:53 - INFO - EVALUATING - Epoch: [11][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 1.2116 (1.2354)	Prec@1 62.000 (57.843)	Prec@5 94.000 (94.471)
2019-05-04 16:44:53 - INFO - 
 Epoch: 12	Training Loss 1.0061 	Training Prec@1 65.432 	Training Prec@5 96.634 	Validation Loss 1.2511 	Validation Prec@1 57.160 	Validation Prec@5 94.290 	
2019-05-04 16:44:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:44:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:44:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:44:53 - INFO - TRAINING - Epoch: [12][0/500]	Time 0.358 (0.358)	Data 0.337 (0.337)	Loss 0.9876 (0.9876)	Prec@1 65.000 (65.000)	Prec@5 97.000 (97.000)
2019-05-04 16:44:54 - INFO - TRAINING - Epoch: [12][50/500]	Time 0.017 (0.027)	Data 0.000 (0.007)	Loss 1.0934 (1.0483)	Prec@1 64.000 (63.843)	Prec@5 96.000 (96.216)
2019-05-04 16:44:55 - INFO - TRAINING - Epoch: [12][100/500]	Time 0.014 (0.023)	Data 0.000 (0.003)	Loss 0.9846 (1.0226)	Prec@1 67.000 (64.624)	Prec@5 98.000 (96.475)
2019-05-04 16:44:56 - INFO - TRAINING - Epoch: [12][150/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.8200 (1.0090)	Prec@1 76.000 (64.874)	Prec@5 95.000 (96.702)
2019-05-04 16:44:57 - INFO - TRAINING - Epoch: [12][200/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.0504 (1.0157)	Prec@1 61.000 (64.781)	Prec@5 99.000 (96.657)
2019-05-04 16:44:58 - INFO - TRAINING - Epoch: [12][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0340 (1.0106)	Prec@1 66.000 (64.912)	Prec@5 96.000 (96.713)
2019-05-04 16:44:59 - INFO - TRAINING - Epoch: [12][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9185 (1.0064)	Prec@1 67.000 (65.173)	Prec@5 98.000 (96.797)
2019-05-04 16:45:00 - INFO - TRAINING - Epoch: [12][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9520 (1.0039)	Prec@1 64.000 (65.214)	Prec@5 97.000 (96.744)
2019-05-04 16:45:01 - INFO - TRAINING - Epoch: [12][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9451 (0.9992)	Prec@1 70.000 (65.337)	Prec@5 99.000 (96.818)
2019-05-04 16:45:02 - INFO - TRAINING - Epoch: [12][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.1693 (0.9954)	Prec@1 60.000 (65.463)	Prec@5 90.000 (96.849)
2019-05-04 16:45:04 - INFO - EVALUATING - Epoch: [12][0/100]	Time 0.376 (0.376)	Data 0.363 (0.363)	Loss 1.8962 (1.8962)	Prec@1 36.000 (36.000)	Prec@5 91.000 (91.000)
2019-05-04 16:45:04 - INFO - EVALUATING - Epoch: [12][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.9932 (1.8852)	Prec@1 40.000 (40.608)	Prec@5 86.000 (89.549)
2019-05-04 16:45:04 - INFO - 
 Epoch: 13	Training Loss 0.9930 	Training Prec@1 65.598 	Training Prec@5 96.850 	Validation Loss 1.8683 	Validation Prec@1 41.160 	Validation Prec@5 89.080 	
2019-05-04 16:45:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:45:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:45:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:45:04 - INFO - TRAINING - Epoch: [13][0/500]	Time 0.368 (0.368)	Data 0.344 (0.344)	Loss 0.9115 (0.9115)	Prec@1 71.000 (71.000)	Prec@5 96.000 (96.000)
2019-05-04 16:45:05 - INFO - TRAINING - Epoch: [13][50/500]	Time 0.022 (0.026)	Data 0.000 (0.007)	Loss 1.1265 (1.0003)	Prec@1 60.000 (65.647)	Prec@5 99.000 (96.431)
2019-05-04 16:45:06 - INFO - TRAINING - Epoch: [13][100/500]	Time 0.022 (0.024)	Data 0.000 (0.004)	Loss 0.9515 (0.9757)	Prec@1 69.000 (66.129)	Prec@5 99.000 (96.891)
2019-05-04 16:45:07 - INFO - TRAINING - Epoch: [13][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.9500 (0.9708)	Prec@1 69.000 (66.536)	Prec@5 98.000 (96.854)
2019-05-04 16:45:09 - INFO - TRAINING - Epoch: [13][200/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.9611 (0.9725)	Prec@1 69.000 (66.577)	Prec@5 98.000 (96.955)
2019-05-04 16:45:10 - INFO - TRAINING - Epoch: [13][250/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 1.0028 (0.9683)	Prec@1 69.000 (66.705)	Prec@5 95.000 (97.016)
2019-05-04 16:45:11 - INFO - TRAINING - Epoch: [13][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8753 (0.9699)	Prec@1 70.000 (66.668)	Prec@5 98.000 (96.980)
2019-05-04 16:45:12 - INFO - TRAINING - Epoch: [13][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 1.2673 (0.9700)	Prec@1 56.000 (66.641)	Prec@5 93.000 (96.997)
2019-05-04 16:45:12 - INFO - TRAINING - Epoch: [13][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.9321 (0.9689)	Prec@1 65.000 (66.589)	Prec@5 99.000 (97.015)
2019-05-04 16:45:13 - INFO - TRAINING - Epoch: [13][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.0077 (0.9673)	Prec@1 68.000 (66.667)	Prec@5 98.000 (96.996)
2019-05-04 16:45:15 - INFO - EVALUATING - Epoch: [13][0/100]	Time 0.349 (0.349)	Data 0.342 (0.342)	Loss 1.2266 (1.2266)	Prec@1 63.000 (63.000)	Prec@5 90.000 (90.000)
2019-05-04 16:45:15 - INFO - EVALUATING - Epoch: [13][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.3671 (1.3130)	Prec@1 57.000 (55.725)	Prec@5 92.000 (92.333)
2019-05-04 16:45:15 - INFO - 
 Epoch: 14	Training Loss 0.9679 	Training Prec@1 66.696 	Training Prec@5 96.970 	Validation Loss 1.2999 	Validation Prec@1 56.130 	Validation Prec@5 92.360 	
2019-05-04 16:45:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:45:15 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:45:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:45:16 - INFO - TRAINING - Epoch: [14][0/500]	Time 0.379 (0.379)	Data 0.353 (0.353)	Loss 0.7645 (0.7645)	Prec@1 75.000 (75.000)	Prec@5 96.000 (96.000)
2019-05-04 16:45:17 - INFO - TRAINING - Epoch: [14][50/500]	Time 0.015 (0.026)	Data 0.000 (0.007)	Loss 0.9515 (0.9541)	Prec@1 70.000 (67.098)	Prec@5 97.000 (96.843)
2019-05-04 16:45:18 - INFO - TRAINING - Epoch: [14][100/500]	Time 0.020 (0.023)	Data 0.000 (0.004)	Loss 1.0264 (0.9606)	Prec@1 64.000 (66.663)	Prec@5 99.000 (97.030)
2019-05-04 16:45:19 - INFO - TRAINING - Epoch: [14][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 1.0656 (0.9604)	Prec@1 67.000 (66.728)	Prec@5 98.000 (96.940)
2019-05-04 16:45:20 - INFO - TRAINING - Epoch: [14][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.9023 (0.9574)	Prec@1 71.000 (66.766)	Prec@5 95.000 (97.005)
2019-05-04 16:45:21 - INFO - TRAINING - Epoch: [14][250/500]	Time 0.025 (0.021)	Data 0.000 (0.002)	Loss 0.9827 (0.9582)	Prec@1 67.000 (66.789)	Prec@5 91.000 (97.004)
2019-05-04 16:45:22 - INFO - TRAINING - Epoch: [14][300/500]	Time 0.034 (0.021)	Data 0.000 (0.001)	Loss 0.8953 (0.9589)	Prec@1 69.000 (66.724)	Prec@5 98.000 (96.987)
2019-05-04 16:45:23 - INFO - TRAINING - Epoch: [14][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9548 (0.9620)	Prec@1 65.000 (66.735)	Prec@5 98.000 (96.960)
2019-05-04 16:45:24 - INFO - TRAINING - Epoch: [14][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.9343 (0.9602)	Prec@1 68.000 (66.940)	Prec@5 99.000 (96.933)
2019-05-04 16:45:25 - INFO - TRAINING - Epoch: [14][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.0293 (0.9615)	Prec@1 67.000 (66.865)	Prec@5 95.000 (96.891)
2019-05-04 16:45:26 - INFO - EVALUATING - Epoch: [14][0/100]	Time 0.386 (0.386)	Data 0.376 (0.376)	Loss 1.0513 (1.0513)	Prec@1 65.000 (65.000)	Prec@5 96.000 (96.000)
2019-05-04 16:45:26 - INFO - EVALUATING - Epoch: [14][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.0085 (1.1028)	Prec@1 66.000 (62.843)	Prec@5 93.000 (95.510)
2019-05-04 16:45:27 - INFO - 
 Epoch: 15	Training Loss 0.9618 	Training Prec@1 66.886 	Training Prec@5 96.904 	Validation Loss 1.1052 	Validation Prec@1 62.500 	Validation Prec@5 95.580 	
2019-05-04 16:45:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:45:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:45:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:45:27 - INFO - TRAINING - Epoch: [15][0/500]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.8228 (0.8228)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-04 16:45:28 - INFO - TRAINING - Epoch: [15][50/500]	Time 0.023 (0.027)	Data 0.000 (0.007)	Loss 1.0301 (1.0112)	Prec@1 69.000 (64.627)	Prec@5 94.000 (96.863)
2019-05-04 16:45:29 - INFO - TRAINING - Epoch: [15][100/500]	Time 0.021 (0.024)	Data 0.000 (0.003)	Loss 1.0517 (0.9835)	Prec@1 62.000 (65.703)	Prec@5 96.000 (96.980)
2019-05-04 16:45:30 - INFO - TRAINING - Epoch: [15][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.8211 (0.9776)	Prec@1 71.000 (66.073)	Prec@5 96.000 (97.053)
2019-05-04 16:45:31 - INFO - TRAINING - Epoch: [15][200/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.9564 (0.9666)	Prec@1 67.000 (66.428)	Prec@5 99.000 (97.070)
2019-05-04 16:45:32 - INFO - TRAINING - Epoch: [15][250/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.7830 (0.9601)	Prec@1 76.000 (66.753)	Prec@5 100.000 (97.048)
2019-05-04 16:45:33 - INFO - TRAINING - Epoch: [15][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8095 (0.9633)	Prec@1 72.000 (66.744)	Prec@5 97.000 (97.007)
2019-05-04 16:45:34 - INFO - TRAINING - Epoch: [15][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 1.0450 (0.9650)	Prec@1 62.000 (66.678)	Prec@5 95.000 (96.977)
2019-05-04 16:45:35 - INFO - TRAINING - Epoch: [15][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8280 (0.9599)	Prec@1 70.000 (66.791)	Prec@5 98.000 (97.030)
2019-05-04 16:45:36 - INFO - TRAINING - Epoch: [15][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8879 (0.9602)	Prec@1 69.000 (66.867)	Prec@5 97.000 (97.022)
2019-05-04 16:45:37 - INFO - EVALUATING - Epoch: [15][0/100]	Time 0.357 (0.357)	Data 0.351 (0.351)	Loss 1.3019 (1.3019)	Prec@1 56.000 (56.000)	Prec@5 94.000 (94.000)
2019-05-04 16:45:38 - INFO - EVALUATING - Epoch: [15][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.5402 (1.5837)	Prec@1 49.000 (48.627)	Prec@5 95.000 (92.196)
2019-05-04 16:45:38 - INFO - 
 Epoch: 16	Training Loss 0.9581 	Training Prec@1 67.058 	Training Prec@5 97.010 	Validation Loss 1.5992 	Validation Prec@1 48.100 	Validation Prec@5 92.370 	
2019-05-04 16:45:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:45:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:45:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:45:38 - INFO - TRAINING - Epoch: [16][0/500]	Time 0.375 (0.375)	Data 0.344 (0.344)	Loss 0.7550 (0.7550)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-04 16:45:39 - INFO - TRAINING - Epoch: [16][50/500]	Time 0.018 (0.027)	Data 0.000 (0.007)	Loss 0.9492 (0.9650)	Prec@1 64.000 (66.569)	Prec@5 97.000 (97.000)
2019-05-04 16:45:40 - INFO - TRAINING - Epoch: [16][100/500]	Time 0.019 (0.023)	Data 0.000 (0.004)	Loss 0.9008 (0.9507)	Prec@1 72.000 (67.079)	Prec@5 96.000 (97.208)
2019-05-04 16:45:41 - INFO - TRAINING - Epoch: [16][150/500]	Time 0.026 (0.023)	Data 0.000 (0.002)	Loss 1.0648 (0.9427)	Prec@1 68.000 (67.430)	Prec@5 96.000 (97.252)
2019-05-04 16:45:42 - INFO - TRAINING - Epoch: [16][200/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.8863 (0.9419)	Prec@1 68.000 (67.537)	Prec@5 98.000 (97.224)
2019-05-04 16:45:43 - INFO - TRAINING - Epoch: [16][250/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 1.0259 (0.9500)	Prec@1 72.000 (67.386)	Prec@5 96.000 (97.127)
2019-05-04 16:45:44 - INFO - TRAINING - Epoch: [16][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9851 (0.9479)	Prec@1 65.000 (67.432)	Prec@5 99.000 (97.130)
2019-05-04 16:45:45 - INFO - TRAINING - Epoch: [16][350/500]	Time 0.011 (0.021)	Data 0.000 (0.001)	Loss 1.1804 (0.9550)	Prec@1 62.000 (67.128)	Prec@5 90.000 (97.071)
2019-05-04 16:45:46 - INFO - TRAINING - Epoch: [16][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8108 (0.9537)	Prec@1 72.000 (67.157)	Prec@5 98.000 (97.040)
2019-05-04 16:45:47 - INFO - TRAINING - Epoch: [16][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.9455 (0.9533)	Prec@1 71.000 (67.253)	Prec@5 97.000 (97.058)
2019-05-04 16:45:48 - INFO - EVALUATING - Epoch: [16][0/100]	Time 0.353 (0.353)	Data 0.337 (0.337)	Loss 1.3638 (1.3638)	Prec@1 49.000 (49.000)	Prec@5 95.000 (95.000)
2019-05-04 16:45:49 - INFO - EVALUATING - Epoch: [16][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.4024 (1.4434)	Prec@1 57.000 (51.118)	Prec@5 91.000 (91.863)
2019-05-04 16:45:49 - INFO - 
 Epoch: 17	Training Loss 0.9523 	Training Prec@1 67.258 	Training Prec@5 97.048 	Validation Loss 1.4489 	Validation Prec@1 51.470 	Validation Prec@5 91.540 	
2019-05-04 16:45:49 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:45:49 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:45:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:45:49 - INFO - TRAINING - Epoch: [17][0/500]	Time 0.354 (0.354)	Data 0.337 (0.337)	Loss 0.8298 (0.8298)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-04 16:45:50 - INFO - TRAINING - Epoch: [17][50/500]	Time 0.021 (0.025)	Data 0.000 (0.007)	Loss 0.9731 (0.9326)	Prec@1 69.000 (68.647)	Prec@5 94.000 (96.882)
2019-05-04 16:45:51 - INFO - TRAINING - Epoch: [17][100/500]	Time 0.026 (0.022)	Data 0.000 (0.003)	Loss 0.8792 (0.9307)	Prec@1 73.000 (68.436)	Prec@5 97.000 (97.178)
2019-05-04 16:45:52 - INFO - TRAINING - Epoch: [17][150/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.7395 (0.9218)	Prec@1 73.000 (68.662)	Prec@5 100.000 (97.351)
2019-05-04 16:45:53 - INFO - TRAINING - Epoch: [17][200/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.8708 (0.9257)	Prec@1 71.000 (68.403)	Prec@5 98.000 (97.308)
2019-05-04 16:45:54 - INFO - TRAINING - Epoch: [17][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.8941 (0.9228)	Prec@1 67.000 (68.394)	Prec@5 99.000 (97.319)
2019-05-04 16:45:55 - INFO - TRAINING - Epoch: [17][300/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.9140 (0.9219)	Prec@1 66.000 (68.505)	Prec@5 98.000 (97.292)
2019-05-04 16:45:56 - INFO - TRAINING - Epoch: [17][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.9673 (0.9275)	Prec@1 64.000 (68.242)	Prec@5 98.000 (97.322)
2019-05-04 16:45:57 - INFO - TRAINING - Epoch: [17][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.0576 (0.9324)	Prec@1 61.000 (68.115)	Prec@5 96.000 (97.182)
2019-05-04 16:45:58 - INFO - TRAINING - Epoch: [17][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.8687 (0.9359)	Prec@1 71.000 (67.949)	Prec@5 99.000 (97.204)
2019-05-04 16:46:00 - INFO - EVALUATING - Epoch: [17][0/100]	Time 0.375 (0.375)	Data 0.361 (0.361)	Loss 1.1785 (1.1785)	Prec@1 63.000 (63.000)	Prec@5 94.000 (94.000)
2019-05-04 16:46:00 - INFO - EVALUATING - Epoch: [17][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.1248 (1.0845)	Prec@1 64.000 (63.961)	Prec@5 90.000 (95.216)
2019-05-04 16:46:00 - INFO - 
 Epoch: 18	Training Loss 0.9346 	Training Prec@1 67.974 	Training Prec@5 97.214 	Validation Loss 1.0916 	Validation Prec@1 63.280 	Validation Prec@5 95.310 	
2019-05-04 16:46:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:00 - INFO - TRAINING - Epoch: [18][0/500]	Time 0.359 (0.359)	Data 0.327 (0.327)	Loss 1.0835 (1.0835)	Prec@1 67.000 (67.000)	Prec@5 96.000 (96.000)
2019-05-04 16:46:01 - INFO - TRAINING - Epoch: [18][50/500]	Time 0.022 (0.027)	Data 0.000 (0.007)	Loss 0.7516 (0.9516)	Prec@1 75.000 (67.353)	Prec@5 100.000 (97.275)
2019-05-04 16:46:02 - INFO - TRAINING - Epoch: [18][100/500]	Time 0.021 (0.023)	Data 0.000 (0.003)	Loss 0.8352 (0.9462)	Prec@1 73.000 (67.663)	Prec@5 97.000 (97.327)
2019-05-04 16:46:03 - INFO - TRAINING - Epoch: [18][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.8282 (0.9408)	Prec@1 70.000 (67.815)	Prec@5 99.000 (97.364)
2019-05-04 16:46:04 - INFO - TRAINING - Epoch: [18][200/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.9098 (0.9259)	Prec@1 71.000 (68.154)	Prec@5 99.000 (97.393)
2019-05-04 16:46:05 - INFO - TRAINING - Epoch: [18][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8730 (0.9263)	Prec@1 70.000 (68.243)	Prec@5 99.000 (97.311)
2019-05-04 16:46:06 - INFO - TRAINING - Epoch: [18][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.9634 (0.9272)	Prec@1 65.000 (68.272)	Prec@5 98.000 (97.249)
2019-05-04 16:46:07 - INFO - TRAINING - Epoch: [18][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9093 (0.9251)	Prec@1 69.000 (68.405)	Prec@5 97.000 (97.254)
2019-05-04 16:46:08 - INFO - TRAINING - Epoch: [18][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9930 (0.9250)	Prec@1 65.000 (68.409)	Prec@5 97.000 (97.232)
2019-05-04 16:46:09 - INFO - TRAINING - Epoch: [18][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7782 (0.9276)	Prec@1 75.000 (68.330)	Prec@5 98.000 (97.157)
2019-05-04 16:46:11 - INFO - EVALUATING - Epoch: [18][0/100]	Time 0.383 (0.383)	Data 0.375 (0.375)	Loss 0.9659 (0.9659)	Prec@1 62.000 (62.000)	Prec@5 99.000 (99.000)
2019-05-04 16:46:11 - INFO - EVALUATING - Epoch: [18][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.0130 (1.1264)	Prec@1 67.000 (60.569)	Prec@5 95.000 (95.941)
2019-05-04 16:46:11 - INFO - 
 Epoch: 19	Training Loss 0.9245 	Training Prec@1 68.484 	Training Prec@5 97.206 	Validation Loss 1.1368 	Validation Prec@1 60.210 	Validation Prec@5 96.040 	
2019-05-04 16:46:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:12 - INFO - TRAINING - Epoch: [19][0/500]	Time 0.385 (0.385)	Data 0.366 (0.366)	Loss 0.8848 (0.8848)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-04 16:46:13 - INFO - TRAINING - Epoch: [19][50/500]	Time 0.015 (0.026)	Data 0.000 (0.007)	Loss 0.8901 (0.9432)	Prec@1 72.000 (67.549)	Prec@5 95.000 (97.294)
2019-05-04 16:46:14 - INFO - TRAINING - Epoch: [19][100/500]	Time 0.019 (0.023)	Data 0.000 (0.004)	Loss 1.0495 (0.9387)	Prec@1 63.000 (67.921)	Prec@5 97.000 (97.178)
2019-05-04 16:46:15 - INFO - TRAINING - Epoch: [19][150/500]	Time 0.013 (0.022)	Data 0.000 (0.003)	Loss 0.8002 (0.9323)	Prec@1 72.000 (68.285)	Prec@5 98.000 (97.325)
2019-05-04 16:46:16 - INFO - TRAINING - Epoch: [19][200/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.7727 (0.9264)	Prec@1 67.000 (68.373)	Prec@5 97.000 (97.279)
2019-05-04 16:46:17 - INFO - TRAINING - Epoch: [19][250/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.0063 (0.9180)	Prec@1 66.000 (68.737)	Prec@5 97.000 (97.299)
2019-05-04 16:46:18 - INFO - TRAINING - Epoch: [19][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.8768 (0.9225)	Prec@1 70.000 (68.571)	Prec@5 96.000 (97.292)
2019-05-04 16:46:18 - INFO - TRAINING - Epoch: [19][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.8956 (0.9197)	Prec@1 68.000 (68.553)	Prec@5 99.000 (97.288)
2019-05-04 16:46:19 - INFO - TRAINING - Epoch: [19][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.8128 (0.9160)	Prec@1 70.000 (68.671)	Prec@5 99.000 (97.339)
2019-05-04 16:46:20 - INFO - TRAINING - Epoch: [19][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.9299 (0.9162)	Prec@1 66.000 (68.690)	Prec@5 98.000 (97.348)
2019-05-04 16:46:22 - INFO - EVALUATING - Epoch: [19][0/100]	Time 0.377 (0.377)	Data 0.362 (0.362)	Loss 1.1734 (1.1734)	Prec@1 63.000 (63.000)	Prec@5 93.000 (93.000)
2019-05-04 16:46:22 - INFO - EVALUATING - Epoch: [19][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.1371 (1.1527)	Prec@1 59.000 (60.882)	Prec@5 95.000 (95.294)
2019-05-04 16:46:22 - INFO - 
 Epoch: 20	Training Loss 0.9140 	Training Prec@1 68.816 	Training Prec@5 97.308 	Validation Loss 1.1654 	Validation Prec@1 60.780 	Validation Prec@5 95.260 	
2019-05-04 16:46:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:23 - INFO - TRAINING - Epoch: [20][0/500]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 1.0684 (1.0684)	Prec@1 61.000 (61.000)	Prec@5 98.000 (98.000)
2019-05-04 16:46:24 - INFO - TRAINING - Epoch: [20][50/500]	Time 0.013 (0.026)	Data 0.000 (0.007)	Loss 1.1263 (0.9301)	Prec@1 61.000 (67.902)	Prec@5 97.000 (97.294)
2019-05-04 16:46:25 - INFO - TRAINING - Epoch: [20][100/500]	Time 0.020 (0.023)	Data 0.000 (0.004)	Loss 0.8846 (0.9146)	Prec@1 73.000 (68.703)	Prec@5 98.000 (97.198)
2019-05-04 16:46:26 - INFO - TRAINING - Epoch: [20][150/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 0.8842 (0.9194)	Prec@1 69.000 (68.536)	Prec@5 98.000 (97.232)
2019-05-04 16:46:27 - INFO - TRAINING - Epoch: [20][200/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 0.7238 (0.9105)	Prec@1 75.000 (68.955)	Prec@5 98.000 (97.269)
2019-05-04 16:46:28 - INFO - TRAINING - Epoch: [20][250/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 1.0633 (0.9141)	Prec@1 62.000 (68.781)	Prec@5 96.000 (97.267)
2019-05-04 16:46:29 - INFO - TRAINING - Epoch: [20][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.9552 (0.9155)	Prec@1 66.000 (68.694)	Prec@5 97.000 (97.292)
2019-05-04 16:46:30 - INFO - TRAINING - Epoch: [20][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9117 (0.9186)	Prec@1 70.000 (68.593)	Prec@5 97.000 (97.285)
2019-05-04 16:46:30 - INFO - TRAINING - Epoch: [20][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8454 (0.9144)	Prec@1 75.000 (68.758)	Prec@5 95.000 (97.314)
2019-05-04 16:46:31 - INFO - TRAINING - Epoch: [20][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6164 (0.9062)	Prec@1 80.000 (69.020)	Prec@5 98.000 (97.346)
2019-05-04 16:46:33 - INFO - EVALUATING - Epoch: [20][0/100]	Time 0.346 (0.346)	Data 0.338 (0.338)	Loss 1.2312 (1.2312)	Prec@1 57.000 (57.000)	Prec@5 95.000 (95.000)
2019-05-04 16:46:33 - INFO - EVALUATING - Epoch: [20][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 1.4502 (1.4098)	Prec@1 59.000 (54.235)	Prec@5 88.000 (91.294)
2019-05-04 16:46:33 - INFO - 
 Epoch: 21	Training Loss 0.9044 	Training Prec@1 69.122 	Training Prec@5 97.328 	Validation Loss 1.4104 	Validation Prec@1 54.330 	Validation Prec@5 91.010 	
2019-05-04 16:46:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:34 - INFO - TRAINING - Epoch: [21][0/500]	Time 0.386 (0.386)	Data 0.360 (0.360)	Loss 1.1362 (1.1362)	Prec@1 66.000 (66.000)	Prec@5 98.000 (98.000)
2019-05-04 16:46:35 - INFO - TRAINING - Epoch: [21][50/500]	Time 0.024 (0.027)	Data 0.000 (0.007)	Loss 0.7887 (0.9300)	Prec@1 71.000 (67.765)	Prec@5 98.000 (97.275)
2019-05-04 16:46:36 - INFO - TRAINING - Epoch: [21][100/500]	Time 0.024 (0.023)	Data 0.000 (0.004)	Loss 0.9690 (0.9086)	Prec@1 67.000 (69.030)	Prec@5 98.000 (97.416)
2019-05-04 16:46:37 - INFO - TRAINING - Epoch: [21][150/500]	Time 0.032 (0.022)	Data 0.000 (0.003)	Loss 0.9882 (0.8903)	Prec@1 66.000 (69.589)	Prec@5 98.000 (97.497)
2019-05-04 16:46:38 - INFO - TRAINING - Epoch: [21][200/500]	Time 0.026 (0.021)	Data 0.000 (0.002)	Loss 0.9303 (0.8951)	Prec@1 67.000 (69.333)	Prec@5 97.000 (97.453)
2019-05-04 16:46:38 - INFO - TRAINING - Epoch: [21][250/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9398 (0.8956)	Prec@1 69.000 (69.283)	Prec@5 95.000 (97.450)
2019-05-04 16:46:39 - INFO - TRAINING - Epoch: [21][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8092 (0.8976)	Prec@1 75.000 (69.302)	Prec@5 94.000 (97.439)
2019-05-04 16:46:40 - INFO - TRAINING - Epoch: [21][350/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.8514 (0.8968)	Prec@1 72.000 (69.274)	Prec@5 97.000 (97.467)
2019-05-04 16:46:41 - INFO - TRAINING - Epoch: [21][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 1.0331 (0.8982)	Prec@1 64.000 (69.190)	Prec@5 97.000 (97.469)
2019-05-04 16:46:42 - INFO - TRAINING - Epoch: [21][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 1.0021 (0.8975)	Prec@1 65.000 (69.357)	Prec@5 97.000 (97.463)
2019-05-04 16:46:44 - INFO - EVALUATING - Epoch: [21][0/100]	Time 0.375 (0.375)	Data 0.363 (0.363)	Loss 1.0744 (1.0744)	Prec@1 61.000 (61.000)	Prec@5 97.000 (97.000)
2019-05-04 16:46:44 - INFO - EVALUATING - Epoch: [21][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.0634 (1.0514)	Prec@1 63.000 (62.961)	Prec@5 95.000 (96.725)
2019-05-04 16:46:44 - INFO - 
 Epoch: 22	Training Loss 0.8964 	Training Prec@1 69.454 	Training Prec@5 97.450 	Validation Loss 1.0692 	Validation Prec@1 62.430 	Validation Prec@5 96.570 	
2019-05-04 16:46:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:45 - INFO - TRAINING - Epoch: [22][0/500]	Time 0.368 (0.368)	Data 0.341 (0.341)	Loss 0.8547 (0.8547)	Prec@1 71.000 (71.000)	Prec@5 97.000 (97.000)
2019-05-04 16:46:46 - INFO - TRAINING - Epoch: [22][50/500]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.8643 (0.9306)	Prec@1 71.000 (68.294)	Prec@5 97.000 (96.980)
2019-05-04 16:46:47 - INFO - TRAINING - Epoch: [22][100/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 0.7327 (0.9270)	Prec@1 74.000 (68.327)	Prec@5 100.000 (97.050)
2019-05-04 16:46:48 - INFO - TRAINING - Epoch: [22][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.0069 (0.9151)	Prec@1 63.000 (68.881)	Prec@5 98.000 (97.185)
2019-05-04 16:46:49 - INFO - TRAINING - Epoch: [22][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.8499 (0.9118)	Prec@1 71.000 (69.015)	Prec@5 97.000 (97.259)
2019-05-04 16:46:50 - INFO - TRAINING - Epoch: [22][250/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 1.0691 (0.9133)	Prec@1 62.000 (69.012)	Prec@5 96.000 (97.343)
2019-05-04 16:46:51 - INFO - TRAINING - Epoch: [22][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.8998 (0.9087)	Prec@1 66.000 (69.136)	Prec@5 98.000 (97.399)
2019-05-04 16:46:52 - INFO - TRAINING - Epoch: [22][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0769 (0.9045)	Prec@1 66.000 (69.311)	Prec@5 94.000 (97.433)
2019-05-04 16:46:53 - INFO - TRAINING - Epoch: [22][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.0522 (0.9010)	Prec@1 66.000 (69.479)	Prec@5 99.000 (97.414)
2019-05-04 16:46:54 - INFO - TRAINING - Epoch: [22][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8815 (0.9035)	Prec@1 66.000 (69.313)	Prec@5 100.000 (97.459)
2019-05-04 16:46:55 - INFO - EVALUATING - Epoch: [22][0/100]	Time 0.373 (0.373)	Data 0.360 (0.360)	Loss 0.9243 (0.9243)	Prec@1 72.000 (72.000)	Prec@5 97.000 (97.000)
2019-05-04 16:46:55 - INFO - EVALUATING - Epoch: [22][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.0602 (1.0617)	Prec@1 64.000 (63.275)	Prec@5 96.000 (96.176)
2019-05-04 16:46:56 - INFO - 
 Epoch: 23	Training Loss 0.9038 	Training Prec@1 69.292 	Training Prec@5 97.466 	Validation Loss 1.0607 	Validation Prec@1 63.520 	Validation Prec@5 96.010 	
2019-05-04 16:46:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:46:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:46:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:46:56 - INFO - TRAINING - Epoch: [23][0/500]	Time 0.373 (0.373)	Data 0.353 (0.353)	Loss 0.9718 (0.9718)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-04 16:46:57 - INFO - TRAINING - Epoch: [23][50/500]	Time 0.017 (0.027)	Data 0.000 (0.007)	Loss 0.8394 (0.9076)	Prec@1 72.000 (69.078)	Prec@5 99.000 (97.294)
2019-05-04 16:46:58 - INFO - TRAINING - Epoch: [23][100/500]	Time 0.012 (0.023)	Data 0.000 (0.004)	Loss 0.8154 (0.9061)	Prec@1 75.000 (68.970)	Prec@5 99.000 (97.337)
2019-05-04 16:46:59 - INFO - TRAINING - Epoch: [23][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.9866 (0.8986)	Prec@1 68.000 (69.285)	Prec@5 97.000 (97.371)
2019-05-04 16:47:00 - INFO - TRAINING - Epoch: [23][200/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.8185 (0.8985)	Prec@1 73.000 (69.428)	Prec@5 98.000 (97.323)
2019-05-04 16:47:01 - INFO - TRAINING - Epoch: [23][250/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 1.0110 (0.8948)	Prec@1 64.000 (69.474)	Prec@5 97.000 (97.375)
2019-05-04 16:47:02 - INFO - TRAINING - Epoch: [23][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9653 (0.8949)	Prec@1 65.000 (69.349)	Prec@5 98.000 (97.432)
2019-05-04 16:47:03 - INFO - TRAINING - Epoch: [23][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9270 (0.8933)	Prec@1 72.000 (69.422)	Prec@5 98.000 (97.479)
2019-05-04 16:47:04 - INFO - TRAINING - Epoch: [23][400/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.9640 (0.8904)	Prec@1 70.000 (69.524)	Prec@5 97.000 (97.521)
2019-05-04 16:47:05 - INFO - TRAINING - Epoch: [23][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.0449 (0.8922)	Prec@1 60.000 (69.483)	Prec@5 97.000 (97.517)
2019-05-04 16:47:06 - INFO - EVALUATING - Epoch: [23][0/100]	Time 0.355 (0.355)	Data 0.340 (0.340)	Loss 1.7022 (1.7022)	Prec@1 49.000 (49.000)	Prec@5 86.000 (86.000)
2019-05-04 16:47:07 - INFO - EVALUATING - Epoch: [23][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 1.5327 (1.8083)	Prec@1 48.000 (45.608)	Prec@5 90.000 (84.373)
2019-05-04 16:47:07 - INFO - 
 Epoch: 24	Training Loss 0.8934 	Training Prec@1 69.496 	Training Prec@5 97.510 	Validation Loss 1.7819 	Validation Prec@1 46.370 	Validation Prec@5 85.130 	
2019-05-04 16:47:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:47:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:47:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:47:07 - INFO - TRAINING - Epoch: [24][0/500]	Time 0.374 (0.374)	Data 0.351 (0.351)	Loss 0.9104 (0.9104)	Prec@1 71.000 (71.000)	Prec@5 96.000 (96.000)
2019-05-04 16:47:08 - INFO - TRAINING - Epoch: [24][50/500]	Time 0.019 (0.025)	Data 0.000 (0.007)	Loss 0.7188 (0.9275)	Prec@1 75.000 (68.314)	Prec@5 99.000 (97.392)
2019-05-04 16:47:09 - INFO - TRAINING - Epoch: [24][100/500]	Time 0.019 (0.022)	Data 0.000 (0.004)	Loss 1.0878 (0.9163)	Prec@1 68.000 (69.000)	Prec@5 95.000 (97.386)
2019-05-04 16:47:10 - INFO - TRAINING - Epoch: [24][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.6770 (0.9073)	Prec@1 79.000 (69.172)	Prec@5 99.000 (97.305)
2019-05-04 16:47:11 - INFO - TRAINING - Epoch: [24][200/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.7366 (0.9055)	Prec@1 74.000 (69.259)	Prec@5 98.000 (97.289)
2019-05-04 16:47:12 - INFO - TRAINING - Epoch: [24][250/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.8431 (0.8964)	Prec@1 72.000 (69.590)	Prec@5 99.000 (97.335)
2019-05-04 16:47:13 - INFO - TRAINING - Epoch: [24][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.7477 (0.8920)	Prec@1 72.000 (69.678)	Prec@5 98.000 (97.389)
2019-05-04 16:47:14 - INFO - TRAINING - Epoch: [24][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7335 (0.8849)	Prec@1 78.000 (69.926)	Prec@5 97.000 (97.436)
2019-05-04 16:47:15 - INFO - TRAINING - Epoch: [24][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8915 (0.8858)	Prec@1 71.000 (69.850)	Prec@5 97.000 (97.411)
2019-05-04 16:47:16 - INFO - TRAINING - Epoch: [24][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.0298 (0.8845)	Prec@1 68.000 (69.936)	Prec@5 95.000 (97.430)
2019-05-04 16:47:18 - INFO - EVALUATING - Epoch: [24][0/100]	Time 0.355 (0.355)	Data 0.348 (0.348)	Loss 0.9360 (0.9360)	Prec@1 68.000 (68.000)	Prec@5 97.000 (97.000)
2019-05-04 16:47:18 - INFO - EVALUATING - Epoch: [24][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.0638 (1.0228)	Prec@1 64.000 (64.902)	Prec@5 96.000 (96.608)
2019-05-04 16:47:18 - INFO - 
 Epoch: 25	Training Loss 0.8858 	Training Prec@1 69.906 	Training Prec@5 97.422 	Validation Loss 1.0263 	Validation Prec@1 64.910 	Validation Prec@5 96.780 	
2019-05-04 16:47:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:47:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:47:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:47:18 - INFO - TRAINING - Epoch: [25][0/500]	Time 0.369 (0.369)	Data 0.343 (0.343)	Loss 0.8580 (0.8580)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-05-04 16:47:19 - INFO - TRAINING - Epoch: [25][50/500]	Time 0.020 (0.026)	Data 0.000 (0.007)	Loss 0.8716 (0.8976)	Prec@1 75.000 (70.490)	Prec@5 100.000 (97.569)
2019-05-04 16:47:20 - INFO - TRAINING - Epoch: [25][100/500]	Time 0.026 (0.023)	Data 0.000 (0.004)	Loss 0.7925 (0.8811)	Prec@1 76.000 (70.465)	Prec@5 98.000 (97.515)
2019-05-04 16:47:22 - INFO - TRAINING - Epoch: [25][150/500]	Time 0.023 (0.023)	Data 0.000 (0.002)	Loss 0.7043 (0.8729)	Prec@1 73.000 (70.589)	Prec@5 98.000 (97.550)
2019-05-04 16:47:23 - INFO - TRAINING - Epoch: [25][200/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.9621 (0.8703)	Prec@1 63.000 (70.483)	Prec@5 98.000 (97.632)
2019-05-04 16:47:24 - INFO - TRAINING - Epoch: [25][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.9380 (0.8731)	Prec@1 68.000 (70.498)	Prec@5 97.000 (97.562)
2019-05-04 16:47:24 - INFO - TRAINING - Epoch: [25][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9953 (0.8728)	Prec@1 69.000 (70.571)	Prec@5 98.000 (97.545)
2019-05-04 16:47:25 - INFO - TRAINING - Epoch: [25][350/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.9407 (0.8755)	Prec@1 68.000 (70.544)	Prec@5 95.000 (97.513)
2019-05-04 16:47:26 - INFO - TRAINING - Epoch: [25][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7763 (0.8760)	Prec@1 71.000 (70.494)	Prec@5 98.000 (97.531)
2019-05-04 16:47:27 - INFO - TRAINING - Epoch: [25][450/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.9745 (0.8775)	Prec@1 72.000 (70.370)	Prec@5 96.000 (97.519)
2019-05-04 16:47:29 - INFO - EVALUATING - Epoch: [25][0/100]	Time 0.348 (0.348)	Data 0.339 (0.339)	Loss 1.4534 (1.4534)	Prec@1 60.000 (60.000)	Prec@5 86.000 (86.000)
2019-05-04 16:47:29 - INFO - EVALUATING - Epoch: [25][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.4756 (1.4564)	Prec@1 59.000 (56.020)	Prec@5 86.000 (87.333)
2019-05-04 16:47:29 - INFO - 
 Epoch: 26	Training Loss 0.8769 	Training Prec@1 70.374 	Training Prec@5 97.532 	Validation Loss 1.4596 	Validation Prec@1 56.090 	Validation Prec@5 87.170 	
2019-05-04 16:47:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:47:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:47:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:47:30 - INFO - TRAINING - Epoch: [26][0/500]	Time 0.382 (0.382)	Data 0.360 (0.360)	Loss 0.6831 (0.6831)	Prec@1 78.000 (78.000)	Prec@5 97.000 (97.000)
2019-05-04 16:47:31 - INFO - TRAINING - Epoch: [26][50/500]	Time 0.014 (0.025)	Data 0.000 (0.007)	Loss 0.8910 (0.9021)	Prec@1 67.000 (69.314)	Prec@5 97.000 (97.176)
2019-05-04 16:47:32 - INFO - TRAINING - Epoch: [26][100/500]	Time 0.020 (0.022)	Data 0.000 (0.004)	Loss 0.9546 (0.8983)	Prec@1 68.000 (69.683)	Prec@5 98.000 (97.386)
2019-05-04 16:47:33 - INFO - TRAINING - Epoch: [26][150/500]	Time 0.012 (0.021)	Data 0.000 (0.003)	Loss 0.9848 (0.8956)	Prec@1 66.000 (69.616)	Prec@5 96.000 (97.344)
2019-05-04 16:47:34 - INFO - TRAINING - Epoch: [26][200/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 1.0576 (0.8882)	Prec@1 72.000 (69.806)	Prec@5 96.000 (97.438)
2019-05-04 16:47:35 - INFO - TRAINING - Epoch: [26][250/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.9704 (0.8868)	Prec@1 66.000 (69.821)	Prec@5 98.000 (97.462)
2019-05-04 16:47:36 - INFO - TRAINING - Epoch: [26][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9265 (0.8848)	Prec@1 69.000 (69.944)	Prec@5 98.000 (97.449)
2019-05-04 16:47:37 - INFO - TRAINING - Epoch: [26][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8741 (0.8812)	Prec@1 72.000 (69.991)	Prec@5 98.000 (97.493)
2019-05-04 16:47:38 - INFO - TRAINING - Epoch: [26][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8954 (0.8798)	Prec@1 72.000 (70.027)	Prec@5 97.000 (97.516)
2019-05-04 16:47:39 - INFO - TRAINING - Epoch: [26][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.9172 (0.8789)	Prec@1 68.000 (70.111)	Prec@5 96.000 (97.483)
2019-05-04 16:47:40 - INFO - EVALUATING - Epoch: [26][0/100]	Time 0.370 (0.370)	Data 0.364 (0.364)	Loss 1.0559 (1.0559)	Prec@1 67.000 (67.000)	Prec@5 96.000 (96.000)
2019-05-04 16:47:40 - INFO - EVALUATING - Epoch: [26][50/100]	Time 0.009 (0.013)	Data 0.000 (0.007)	Loss 1.0057 (1.0459)	Prec@1 66.000 (63.451)	Prec@5 97.000 (96.706)
2019-05-04 16:47:40 - INFO - 
 Epoch: 27	Training Loss 0.8794 	Training Prec@1 70.198 	Training Prec@5 97.448 	Validation Loss 1.0488 	Validation Prec@1 63.250 	Validation Prec@5 96.790 	
2019-05-04 16:47:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:47:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:47:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:47:41 - INFO - TRAINING - Epoch: [27][0/500]	Time 0.355 (0.355)	Data 0.329 (0.329)	Loss 0.8700 (0.8700)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-04 16:47:42 - INFO - TRAINING - Epoch: [27][50/500]	Time 0.018 (0.026)	Data 0.000 (0.007)	Loss 0.8309 (0.8859)	Prec@1 70.000 (70.039)	Prec@5 96.000 (97.275)
2019-05-04 16:47:43 - INFO - TRAINING - Epoch: [27][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.8165 (0.8801)	Prec@1 76.000 (70.436)	Prec@5 98.000 (97.406)
2019-05-04 16:47:44 - INFO - TRAINING - Epoch: [27][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.9411 (0.8836)	Prec@1 70.000 (70.344)	Prec@5 97.000 (97.424)
2019-05-04 16:47:45 - INFO - TRAINING - Epoch: [27][200/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 1.0712 (0.8805)	Prec@1 61.000 (70.303)	Prec@5 95.000 (97.522)
2019-05-04 16:47:46 - INFO - TRAINING - Epoch: [27][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.9422 (0.8781)	Prec@1 72.000 (70.386)	Prec@5 97.000 (97.538)
2019-05-04 16:47:47 - INFO - TRAINING - Epoch: [27][300/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.9642 (0.8745)	Prec@1 69.000 (70.545)	Prec@5 95.000 (97.505)
2019-05-04 16:47:48 - INFO - TRAINING - Epoch: [27][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.9110 (0.8739)	Prec@1 68.000 (70.570)	Prec@5 100.000 (97.504)
2019-05-04 16:47:49 - INFO - TRAINING - Epoch: [27][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.9322 (0.8709)	Prec@1 70.000 (70.554)	Prec@5 97.000 (97.571)
2019-05-04 16:47:50 - INFO - TRAINING - Epoch: [27][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8879 (0.8723)	Prec@1 72.000 (70.501)	Prec@5 98.000 (97.561)
2019-05-04 16:47:51 - INFO - EVALUATING - Epoch: [27][0/100]	Time 0.331 (0.331)	Data 0.322 (0.322)	Loss 1.1011 (1.1011)	Prec@1 62.000 (62.000)	Prec@5 96.000 (96.000)
2019-05-04 16:47:52 - INFO - EVALUATING - Epoch: [27][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.0552 (1.1307)	Prec@1 65.000 (62.059)	Prec@5 96.000 (95.490)
2019-05-04 16:47:52 - INFO - 
 Epoch: 28	Training Loss 0.8743 	Training Prec@1 70.406 	Training Prec@5 97.534 	Validation Loss 1.1418 	Validation Prec@1 61.810 	Validation Prec@5 95.390 	
2019-05-04 16:47:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:47:52 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:47:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:47:52 - INFO - TRAINING - Epoch: [28][0/500]	Time 0.350 (0.350)	Data 0.322 (0.322)	Loss 1.0007 (1.0007)	Prec@1 65.000 (65.000)	Prec@5 97.000 (97.000)
2019-05-04 16:47:53 - INFO - TRAINING - Epoch: [28][50/500]	Time 0.017 (0.026)	Data 0.000 (0.006)	Loss 0.8523 (0.8914)	Prec@1 71.000 (69.922)	Prec@5 99.000 (97.353)
2019-05-04 16:47:54 - INFO - TRAINING - Epoch: [28][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.8261 (0.8866)	Prec@1 73.000 (69.802)	Prec@5 96.000 (97.515)
2019-05-04 16:47:55 - INFO - TRAINING - Epoch: [28][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.8388 (0.8757)	Prec@1 69.000 (70.192)	Prec@5 99.000 (97.470)
2019-05-04 16:47:56 - INFO - TRAINING - Epoch: [28][200/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.8455 (0.8763)	Prec@1 71.000 (70.353)	Prec@5 99.000 (97.418)
2019-05-04 16:47:57 - INFO - TRAINING - Epoch: [28][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8403 (0.8720)	Prec@1 69.000 (70.637)	Prec@5 98.000 (97.378)
2019-05-04 16:47:58 - INFO - TRAINING - Epoch: [28][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.8502 (0.8677)	Prec@1 70.000 (70.688)	Prec@5 99.000 (97.475)
2019-05-04 16:47:59 - INFO - TRAINING - Epoch: [28][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7512 (0.8709)	Prec@1 71.000 (70.655)	Prec@5 99.000 (97.467)
2019-05-04 16:48:00 - INFO - TRAINING - Epoch: [28][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.8458 (0.8703)	Prec@1 72.000 (70.626)	Prec@5 99.000 (97.481)
2019-05-04 16:48:01 - INFO - TRAINING - Epoch: [28][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.8690 (0.8689)	Prec@1 72.000 (70.621)	Prec@5 98.000 (97.494)
2019-05-04 16:48:02 - INFO - EVALUATING - Epoch: [28][0/100]	Time 0.267 (0.267)	Data 0.257 (0.257)	Loss 1.1037 (1.1037)	Prec@1 55.000 (55.000)	Prec@5 98.000 (98.000)
2019-05-04 16:48:02 - INFO - EVALUATING - Epoch: [28][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 1.2197 (1.1468)	Prec@1 57.000 (58.804)	Prec@5 96.000 (95.529)
2019-05-04 16:48:03 - INFO - 
 Epoch: 29	Training Loss 0.8704 	Training Prec@1 70.586 	Training Prec@5 97.474 	Validation Loss 1.1591 	Validation Prec@1 58.190 	Validation Prec@5 95.730 	
2019-05-04 16:48:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:03 - INFO - TRAINING - Epoch: [29][0/500]	Time 0.386 (0.386)	Data 0.363 (0.363)	Loss 1.0366 (1.0366)	Prec@1 64.000 (64.000)	Prec@5 96.000 (96.000)
2019-05-04 16:48:04 - INFO - TRAINING - Epoch: [29][50/500]	Time 0.027 (0.026)	Data 0.000 (0.007)	Loss 0.9323 (0.8627)	Prec@1 66.000 (70.157)	Prec@5 96.000 (97.824)
2019-05-04 16:48:05 - INFO - TRAINING - Epoch: [29][100/500]	Time 0.022 (0.023)	Data 0.000 (0.004)	Loss 0.9290 (0.8601)	Prec@1 67.000 (70.545)	Prec@5 98.000 (97.762)
2019-05-04 16:48:06 - INFO - TRAINING - Epoch: [29][150/500]	Time 0.029 (0.022)	Data 0.000 (0.003)	Loss 1.0026 (0.8525)	Prec@1 67.000 (71.020)	Prec@5 97.000 (97.728)
2019-05-04 16:48:07 - INFO - TRAINING - Epoch: [29][200/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.8842 (0.8645)	Prec@1 73.000 (70.522)	Prec@5 96.000 (97.577)
2019-05-04 16:48:08 - INFO - TRAINING - Epoch: [29][250/500]	Time 0.021 (0.020)	Data 0.000 (0.002)	Loss 0.7931 (0.8665)	Prec@1 73.000 (70.478)	Prec@5 96.000 (97.590)
2019-05-04 16:48:09 - INFO - TRAINING - Epoch: [29][300/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.7898 (0.8636)	Prec@1 70.000 (70.691)	Prec@5 98.000 (97.585)
2019-05-04 16:48:10 - INFO - TRAINING - Epoch: [29][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8818 (0.8649)	Prec@1 72.000 (70.689)	Prec@5 97.000 (97.564)
2019-05-04 16:48:11 - INFO - TRAINING - Epoch: [29][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.9208 (0.8649)	Prec@1 71.000 (70.678)	Prec@5 98.000 (97.569)
2019-05-04 16:48:12 - INFO - TRAINING - Epoch: [29][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.9197 (0.8618)	Prec@1 66.000 (70.816)	Prec@5 98.000 (97.627)
2019-05-04 16:48:13 - INFO - EVALUATING - Epoch: [29][0/100]	Time 0.367 (0.367)	Data 0.360 (0.360)	Loss 1.4583 (1.4583)	Prec@1 52.000 (52.000)	Prec@5 93.000 (93.000)
2019-05-04 16:48:13 - INFO - EVALUATING - Epoch: [29][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.4196 (1.3484)	Prec@1 51.000 (57.039)	Prec@5 94.000 (94.216)
2019-05-04 16:48:14 - INFO - 
 Epoch: 30	Training Loss 0.8624 	Training Prec@1 70.768 	Training Prec@5 97.646 	Validation Loss 1.3594 	Validation Prec@1 56.300 	Validation Prec@5 94.220 	
2019-05-04 16:48:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:14 - INFO - TRAINING - Epoch: [30][0/500]	Time 0.375 (0.375)	Data 0.355 (0.355)	Loss 0.7477 (0.7477)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-04 16:48:15 - INFO - TRAINING - Epoch: [30][50/500]	Time 0.019 (0.026)	Data 0.000 (0.007)	Loss 0.8387 (0.8941)	Prec@1 72.000 (69.510)	Prec@5 98.000 (97.275)
2019-05-04 16:48:16 - INFO - TRAINING - Epoch: [30][100/500]	Time 0.020 (0.024)	Data 0.000 (0.004)	Loss 1.0827 (0.8774)	Prec@1 66.000 (70.218)	Prec@5 97.000 (97.535)
2019-05-04 16:48:17 - INFO - TRAINING - Epoch: [30][150/500]	Time 0.021 (0.023)	Data 0.000 (0.002)	Loss 0.7344 (0.8652)	Prec@1 73.000 (70.742)	Prec@5 98.000 (97.477)
2019-05-04 16:48:18 - INFO - TRAINING - Epoch: [30][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.0160 (0.8702)	Prec@1 63.000 (70.433)	Prec@5 99.000 (97.552)
2019-05-04 16:48:19 - INFO - TRAINING - Epoch: [30][250/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.6914 (0.8637)	Prec@1 76.000 (70.725)	Prec@5 100.000 (97.566)
2019-05-04 16:48:20 - INFO - TRAINING - Epoch: [30][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8551 (0.8666)	Prec@1 68.000 (70.681)	Prec@5 97.000 (97.585)
2019-05-04 16:48:21 - INFO - TRAINING - Epoch: [30][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8673 (0.8639)	Prec@1 66.000 (70.823)	Prec@5 97.000 (97.601)
2019-05-04 16:48:22 - INFO - TRAINING - Epoch: [30][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7418 (0.8622)	Prec@1 77.000 (70.838)	Prec@5 98.000 (97.623)
2019-05-04 16:48:23 - INFO - TRAINING - Epoch: [30][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.7606 (0.8624)	Prec@1 75.000 (70.820)	Prec@5 99.000 (97.659)
2019-05-04 16:48:24 - INFO - EVALUATING - Epoch: [30][0/100]	Time 0.367 (0.367)	Data 0.358 (0.358)	Loss 1.4499 (1.4499)	Prec@1 54.000 (54.000)	Prec@5 88.000 (88.000)
2019-05-04 16:48:25 - INFO - EVALUATING - Epoch: [30][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.3774 (1.4293)	Prec@1 53.000 (55.059)	Prec@5 90.000 (89.902)
2019-05-04 16:48:25 - INFO - 
 Epoch: 31	Training Loss 0.8635 	Training Prec@1 70.768 	Training Prec@5 97.666 	Validation Loss 1.4488 	Validation Prec@1 54.960 	Validation Prec@5 89.690 	
2019-05-04 16:48:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:25 - INFO - TRAINING - Epoch: [31][0/500]	Time 0.339 (0.339)	Data 0.319 (0.319)	Loss 1.0668 (1.0668)	Prec@1 65.000 (65.000)	Prec@5 97.000 (97.000)
2019-05-04 16:48:26 - INFO - TRAINING - Epoch: [31][50/500]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.8216 (0.8902)	Prec@1 72.000 (70.196)	Prec@5 99.000 (97.431)
2019-05-04 16:48:27 - INFO - TRAINING - Epoch: [31][100/500]	Time 0.023 (0.022)	Data 0.000 (0.003)	Loss 0.8940 (0.8801)	Prec@1 69.000 (70.436)	Prec@5 100.000 (97.525)
2019-05-04 16:48:28 - INFO - TRAINING - Epoch: [31][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.9417 (0.8664)	Prec@1 67.000 (70.887)	Prec@5 97.000 (97.530)
2019-05-04 16:48:29 - INFO - TRAINING - Epoch: [31][200/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.8332 (0.8643)	Prec@1 73.000 (70.910)	Prec@5 97.000 (97.602)
2019-05-04 16:48:30 - INFO - TRAINING - Epoch: [31][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.9010 (0.8563)	Prec@1 70.000 (71.335)	Prec@5 96.000 (97.681)
2019-05-04 16:48:31 - INFO - TRAINING - Epoch: [31][300/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7657 (0.8642)	Prec@1 74.000 (70.997)	Prec@5 97.000 (97.618)
2019-05-04 16:48:32 - INFO - TRAINING - Epoch: [31][350/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 1.1315 (0.8595)	Prec@1 63.000 (71.031)	Prec@5 93.000 (97.678)
2019-05-04 16:48:33 - INFO - TRAINING - Epoch: [31][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.9024 (0.8566)	Prec@1 67.000 (71.085)	Prec@5 97.000 (97.658)
2019-05-04 16:48:34 - INFO - TRAINING - Epoch: [31][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7609 (0.8537)	Prec@1 74.000 (71.166)	Prec@5 99.000 (97.659)
2019-05-04 16:48:35 - INFO - EVALUATING - Epoch: [31][0/100]	Time 0.378 (0.378)	Data 0.363 (0.363)	Loss 1.6763 (1.6763)	Prec@1 46.000 (46.000)	Prec@5 90.000 (90.000)
2019-05-04 16:48:36 - INFO - EVALUATING - Epoch: [31][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.6886 (1.7868)	Prec@1 46.000 (43.235)	Prec@5 92.000 (87.922)
2019-05-04 16:48:36 - INFO - 
 Epoch: 32	Training Loss 0.8527 	Training Prec@1 71.190 	Training Prec@5 97.656 	Validation Loss 1.7856 	Validation Prec@1 43.560 	Validation Prec@5 87.940 	
2019-05-04 16:48:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:36 - INFO - TRAINING - Epoch: [32][0/500]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.9644 (0.9644)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-05-04 16:48:37 - INFO - TRAINING - Epoch: [32][50/500]	Time 0.017 (0.027)	Data 0.000 (0.007)	Loss 0.9057 (0.8623)	Prec@1 69.000 (71.196)	Prec@5 96.000 (97.824)
2019-05-04 16:48:38 - INFO - TRAINING - Epoch: [32][100/500]	Time 0.015 (0.023)	Data 0.000 (0.004)	Loss 0.8495 (0.8753)	Prec@1 73.000 (70.663)	Prec@5 98.000 (97.574)
2019-05-04 16:48:39 - INFO - TRAINING - Epoch: [32][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.7910 (0.8678)	Prec@1 74.000 (70.901)	Prec@5 98.000 (97.589)
2019-05-04 16:48:40 - INFO - TRAINING - Epoch: [32][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9588 (0.8678)	Prec@1 70.000 (70.866)	Prec@5 95.000 (97.547)
2019-05-04 16:48:41 - INFO - TRAINING - Epoch: [32][250/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.9800 (0.8722)	Prec@1 70.000 (70.725)	Prec@5 98.000 (97.502)
2019-05-04 16:48:42 - INFO - TRAINING - Epoch: [32][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.9486 (0.8695)	Prec@1 64.000 (70.844)	Prec@5 97.000 (97.492)
2019-05-04 16:48:43 - INFO - TRAINING - Epoch: [32][350/500]	Time 0.031 (0.020)	Data 0.000 (0.001)	Loss 0.8785 (0.8666)	Prec@1 70.000 (70.977)	Prec@5 97.000 (97.496)
2019-05-04 16:48:44 - INFO - TRAINING - Epoch: [32][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8940 (0.8636)	Prec@1 70.000 (71.047)	Prec@5 97.000 (97.524)
2019-05-04 16:48:45 - INFO - TRAINING - Epoch: [32][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.8067 (0.8562)	Prec@1 71.000 (71.279)	Prec@5 98.000 (97.554)
2019-05-04 16:48:46 - INFO - EVALUATING - Epoch: [32][0/100]	Time 0.274 (0.274)	Data 0.264 (0.264)	Loss 1.1271 (1.1271)	Prec@1 64.000 (64.000)	Prec@5 94.000 (94.000)
2019-05-04 16:48:46 - INFO - EVALUATING - Epoch: [32][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 1.0691 (1.1539)	Prec@1 68.000 (62.451)	Prec@5 93.000 (94.725)
2019-05-04 16:48:47 - INFO - 
 Epoch: 33	Training Loss 0.8534 	Training Prec@1 71.302 	Training Prec@5 97.596 	Validation Loss 1.1501 	Validation Prec@1 62.440 	Validation Prec@5 94.330 	
2019-05-04 16:48:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:47 - INFO - TRAINING - Epoch: [33][0/500]	Time 0.368 (0.368)	Data 0.339 (0.339)	Loss 0.7654 (0.7654)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-04 16:48:48 - INFO - TRAINING - Epoch: [33][50/500]	Time 0.016 (0.028)	Data 0.000 (0.007)	Loss 0.8456 (0.8342)	Prec@1 72.000 (71.980)	Prec@5 98.000 (97.608)
2019-05-04 16:48:49 - INFO - TRAINING - Epoch: [33][100/500]	Time 0.020 (0.024)	Data 0.000 (0.004)	Loss 0.9858 (0.8628)	Prec@1 63.000 (70.941)	Prec@5 96.000 (97.436)
2019-05-04 16:48:50 - INFO - TRAINING - Epoch: [33][150/500]	Time 0.026 (0.023)	Data 0.000 (0.002)	Loss 0.9428 (0.8527)	Prec@1 65.000 (71.199)	Prec@5 98.000 (97.662)
2019-05-04 16:48:51 - INFO - TRAINING - Epoch: [33][200/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 1.0307 (0.8547)	Prec@1 64.000 (71.100)	Prec@5 96.000 (97.697)
2019-05-04 16:48:52 - INFO - TRAINING - Epoch: [33][250/500]	Time 0.014 (0.022)	Data 0.000 (0.001)	Loss 0.8953 (0.8447)	Prec@1 73.000 (71.283)	Prec@5 99.000 (97.789)
2019-05-04 16:48:53 - INFO - TRAINING - Epoch: [33][300/500]	Time 0.028 (0.022)	Data 0.000 (0.001)	Loss 1.0132 (0.8522)	Prec@1 65.000 (71.043)	Prec@5 97.000 (97.738)
2019-05-04 16:48:54 - INFO - TRAINING - Epoch: [33][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9561 (0.8549)	Prec@1 65.000 (70.900)	Prec@5 99.000 (97.746)
2019-05-04 16:48:55 - INFO - TRAINING - Epoch: [33][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8524 (0.8542)	Prec@1 72.000 (70.935)	Prec@5 96.000 (97.736)
2019-05-04 16:48:56 - INFO - TRAINING - Epoch: [33][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8200 (0.8538)	Prec@1 74.000 (70.973)	Prec@5 97.000 (97.707)
2019-05-04 16:48:58 - INFO - EVALUATING - Epoch: [33][0/100]	Time 0.351 (0.351)	Data 0.342 (0.342)	Loss 1.1853 (1.1853)	Prec@1 66.000 (66.000)	Prec@5 93.000 (93.000)
2019-05-04 16:48:58 - INFO - EVALUATING - Epoch: [33][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.2379 (1.2466)	Prec@1 63.000 (59.902)	Prec@5 94.000 (93.863)
2019-05-04 16:48:58 - INFO - 
 Epoch: 34	Training Loss 0.8523 	Training Prec@1 71.060 	Training Prec@5 97.740 	Validation Loss 1.2560 	Validation Prec@1 59.980 	Validation Prec@5 93.330 	
2019-05-04 16:48:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:48:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:48:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:48:58 - INFO - TRAINING - Epoch: [34][0/500]	Time 0.334 (0.334)	Data 0.315 (0.315)	Loss 0.8108 (0.8108)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-04 16:48:59 - INFO - TRAINING - Epoch: [34][50/500]	Time 0.015 (0.026)	Data 0.000 (0.007)	Loss 1.0521 (0.8544)	Prec@1 64.000 (71.353)	Prec@5 97.000 (97.667)
2019-05-04 16:49:00 - INFO - TRAINING - Epoch: [34][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.8106 (0.8523)	Prec@1 69.000 (71.257)	Prec@5 98.000 (97.822)
2019-05-04 16:49:02 - INFO - TRAINING - Epoch: [34][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.7246 (0.8471)	Prec@1 72.000 (71.391)	Prec@5 97.000 (97.828)
2019-05-04 16:49:03 - INFO - TRAINING - Epoch: [34][200/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.6961 (0.8481)	Prec@1 77.000 (71.343)	Prec@5 100.000 (97.761)
2019-05-04 16:49:03 - INFO - TRAINING - Epoch: [34][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8755 (0.8519)	Prec@1 71.000 (71.295)	Prec@5 99.000 (97.717)
2019-05-04 16:49:04 - INFO - TRAINING - Epoch: [34][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 1.0281 (0.8531)	Prec@1 65.000 (71.249)	Prec@5 96.000 (97.638)
2019-05-04 16:49:06 - INFO - TRAINING - Epoch: [34][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.9054 (0.8555)	Prec@1 69.000 (71.177)	Prec@5 98.000 (97.613)
2019-05-04 16:49:07 - INFO - TRAINING - Epoch: [34][400/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.8859 (0.8576)	Prec@1 68.000 (71.052)	Prec@5 97.000 (97.618)
2019-05-04 16:49:08 - INFO - TRAINING - Epoch: [34][450/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9035 (0.8579)	Prec@1 70.000 (71.018)	Prec@5 98.000 (97.608)
2019-05-04 16:49:09 - INFO - EVALUATING - Epoch: [34][0/100]	Time 0.352 (0.352)	Data 0.341 (0.341)	Loss 1.2750 (1.2750)	Prec@1 56.000 (56.000)	Prec@5 95.000 (95.000)
2019-05-04 16:49:09 - INFO - EVALUATING - Epoch: [34][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.2263 (1.1649)	Prec@1 54.000 (60.882)	Prec@5 93.000 (94.784)
2019-05-04 16:49:09 - INFO - 
 Epoch: 35	Training Loss 0.8551 	Training Prec@1 71.170 	Training Prec@5 97.624 	Validation Loss 1.1717 	Validation Prec@1 60.690 	Validation Prec@5 94.770 	
2019-05-04 16:49:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:49:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:49:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:49:10 - INFO - TRAINING - Epoch: [35][0/500]	Time 0.389 (0.389)	Data 0.362 (0.362)	Loss 0.7779 (0.7779)	Prec@1 70.000 (70.000)	Prec@5 100.000 (100.000)
2019-05-04 16:49:11 - INFO - TRAINING - Epoch: [35][50/500]	Time 0.013 (0.026)	Data 0.000 (0.007)	Loss 1.1934 (0.8794)	Prec@1 61.000 (70.020)	Prec@5 96.000 (97.373)
2019-05-04 16:49:12 - INFO - TRAINING - Epoch: [35][100/500]	Time 0.015 (0.023)	Data 0.000 (0.004)	Loss 0.8871 (0.8607)	Prec@1 69.000 (70.822)	Prec@5 100.000 (97.584)
2019-05-04 16:49:13 - INFO - TRAINING - Epoch: [35][150/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 0.8801 (0.8584)	Prec@1 68.000 (70.868)	Prec@5 99.000 (97.636)
2019-05-04 16:49:14 - INFO - TRAINING - Epoch: [35][200/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.8112 (0.8606)	Prec@1 74.000 (70.831)	Prec@5 99.000 (97.527)
2019-05-04 16:49:15 - INFO - TRAINING - Epoch: [35][250/500]	Time 0.027 (0.021)	Data 0.000 (0.002)	Loss 1.0046 (0.8618)	Prec@1 64.000 (70.841)	Prec@5 95.000 (97.574)
2019-05-04 16:49:16 - INFO - TRAINING - Epoch: [35][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8065 (0.8585)	Prec@1 74.000 (70.953)	Prec@5 98.000 (97.605)
2019-05-04 16:49:17 - INFO - TRAINING - Epoch: [35][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7255 (0.8536)	Prec@1 77.000 (71.134)	Prec@5 98.000 (97.635)
2019-05-04 16:49:18 - INFO - TRAINING - Epoch: [35][400/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.6758 (0.8514)	Prec@1 77.000 (71.177)	Prec@5 98.000 (97.668)
2019-05-04 16:49:19 - INFO - TRAINING - Epoch: [35][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9821 (0.8560)	Prec@1 64.000 (71.027)	Prec@5 96.000 (97.616)
2019-05-04 16:49:20 - INFO - EVALUATING - Epoch: [35][0/100]	Time 0.364 (0.364)	Data 0.348 (0.348)	Loss 1.1490 (1.1490)	Prec@1 59.000 (59.000)	Prec@5 95.000 (95.000)
2019-05-04 16:49:20 - INFO - EVALUATING - Epoch: [35][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.9211 (1.1636)	Prec@1 67.000 (60.725)	Prec@5 96.000 (94.784)
2019-05-04 16:49:21 - INFO - 
 Epoch: 36	Training Loss 0.8566 	Training Prec@1 71.036 	Training Prec@5 97.642 	Validation Loss 1.1753 	Validation Prec@1 60.580 	Validation Prec@5 94.580 	
2019-05-04 16:49:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:49:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:49:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:49:21 - INFO - TRAINING - Epoch: [36][0/500]	Time 0.370 (0.370)	Data 0.347 (0.347)	Loss 1.0355 (1.0355)	Prec@1 66.000 (66.000)	Prec@5 95.000 (95.000)
2019-05-04 16:49:22 - INFO - TRAINING - Epoch: [36][50/500]	Time 0.018 (0.026)	Data 0.000 (0.007)	Loss 0.7188 (0.8632)	Prec@1 78.000 (70.941)	Prec@5 100.000 (97.471)
2019-05-04 16:49:23 - INFO - TRAINING - Epoch: [36][100/500]	Time 0.016 (0.023)	Data 0.000 (0.004)	Loss 0.8373 (0.8477)	Prec@1 69.000 (71.297)	Prec@5 99.000 (97.723)
2019-05-04 16:49:24 - INFO - TRAINING - Epoch: [36][150/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.7501 (0.8534)	Prec@1 79.000 (71.013)	Prec@5 98.000 (97.695)
2019-05-04 16:49:25 - INFO - TRAINING - Epoch: [36][200/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.7598 (0.8459)	Prec@1 75.000 (71.254)	Prec@5 96.000 (97.831)
2019-05-04 16:49:26 - INFO - TRAINING - Epoch: [36][250/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.6957 (0.8421)	Prec@1 71.000 (71.410)	Prec@5 99.000 (97.833)
2019-05-04 16:49:27 - INFO - TRAINING - Epoch: [36][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.0377 (0.8410)	Prec@1 67.000 (71.435)	Prec@5 97.000 (97.841)
2019-05-04 16:49:28 - INFO - TRAINING - Epoch: [36][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6572 (0.8413)	Prec@1 78.000 (71.407)	Prec@5 99.000 (97.803)
2019-05-04 16:49:29 - INFO - TRAINING - Epoch: [36][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8614 (0.8451)	Prec@1 72.000 (71.267)	Prec@5 96.000 (97.741)
2019-05-04 16:49:30 - INFO - TRAINING - Epoch: [36][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8711 (0.8450)	Prec@1 67.000 (71.297)	Prec@5 98.000 (97.745)
2019-05-04 16:49:31 - INFO - EVALUATING - Epoch: [36][0/100]	Time 0.346 (0.346)	Data 0.331 (0.331)	Loss 1.2039 (1.2039)	Prec@1 59.000 (59.000)	Prec@5 94.000 (94.000)
2019-05-04 16:49:32 - INFO - EVALUATING - Epoch: [36][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.3636 (1.3808)	Prec@1 52.000 (53.059)	Prec@5 91.000 (93.255)
2019-05-04 16:49:32 - INFO - 
 Epoch: 37	Training Loss 0.8456 	Training Prec@1 71.320 	Training Prec@5 97.714 	Validation Loss 1.4032 	Validation Prec@1 52.530 	Validation Prec@5 93.040 	
2019-05-04 16:49:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:49:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:49:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:49:32 - INFO - TRAINING - Epoch: [37][0/500]	Time 0.349 (0.349)	Data 0.330 (0.330)	Loss 0.9903 (0.9903)	Prec@1 71.000 (71.000)	Prec@5 94.000 (94.000)
2019-05-04 16:49:33 - INFO - TRAINING - Epoch: [37][50/500]	Time 0.020 (0.027)	Data 0.000 (0.007)	Loss 0.8140 (0.8456)	Prec@1 73.000 (71.725)	Prec@5 99.000 (97.588)
2019-05-04 16:49:34 - INFO - TRAINING - Epoch: [37][100/500]	Time 0.013 (0.023)	Data 0.000 (0.004)	Loss 0.9597 (0.8485)	Prec@1 67.000 (71.396)	Prec@5 98.000 (97.634)
2019-05-04 16:49:35 - INFO - TRAINING - Epoch: [37][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6956 (0.8419)	Prec@1 74.000 (71.715)	Prec@5 99.000 (97.662)
2019-05-04 16:49:36 - INFO - TRAINING - Epoch: [37][200/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.8071 (0.8465)	Prec@1 75.000 (71.701)	Prec@5 99.000 (97.537)
2019-05-04 16:49:37 - INFO - TRAINING - Epoch: [37][250/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.9165 (0.8357)	Prec@1 74.000 (71.920)	Prec@5 99.000 (97.610)
2019-05-04 16:49:38 - INFO - TRAINING - Epoch: [37][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6620 (0.8366)	Prec@1 78.000 (71.970)	Prec@5 100.000 (97.591)
2019-05-04 16:49:39 - INFO - TRAINING - Epoch: [37][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8945 (0.8369)	Prec@1 72.000 (71.940)	Prec@5 97.000 (97.641)
2019-05-04 16:49:40 - INFO - TRAINING - Epoch: [37][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6294 (0.8361)	Prec@1 79.000 (71.905)	Prec@5 99.000 (97.663)
2019-05-04 16:49:41 - INFO - TRAINING - Epoch: [37][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6669 (0.8396)	Prec@1 80.000 (71.767)	Prec@5 99.000 (97.670)
2019-05-04 16:49:43 - INFO - EVALUATING - Epoch: [37][0/100]	Time 0.375 (0.375)	Data 0.362 (0.362)	Loss 1.0715 (1.0715)	Prec@1 64.000 (64.000)	Prec@5 95.000 (95.000)
2019-05-04 16:49:43 - INFO - EVALUATING - Epoch: [37][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.2664 (1.1450)	Prec@1 59.000 (62.294)	Prec@5 92.000 (94.980)
2019-05-04 16:49:43 - INFO - 
 Epoch: 38	Training Loss 0.8412 	Training Prec@1 71.694 	Training Prec@5 97.650 	Validation Loss 1.1661 	Validation Prec@1 61.130 	Validation Prec@5 95.050 	
2019-05-04 16:49:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:49:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:49:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:49:43 - INFO - TRAINING - Epoch: [38][0/500]	Time 0.366 (0.366)	Data 0.345 (0.345)	Loss 0.7912 (0.7912)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-04 16:49:44 - INFO - TRAINING - Epoch: [38][50/500]	Time 0.018 (0.026)	Data 0.000 (0.007)	Loss 0.6714 (0.8649)	Prec@1 74.000 (70.510)	Prec@5 100.000 (97.686)
2019-05-04 16:49:45 - INFO - TRAINING - Epoch: [38][100/500]	Time 0.013 (0.023)	Data 0.000 (0.004)	Loss 0.6174 (0.8574)	Prec@1 81.000 (70.802)	Prec@5 98.000 (97.594)
2019-05-04 16:49:46 - INFO - TRAINING - Epoch: [38][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7661 (0.8507)	Prec@1 72.000 (71.185)	Prec@5 99.000 (97.583)
2019-05-04 16:49:47 - INFO - TRAINING - Epoch: [38][200/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.7765 (0.8480)	Prec@1 75.000 (71.294)	Prec@5 95.000 (97.687)
2019-05-04 16:49:48 - INFO - TRAINING - Epoch: [38][250/500]	Time 0.012 (0.021)	Data 0.000 (0.002)	Loss 0.8961 (0.8528)	Prec@1 69.000 (71.247)	Prec@5 98.000 (97.618)
2019-05-04 16:49:49 - INFO - TRAINING - Epoch: [38][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8295 (0.8513)	Prec@1 71.000 (71.326)	Prec@5 96.000 (97.591)
2019-05-04 16:49:50 - INFO - TRAINING - Epoch: [38][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 1.0761 (0.8482)	Prec@1 65.000 (71.424)	Prec@5 96.000 (97.630)
2019-05-04 16:49:51 - INFO - TRAINING - Epoch: [38][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.9235 (0.8496)	Prec@1 69.000 (71.374)	Prec@5 97.000 (97.611)
2019-05-04 16:49:52 - INFO - TRAINING - Epoch: [38][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7855 (0.8490)	Prec@1 70.000 (71.384)	Prec@5 99.000 (97.619)
2019-05-04 16:49:54 - INFO - EVALUATING - Epoch: [38][0/100]	Time 0.247 (0.247)	Data 0.241 (0.241)	Loss 1.0950 (1.0950)	Prec@1 61.000 (61.000)	Prec@5 98.000 (98.000)
2019-05-04 16:49:54 - INFO - EVALUATING - Epoch: [38][50/100]	Time 0.006 (0.011)	Data 0.000 (0.006)	Loss 1.0425 (1.1984)	Prec@1 65.000 (59.059)	Prec@5 97.000 (95.020)
2019-05-04 16:49:54 - INFO - 
 Epoch: 39	Training Loss 0.8475 	Training Prec@1 71.440 	Training Prec@5 97.634 	Validation Loss 1.2016 	Validation Prec@1 59.180 	Validation Prec@5 95.130 	
2019-05-04 16:49:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:49:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:49:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:49:55 - INFO - TRAINING - Epoch: [39][0/500]	Time 0.368 (0.368)	Data 0.346 (0.346)	Loss 0.7145 (0.7145)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-04 16:49:56 - INFO - TRAINING - Epoch: [39][50/500]	Time 0.028 (0.026)	Data 0.000 (0.007)	Loss 1.0293 (0.8818)	Prec@1 62.000 (70.549)	Prec@5 98.000 (97.529)
2019-05-04 16:49:57 - INFO - TRAINING - Epoch: [39][100/500]	Time 0.016 (0.023)	Data 0.000 (0.004)	Loss 0.6603 (0.8580)	Prec@1 79.000 (71.198)	Prec@5 99.000 (97.604)
2019-05-04 16:49:58 - INFO - TRAINING - Epoch: [39][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.9722 (0.8530)	Prec@1 70.000 (71.344)	Prec@5 97.000 (97.642)
2019-05-04 16:49:59 - INFO - TRAINING - Epoch: [39][200/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.7893 (0.8530)	Prec@1 73.000 (71.134)	Prec@5 97.000 (97.647)
2019-05-04 16:50:00 - INFO - TRAINING - Epoch: [39][250/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.7918 (0.8416)	Prec@1 74.000 (71.582)	Prec@5 96.000 (97.705)
2019-05-04 16:50:01 - INFO - TRAINING - Epoch: [39][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7928 (0.8427)	Prec@1 74.000 (71.598)	Prec@5 97.000 (97.674)
2019-05-04 16:50:02 - INFO - TRAINING - Epoch: [39][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8911 (0.8414)	Prec@1 73.000 (71.709)	Prec@5 97.000 (97.615)
2019-05-04 16:50:03 - INFO - TRAINING - Epoch: [39][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6532 (0.8376)	Prec@1 79.000 (71.943)	Prec@5 98.000 (97.613)
2019-05-04 16:50:04 - INFO - TRAINING - Epoch: [39][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8004 (0.8366)	Prec@1 73.000 (71.907)	Prec@5 97.000 (97.630)
2019-05-04 16:50:05 - INFO - EVALUATING - Epoch: [39][0/100]	Time 0.379 (0.379)	Data 0.367 (0.367)	Loss 0.8068 (0.8068)	Prec@1 70.000 (70.000)	Prec@5 97.000 (97.000)
2019-05-04 16:50:05 - INFO - EVALUATING - Epoch: [39][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.8918 (0.8845)	Prec@1 70.000 (69.608)	Prec@5 95.000 (97.333)
2019-05-04 16:50:06 - INFO - 
 Epoch: 40	Training Loss 0.8368 	Training Prec@1 71.910 	Training Prec@5 97.620 	Validation Loss 0.8779 	Validation Prec@1 69.170 	Validation Prec@5 97.630 	
2019-05-04 16:50:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:50:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:50:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:50:06 - INFO - TRAINING - Epoch: [40][0/500]	Time 0.257 (0.257)	Data 0.234 (0.234)	Loss 0.7975 (0.7975)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-04 16:50:07 - INFO - TRAINING - Epoch: [40][50/500]	Time 0.016 (0.023)	Data 0.000 (0.005)	Loss 0.8891 (0.8458)	Prec@1 69.000 (71.039)	Prec@5 97.000 (97.745)
2019-05-04 16:50:08 - INFO - TRAINING - Epoch: [40][100/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9330 (0.8292)	Prec@1 70.000 (72.238)	Prec@5 99.000 (97.901)
2019-05-04 16:50:09 - INFO - TRAINING - Epoch: [40][150/500]	Time 0.011 (0.021)	Data 0.000 (0.002)	Loss 0.8512 (0.8310)	Prec@1 70.000 (72.007)	Prec@5 98.000 (97.861)
2019-05-04 16:50:10 - INFO - TRAINING - Epoch: [40][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6951 (0.8315)	Prec@1 73.000 (71.806)	Prec@5 100.000 (97.891)
2019-05-04 16:50:11 - INFO - TRAINING - Epoch: [40][250/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.7966 (0.8285)	Prec@1 74.000 (71.857)	Prec@5 98.000 (97.873)
2019-05-04 16:50:12 - INFO - TRAINING - Epoch: [40][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8989 (0.8386)	Prec@1 69.000 (71.651)	Prec@5 97.000 (97.837)
2019-05-04 16:50:13 - INFO - TRAINING - Epoch: [40][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6631 (0.8379)	Prec@1 77.000 (71.672)	Prec@5 98.000 (97.826)
2019-05-04 16:50:14 - INFO - TRAINING - Epoch: [40][400/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7146 (0.8360)	Prec@1 73.000 (71.688)	Prec@5 99.000 (97.805)
2019-05-04 16:50:15 - INFO - TRAINING - Epoch: [40][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8907 (0.8394)	Prec@1 65.000 (71.623)	Prec@5 99.000 (97.792)
2019-05-04 16:50:16 - INFO - EVALUATING - Epoch: [40][0/100]	Time 0.354 (0.354)	Data 0.349 (0.349)	Loss 1.0973 (1.0973)	Prec@1 65.000 (65.000)	Prec@5 91.000 (91.000)
2019-05-04 16:50:16 - INFO - EVALUATING - Epoch: [40][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.1071 (1.0877)	Prec@1 63.000 (64.000)	Prec@5 92.000 (95.020)
2019-05-04 16:50:17 - INFO - 
 Epoch: 41	Training Loss 0.8396 	Training Prec@1 71.616 	Training Prec@5 97.792 	Validation Loss 1.0901 	Validation Prec@1 63.700 	Validation Prec@5 94.930 	
2019-05-04 16:50:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:50:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:50:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:50:17 - INFO - TRAINING - Epoch: [41][0/500]	Time 0.267 (0.267)	Data 0.247 (0.247)	Loss 0.6491 (0.6491)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-04 16:50:18 - INFO - TRAINING - Epoch: [41][50/500]	Time 0.027 (0.026)	Data 0.000 (0.005)	Loss 0.8479 (0.8495)	Prec@1 73.000 (71.098)	Prec@5 95.000 (97.529)
2019-05-04 16:50:19 - INFO - TRAINING - Epoch: [41][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.8704 (0.8493)	Prec@1 66.000 (70.941)	Prec@5 99.000 (97.545)
2019-05-04 16:50:20 - INFO - TRAINING - Epoch: [41][150/500]	Time 0.024 (0.023)	Data 0.000 (0.002)	Loss 0.8122 (0.8488)	Prec@1 70.000 (71.252)	Prec@5 98.000 (97.596)
2019-05-04 16:50:21 - INFO - TRAINING - Epoch: [41][200/500]	Time 0.017 (0.022)	Data 0.000 (0.001)	Loss 0.9634 (0.8508)	Prec@1 69.000 (71.274)	Prec@5 97.000 (97.572)
2019-05-04 16:50:22 - INFO - TRAINING - Epoch: [41][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.8231 (0.8445)	Prec@1 75.000 (71.458)	Prec@5 98.000 (97.606)
2019-05-04 16:50:23 - INFO - TRAINING - Epoch: [41][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7182 (0.8390)	Prec@1 75.000 (71.601)	Prec@5 100.000 (97.691)
2019-05-04 16:50:24 - INFO - TRAINING - Epoch: [41][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7648 (0.8397)	Prec@1 75.000 (71.655)	Prec@5 98.000 (97.638)
2019-05-04 16:50:25 - INFO - TRAINING - Epoch: [41][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5483 (0.8375)	Prec@1 81.000 (71.763)	Prec@5 100.000 (97.656)
2019-05-04 16:50:26 - INFO - TRAINING - Epoch: [41][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8457 (0.8352)	Prec@1 74.000 (71.869)	Prec@5 98.000 (97.690)
2019-05-04 16:50:27 - INFO - EVALUATING - Epoch: [41][0/100]	Time 0.280 (0.280)	Data 0.270 (0.270)	Loss 0.9191 (0.9191)	Prec@1 68.000 (68.000)	Prec@5 96.000 (96.000)
2019-05-04 16:50:28 - INFO - EVALUATING - Epoch: [41][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.8218 (0.9113)	Prec@1 77.000 (69.549)	Prec@5 97.000 (97.137)
2019-05-04 16:50:28 - INFO - 
 Epoch: 42	Training Loss 0.8366 	Training Prec@1 71.866 	Training Prec@5 97.656 	Validation Loss 0.9177 	Validation Prec@1 69.240 	Validation Prec@5 97.020 	
2019-05-04 16:50:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:50:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:50:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:50:28 - INFO - TRAINING - Epoch: [42][0/500]	Time 0.363 (0.363)	Data 0.344 (0.344)	Loss 0.8294 (0.8294)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-05-04 16:50:29 - INFO - TRAINING - Epoch: [42][50/500]	Time 0.022 (0.027)	Data 0.000 (0.007)	Loss 1.0412 (0.8571)	Prec@1 65.000 (70.804)	Prec@5 97.000 (97.843)
2019-05-04 16:50:30 - INFO - TRAINING - Epoch: [42][100/500]	Time 0.012 (0.023)	Data 0.000 (0.004)	Loss 0.8835 (0.8516)	Prec@1 69.000 (71.168)	Prec@5 95.000 (97.584)
2019-05-04 16:50:31 - INFO - TRAINING - Epoch: [42][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.8602 (0.8397)	Prec@1 69.000 (71.709)	Prec@5 96.000 (97.629)
2019-05-04 16:50:32 - INFO - TRAINING - Epoch: [42][200/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.9392 (0.8375)	Prec@1 66.000 (71.642)	Prec@5 96.000 (97.652)
2019-05-04 16:50:33 - INFO - TRAINING - Epoch: [42][250/500]	Time 0.026 (0.021)	Data 0.000 (0.002)	Loss 0.5487 (0.8337)	Prec@1 83.000 (71.741)	Prec@5 100.000 (97.729)
2019-05-04 16:50:34 - INFO - TRAINING - Epoch: [42][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8614 (0.8364)	Prec@1 72.000 (71.731)	Prec@5 99.000 (97.734)
2019-05-04 16:50:35 - INFO - TRAINING - Epoch: [42][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8584 (0.8343)	Prec@1 72.000 (71.815)	Prec@5 100.000 (97.746)
2019-05-04 16:50:36 - INFO - TRAINING - Epoch: [42][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8809 (0.8361)	Prec@1 74.000 (71.728)	Prec@5 97.000 (97.741)
2019-05-04 16:50:37 - INFO - TRAINING - Epoch: [42][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.0666 (0.8388)	Prec@1 58.000 (71.647)	Prec@5 96.000 (97.712)
2019-05-04 16:50:38 - INFO - EVALUATING - Epoch: [42][0/100]	Time 0.336 (0.336)	Data 0.327 (0.327)	Loss 1.1870 (1.1870)	Prec@1 61.000 (61.000)	Prec@5 96.000 (96.000)
2019-05-04 16:50:39 - INFO - EVALUATING - Epoch: [42][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.1216 (1.1047)	Prec@1 64.000 (61.882)	Prec@5 93.000 (96.118)
2019-05-04 16:50:39 - INFO - 
 Epoch: 43	Training Loss 0.8375 	Training Prec@1 71.714 	Training Prec@5 97.732 	Validation Loss 1.1067 	Validation Prec@1 61.700 	Validation Prec@5 95.920 	
2019-05-04 16:50:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:50:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:50:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:50:39 - INFO - TRAINING - Epoch: [43][0/500]	Time 0.362 (0.362)	Data 0.339 (0.339)	Loss 1.0033 (1.0033)	Prec@1 68.000 (68.000)	Prec@5 95.000 (95.000)
2019-05-04 16:50:40 - INFO - TRAINING - Epoch: [43][50/500]	Time 0.026 (0.028)	Data 0.000 (0.007)	Loss 0.6942 (0.8585)	Prec@1 74.000 (71.431)	Prec@5 99.000 (97.373)
2019-05-04 16:50:42 - INFO - TRAINING - Epoch: [43][100/500]	Time 0.021 (0.025)	Data 0.000 (0.004)	Loss 0.7581 (0.8444)	Prec@1 75.000 (71.564)	Prec@5 98.000 (97.495)
2019-05-04 16:50:43 - INFO - TRAINING - Epoch: [43][150/500]	Time 0.032 (0.023)	Data 0.000 (0.002)	Loss 0.9871 (0.8426)	Prec@1 62.000 (71.444)	Prec@5 99.000 (97.530)
2019-05-04 16:50:43 - INFO - TRAINING - Epoch: [43][200/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.7349 (0.8386)	Prec@1 74.000 (71.542)	Prec@5 99.000 (97.677)
2019-05-04 16:50:44 - INFO - TRAINING - Epoch: [43][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 1.0245 (0.8358)	Prec@1 69.000 (71.777)	Prec@5 94.000 (97.769)
2019-05-04 16:50:46 - INFO - TRAINING - Epoch: [43][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8481 (0.8373)	Prec@1 68.000 (71.728)	Prec@5 99.000 (97.771)
2019-05-04 16:50:47 - INFO - TRAINING - Epoch: [43][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6353 (0.8339)	Prec@1 76.000 (71.803)	Prec@5 100.000 (97.815)
2019-05-04 16:50:47 - INFO - TRAINING - Epoch: [43][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 1.0520 (0.8333)	Prec@1 68.000 (71.818)	Prec@5 95.000 (97.778)
2019-05-04 16:50:48 - INFO - TRAINING - Epoch: [43][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.9275 (0.8311)	Prec@1 70.000 (71.922)	Prec@5 98.000 (97.798)
2019-05-04 16:50:50 - INFO - EVALUATING - Epoch: [43][0/100]	Time 0.287 (0.287)	Data 0.277 (0.277)	Loss 1.2455 (1.2455)	Prec@1 61.000 (61.000)	Prec@5 96.000 (96.000)
2019-05-04 16:50:50 - INFO - EVALUATING - Epoch: [43][50/100]	Time 0.004 (0.011)	Data 0.000 (0.006)	Loss 1.4123 (1.2313)	Prec@1 53.000 (59.980)	Prec@5 93.000 (95.608)
2019-05-04 16:50:50 - INFO - 
 Epoch: 44	Training Loss 0.8308 	Training Prec@1 71.908 	Training Prec@5 97.804 	Validation Loss 1.2358 	Validation Prec@1 59.210 	Validation Prec@5 95.490 	
2019-05-04 16:50:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:50:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:50:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:50:51 - INFO - TRAINING - Epoch: [44][0/500]	Time 0.343 (0.343)	Data 0.321 (0.321)	Loss 0.7815 (0.7815)	Prec@1 77.000 (77.000)	Prec@5 97.000 (97.000)
2019-05-04 16:50:52 - INFO - TRAINING - Epoch: [44][50/500]	Time 0.013 (0.029)	Data 0.000 (0.006)	Loss 1.0899 (0.8479)	Prec@1 67.000 (71.667)	Prec@5 98.000 (97.451)
2019-05-04 16:50:53 - INFO - TRAINING - Epoch: [44][100/500]	Time 0.028 (0.025)	Data 0.000 (0.003)	Loss 0.6684 (0.8483)	Prec@1 79.000 (71.525)	Prec@5 98.000 (97.446)
2019-05-04 16:50:54 - INFO - TRAINING - Epoch: [44][150/500]	Time 0.016 (0.023)	Data 0.000 (0.002)	Loss 0.8225 (0.8395)	Prec@1 74.000 (71.795)	Prec@5 97.000 (97.576)
2019-05-04 16:50:55 - INFO - TRAINING - Epoch: [44][200/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6878 (0.8362)	Prec@1 77.000 (71.935)	Prec@5 99.000 (97.612)
2019-05-04 16:50:56 - INFO - TRAINING - Epoch: [44][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.7519 (0.8328)	Prec@1 72.000 (72.112)	Prec@5 99.000 (97.606)
2019-05-04 16:50:57 - INFO - TRAINING - Epoch: [44][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8781 (0.8323)	Prec@1 67.000 (72.130)	Prec@5 97.000 (97.601)
2019-05-04 16:50:58 - INFO - TRAINING - Epoch: [44][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7555 (0.8324)	Prec@1 71.000 (72.074)	Prec@5 100.000 (97.658)
2019-05-04 16:50:59 - INFO - TRAINING - Epoch: [44][400/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.9382 (0.8290)	Prec@1 70.000 (72.187)	Prec@5 96.000 (97.723)
2019-05-04 16:51:00 - INFO - TRAINING - Epoch: [44][450/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.8647 (0.8303)	Prec@1 72.000 (72.177)	Prec@5 97.000 (97.707)
2019-05-04 16:51:01 - INFO - EVALUATING - Epoch: [44][0/100]	Time 0.374 (0.374)	Data 0.365 (0.365)	Loss 1.5084 (1.5084)	Prec@1 49.000 (49.000)	Prec@5 91.000 (91.000)
2019-05-04 16:51:01 - INFO - EVALUATING - Epoch: [44][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 1.3356 (1.3638)	Prec@1 53.000 (53.392)	Prec@5 95.000 (93.882)
2019-05-04 16:51:02 - INFO - 
 Epoch: 45	Training Loss 0.8297 	Training Prec@1 72.184 	Training Prec@5 97.726 	Validation Loss 1.3679 	Validation Prec@1 53.020 	Validation Prec@5 94.020 	
2019-05-04 16:51:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:02 - INFO - TRAINING - Epoch: [45][0/500]	Time 0.375 (0.375)	Data 0.350 (0.350)	Loss 0.7440 (0.7440)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-04 16:51:03 - INFO - TRAINING - Epoch: [45][50/500]	Time 0.023 (0.027)	Data 0.000 (0.007)	Loss 0.8012 (0.8626)	Prec@1 73.000 (70.804)	Prec@5 97.000 (97.647)
2019-05-04 16:51:04 - INFO - TRAINING - Epoch: [45][100/500]	Time 0.026 (0.024)	Data 0.000 (0.004)	Loss 0.7140 (0.8572)	Prec@1 77.000 (71.089)	Prec@5 97.000 (97.495)
2019-05-04 16:51:05 - INFO - TRAINING - Epoch: [45][150/500]	Time 0.016 (0.023)	Data 0.000 (0.002)	Loss 0.7146 (0.8435)	Prec@1 74.000 (71.444)	Prec@5 99.000 (97.583)
2019-05-04 16:51:06 - INFO - TRAINING - Epoch: [45][200/500]	Time 0.030 (0.022)	Data 0.000 (0.002)	Loss 0.9352 (0.8409)	Prec@1 72.000 (71.642)	Prec@5 97.000 (97.587)
2019-05-04 16:51:07 - INFO - TRAINING - Epoch: [45][250/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.7254 (0.8392)	Prec@1 76.000 (71.665)	Prec@5 99.000 (97.633)
2019-05-04 16:51:08 - INFO - TRAINING - Epoch: [45][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8713 (0.8408)	Prec@1 73.000 (71.641)	Prec@5 99.000 (97.621)
2019-05-04 16:51:09 - INFO - TRAINING - Epoch: [45][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8665 (0.8356)	Prec@1 69.000 (71.895)	Prec@5 97.000 (97.632)
2019-05-04 16:51:10 - INFO - TRAINING - Epoch: [45][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7231 (0.8333)	Prec@1 74.000 (71.990)	Prec@5 98.000 (97.613)
2019-05-04 16:51:11 - INFO - TRAINING - Epoch: [45][450/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.7768 (0.8311)	Prec@1 73.000 (72.115)	Prec@5 99.000 (97.630)
2019-05-04 16:51:12 - INFO - EVALUATING - Epoch: [45][0/100]	Time 0.290 (0.290)	Data 0.280 (0.280)	Loss 1.8578 (1.8578)	Prec@1 55.000 (55.000)	Prec@5 84.000 (84.000)
2019-05-04 16:51:13 - INFO - EVALUATING - Epoch: [45][50/100]	Time 0.007 (0.012)	Data 0.000 (0.006)	Loss 1.6821 (1.7109)	Prec@1 55.000 (51.333)	Prec@5 81.000 (85.431)
2019-05-04 16:51:13 - INFO - 
 Epoch: 46	Training Loss 0.8317 	Training Prec@1 72.146 	Training Prec@5 97.652 	Validation Loss 1.7202 	Validation Prec@1 50.570 	Validation Prec@5 85.470 	
2019-05-04 16:51:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:13 - INFO - TRAINING - Epoch: [46][0/500]	Time 0.249 (0.249)	Data 0.228 (0.228)	Loss 0.9554 (0.9554)	Prec@1 70.000 (70.000)	Prec@5 98.000 (98.000)
2019-05-04 16:51:14 - INFO - TRAINING - Epoch: [46][50/500]	Time 0.023 (0.024)	Data 0.000 (0.005)	Loss 0.6671 (0.8764)	Prec@1 81.000 (70.843)	Prec@5 99.000 (97.824)
2019-05-04 16:51:15 - INFO - TRAINING - Epoch: [46][100/500]	Time 0.029 (0.022)	Data 0.000 (0.002)	Loss 0.6330 (0.8506)	Prec@1 81.000 (71.366)	Prec@5 99.000 (97.782)
2019-05-04 16:51:16 - INFO - TRAINING - Epoch: [46][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.8951 (0.8282)	Prec@1 71.000 (72.040)	Prec@5 99.000 (97.921)
2019-05-04 16:51:17 - INFO - TRAINING - Epoch: [46][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8301 (0.8292)	Prec@1 70.000 (72.035)	Prec@5 98.000 (97.905)
2019-05-04 16:51:18 - INFO - TRAINING - Epoch: [46][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8559 (0.8283)	Prec@1 72.000 (72.008)	Prec@5 98.000 (97.892)
2019-05-04 16:51:19 - INFO - TRAINING - Epoch: [46][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6887 (0.8330)	Prec@1 76.000 (71.874)	Prec@5 98.000 (97.811)
2019-05-04 16:51:20 - INFO - TRAINING - Epoch: [46][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6239 (0.8341)	Prec@1 79.000 (71.886)	Prec@5 100.000 (97.798)
2019-05-04 16:51:21 - INFO - TRAINING - Epoch: [46][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8002 (0.8298)	Prec@1 77.000 (71.998)	Prec@5 99.000 (97.823)
2019-05-04 16:51:22 - INFO - TRAINING - Epoch: [46][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8519 (0.8310)	Prec@1 70.000 (72.022)	Prec@5 97.000 (97.823)
2019-05-04 16:51:24 - INFO - EVALUATING - Epoch: [46][0/100]	Time 0.352 (0.352)	Data 0.344 (0.344)	Loss 1.1027 (1.1027)	Prec@1 63.000 (63.000)	Prec@5 96.000 (96.000)
2019-05-04 16:51:24 - INFO - EVALUATING - Epoch: [46][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.0272 (1.0689)	Prec@1 67.000 (62.922)	Prec@5 98.000 (96.706)
2019-05-04 16:51:24 - INFO - 
 Epoch: 47	Training Loss 0.8318 	Training Prec@1 71.972 	Training Prec@5 97.802 	Validation Loss 1.0700 	Validation Prec@1 62.910 	Validation Prec@5 96.660 	
2019-05-04 16:51:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:25 - INFO - TRAINING - Epoch: [47][0/500]	Time 0.371 (0.371)	Data 0.350 (0.350)	Loss 0.7474 (0.7474)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-04 16:51:26 - INFO - TRAINING - Epoch: [47][50/500]	Time 0.020 (0.027)	Data 0.000 (0.007)	Loss 0.8219 (0.8626)	Prec@1 74.000 (70.824)	Prec@5 98.000 (97.451)
2019-05-04 16:51:27 - INFO - TRAINING - Epoch: [47][100/500]	Time 0.022 (0.023)	Data 0.000 (0.004)	Loss 0.9947 (0.8486)	Prec@1 65.000 (71.168)	Prec@5 97.000 (97.703)
2019-05-04 16:51:27 - INFO - TRAINING - Epoch: [47][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.9361 (0.8420)	Prec@1 70.000 (71.530)	Prec@5 96.000 (97.682)
2019-05-04 16:51:28 - INFO - TRAINING - Epoch: [47][200/500]	Time 0.030 (0.021)	Data 0.000 (0.002)	Loss 0.8335 (0.8383)	Prec@1 73.000 (71.711)	Prec@5 97.000 (97.642)
2019-05-04 16:51:29 - INFO - TRAINING - Epoch: [47][250/500]	Time 0.029 (0.021)	Data 0.000 (0.002)	Loss 0.7790 (0.8352)	Prec@1 71.000 (71.793)	Prec@5 100.000 (97.657)
2019-05-04 16:51:30 - INFO - TRAINING - Epoch: [47][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8789 (0.8352)	Prec@1 71.000 (71.708)	Prec@5 97.000 (97.691)
2019-05-04 16:51:31 - INFO - TRAINING - Epoch: [47][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7899 (0.8381)	Prec@1 74.000 (71.635)	Prec@5 98.000 (97.667)
2019-05-04 16:51:32 - INFO - TRAINING - Epoch: [47][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7262 (0.8353)	Prec@1 76.000 (71.800)	Prec@5 98.000 (97.676)
2019-05-04 16:51:33 - INFO - TRAINING - Epoch: [47][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.9037 (0.8379)	Prec@1 71.000 (71.738)	Prec@5 98.000 (97.663)
2019-05-04 16:51:35 - INFO - EVALUATING - Epoch: [47][0/100]	Time 0.346 (0.346)	Data 0.340 (0.340)	Loss 1.3085 (1.3085)	Prec@1 60.000 (60.000)	Prec@5 92.000 (92.000)
2019-05-04 16:51:35 - INFO - EVALUATING - Epoch: [47][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.2300 (1.3227)	Prec@1 59.000 (55.608)	Prec@5 95.000 (94.706)
2019-05-04 16:51:35 - INFO - 
 Epoch: 48	Training Loss 0.8365 	Training Prec@1 71.834 	Training Prec@5 97.648 	Validation Loss 1.3234 	Validation Prec@1 55.840 	Validation Prec@5 94.550 	
2019-05-04 16:51:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:36 - INFO - TRAINING - Epoch: [48][0/500]	Time 0.259 (0.259)	Data 0.238 (0.238)	Loss 0.8892 (0.8892)	Prec@1 73.000 (73.000)	Prec@5 98.000 (98.000)
2019-05-04 16:51:37 - INFO - TRAINING - Epoch: [48][50/500]	Time 0.025 (0.024)	Data 0.000 (0.005)	Loss 0.9432 (0.8462)	Prec@1 68.000 (71.824)	Prec@5 95.000 (97.882)
2019-05-04 16:51:38 - INFO - TRAINING - Epoch: [48][100/500]	Time 0.021 (0.022)	Data 0.000 (0.003)	Loss 0.9862 (0.8388)	Prec@1 72.000 (71.881)	Prec@5 94.000 (97.782)
2019-05-04 16:51:39 - INFO - TRAINING - Epoch: [48][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.7893 (0.8366)	Prec@1 76.000 (71.921)	Prec@5 99.000 (97.868)
2019-05-04 16:51:40 - INFO - TRAINING - Epoch: [48][200/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8695 (0.8446)	Prec@1 73.000 (71.701)	Prec@5 98.000 (97.731)
2019-05-04 16:51:41 - INFO - TRAINING - Epoch: [48][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6699 (0.8411)	Prec@1 80.000 (71.761)	Prec@5 97.000 (97.717)
2019-05-04 16:51:42 - INFO - TRAINING - Epoch: [48][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7782 (0.8375)	Prec@1 73.000 (71.831)	Prec@5 98.000 (97.807)
2019-05-04 16:51:43 - INFO - TRAINING - Epoch: [48][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8506 (0.8359)	Prec@1 66.000 (71.917)	Prec@5 99.000 (97.789)
2019-05-04 16:51:44 - INFO - TRAINING - Epoch: [48][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7595 (0.8363)	Prec@1 72.000 (71.883)	Prec@5 100.000 (97.793)
2019-05-04 16:51:45 - INFO - TRAINING - Epoch: [48][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8860 (0.8356)	Prec@1 72.000 (71.889)	Prec@5 99.000 (97.843)
2019-05-04 16:51:46 - INFO - EVALUATING - Epoch: [48][0/100]	Time 0.340 (0.340)	Data 0.327 (0.327)	Loss 1.1273 (1.1273)	Prec@1 60.000 (60.000)	Prec@5 97.000 (97.000)
2019-05-04 16:51:46 - INFO - EVALUATING - Epoch: [48][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.1624 (1.1357)	Prec@1 59.000 (59.549)	Prec@5 95.000 (95.627)
2019-05-04 16:51:47 - INFO - 
 Epoch: 49	Training Loss 0.8336 	Training Prec@1 71.914 	Training Prec@5 97.868 	Validation Loss 1.1453 	Validation Prec@1 59.490 	Validation Prec@5 95.500 	
2019-05-04 16:51:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:47 - INFO - TRAINING - Epoch: [49][0/500]	Time 0.351 (0.351)	Data 0.323 (0.323)	Loss 0.7936 (0.7936)	Prec@1 78.000 (78.000)	Prec@5 96.000 (96.000)
2019-05-04 16:51:48 - INFO - TRAINING - Epoch: [49][50/500]	Time 0.019 (0.026)	Data 0.000 (0.006)	Loss 0.8127 (0.8281)	Prec@1 72.000 (71.647)	Prec@5 98.000 (97.980)
2019-05-04 16:51:49 - INFO - TRAINING - Epoch: [49][100/500]	Time 0.025 (0.023)	Data 0.000 (0.003)	Loss 0.6201 (0.8283)	Prec@1 76.000 (71.584)	Prec@5 98.000 (97.792)
2019-05-04 16:51:50 - INFO - TRAINING - Epoch: [49][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.0642 (0.8304)	Prec@1 69.000 (71.748)	Prec@5 95.000 (97.815)
2019-05-04 16:51:51 - INFO - TRAINING - Epoch: [49][200/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.8703 (0.8349)	Prec@1 71.000 (71.687)	Prec@5 98.000 (97.776)
2019-05-04 16:51:52 - INFO - TRAINING - Epoch: [49][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8033 (0.8307)	Prec@1 71.000 (71.701)	Prec@5 99.000 (97.805)
2019-05-04 16:51:53 - INFO - TRAINING - Epoch: [49][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7114 (0.8272)	Prec@1 78.000 (71.970)	Prec@5 98.000 (97.824)
2019-05-04 16:51:54 - INFO - TRAINING - Epoch: [49][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7997 (0.8272)	Prec@1 73.000 (72.003)	Prec@5 95.000 (97.815)
2019-05-04 16:51:55 - INFO - TRAINING - Epoch: [49][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6747 (0.8263)	Prec@1 77.000 (72.017)	Prec@5 100.000 (97.835)
2019-05-04 16:51:56 - INFO - TRAINING - Epoch: [49][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8136 (0.8315)	Prec@1 73.000 (71.849)	Prec@5 98.000 (97.789)
2019-05-04 16:51:58 - INFO - EVALUATING - Epoch: [49][0/100]	Time 0.367 (0.367)	Data 0.361 (0.361)	Loss 1.0705 (1.0705)	Prec@1 63.000 (63.000)	Prec@5 95.000 (95.000)
2019-05-04 16:51:58 - INFO - EVALUATING - Epoch: [49][50/100]	Time 0.005 (0.013)	Data 0.000 (0.008)	Loss 1.0713 (1.0101)	Prec@1 65.000 (65.627)	Prec@5 94.000 (96.529)
2019-05-04 16:51:58 - INFO - 
 Epoch: 50	Training Loss 0.8314 	Training Prec@1 71.872 	Training Prec@5 97.774 	Validation Loss 1.0020 	Validation Prec@1 65.860 	Validation Prec@5 96.790 	
2019-05-04 16:51:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:51:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:51:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:51:58 - INFO - TRAINING - Epoch: [50][0/500]	Time 0.272 (0.272)	Data 0.248 (0.248)	Loss 0.7856 (0.7856)	Prec@1 72.000 (72.000)	Prec@5 100.000 (100.000)
2019-05-04 16:51:59 - INFO - TRAINING - Epoch: [50][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.7428 (0.8334)	Prec@1 73.000 (71.784)	Prec@5 99.000 (97.824)
2019-05-04 16:52:00 - INFO - TRAINING - Epoch: [50][100/500]	Time 0.024 (0.023)	Data 0.000 (0.003)	Loss 0.8792 (0.8241)	Prec@1 71.000 (72.119)	Prec@5 99.000 (97.713)
2019-05-04 16:52:01 - INFO - TRAINING - Epoch: [50][150/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 1.0708 (0.8345)	Prec@1 60.000 (71.762)	Prec@5 99.000 (97.742)
2019-05-04 16:52:02 - INFO - TRAINING - Epoch: [50][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9199 (0.8340)	Prec@1 66.000 (71.652)	Prec@5 99.000 (97.776)
2019-05-04 16:52:03 - INFO - TRAINING - Epoch: [50][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.9358 (0.8272)	Prec@1 72.000 (71.924)	Prec@5 93.000 (97.801)
2019-05-04 16:52:04 - INFO - TRAINING - Epoch: [50][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6962 (0.8265)	Prec@1 77.000 (71.967)	Prec@5 97.000 (97.834)
2019-05-04 16:52:05 - INFO - TRAINING - Epoch: [50][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6666 (0.8283)	Prec@1 77.000 (71.943)	Prec@5 100.000 (97.823)
2019-05-04 16:52:06 - INFO - TRAINING - Epoch: [50][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7348 (0.8298)	Prec@1 76.000 (71.975)	Prec@5 99.000 (97.810)
2019-05-04 16:52:07 - INFO - TRAINING - Epoch: [50][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8291 (0.8304)	Prec@1 72.000 (71.978)	Prec@5 99.000 (97.796)
2019-05-04 16:52:09 - INFO - EVALUATING - Epoch: [50][0/100]	Time 0.339 (0.339)	Data 0.334 (0.334)	Loss 1.2250 (1.2250)	Prec@1 58.000 (58.000)	Prec@5 96.000 (96.000)
2019-05-04 16:52:09 - INFO - EVALUATING - Epoch: [50][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.2532 (1.2007)	Prec@1 62.000 (59.373)	Prec@5 91.000 (94.353)
2019-05-04 16:52:09 - INFO - 
 Epoch: 51	Training Loss 0.8289 	Training Prec@1 72.070 	Training Prec@5 97.788 	Validation Loss 1.2108 	Validation Prec@1 58.960 	Validation Prec@5 94.220 	
2019-05-04 16:52:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:52:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:52:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:52:10 - INFO - TRAINING - Epoch: [51][0/500]	Time 0.370 (0.370)	Data 0.333 (0.333)	Loss 0.7475 (0.7475)	Prec@1 81.000 (81.000)	Prec@5 97.000 (97.000)
2019-05-04 16:52:11 - INFO - TRAINING - Epoch: [51][50/500]	Time 0.015 (0.027)	Data 0.000 (0.007)	Loss 0.7916 (0.8477)	Prec@1 74.000 (71.176)	Prec@5 99.000 (97.824)
2019-05-04 16:52:12 - INFO - TRAINING - Epoch: [51][100/500]	Time 0.023 (0.024)	Data 0.000 (0.003)	Loss 0.7921 (0.8480)	Prec@1 75.000 (71.673)	Prec@5 97.000 (97.594)
2019-05-04 16:52:13 - INFO - TRAINING - Epoch: [51][150/500]	Time 0.014 (0.023)	Data 0.000 (0.002)	Loss 0.7755 (0.8325)	Prec@1 80.000 (72.245)	Prec@5 95.000 (97.702)
2019-05-04 16:52:14 - INFO - TRAINING - Epoch: [51][200/500]	Time 0.030 (0.022)	Data 0.000 (0.002)	Loss 0.7387 (0.8357)	Prec@1 74.000 (72.050)	Prec@5 99.000 (97.716)
2019-05-04 16:52:15 - INFO - TRAINING - Epoch: [51][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.8529 (0.8363)	Prec@1 72.000 (71.992)	Prec@5 95.000 (97.705)
2019-05-04 16:52:16 - INFO - TRAINING - Epoch: [51][300/500]	Time 0.013 (0.022)	Data 0.000 (0.001)	Loss 0.7195 (0.8381)	Prec@1 73.000 (71.794)	Prec@5 100.000 (97.704)
2019-05-04 16:52:17 - INFO - TRAINING - Epoch: [51][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7485 (0.8321)	Prec@1 73.000 (71.969)	Prec@5 98.000 (97.741)
2019-05-04 16:52:18 - INFO - TRAINING - Epoch: [51][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8138 (0.8309)	Prec@1 76.000 (72.027)	Prec@5 99.000 (97.768)
2019-05-04 16:52:19 - INFO - TRAINING - Epoch: [51][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8584 (0.8308)	Prec@1 69.000 (72.013)	Prec@5 98.000 (97.763)
2019-05-04 16:52:20 - INFO - EVALUATING - Epoch: [51][0/100]	Time 0.364 (0.364)	Data 0.355 (0.355)	Loss 1.3645 (1.3645)	Prec@1 61.000 (61.000)	Prec@5 92.000 (92.000)
2019-05-04 16:52:20 - INFO - EVALUATING - Epoch: [51][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.4227 (1.3732)	Prec@1 56.000 (55.804)	Prec@5 92.000 (94.255)
2019-05-04 16:52:21 - INFO - 
 Epoch: 52	Training Loss 0.8297 	Training Prec@1 72.038 	Training Prec@5 97.796 	Validation Loss 1.3754 	Validation Prec@1 55.590 	Validation Prec@5 94.440 	
2019-05-04 16:52:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:52:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:52:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:52:21 - INFO - TRAINING - Epoch: [52][0/500]	Time 0.367 (0.367)	Data 0.348 (0.348)	Loss 0.8237 (0.8237)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-04 16:52:22 - INFO - TRAINING - Epoch: [52][50/500]	Time 0.021 (0.027)	Data 0.000 (0.007)	Loss 0.7902 (0.8427)	Prec@1 74.000 (71.314)	Prec@5 96.000 (97.569)
2019-05-04 16:52:23 - INFO - TRAINING - Epoch: [52][100/500]	Time 0.027 (0.024)	Data 0.000 (0.004)	Loss 0.8851 (0.8348)	Prec@1 71.000 (71.475)	Prec@5 97.000 (97.584)
2019-05-04 16:52:24 - INFO - TRAINING - Epoch: [52][150/500]	Time 0.018 (0.023)	Data 0.000 (0.002)	Loss 0.8577 (0.8388)	Prec@1 70.000 (71.417)	Prec@5 98.000 (97.603)
2019-05-04 16:52:25 - INFO - TRAINING - Epoch: [52][200/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.9024 (0.8292)	Prec@1 68.000 (71.856)	Prec@5 96.000 (97.682)
2019-05-04 16:52:26 - INFO - TRAINING - Epoch: [52][250/500]	Time 0.011 (0.021)	Data 0.000 (0.002)	Loss 0.9915 (0.8321)	Prec@1 69.000 (71.845)	Prec@5 98.000 (97.665)
2019-05-04 16:52:27 - INFO - TRAINING - Epoch: [52][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8256 (0.8321)	Prec@1 71.000 (71.957)	Prec@5 96.000 (97.668)
2019-05-04 16:52:28 - INFO - TRAINING - Epoch: [52][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6445 (0.8329)	Prec@1 76.000 (71.912)	Prec@5 99.000 (97.658)
2019-05-04 16:52:29 - INFO - TRAINING - Epoch: [52][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.9354 (0.8306)	Prec@1 65.000 (71.928)	Prec@5 97.000 (97.696)
2019-05-04 16:52:30 - INFO - TRAINING - Epoch: [52][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7150 (0.8269)	Prec@1 75.000 (72.106)	Prec@5 100.000 (97.725)
2019-05-04 16:52:31 - INFO - EVALUATING - Epoch: [52][0/100]	Time 0.282 (0.282)	Data 0.273 (0.273)	Loss 1.6387 (1.6387)	Prec@1 50.000 (50.000)	Prec@5 90.000 (90.000)
2019-05-04 16:52:31 - INFO - EVALUATING - Epoch: [52][50/100]	Time 0.004 (0.011)	Data 0.000 (0.006)	Loss 1.7377 (1.6388)	Prec@1 44.000 (49.647)	Prec@5 90.000 (88.510)
2019-05-04 16:52:32 - INFO - 
 Epoch: 53	Training Loss 0.8256 	Training Prec@1 72.158 	Training Prec@5 97.734 	Validation Loss 1.6410 	Validation Prec@1 48.860 	Validation Prec@5 88.810 	
2019-05-04 16:52:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:52:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:52:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:52:32 - INFO - TRAINING - Epoch: [53][0/500]	Time 0.378 (0.378)	Data 0.355 (0.355)	Loss 0.8576 (0.8576)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-04 16:52:33 - INFO - TRAINING - Epoch: [53][50/500]	Time 0.027 (0.025)	Data 0.000 (0.007)	Loss 0.8129 (0.8251)	Prec@1 71.000 (72.176)	Prec@5 99.000 (98.020)
2019-05-04 16:52:34 - INFO - TRAINING - Epoch: [53][100/500]	Time 0.021 (0.023)	Data 0.000 (0.004)	Loss 0.7477 (0.8348)	Prec@1 73.000 (71.644)	Prec@5 99.000 (97.802)
2019-05-04 16:52:35 - INFO - TRAINING - Epoch: [53][150/500]	Time 0.028 (0.023)	Data 0.000 (0.002)	Loss 0.9395 (0.8310)	Prec@1 71.000 (71.993)	Prec@5 98.000 (97.715)
2019-05-04 16:52:36 - INFO - TRAINING - Epoch: [53][200/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.8253 (0.8280)	Prec@1 73.000 (72.065)	Prec@5 98.000 (97.811)
2019-05-04 16:52:37 - INFO - TRAINING - Epoch: [53][250/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.6770 (0.8239)	Prec@1 78.000 (72.139)	Prec@5 99.000 (97.849)
2019-05-04 16:52:38 - INFO - TRAINING - Epoch: [53][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.8953 (0.8250)	Prec@1 74.000 (72.173)	Prec@5 96.000 (97.831)
2019-05-04 16:52:39 - INFO - TRAINING - Epoch: [53][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6165 (0.8215)	Prec@1 77.000 (72.313)	Prec@5 98.000 (97.826)
2019-05-04 16:52:40 - INFO - TRAINING - Epoch: [53][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.9647 (0.8191)	Prec@1 68.000 (72.436)	Prec@5 96.000 (97.855)
2019-05-04 16:52:41 - INFO - TRAINING - Epoch: [53][450/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.8832 (0.8186)	Prec@1 72.000 (72.457)	Prec@5 97.000 (97.831)
2019-05-04 16:52:42 - INFO - EVALUATING - Epoch: [53][0/100]	Time 0.248 (0.248)	Data 0.243 (0.243)	Loss 1.0402 (1.0402)	Prec@1 68.000 (68.000)	Prec@5 95.000 (95.000)
2019-05-04 16:52:43 - INFO - EVALUATING - Epoch: [53][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.9904 (1.0624)	Prec@1 67.000 (65.588)	Prec@5 92.000 (95.353)
2019-05-04 16:52:43 - INFO - 
 Epoch: 54	Training Loss 0.8180 	Training Prec@1 72.494 	Training Prec@5 97.832 	Validation Loss 1.0595 	Validation Prec@1 65.220 	Validation Prec@5 95.500 	
2019-05-04 16:52:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:52:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:52:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:52:43 - INFO - TRAINING - Epoch: [54][0/500]	Time 0.280 (0.280)	Data 0.260 (0.260)	Loss 0.6554 (0.6554)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-04 16:52:44 - INFO - TRAINING - Epoch: [54][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.7342 (0.8509)	Prec@1 76.000 (71.275)	Prec@5 99.000 (97.824)
2019-05-04 16:52:45 - INFO - TRAINING - Epoch: [54][100/500]	Time 0.019 (0.022)	Data 0.000 (0.003)	Loss 0.6809 (0.8549)	Prec@1 83.000 (71.188)	Prec@5 97.000 (97.644)
2019-05-04 16:52:46 - INFO - TRAINING - Epoch: [54][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.7807 (0.8354)	Prec@1 69.000 (71.795)	Prec@5 99.000 (97.715)
2019-05-04 16:52:47 - INFO - TRAINING - Epoch: [54][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7855 (0.8300)	Prec@1 73.000 (71.826)	Prec@5 100.000 (97.846)
2019-05-04 16:52:48 - INFO - TRAINING - Epoch: [54][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.8873 (0.8320)	Prec@1 73.000 (71.761)	Prec@5 96.000 (97.825)
2019-05-04 16:52:49 - INFO - TRAINING - Epoch: [54][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7207 (0.8307)	Prec@1 72.000 (71.844)	Prec@5 100.000 (97.834)
2019-05-04 16:52:50 - INFO - TRAINING - Epoch: [54][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.8892 (0.8305)	Prec@1 69.000 (71.866)	Prec@5 96.000 (97.801)
2019-05-04 16:52:51 - INFO - TRAINING - Epoch: [54][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7714 (0.8318)	Prec@1 78.000 (71.803)	Prec@5 98.000 (97.800)
2019-05-04 16:52:52 - INFO - TRAINING - Epoch: [54][450/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.9745 (0.8287)	Prec@1 65.000 (71.951)	Prec@5 98.000 (97.825)
2019-05-04 16:52:54 - INFO - EVALUATING - Epoch: [54][0/100]	Time 0.353 (0.353)	Data 0.339 (0.339)	Loss 1.1005 (1.1005)	Prec@1 65.000 (65.000)	Prec@5 95.000 (95.000)
2019-05-04 16:52:54 - INFO - EVALUATING - Epoch: [54][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.1396 (1.1965)	Prec@1 66.000 (60.333)	Prec@5 94.000 (93.980)
2019-05-04 16:52:54 - INFO - 
 Epoch: 55	Training Loss 0.8254 	Training Prec@1 72.006 	Training Prec@5 97.860 	Validation Loss 1.2014 	Validation Prec@1 60.290 	Validation Prec@5 93.800 	
2019-05-04 16:52:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:52:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:52:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:52:55 - INFO - TRAINING - Epoch: [55][0/500]	Time 0.352 (0.352)	Data 0.325 (0.325)	Loss 0.9712 (0.9712)	Prec@1 64.000 (64.000)	Prec@5 95.000 (95.000)
2019-05-04 16:52:55 - INFO - TRAINING - Epoch: [55][50/500]	Time 0.021 (0.026)	Data 0.000 (0.007)	Loss 0.7869 (0.8460)	Prec@1 70.000 (71.216)	Prec@5 99.000 (97.824)
2019-05-04 16:52:56 - INFO - TRAINING - Epoch: [55][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.9008 (0.8283)	Prec@1 69.000 (72.099)	Prec@5 98.000 (97.861)
2019-05-04 16:52:57 - INFO - TRAINING - Epoch: [55][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.8292 (0.8286)	Prec@1 68.000 (72.119)	Prec@5 98.000 (97.828)
2019-05-04 16:52:58 - INFO - TRAINING - Epoch: [55][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7587 (0.8286)	Prec@1 71.000 (72.030)	Prec@5 99.000 (97.811)
2019-05-04 16:52:59 - INFO - TRAINING - Epoch: [55][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7247 (0.8284)	Prec@1 75.000 (72.048)	Prec@5 99.000 (97.781)
2019-05-04 16:53:00 - INFO - TRAINING - Epoch: [55][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7621 (0.8273)	Prec@1 70.000 (72.156)	Prec@5 100.000 (97.748)
2019-05-04 16:53:01 - INFO - TRAINING - Epoch: [55][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8742 (0.8248)	Prec@1 72.000 (72.330)	Prec@5 97.000 (97.795)
2019-05-04 16:53:02 - INFO - TRAINING - Epoch: [55][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.8814 (0.8254)	Prec@1 65.000 (72.269)	Prec@5 100.000 (97.833)
2019-05-04 16:53:03 - INFO - TRAINING - Epoch: [55][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.8481 (0.8236)	Prec@1 68.000 (72.251)	Prec@5 98.000 (97.865)
2019-05-04 16:53:05 - INFO - EVALUATING - Epoch: [55][0/100]	Time 0.361 (0.361)	Data 0.355 (0.355)	Loss 0.9934 (0.9934)	Prec@1 65.000 (65.000)	Prec@5 98.000 (98.000)
2019-05-04 16:53:05 - INFO - EVALUATING - Epoch: [55][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.9369 (0.9691)	Prec@1 66.000 (66.902)	Prec@5 95.000 (96.843)
2019-05-04 16:53:05 - INFO - 
 Epoch: 56	Training Loss 0.8248 	Training Prec@1 72.252 	Training Prec@5 97.854 	Validation Loss 0.9710 	Validation Prec@1 67.060 	Validation Prec@5 96.930 	
2019-05-04 16:53:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:53:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:53:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:53:06 - INFO - TRAINING - Epoch: [56][0/500]	Time 0.370 (0.370)	Data 0.350 (0.350)	Loss 0.8276 (0.8276)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-05-04 16:53:07 - INFO - TRAINING - Epoch: [56][50/500]	Time 0.022 (0.027)	Data 0.000 (0.007)	Loss 0.8085 (0.8239)	Prec@1 77.000 (72.059)	Prec@5 99.000 (97.706)
2019-05-04 16:53:08 - INFO - TRAINING - Epoch: [56][100/500]	Time 0.029 (0.024)	Data 0.000 (0.004)	Loss 0.7113 (0.8192)	Prec@1 75.000 (72.495)	Prec@5 98.000 (97.673)
2019-05-04 16:53:09 - INFO - TRAINING - Epoch: [56][150/500]	Time 0.025 (0.023)	Data 0.000 (0.002)	Loss 0.7672 (0.8150)	Prec@1 75.000 (72.603)	Prec@5 97.000 (97.801)
2019-05-04 16:53:10 - INFO - TRAINING - Epoch: [56][200/500]	Time 0.026 (0.022)	Data 0.000 (0.002)	Loss 0.7539 (0.8160)	Prec@1 78.000 (72.677)	Prec@5 95.000 (97.816)
2019-05-04 16:53:11 - INFO - TRAINING - Epoch: [56][250/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.6804 (0.8137)	Prec@1 75.000 (72.673)	Prec@5 99.000 (97.849)
2019-05-04 16:53:12 - INFO - TRAINING - Epoch: [56][300/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.0672 (0.8166)	Prec@1 66.000 (72.608)	Prec@5 93.000 (97.831)
2019-05-04 16:53:13 - INFO - TRAINING - Epoch: [56][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.9177 (0.8193)	Prec@1 71.000 (72.444)	Prec@5 95.000 (97.781)
2019-05-04 16:53:14 - INFO - TRAINING - Epoch: [56][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.9495 (0.8197)	Prec@1 68.000 (72.374)	Prec@5 95.000 (97.820)
2019-05-04 16:53:15 - INFO - TRAINING - Epoch: [56][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7593 (0.8205)	Prec@1 75.000 (72.366)	Prec@5 99.000 (97.825)
2019-05-04 16:53:16 - INFO - EVALUATING - Epoch: [56][0/100]	Time 0.361 (0.361)	Data 0.353 (0.353)	Loss 1.1181 (1.1181)	Prec@1 64.000 (64.000)	Prec@5 96.000 (96.000)
2019-05-04 16:53:16 - INFO - EVALUATING - Epoch: [56][50/100]	Time 0.006 (0.013)	Data 0.000 (0.008)	Loss 0.9982 (1.1294)	Prec@1 63.000 (63.490)	Prec@5 95.000 (94.078)
2019-05-04 16:53:17 - INFO - 
 Epoch: 57	Training Loss 0.8203 	Training Prec@1 72.318 	Training Prec@5 97.824 	Validation Loss 1.1381 	Validation Prec@1 62.880 	Validation Prec@5 94.320 	
2019-05-04 16:53:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:53:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:53:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:53:17 - INFO - TRAINING - Epoch: [57][0/500]	Time 0.270 (0.270)	Data 0.250 (0.250)	Loss 0.8665 (0.8665)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-04 16:53:18 - INFO - TRAINING - Epoch: [57][50/500]	Time 0.021 (0.024)	Data 0.000 (0.005)	Loss 0.7012 (0.8523)	Prec@1 75.000 (71.392)	Prec@5 100.000 (97.471)
2019-05-04 16:53:19 - INFO - TRAINING - Epoch: [57][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 0.8897 (0.8241)	Prec@1 68.000 (72.386)	Prec@5 95.000 (97.713)
2019-05-04 16:53:20 - INFO - TRAINING - Epoch: [57][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.8097 (0.8361)	Prec@1 72.000 (71.795)	Prec@5 99.000 (97.656)
2019-05-04 16:53:21 - INFO - TRAINING - Epoch: [57][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7972 (0.8261)	Prec@1 75.000 (72.085)	Prec@5 99.000 (97.751)
2019-05-04 16:53:22 - INFO - TRAINING - Epoch: [57][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8005 (0.8251)	Prec@1 77.000 (72.143)	Prec@5 96.000 (97.765)
2019-05-04 16:53:23 - INFO - TRAINING - Epoch: [57][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8158 (0.8238)	Prec@1 73.000 (72.203)	Prec@5 98.000 (97.734)
2019-05-04 16:53:24 - INFO - TRAINING - Epoch: [57][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7593 (0.8296)	Prec@1 78.000 (72.034)	Prec@5 96.000 (97.684)
2019-05-04 16:53:25 - INFO - TRAINING - Epoch: [57][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8422 (0.8320)	Prec@1 76.000 (71.915)	Prec@5 97.000 (97.671)
2019-05-04 16:53:26 - INFO - TRAINING - Epoch: [57][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.8505 (0.8301)	Prec@1 77.000 (72.013)	Prec@5 99.000 (97.701)
2019-05-04 16:53:27 - INFO - EVALUATING - Epoch: [57][0/100]	Time 0.379 (0.379)	Data 0.372 (0.372)	Loss 1.4778 (1.4778)	Prec@1 51.000 (51.000)	Prec@5 92.000 (92.000)
2019-05-04 16:53:27 - INFO - EVALUATING - Epoch: [57][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.2880 (1.3178)	Prec@1 60.000 (57.882)	Prec@5 93.000 (91.529)
2019-05-04 16:53:28 - INFO - 
 Epoch: 58	Training Loss 0.8297 	Training Prec@1 72.042 	Training Prec@5 97.672 	Validation Loss 1.3168 	Validation Prec@1 57.490 	Validation Prec@5 91.890 	
2019-05-04 16:53:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:53:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:53:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:53:28 - INFO - TRAINING - Epoch: [58][0/500]	Time 0.264 (0.264)	Data 0.240 (0.240)	Loss 0.7075 (0.7075)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-04 16:53:29 - INFO - TRAINING - Epoch: [58][50/500]	Time 0.021 (0.025)	Data 0.000 (0.005)	Loss 0.7781 (0.8104)	Prec@1 74.000 (73.353)	Prec@5 100.000 (97.824)
2019-05-04 16:53:30 - INFO - TRAINING - Epoch: [58][100/500]	Time 0.013 (0.023)	Data 0.000 (0.003)	Loss 0.9777 (0.8127)	Prec@1 72.000 (72.762)	Prec@5 95.000 (97.911)
2019-05-04 16:53:31 - INFO - TRAINING - Epoch: [58][150/500]	Time 0.030 (0.022)	Data 0.000 (0.002)	Loss 0.7187 (0.8143)	Prec@1 71.000 (72.662)	Prec@5 99.000 (97.980)
2019-05-04 16:53:32 - INFO - TRAINING - Epoch: [58][200/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7010 (0.8046)	Prec@1 73.000 (72.955)	Prec@5 98.000 (98.010)
2019-05-04 16:53:33 - INFO - TRAINING - Epoch: [58][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.9042 (0.8116)	Prec@1 66.000 (72.777)	Prec@5 97.000 (97.900)
2019-05-04 16:53:34 - INFO - TRAINING - Epoch: [58][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.9162 (0.8148)	Prec@1 67.000 (72.598)	Prec@5 98.000 (97.920)
2019-05-04 16:53:35 - INFO - TRAINING - Epoch: [58][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8360 (0.8162)	Prec@1 74.000 (72.504)	Prec@5 99.000 (97.957)
2019-05-04 16:53:36 - INFO - TRAINING - Epoch: [58][400/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6268 (0.8174)	Prec@1 78.000 (72.491)	Prec@5 100.000 (97.938)
2019-05-04 16:53:37 - INFO - TRAINING - Epoch: [58][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 1.0004 (0.8196)	Prec@1 72.000 (72.415)	Prec@5 95.000 (97.918)
2019-05-04 16:53:38 - INFO - EVALUATING - Epoch: [58][0/100]	Time 0.328 (0.328)	Data 0.322 (0.322)	Loss 0.8352 (0.8352)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-04 16:53:39 - INFO - EVALUATING - Epoch: [58][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.9184 (0.9328)	Prec@1 66.000 (68.549)	Prec@5 97.000 (97.039)
2019-05-04 16:53:39 - INFO - 
 Epoch: 59	Training Loss 0.8186 	Training Prec@1 72.456 	Training Prec@5 97.928 	Validation Loss 0.9306 	Validation Prec@1 68.750 	Validation Prec@5 96.960 	
2019-05-04 16:53:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:53:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:53:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:53:39 - INFO - TRAINING - Epoch: [59][0/500]	Time 0.275 (0.275)	Data 0.251 (0.251)	Loss 0.9439 (0.9439)	Prec@1 65.000 (65.000)	Prec@5 98.000 (98.000)
2019-05-04 16:53:40 - INFO - TRAINING - Epoch: [59][50/500]	Time 0.014 (0.025)	Data 0.000 (0.005)	Loss 0.9061 (0.8497)	Prec@1 72.000 (71.275)	Prec@5 97.000 (97.902)
2019-05-04 16:53:41 - INFO - TRAINING - Epoch: [59][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.6714 (0.8082)	Prec@1 79.000 (72.703)	Prec@5 99.000 (98.079)
2019-05-04 16:53:42 - INFO - TRAINING - Epoch: [59][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.6957 (0.7935)	Prec@1 76.000 (73.272)	Prec@5 99.000 (98.007)
2019-05-04 16:53:43 - INFO - TRAINING - Epoch: [59][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6517 (0.7992)	Prec@1 76.000 (73.164)	Prec@5 100.000 (98.000)
2019-05-04 16:53:44 - INFO - TRAINING - Epoch: [59][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7311 (0.8045)	Prec@1 74.000 (73.004)	Prec@5 99.000 (98.008)
2019-05-04 16:53:45 - INFO - TRAINING - Epoch: [59][300/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.7843 (0.8057)	Prec@1 69.000 (72.973)	Prec@5 99.000 (97.970)
2019-05-04 16:53:46 - INFO - TRAINING - Epoch: [59][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.9121 (0.8080)	Prec@1 69.000 (72.843)	Prec@5 96.000 (97.923)
2019-05-04 16:53:47 - INFO - TRAINING - Epoch: [59][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.9353 (0.8124)	Prec@1 70.000 (72.636)	Prec@5 100.000 (97.933)
2019-05-04 16:53:48 - INFO - TRAINING - Epoch: [59][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8044 (0.8129)	Prec@1 69.000 (72.676)	Prec@5 99.000 (97.918)
2019-05-04 16:53:49 - INFO - EVALUATING - Epoch: [59][0/100]	Time 0.318 (0.318)	Data 0.312 (0.312)	Loss 0.9420 (0.9420)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-05-04 16:53:50 - INFO - EVALUATING - Epoch: [59][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.9935 (1.0548)	Prec@1 70.000 (64.235)	Prec@5 99.000 (96.647)
2019-05-04 16:53:50 - INFO - 
 Epoch: 60	Training Loss 0.8152 	Training Prec@1 72.564 	Training Prec@5 97.900 	Validation Loss 1.0672 	Validation Prec@1 63.430 	Validation Prec@5 96.680 	
2019-05-04 16:53:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:53:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:53:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:53:50 - INFO - TRAINING - Epoch: [60][0/500]	Time 0.371 (0.371)	Data 0.338 (0.338)	Loss 0.7251 (0.7251)	Prec@1 76.000 (76.000)	Prec@5 96.000 (96.000)
2019-05-04 16:53:51 - INFO - TRAINING - Epoch: [60][50/500]	Time 0.016 (0.026)	Data 0.000 (0.007)	Loss 0.7250 (0.7832)	Prec@1 70.000 (73.667)	Prec@5 99.000 (97.745)
2019-05-04 16:53:52 - INFO - TRAINING - Epoch: [60][100/500]	Time 0.018 (0.023)	Data 0.000 (0.003)	Loss 0.7183 (0.7970)	Prec@1 83.000 (73.000)	Prec@5 97.000 (97.911)
2019-05-04 16:53:53 - INFO - TRAINING - Epoch: [60][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.8605 (0.8059)	Prec@1 71.000 (72.795)	Prec@5 95.000 (97.775)
2019-05-04 16:53:54 - INFO - TRAINING - Epoch: [60][200/500]	Time 0.029 (0.021)	Data 0.000 (0.002)	Loss 0.9524 (0.8114)	Prec@1 71.000 (72.602)	Prec@5 98.000 (97.841)
2019-05-04 16:53:55 - INFO - TRAINING - Epoch: [60][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.9055 (0.8200)	Prec@1 71.000 (72.410)	Prec@5 96.000 (97.805)
2019-05-04 16:53:56 - INFO - TRAINING - Epoch: [60][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8634 (0.8244)	Prec@1 70.000 (72.382)	Prec@5 99.000 (97.804)
2019-05-04 16:53:57 - INFO - TRAINING - Epoch: [60][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7537 (0.8252)	Prec@1 75.000 (72.259)	Prec@5 99.000 (97.783)
2019-05-04 16:53:58 - INFO - TRAINING - Epoch: [60][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.9429 (0.8272)	Prec@1 68.000 (72.254)	Prec@5 98.000 (97.798)
2019-05-04 16:53:59 - INFO - TRAINING - Epoch: [60][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.9182 (0.8263)	Prec@1 70.000 (72.297)	Prec@5 99.000 (97.780)
2019-05-04 16:54:00 - INFO - EVALUATING - Epoch: [60][0/100]	Time 0.354 (0.354)	Data 0.344 (0.344)	Loss 0.8994 (0.8994)	Prec@1 68.000 (68.000)	Prec@5 96.000 (96.000)
2019-05-04 16:54:01 - INFO - EVALUATING - Epoch: [60][50/100]	Time 0.008 (0.012)	Data 0.000 (0.007)	Loss 0.8023 (0.8921)	Prec@1 77.000 (70.157)	Prec@5 96.000 (97.588)
2019-05-04 16:54:01 - INFO - 
 Epoch: 61	Training Loss 0.8235 	Training Prec@1 72.400 	Training Prec@5 97.806 	Validation Loss 0.9011 	Validation Prec@1 69.560 	Validation Prec@5 97.530 	
2019-05-04 16:54:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:01 - INFO - TRAINING - Epoch: [61][0/500]	Time 0.371 (0.371)	Data 0.353 (0.353)	Loss 0.7084 (0.7084)	Prec@1 76.000 (76.000)	Prec@5 98.000 (98.000)
2019-05-04 16:54:02 - INFO - TRAINING - Epoch: [61][50/500]	Time 0.029 (0.027)	Data 0.000 (0.007)	Loss 0.8792 (0.8713)	Prec@1 72.000 (70.706)	Prec@5 98.000 (97.745)
2019-05-04 16:54:04 - INFO - TRAINING - Epoch: [61][100/500]	Time 0.021 (0.025)	Data 0.000 (0.004)	Loss 0.8006 (0.8410)	Prec@1 71.000 (71.723)	Prec@5 99.000 (97.782)
2019-05-04 16:54:05 - INFO - TRAINING - Epoch: [61][150/500]	Time 0.026 (0.023)	Data 0.000 (0.002)	Loss 0.9523 (0.8396)	Prec@1 66.000 (71.536)	Prec@5 98.000 (97.808)
2019-05-04 16:54:06 - INFO - TRAINING - Epoch: [61][200/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.7602 (0.8353)	Prec@1 73.000 (71.622)	Prec@5 98.000 (97.871)
2019-05-04 16:54:06 - INFO - TRAINING - Epoch: [61][250/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7577 (0.8351)	Prec@1 74.000 (71.753)	Prec@5 96.000 (97.837)
2019-05-04 16:54:08 - INFO - TRAINING - Epoch: [61][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7785 (0.8326)	Prec@1 73.000 (71.814)	Prec@5 97.000 (97.817)
2019-05-04 16:54:09 - INFO - TRAINING - Epoch: [61][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8839 (0.8310)	Prec@1 70.000 (71.846)	Prec@5 97.000 (97.832)
2019-05-04 16:54:10 - INFO - TRAINING - Epoch: [61][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9577 (0.8264)	Prec@1 72.000 (72.050)	Prec@5 95.000 (97.883)
2019-05-04 16:54:11 - INFO - TRAINING - Epoch: [61][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8009 (0.8245)	Prec@1 74.000 (72.126)	Prec@5 96.000 (97.896)
2019-05-04 16:54:12 - INFO - EVALUATING - Epoch: [61][0/100]	Time 0.355 (0.355)	Data 0.342 (0.342)	Loss 1.1805 (1.1805)	Prec@1 65.000 (65.000)	Prec@5 96.000 (96.000)
2019-05-04 16:54:12 - INFO - EVALUATING - Epoch: [61][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.1303 (1.1285)	Prec@1 59.000 (62.294)	Prec@5 94.000 (95.333)
2019-05-04 16:54:12 - INFO - 
 Epoch: 62	Training Loss 0.8251 	Training Prec@1 72.072 	Training Prec@5 97.910 	Validation Loss 1.1412 	Validation Prec@1 61.520 	Validation Prec@5 95.340 	
2019-05-04 16:54:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:13 - INFO - TRAINING - Epoch: [62][0/500]	Time 0.286 (0.286)	Data 0.266 (0.266)	Loss 0.5745 (0.5745)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-04 16:54:14 - INFO - TRAINING - Epoch: [62][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.6870 (0.8556)	Prec@1 76.000 (71.529)	Prec@5 99.000 (97.314)
2019-05-04 16:54:15 - INFO - TRAINING - Epoch: [62][100/500]	Time 0.023 (0.023)	Data 0.000 (0.003)	Loss 0.8070 (0.8325)	Prec@1 72.000 (72.178)	Prec@5 98.000 (97.564)
2019-05-04 16:54:16 - INFO - TRAINING - Epoch: [62][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.8780 (0.8306)	Prec@1 70.000 (72.338)	Prec@5 98.000 (97.543)
2019-05-04 16:54:17 - INFO - TRAINING - Epoch: [62][200/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8171 (0.8200)	Prec@1 70.000 (72.741)	Prec@5 98.000 (97.736)
2019-05-04 16:54:18 - INFO - TRAINING - Epoch: [62][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8885 (0.8221)	Prec@1 73.000 (72.665)	Prec@5 97.000 (97.733)
2019-05-04 16:54:19 - INFO - TRAINING - Epoch: [62][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.9788 (0.8282)	Prec@1 70.000 (72.375)	Prec@5 97.000 (97.708)
2019-05-04 16:54:20 - INFO - TRAINING - Epoch: [62][350/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 1.0441 (0.8258)	Prec@1 64.000 (72.405)	Prec@5 97.000 (97.695)
2019-05-04 16:54:21 - INFO - TRAINING - Epoch: [62][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8774 (0.8250)	Prec@1 71.000 (72.494)	Prec@5 95.000 (97.643)
2019-05-04 16:54:22 - INFO - TRAINING - Epoch: [62][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7522 (0.8249)	Prec@1 75.000 (72.435)	Prec@5 98.000 (97.654)
2019-05-04 16:54:23 - INFO - EVALUATING - Epoch: [62][0/100]	Time 0.359 (0.359)	Data 0.346 (0.346)	Loss 1.1693 (1.1693)	Prec@1 64.000 (64.000)	Prec@5 96.000 (96.000)
2019-05-04 16:54:23 - INFO - EVALUATING - Epoch: [62][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.2612 (1.1898)	Prec@1 59.000 (60.059)	Prec@5 92.000 (94.824)
2019-05-04 16:54:24 - INFO - 
 Epoch: 63	Training Loss 0.8236 	Training Prec@1 72.442 	Training Prec@5 97.696 	Validation Loss 1.2011 	Validation Prec@1 59.570 	Validation Prec@5 94.930 	
2019-05-04 16:54:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:24 - INFO - TRAINING - Epoch: [63][0/500]	Time 0.293 (0.293)	Data 0.268 (0.268)	Loss 0.9099 (0.9099)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-04 16:54:25 - INFO - TRAINING - Epoch: [63][50/500]	Time 0.017 (0.026)	Data 0.000 (0.005)	Loss 0.7164 (0.8301)	Prec@1 78.000 (72.137)	Prec@5 97.000 (97.667)
2019-05-04 16:54:26 - INFO - TRAINING - Epoch: [63][100/500]	Time 0.018 (0.023)	Data 0.000 (0.003)	Loss 0.8660 (0.8162)	Prec@1 69.000 (72.762)	Prec@5 98.000 (97.772)
2019-05-04 16:54:27 - INFO - TRAINING - Epoch: [63][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.8932 (0.8187)	Prec@1 70.000 (72.543)	Prec@5 96.000 (97.709)
2019-05-04 16:54:28 - INFO - TRAINING - Epoch: [63][200/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.7912 (0.8208)	Prec@1 78.000 (72.488)	Prec@5 98.000 (97.746)
2019-05-04 16:54:29 - INFO - TRAINING - Epoch: [63][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7402 (0.8232)	Prec@1 73.000 (72.442)	Prec@5 98.000 (97.797)
2019-05-04 16:54:30 - INFO - TRAINING - Epoch: [63][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6797 (0.8238)	Prec@1 77.000 (72.395)	Prec@5 99.000 (97.741)
2019-05-04 16:54:31 - INFO - TRAINING - Epoch: [63][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7478 (0.8202)	Prec@1 73.000 (72.516)	Prec@5 98.000 (97.758)
2019-05-04 16:54:32 - INFO - TRAINING - Epoch: [63][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8333 (0.8174)	Prec@1 74.000 (72.613)	Prec@5 98.000 (97.786)
2019-05-04 16:54:33 - INFO - TRAINING - Epoch: [63][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9874 (0.8123)	Prec@1 68.000 (72.752)	Prec@5 96.000 (97.838)
2019-05-04 16:54:34 - INFO - EVALUATING - Epoch: [63][0/100]	Time 0.384 (0.384)	Data 0.370 (0.370)	Loss 1.3360 (1.3360)	Prec@1 51.000 (51.000)	Prec@5 93.000 (93.000)
2019-05-04 16:54:35 - INFO - EVALUATING - Epoch: [63][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.2918 (1.3098)	Prec@1 55.000 (57.529)	Prec@5 93.000 (92.373)
2019-05-04 16:54:35 - INFO - 
 Epoch: 64	Training Loss 0.8137 	Training Prec@1 72.632 	Training Prec@5 97.836 	Validation Loss 1.3329 	Validation Prec@1 56.890 	Validation Prec@5 91.880 	
2019-05-04 16:54:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:35 - INFO - TRAINING - Epoch: [64][0/500]	Time 0.314 (0.314)	Data 0.284 (0.284)	Loss 0.8258 (0.8258)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-05-04 16:54:36 - INFO - TRAINING - Epoch: [64][50/500]	Time 0.011 (0.025)	Data 0.000 (0.006)	Loss 0.7632 (0.8346)	Prec@1 74.000 (71.627)	Prec@5 99.000 (97.824)
2019-05-04 16:54:37 - INFO - TRAINING - Epoch: [64][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.6623 (0.8118)	Prec@1 75.000 (72.871)	Prec@5 99.000 (97.832)
2019-05-04 16:54:38 - INFO - TRAINING - Epoch: [64][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.7019 (0.8159)	Prec@1 70.000 (72.755)	Prec@5 99.000 (97.795)
2019-05-04 16:54:39 - INFO - TRAINING - Epoch: [64][200/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7328 (0.8175)	Prec@1 76.000 (72.577)	Prec@5 99.000 (97.866)
2019-05-04 16:54:40 - INFO - TRAINING - Epoch: [64][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.8563 (0.8129)	Prec@1 70.000 (72.757)	Prec@5 98.000 (97.841)
2019-05-04 16:54:41 - INFO - TRAINING - Epoch: [64][300/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.9760 (0.8151)	Prec@1 61.000 (72.658)	Prec@5 99.000 (97.874)
2019-05-04 16:54:42 - INFO - TRAINING - Epoch: [64][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9975 (0.8187)	Prec@1 66.000 (72.561)	Prec@5 97.000 (97.860)
2019-05-04 16:54:43 - INFO - TRAINING - Epoch: [64][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7575 (0.8163)	Prec@1 71.000 (72.576)	Prec@5 97.000 (97.865)
2019-05-04 16:54:44 - INFO - TRAINING - Epoch: [64][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6590 (0.8142)	Prec@1 75.000 (72.665)	Prec@5 100.000 (97.831)
2019-05-04 16:54:46 - INFO - EVALUATING - Epoch: [64][0/100]	Time 0.350 (0.350)	Data 0.341 (0.341)	Loss 1.7687 (1.7687)	Prec@1 50.000 (50.000)	Prec@5 89.000 (89.000)
2019-05-04 16:54:46 - INFO - EVALUATING - Epoch: [64][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.6018 (1.6503)	Prec@1 48.000 (49.510)	Prec@5 89.000 (90.529)
2019-05-04 16:54:46 - INFO - 
 Epoch: 65	Training Loss 0.8129 	Training Prec@1 72.724 	Training Prec@5 97.852 	Validation Loss 1.6668 	Validation Prec@1 49.300 	Validation Prec@5 90.560 	
2019-05-04 16:54:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:46 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:47 - INFO - TRAINING - Epoch: [65][0/500]	Time 0.274 (0.274)	Data 0.249 (0.249)	Loss 0.7096 (0.7096)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-04 16:54:48 - INFO - TRAINING - Epoch: [65][50/500]	Time 0.021 (0.026)	Data 0.000 (0.005)	Loss 0.7393 (0.8001)	Prec@1 75.000 (73.078)	Prec@5 99.000 (97.941)
2019-05-04 16:54:49 - INFO - TRAINING - Epoch: [65][100/500]	Time 0.021 (0.022)	Data 0.000 (0.003)	Loss 0.8189 (0.8004)	Prec@1 75.000 (72.911)	Prec@5 99.000 (97.851)
2019-05-04 16:54:50 - INFO - TRAINING - Epoch: [65][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.8305 (0.8129)	Prec@1 76.000 (72.603)	Prec@5 100.000 (97.689)
2019-05-04 16:54:51 - INFO - TRAINING - Epoch: [65][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7272 (0.8145)	Prec@1 80.000 (72.537)	Prec@5 98.000 (97.801)
2019-05-04 16:54:52 - INFO - TRAINING - Epoch: [65][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 1.0345 (0.8156)	Prec@1 65.000 (72.474)	Prec@5 97.000 (97.805)
2019-05-04 16:54:53 - INFO - TRAINING - Epoch: [65][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6790 (0.8175)	Prec@1 81.000 (72.472)	Prec@5 98.000 (97.787)
2019-05-04 16:54:54 - INFO - TRAINING - Epoch: [65][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7748 (0.8211)	Prec@1 73.000 (72.359)	Prec@5 97.000 (97.752)
2019-05-04 16:54:55 - INFO - TRAINING - Epoch: [65][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8519 (0.8195)	Prec@1 70.000 (72.344)	Prec@5 98.000 (97.736)
2019-05-04 16:54:56 - INFO - TRAINING - Epoch: [65][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6991 (0.8179)	Prec@1 73.000 (72.455)	Prec@5 98.000 (97.743)
2019-05-04 16:54:57 - INFO - EVALUATING - Epoch: [65][0/100]	Time 0.365 (0.365)	Data 0.359 (0.359)	Loss 0.8699 (0.8699)	Prec@1 72.000 (72.000)	Prec@5 97.000 (97.000)
2019-05-04 16:54:57 - INFO - EVALUATING - Epoch: [65][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.9875 (0.9482)	Prec@1 72.000 (68.020)	Prec@5 95.000 (96.373)
2019-05-04 16:54:58 - INFO - 
 Epoch: 66	Training Loss 0.8200 	Training Prec@1 72.458 	Training Prec@5 97.730 	Validation Loss 0.9752 	Validation Prec@1 66.650 	Validation Prec@5 96.350 	
2019-05-04 16:54:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:54:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:54:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:54:58 - INFO - TRAINING - Epoch: [66][0/500]	Time 0.291 (0.291)	Data 0.268 (0.268)	Loss 0.8776 (0.8776)	Prec@1 75.000 (75.000)	Prec@5 96.000 (96.000)
2019-05-04 16:54:59 - INFO - TRAINING - Epoch: [66][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.9941 (0.8511)	Prec@1 66.000 (70.804)	Prec@5 96.000 (97.490)
2019-05-04 16:55:00 - INFO - TRAINING - Epoch: [66][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 0.8899 (0.8354)	Prec@1 76.000 (71.396)	Prec@5 97.000 (97.782)
2019-05-04 16:55:01 - INFO - TRAINING - Epoch: [66][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.8293 (0.8339)	Prec@1 74.000 (71.755)	Prec@5 95.000 (97.828)
2019-05-04 16:55:02 - INFO - TRAINING - Epoch: [66][200/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.9793 (0.8326)	Prec@1 63.000 (71.975)	Prec@5 98.000 (97.811)
2019-05-04 16:55:03 - INFO - TRAINING - Epoch: [66][250/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8007 (0.8335)	Prec@1 70.000 (71.936)	Prec@5 98.000 (97.721)
2019-05-04 16:55:04 - INFO - TRAINING - Epoch: [66][300/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7027 (0.8263)	Prec@1 78.000 (72.189)	Prec@5 98.000 (97.757)
2019-05-04 16:55:05 - INFO - TRAINING - Epoch: [66][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8958 (0.8300)	Prec@1 71.000 (72.131)	Prec@5 99.000 (97.752)
2019-05-04 16:55:06 - INFO - TRAINING - Epoch: [66][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8209 (0.8270)	Prec@1 68.000 (72.135)	Prec@5 99.000 (97.813)
2019-05-04 16:55:07 - INFO - TRAINING - Epoch: [66][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7714 (0.8259)	Prec@1 75.000 (72.164)	Prec@5 99.000 (97.800)
2019-05-04 16:55:08 - INFO - EVALUATING - Epoch: [66][0/100]	Time 0.351 (0.351)	Data 0.340 (0.340)	Loss 1.3509 (1.3509)	Prec@1 61.000 (61.000)	Prec@5 88.000 (88.000)
2019-05-04 16:55:08 - INFO - EVALUATING - Epoch: [66][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.3277 (1.3526)	Prec@1 63.000 (58.353)	Prec@5 91.000 (90.255)
2019-05-04 16:55:09 - INFO - 
 Epoch: 67	Training Loss 0.8250 	Training Prec@1 72.124 	Training Prec@5 97.838 	Validation Loss 1.3616 	Validation Prec@1 57.530 	Validation Prec@5 90.240 	
2019-05-04 16:55:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:55:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:55:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:55:09 - INFO - TRAINING - Epoch: [67][0/500]	Time 0.278 (0.278)	Data 0.252 (0.252)	Loss 0.8619 (0.8619)	Prec@1 73.000 (73.000)	Prec@5 95.000 (95.000)
2019-05-04 16:55:10 - INFO - TRAINING - Epoch: [67][50/500]	Time 0.020 (0.025)	Data 0.000 (0.005)	Loss 0.9701 (0.8567)	Prec@1 65.000 (71.098)	Prec@5 99.000 (97.549)
2019-05-04 16:55:11 - INFO - TRAINING - Epoch: [67][100/500]	Time 0.013 (0.023)	Data 0.000 (0.003)	Loss 0.8031 (0.8266)	Prec@1 72.000 (72.050)	Prec@5 100.000 (97.693)
2019-05-04 16:55:12 - INFO - TRAINING - Epoch: [67][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.9603 (0.8184)	Prec@1 72.000 (72.338)	Prec@5 99.000 (97.841)
2019-05-04 16:55:13 - INFO - TRAINING - Epoch: [67][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8898 (0.8164)	Prec@1 68.000 (72.428)	Prec@5 98.000 (97.836)
2019-05-04 16:55:14 - INFO - TRAINING - Epoch: [67][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.9619 (0.8159)	Prec@1 67.000 (72.382)	Prec@5 99.000 (97.829)
2019-05-04 16:55:15 - INFO - TRAINING - Epoch: [67][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8149 (0.8170)	Prec@1 70.000 (72.395)	Prec@5 99.000 (97.811)
2019-05-04 16:55:16 - INFO - TRAINING - Epoch: [67][350/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.7664 (0.8131)	Prec@1 73.000 (72.513)	Prec@5 100.000 (97.855)
2019-05-04 16:55:17 - INFO - TRAINING - Epoch: [67][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7812 (0.8166)	Prec@1 75.000 (72.449)	Prec@5 98.000 (97.878)
2019-05-04 16:55:18 - INFO - TRAINING - Epoch: [67][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6218 (0.8192)	Prec@1 80.000 (72.415)	Prec@5 99.000 (97.847)
2019-05-04 16:55:19 - INFO - EVALUATING - Epoch: [67][0/100]	Time 0.364 (0.364)	Data 0.352 (0.352)	Loss 0.8866 (0.8866)	Prec@1 72.000 (72.000)	Prec@5 97.000 (97.000)
2019-05-04 16:55:20 - INFO - EVALUATING - Epoch: [67][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 1.0042 (1.0322)	Prec@1 68.000 (65.137)	Prec@5 95.000 (96.020)
2019-05-04 16:55:20 - INFO - 
 Epoch: 68	Training Loss 0.8164 	Training Prec@1 72.498 	Training Prec@5 97.858 	Validation Loss 1.0447 	Validation Prec@1 64.680 	Validation Prec@5 96.160 	
2019-05-04 16:55:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:55:20 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:55:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:55:20 - INFO - TRAINING - Epoch: [68][0/500]	Time 0.389 (0.389)	Data 0.367 (0.367)	Loss 0.8539 (0.8539)	Prec@1 72.000 (72.000)	Prec@5 100.000 (100.000)
2019-05-04 16:55:21 - INFO - TRAINING - Epoch: [68][50/500]	Time 0.015 (0.029)	Data 0.000 (0.007)	Loss 1.0281 (0.8643)	Prec@1 64.000 (70.196)	Prec@5 96.000 (97.627)
2019-05-04 16:55:22 - INFO - TRAINING - Epoch: [68][100/500]	Time 0.016 (0.024)	Data 0.000 (0.004)	Loss 0.7015 (0.8321)	Prec@1 79.000 (71.713)	Prec@5 98.000 (97.713)
2019-05-04 16:55:23 - INFO - TRAINING - Epoch: [68][150/500]	Time 0.014 (0.023)	Data 0.000 (0.003)	Loss 0.6901 (0.8255)	Prec@1 79.000 (72.053)	Prec@5 99.000 (97.815)
2019-05-04 16:55:24 - INFO - TRAINING - Epoch: [68][200/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.6709 (0.8237)	Prec@1 78.000 (72.050)	Prec@5 98.000 (97.886)
2019-05-04 16:55:25 - INFO - TRAINING - Epoch: [68][250/500]	Time 0.026 (0.022)	Data 0.000 (0.002)	Loss 0.9155 (0.8176)	Prec@1 65.000 (72.343)	Prec@5 96.000 (97.928)
2019-05-04 16:55:26 - INFO - TRAINING - Epoch: [68][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8347 (0.8147)	Prec@1 72.000 (72.478)	Prec@5 99.000 (97.900)
2019-05-04 16:55:27 - INFO - TRAINING - Epoch: [68][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7487 (0.8121)	Prec@1 72.000 (72.613)	Prec@5 98.000 (97.912)
2019-05-04 16:55:28 - INFO - TRAINING - Epoch: [68][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9223 (0.8168)	Prec@1 62.000 (72.434)	Prec@5 100.000 (97.903)
2019-05-04 16:55:29 - INFO - TRAINING - Epoch: [68][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8398 (0.8166)	Prec@1 69.000 (72.446)	Prec@5 98.000 (97.896)
2019-05-04 16:55:31 - INFO - EVALUATING - Epoch: [68][0/100]	Time 0.372 (0.372)	Data 0.359 (0.359)	Loss 1.0892 (1.0892)	Prec@1 64.000 (64.000)	Prec@5 97.000 (97.000)
2019-05-04 16:55:31 - INFO - EVALUATING - Epoch: [68][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.0853 (1.1642)	Prec@1 65.000 (60.431)	Prec@5 95.000 (95.667)
2019-05-04 16:55:31 - INFO - 
 Epoch: 69	Training Loss 0.8167 	Training Prec@1 72.480 	Training Prec@5 97.866 	Validation Loss 1.1571 	Validation Prec@1 60.810 	Validation Prec@5 95.670 	
2019-05-04 16:55:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:55:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:55:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:55:32 - INFO - TRAINING - Epoch: [69][0/500]	Time 0.277 (0.277)	Data 0.256 (0.256)	Loss 1.0061 (1.0061)	Prec@1 70.000 (70.000)	Prec@5 93.000 (93.000)
2019-05-04 16:55:33 - INFO - TRAINING - Epoch: [69][50/500]	Time 0.022 (0.025)	Data 0.000 (0.005)	Loss 0.7295 (0.8355)	Prec@1 78.000 (72.333)	Prec@5 97.000 (97.569)
2019-05-04 16:55:34 - INFO - TRAINING - Epoch: [69][100/500]	Time 0.022 (0.023)	Data 0.000 (0.003)	Loss 0.6652 (0.8244)	Prec@1 75.000 (72.545)	Prec@5 99.000 (97.723)
2019-05-04 16:55:35 - INFO - TRAINING - Epoch: [69][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.8997 (0.8163)	Prec@1 73.000 (72.868)	Prec@5 96.000 (97.854)
2019-05-04 16:55:36 - INFO - TRAINING - Epoch: [69][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9169 (0.8216)	Prec@1 66.000 (72.627)	Prec@5 96.000 (97.846)
2019-05-04 16:55:37 - INFO - TRAINING - Epoch: [69][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7187 (0.8225)	Prec@1 79.000 (72.462)	Prec@5 99.000 (97.884)
2019-05-04 16:55:38 - INFO - TRAINING - Epoch: [69][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8147 (0.8333)	Prec@1 69.000 (71.980)	Prec@5 100.000 (97.781)
2019-05-04 16:55:39 - INFO - TRAINING - Epoch: [69][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9150 (0.8327)	Prec@1 68.000 (71.989)	Prec@5 97.000 (97.772)
2019-05-04 16:55:40 - INFO - TRAINING - Epoch: [69][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.9434 (0.8297)	Prec@1 71.000 (72.092)	Prec@5 98.000 (97.808)
2019-05-04 16:55:41 - INFO - TRAINING - Epoch: [69][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6716 (0.8287)	Prec@1 79.000 (72.098)	Prec@5 100.000 (97.820)
2019-05-04 16:55:42 - INFO - EVALUATING - Epoch: [69][0/100]	Time 0.396 (0.396)	Data 0.385 (0.385)	Loss 1.3149 (1.3149)	Prec@1 58.000 (58.000)	Prec@5 95.000 (95.000)
2019-05-04 16:55:42 - INFO - EVALUATING - Epoch: [69][50/100]	Time 0.005 (0.014)	Data 0.000 (0.008)	Loss 1.2189 (1.3401)	Prec@1 60.000 (57.137)	Prec@5 92.000 (92.490)
2019-05-04 16:55:43 - INFO - 
 Epoch: 70	Training Loss 0.8262 	Training Prec@1 72.160 	Training Prec@5 97.788 	Validation Loss 1.3430 	Validation Prec@1 57.010 	Validation Prec@5 92.370 	
2019-05-04 16:55:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:55:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:55:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:55:43 - INFO - TRAINING - Epoch: [70][0/500]	Time 0.260 (0.260)	Data 0.234 (0.234)	Loss 0.5703 (0.5703)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-04 16:55:44 - INFO - TRAINING - Epoch: [70][50/500]	Time 0.025 (0.025)	Data 0.000 (0.005)	Loss 0.8733 (0.8427)	Prec@1 70.000 (71.471)	Prec@5 99.000 (97.745)
2019-05-04 16:55:45 - INFO - TRAINING - Epoch: [70][100/500]	Time 0.017 (0.023)	Data 0.000 (0.002)	Loss 0.7519 (0.8206)	Prec@1 79.000 (72.208)	Prec@5 98.000 (97.772)
2019-05-04 16:55:46 - INFO - TRAINING - Epoch: [70][150/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.7257 (0.8196)	Prec@1 76.000 (72.344)	Prec@5 99.000 (97.781)
2019-05-04 16:55:47 - INFO - TRAINING - Epoch: [70][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6779 (0.8228)	Prec@1 79.000 (72.294)	Prec@5 98.000 (97.761)
2019-05-04 16:55:48 - INFO - TRAINING - Epoch: [70][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7882 (0.8203)	Prec@1 74.000 (72.462)	Prec@5 97.000 (97.797)
2019-05-04 16:55:49 - INFO - TRAINING - Epoch: [70][300/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.6873 (0.8201)	Prec@1 75.000 (72.399)	Prec@5 100.000 (97.791)
2019-05-04 16:55:50 - INFO - TRAINING - Epoch: [70][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7804 (0.8224)	Prec@1 69.000 (72.311)	Prec@5 98.000 (97.792)
2019-05-04 16:55:51 - INFO - TRAINING - Epoch: [70][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7822 (0.8161)	Prec@1 77.000 (72.511)	Prec@5 98.000 (97.858)
2019-05-04 16:55:52 - INFO - TRAINING - Epoch: [70][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7331 (0.8139)	Prec@1 75.000 (72.574)	Prec@5 99.000 (97.907)
2019-05-04 16:55:53 - INFO - EVALUATING - Epoch: [70][0/100]	Time 0.270 (0.270)	Data 0.259 (0.259)	Loss 1.0497 (1.0497)	Prec@1 61.000 (61.000)	Prec@5 96.000 (96.000)
2019-05-04 16:55:53 - INFO - EVALUATING - Epoch: [70][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 1.2559 (1.1040)	Prec@1 57.000 (62.961)	Prec@5 96.000 (96.098)
2019-05-04 16:55:53 - INFO - 
 Epoch: 71	Training Loss 0.8140 	Training Prec@1 72.530 	Training Prec@5 97.914 	Validation Loss 1.1130 	Validation Prec@1 62.620 	Validation Prec@5 95.850 	
2019-05-04 16:55:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:55:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:55:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:55:54 - INFO - TRAINING - Epoch: [71][0/500]	Time 0.281 (0.281)	Data 0.253 (0.253)	Loss 0.9187 (0.9187)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-04 16:55:55 - INFO - TRAINING - Epoch: [71][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.7767 (0.8481)	Prec@1 74.000 (71.627)	Prec@5 98.000 (97.490)
2019-05-04 16:55:56 - INFO - TRAINING - Epoch: [71][100/500]	Time 0.025 (0.023)	Data 0.000 (0.003)	Loss 0.8825 (0.8229)	Prec@1 73.000 (72.614)	Prec@5 98.000 (97.743)
2019-05-04 16:55:57 - INFO - TRAINING - Epoch: [71][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.9226 (0.8203)	Prec@1 69.000 (72.715)	Prec@5 97.000 (97.768)
2019-05-04 16:55:58 - INFO - TRAINING - Epoch: [71][200/500]	Time 0.023 (0.022)	Data 0.000 (0.001)	Loss 0.9294 (0.8165)	Prec@1 70.000 (73.010)	Prec@5 99.000 (97.756)
2019-05-04 16:55:59 - INFO - TRAINING - Epoch: [71][250/500]	Time 0.027 (0.022)	Data 0.000 (0.001)	Loss 0.8237 (0.8190)	Prec@1 67.000 (72.861)	Prec@5 98.000 (97.737)
2019-05-04 16:56:00 - INFO - TRAINING - Epoch: [71][300/500]	Time 0.017 (0.022)	Data 0.000 (0.001)	Loss 0.6534 (0.8203)	Prec@1 76.000 (72.664)	Prec@5 99.000 (97.728)
2019-05-04 16:56:01 - INFO - TRAINING - Epoch: [71][350/500]	Time 0.032 (0.022)	Data 0.000 (0.001)	Loss 0.5538 (0.8188)	Prec@1 82.000 (72.641)	Prec@5 100.000 (97.729)
2019-05-04 16:56:02 - INFO - TRAINING - Epoch: [71][400/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.6934 (0.8190)	Prec@1 78.000 (72.576)	Prec@5 99.000 (97.756)
2019-05-04 16:56:03 - INFO - TRAINING - Epoch: [71][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7580 (0.8172)	Prec@1 76.000 (72.559)	Prec@5 99.000 (97.761)
2019-05-04 16:56:04 - INFO - EVALUATING - Epoch: [71][0/100]	Time 0.347 (0.347)	Data 0.333 (0.333)	Loss 1.3881 (1.3881)	Prec@1 58.000 (58.000)	Prec@5 90.000 (90.000)
2019-05-04 16:56:05 - INFO - EVALUATING - Epoch: [71][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.4325 (1.4866)	Prec@1 49.000 (51.196)	Prec@5 95.000 (89.980)
2019-05-04 16:56:05 - INFO - 
 Epoch: 72	Training Loss 0.8180 	Training Prec@1 72.476 	Training Prec@5 97.772 	Validation Loss 1.4660 	Validation Prec@1 51.980 	Validation Prec@5 90.130 	
2019-05-04 16:56:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:56:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:56:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:56:05 - INFO - TRAINING - Epoch: [72][0/500]	Time 0.276 (0.276)	Data 0.247 (0.247)	Loss 0.8293 (0.8293)	Prec@1 72.000 (72.000)	Prec@5 97.000 (97.000)
2019-05-04 16:56:06 - INFO - TRAINING - Epoch: [72][50/500]	Time 0.023 (0.024)	Data 0.000 (0.005)	Loss 0.7335 (0.8627)	Prec@1 72.000 (70.667)	Prec@5 100.000 (97.235)
2019-05-04 16:56:07 - INFO - TRAINING - Epoch: [72][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 0.6595 (0.8278)	Prec@1 78.000 (71.653)	Prec@5 100.000 (97.505)
2019-05-04 16:56:08 - INFO - TRAINING - Epoch: [72][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.8097 (0.8168)	Prec@1 70.000 (72.099)	Prec@5 97.000 (97.702)
2019-05-04 16:56:09 - INFO - TRAINING - Epoch: [72][200/500]	Time 0.014 (0.022)	Data 0.000 (0.001)	Loss 0.6171 (0.8129)	Prec@1 79.000 (72.458)	Prec@5 99.000 (97.781)
2019-05-04 16:56:11 - INFO - TRAINING - Epoch: [72][250/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.8602 (0.8146)	Prec@1 74.000 (72.446)	Prec@5 97.000 (97.793)
2019-05-04 16:56:11 - INFO - TRAINING - Epoch: [72][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8182 (0.8176)	Prec@1 72.000 (72.412)	Prec@5 96.000 (97.777)
2019-05-04 16:56:12 - INFO - TRAINING - Epoch: [72][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5784 (0.8186)	Prec@1 81.000 (72.322)	Prec@5 99.000 (97.778)
2019-05-04 16:56:13 - INFO - TRAINING - Epoch: [72][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7824 (0.8132)	Prec@1 77.000 (72.571)	Prec@5 100.000 (97.788)
2019-05-04 16:56:14 - INFO - TRAINING - Epoch: [72][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6472 (0.8107)	Prec@1 79.000 (72.594)	Prec@5 99.000 (97.812)
2019-05-04 16:56:16 - INFO - EVALUATING - Epoch: [72][0/100]	Time 0.352 (0.352)	Data 0.343 (0.343)	Loss 1.0106 (1.0106)	Prec@1 68.000 (68.000)	Prec@5 98.000 (98.000)
2019-05-04 16:56:16 - INFO - EVALUATING - Epoch: [72][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 1.1128 (1.1232)	Prec@1 65.000 (61.412)	Prec@5 95.000 (95.804)
2019-05-04 16:56:16 - INFO - 
 Epoch: 73	Training Loss 0.8136 	Training Prec@1 72.486 	Training Prec@5 97.802 	Validation Loss 1.1277 	Validation Prec@1 62.300 	Validation Prec@5 95.510 	
2019-05-04 16:56:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:56:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:56:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:56:17 - INFO - TRAINING - Epoch: [73][0/500]	Time 0.268 (0.268)	Data 0.237 (0.237)	Loss 0.9115 (0.9115)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-05-04 16:56:18 - INFO - TRAINING - Epoch: [73][50/500]	Time 0.013 (0.025)	Data 0.000 (0.005)	Loss 0.8758 (0.8611)	Prec@1 67.000 (71.157)	Prec@5 99.000 (97.686)
2019-05-04 16:56:19 - INFO - TRAINING - Epoch: [73][100/500]	Time 0.016 (0.023)	Data 0.000 (0.003)	Loss 0.7788 (0.8305)	Prec@1 74.000 (71.871)	Prec@5 99.000 (97.921)
2019-05-04 16:56:20 - INFO - TRAINING - Epoch: [73][150/500]	Time 0.029 (0.022)	Data 0.000 (0.002)	Loss 0.9559 (0.8123)	Prec@1 65.000 (72.483)	Prec@5 97.000 (98.046)
2019-05-04 16:56:21 - INFO - TRAINING - Epoch: [73][200/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.9831 (0.8159)	Prec@1 67.000 (72.448)	Prec@5 96.000 (97.945)
2019-05-04 16:56:22 - INFO - TRAINING - Epoch: [73][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7635 (0.8110)	Prec@1 77.000 (72.681)	Prec@5 97.000 (97.892)
2019-05-04 16:56:23 - INFO - TRAINING - Epoch: [73][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6612 (0.8104)	Prec@1 79.000 (72.804)	Prec@5 98.000 (97.884)
2019-05-04 16:56:24 - INFO - TRAINING - Epoch: [73][350/500]	Time 0.011 (0.021)	Data 0.000 (0.001)	Loss 0.7813 (0.8110)	Prec@1 73.000 (72.741)	Prec@5 98.000 (97.877)
2019-05-04 16:56:25 - INFO - TRAINING - Epoch: [73][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8076 (0.8124)	Prec@1 72.000 (72.696)	Prec@5 97.000 (97.853)
2019-05-04 16:56:26 - INFO - TRAINING - Epoch: [73][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.7165 (0.8124)	Prec@1 72.000 (72.647)	Prec@5 100.000 (97.856)
2019-05-04 16:56:27 - INFO - EVALUATING - Epoch: [73][0/100]	Time 0.362 (0.362)	Data 0.348 (0.348)	Loss 0.9543 (0.9543)	Prec@1 71.000 (71.000)	Prec@5 96.000 (96.000)
2019-05-04 16:56:27 - INFO - EVALUATING - Epoch: [73][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 1.0226 (0.9723)	Prec@1 67.000 (67.863)	Prec@5 96.000 (96.353)
2019-05-04 16:56:27 - INFO - 
 Epoch: 74	Training Loss 0.8110 	Training Prec@1 72.684 	Training Prec@5 97.848 	Validation Loss 0.9684 	Validation Prec@1 67.980 	Validation Prec@5 96.450 	
2019-05-04 16:56:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:56:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:56:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:56:28 - INFO - TRAINING - Epoch: [74][0/500]	Time 0.267 (0.267)	Data 0.241 (0.241)	Loss 0.8766 (0.8766)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-04 16:56:29 - INFO - TRAINING - Epoch: [74][50/500]	Time 0.018 (0.026)	Data 0.000 (0.005)	Loss 1.0070 (0.8498)	Prec@1 67.000 (71.922)	Prec@5 98.000 (97.471)
2019-05-04 16:56:30 - INFO - TRAINING - Epoch: [74][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.8716 (0.8336)	Prec@1 70.000 (72.208)	Prec@5 99.000 (97.644)
2019-05-04 16:56:31 - INFO - TRAINING - Epoch: [74][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.6949 (0.8324)	Prec@1 82.000 (72.199)	Prec@5 100.000 (97.735)
2019-05-04 16:56:32 - INFO - TRAINING - Epoch: [74][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0182 (0.8322)	Prec@1 64.000 (72.174)	Prec@5 98.000 (97.751)
2019-05-04 16:56:33 - INFO - TRAINING - Epoch: [74][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.9281 (0.8344)	Prec@1 66.000 (71.992)	Prec@5 99.000 (97.777)
2019-05-04 16:56:34 - INFO - TRAINING - Epoch: [74][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8649 (0.8286)	Prec@1 72.000 (72.213)	Prec@5 97.000 (97.831)
2019-05-04 16:56:35 - INFO - TRAINING - Epoch: [74][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7336 (0.8292)	Prec@1 78.000 (72.123)	Prec@5 98.000 (97.826)
2019-05-04 16:56:36 - INFO - TRAINING - Epoch: [74][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.8469 (0.8276)	Prec@1 71.000 (72.197)	Prec@5 98.000 (97.838)
2019-05-04 16:56:37 - INFO - TRAINING - Epoch: [74][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.9072 (0.8251)	Prec@1 71.000 (72.310)	Prec@5 96.000 (97.831)
2019-05-04 16:56:38 - INFO - EVALUATING - Epoch: [74][0/100]	Time 0.382 (0.382)	Data 0.369 (0.369)	Loss 1.4618 (1.4618)	Prec@1 52.000 (52.000)	Prec@5 91.000 (91.000)
2019-05-04 16:56:38 - INFO - EVALUATING - Epoch: [74][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 1.4456 (1.4577)	Prec@1 47.000 (53.157)	Prec@5 93.000 (91.647)
2019-05-04 16:56:39 - INFO - 
 Epoch: 75	Training Loss 0.8225 	Training Prec@1 72.380 	Training Prec@5 97.828 	Validation Loss 1.4633 	Validation Prec@1 52.550 	Validation Prec@5 91.640 	
2019-05-04 16:56:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:56:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:56:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:56:39 - INFO - TRAINING - Epoch: [75][0/500]	Time 0.292 (0.292)	Data 0.259 (0.259)	Loss 0.7417 (0.7417)	Prec@1 75.000 (75.000)	Prec@5 96.000 (96.000)
2019-05-04 16:56:40 - INFO - TRAINING - Epoch: [75][50/500]	Time 0.026 (0.027)	Data 0.000 (0.005)	Loss 1.0431 (0.8213)	Prec@1 66.000 (72.294)	Prec@5 97.000 (97.941)
2019-05-04 16:56:41 - INFO - TRAINING - Epoch: [75][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.9082 (0.8213)	Prec@1 72.000 (71.970)	Prec@5 96.000 (97.980)
2019-05-04 16:56:42 - INFO - TRAINING - Epoch: [75][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.8624 (0.8114)	Prec@1 70.000 (72.510)	Prec@5 98.000 (97.921)
2019-05-04 16:56:43 - INFO - TRAINING - Epoch: [75][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6505 (0.8097)	Prec@1 79.000 (72.617)	Prec@5 97.000 (98.000)
2019-05-04 16:56:44 - INFO - TRAINING - Epoch: [75][250/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.7987 (0.8048)	Prec@1 73.000 (72.861)	Prec@5 98.000 (97.968)
2019-05-04 16:56:45 - INFO - TRAINING - Epoch: [75][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7645 (0.8106)	Prec@1 71.000 (72.678)	Prec@5 99.000 (97.967)
2019-05-04 16:56:46 - INFO - TRAINING - Epoch: [75][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.9726 (0.8088)	Prec@1 72.000 (72.795)	Prec@5 98.000 (97.974)
2019-05-04 16:56:47 - INFO - TRAINING - Epoch: [75][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8247 (0.8066)	Prec@1 73.000 (72.935)	Prec@5 96.000 (97.963)
2019-05-04 16:56:48 - INFO - TRAINING - Epoch: [75][450/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.7145 (0.8075)	Prec@1 72.000 (72.898)	Prec@5 99.000 (97.936)
2019-05-04 16:56:49 - INFO - EVALUATING - Epoch: [75][0/100]	Time 0.337 (0.337)	Data 0.329 (0.329)	Loss 0.8833 (0.8833)	Prec@1 65.000 (65.000)	Prec@5 96.000 (96.000)
2019-05-04 16:56:49 - INFO - EVALUATING - Epoch: [75][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.0224 (1.0358)	Prec@1 63.000 (63.549)	Prec@5 97.000 (96.098)
2019-05-04 16:56:49 - INFO - 
 Epoch: 76	Training Loss 0.8102 	Training Prec@1 72.826 	Training Prec@5 97.914 	Validation Loss 1.0410 	Validation Prec@1 63.300 	Validation Prec@5 96.200 	
2019-05-04 16:56:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:56:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:56:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:56:50 - INFO - TRAINING - Epoch: [76][0/500]	Time 0.292 (0.292)	Data 0.265 (0.265)	Loss 0.7791 (0.7791)	Prec@1 71.000 (71.000)	Prec@5 100.000 (100.000)
2019-05-04 16:56:51 - INFO - TRAINING - Epoch: [76][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.8393 (0.8325)	Prec@1 72.000 (71.843)	Prec@5 98.000 (97.882)
2019-05-04 16:56:52 - INFO - TRAINING - Epoch: [76][100/500]	Time 0.029 (0.022)	Data 0.000 (0.003)	Loss 0.9488 (0.8332)	Prec@1 73.000 (72.129)	Prec@5 95.000 (97.861)
2019-05-04 16:56:53 - INFO - TRAINING - Epoch: [76][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.8594 (0.8211)	Prec@1 67.000 (72.570)	Prec@5 99.000 (97.921)
2019-05-04 16:56:54 - INFO - TRAINING - Epoch: [76][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7619 (0.8249)	Prec@1 75.000 (72.353)	Prec@5 99.000 (97.776)
2019-05-04 16:56:55 - INFO - TRAINING - Epoch: [76][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0398 (0.8223)	Prec@1 69.000 (72.526)	Prec@5 96.000 (97.773)
2019-05-04 16:56:56 - INFO - TRAINING - Epoch: [76][300/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7765 (0.8178)	Prec@1 69.000 (72.701)	Prec@5 100.000 (97.797)
2019-05-04 16:56:57 - INFO - TRAINING - Epoch: [76][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.8163 (0.8157)	Prec@1 71.000 (72.621)	Prec@5 98.000 (97.889)
2019-05-04 16:56:58 - INFO - TRAINING - Epoch: [76][400/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7750 (0.8165)	Prec@1 74.000 (72.663)	Prec@5 99.000 (97.888)
2019-05-04 16:56:59 - INFO - TRAINING - Epoch: [76][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8768 (0.8155)	Prec@1 70.000 (72.674)	Prec@5 98.000 (97.865)
2019-05-04 16:57:00 - INFO - EVALUATING - Epoch: [76][0/100]	Time 0.367 (0.367)	Data 0.355 (0.355)	Loss 1.4365 (1.4365)	Prec@1 53.000 (53.000)	Prec@5 91.000 (91.000)
2019-05-04 16:57:00 - INFO - EVALUATING - Epoch: [76][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.6002 (1.4606)	Prec@1 51.000 (51.843)	Prec@5 89.000 (91.216)
2019-05-04 16:57:00 - INFO - 
 Epoch: 77	Training Loss 0.8133 	Training Prec@1 72.730 	Training Prec@5 97.854 	Validation Loss 1.4454 	Validation Prec@1 52.390 	Validation Prec@5 91.400 	
2019-05-04 16:57:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:01 - INFO - TRAINING - Epoch: [77][0/500]	Time 0.273 (0.273)	Data 0.247 (0.247)	Loss 0.6160 (0.6160)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-04 16:57:02 - INFO - TRAINING - Epoch: [77][50/500]	Time 0.027 (0.026)	Data 0.000 (0.005)	Loss 0.9361 (0.8390)	Prec@1 64.000 (71.686)	Prec@5 98.000 (97.588)
2019-05-04 16:57:03 - INFO - TRAINING - Epoch: [77][100/500]	Time 0.018 (0.023)	Data 0.000 (0.003)	Loss 0.7732 (0.8095)	Prec@1 74.000 (72.980)	Prec@5 98.000 (97.802)
2019-05-04 16:57:04 - INFO - TRAINING - Epoch: [77][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.8160 (0.8054)	Prec@1 71.000 (72.993)	Prec@5 97.000 (97.934)
2019-05-04 16:57:05 - INFO - TRAINING - Epoch: [77][200/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.8597 (0.8060)	Prec@1 72.000 (72.970)	Prec@5 98.000 (97.881)
2019-05-04 16:57:06 - INFO - TRAINING - Epoch: [77][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8211 (0.8066)	Prec@1 77.000 (72.769)	Prec@5 98.000 (97.920)
2019-05-04 16:57:07 - INFO - TRAINING - Epoch: [77][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7950 (0.8071)	Prec@1 76.000 (72.804)	Prec@5 97.000 (97.867)
2019-05-04 16:57:08 - INFO - TRAINING - Epoch: [77][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7942 (0.8037)	Prec@1 76.000 (72.906)	Prec@5 98.000 (97.875)
2019-05-04 16:57:09 - INFO - TRAINING - Epoch: [77][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7016 (0.7994)	Prec@1 77.000 (73.047)	Prec@5 97.000 (97.875)
2019-05-04 16:57:10 - INFO - TRAINING - Epoch: [77][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8668 (0.8018)	Prec@1 68.000 (72.984)	Prec@5 98.000 (97.867)
2019-05-04 16:57:11 - INFO - EVALUATING - Epoch: [77][0/100]	Time 0.379 (0.379)	Data 0.368 (0.368)	Loss 1.0130 (1.0130)	Prec@1 68.000 (68.000)	Prec@5 96.000 (96.000)
2019-05-04 16:57:12 - INFO - EVALUATING - Epoch: [77][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.3128 (1.1331)	Prec@1 54.000 (61.667)	Prec@5 95.000 (95.667)
2019-05-04 16:57:12 - INFO - 
 Epoch: 78	Training Loss 0.8046 	Training Prec@1 72.940 	Training Prec@5 97.874 	Validation Loss 1.1343 	Validation Prec@1 61.700 	Validation Prec@5 95.640 	
2019-05-04 16:57:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:12 - INFO - TRAINING - Epoch: [78][0/500]	Time 0.279 (0.279)	Data 0.244 (0.244)	Loss 0.8221 (0.8221)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-04 16:57:13 - INFO - TRAINING - Epoch: [78][50/500]	Time 0.014 (0.024)	Data 0.000 (0.005)	Loss 1.0608 (0.8306)	Prec@1 66.000 (72.412)	Prec@5 96.000 (97.451)
2019-05-04 16:57:14 - INFO - TRAINING - Epoch: [78][100/500]	Time 0.029 (0.023)	Data 0.000 (0.003)	Loss 0.7973 (0.8214)	Prec@1 73.000 (72.644)	Prec@5 98.000 (97.426)
2019-05-04 16:57:15 - INFO - TRAINING - Epoch: [78][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.6790 (0.8189)	Prec@1 74.000 (72.821)	Prec@5 99.000 (97.470)
2019-05-04 16:57:16 - INFO - TRAINING - Epoch: [78][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.8319 (0.8179)	Prec@1 73.000 (72.731)	Prec@5 97.000 (97.507)
2019-05-04 16:57:17 - INFO - TRAINING - Epoch: [78][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.6466 (0.8159)	Prec@1 77.000 (72.729)	Prec@5 100.000 (97.610)
2019-05-04 16:57:18 - INFO - TRAINING - Epoch: [78][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9011 (0.8132)	Prec@1 70.000 (72.757)	Prec@5 96.000 (97.645)
2019-05-04 16:57:19 - INFO - TRAINING - Epoch: [78][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7301 (0.8110)	Prec@1 79.000 (72.795)	Prec@5 99.000 (97.689)
2019-05-04 16:57:20 - INFO - TRAINING - Epoch: [78][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.8491 (0.8106)	Prec@1 70.000 (72.721)	Prec@5 99.000 (97.671)
2019-05-04 16:57:21 - INFO - TRAINING - Epoch: [78][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8140 (0.8089)	Prec@1 74.000 (72.814)	Prec@5 99.000 (97.707)
2019-05-04 16:57:23 - INFO - EVALUATING - Epoch: [78][0/100]	Time 0.391 (0.391)	Data 0.377 (0.377)	Loss 0.8431 (0.8431)	Prec@1 71.000 (71.000)	Prec@5 97.000 (97.000)
2019-05-04 16:57:23 - INFO - EVALUATING - Epoch: [78][50/100]	Time 0.005 (0.013)	Data 0.000 (0.008)	Loss 0.9376 (0.9163)	Prec@1 69.000 (69.039)	Prec@5 97.000 (97.353)
2019-05-04 16:57:23 - INFO - 
 Epoch: 79	Training Loss 0.8083 	Training Prec@1 72.900 	Training Prec@5 97.720 	Validation Loss 0.9207 	Validation Prec@1 68.820 	Validation Prec@5 97.320 	
2019-05-04 16:57:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:23 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:24 - INFO - TRAINING - Epoch: [79][0/500]	Time 0.298 (0.298)	Data 0.272 (0.272)	Loss 0.7695 (0.7695)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-04 16:57:25 - INFO - TRAINING - Epoch: [79][50/500]	Time 0.021 (0.025)	Data 0.000 (0.005)	Loss 0.7548 (0.8269)	Prec@1 73.000 (71.588)	Prec@5 99.000 (98.078)
2019-05-04 16:57:26 - INFO - TRAINING - Epoch: [79][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.7246 (0.8349)	Prec@1 76.000 (71.743)	Prec@5 99.000 (97.772)
2019-05-04 16:57:27 - INFO - TRAINING - Epoch: [79][150/500]	Time 0.030 (0.021)	Data 0.000 (0.002)	Loss 0.6936 (0.8323)	Prec@1 77.000 (71.887)	Prec@5 99.000 (97.854)
2019-05-04 16:57:28 - INFO - TRAINING - Epoch: [79][200/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.7487 (0.8248)	Prec@1 71.000 (72.104)	Prec@5 100.000 (97.886)
2019-05-04 16:57:29 - INFO - TRAINING - Epoch: [79][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7150 (0.8236)	Prec@1 75.000 (72.199)	Prec@5 99.000 (97.841)
2019-05-04 16:57:30 - INFO - TRAINING - Epoch: [79][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7649 (0.8185)	Prec@1 76.000 (72.332)	Prec@5 99.000 (97.877)
2019-05-04 16:57:31 - INFO - TRAINING - Epoch: [79][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8273 (0.8154)	Prec@1 73.000 (72.362)	Prec@5 99.000 (97.946)
2019-05-04 16:57:32 - INFO - TRAINING - Epoch: [79][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.9415 (0.8193)	Prec@1 69.000 (72.202)	Prec@5 97.000 (97.925)
2019-05-04 16:57:33 - INFO - TRAINING - Epoch: [79][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7046 (0.8187)	Prec@1 78.000 (72.286)	Prec@5 99.000 (97.874)
2019-05-04 16:57:34 - INFO - EVALUATING - Epoch: [79][0/100]	Time 0.374 (0.374)	Data 0.361 (0.361)	Loss 1.2934 (1.2934)	Prec@1 54.000 (54.000)	Prec@5 97.000 (97.000)
2019-05-04 16:57:34 - INFO - EVALUATING - Epoch: [79][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.1651 (1.2529)	Prec@1 63.000 (56.431)	Prec@5 96.000 (94.863)
2019-05-04 16:57:35 - INFO - 
 Epoch: 80	Training Loss 0.8197 	Training Prec@1 72.292 	Training Prec@5 97.848 	Validation Loss 1.2656 	Validation Prec@1 56.150 	Validation Prec@5 94.570 	
2019-05-04 16:57:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:35 - INFO - TRAINING - Epoch: [80][0/500]	Time 0.259 (0.259)	Data 0.229 (0.229)	Loss 0.6828 (0.6828)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-05-04 16:57:36 - INFO - TRAINING - Epoch: [80][50/500]	Time 0.019 (0.022)	Data 0.000 (0.005)	Loss 0.6808 (0.8323)	Prec@1 77.000 (72.510)	Prec@5 99.000 (97.451)
2019-05-04 16:57:37 - INFO - TRAINING - Epoch: [80][100/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.8942 (0.8180)	Prec@1 74.000 (72.881)	Prec@5 97.000 (97.653)
2019-05-04 16:57:38 - INFO - TRAINING - Epoch: [80][150/500]	Time 0.027 (0.021)	Data 0.000 (0.002)	Loss 0.6805 (0.8228)	Prec@1 75.000 (72.702)	Prec@5 98.000 (97.788)
2019-05-04 16:57:39 - INFO - TRAINING - Epoch: [80][200/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.9233 (0.8185)	Prec@1 67.000 (72.657)	Prec@5 97.000 (97.965)
2019-05-04 16:57:40 - INFO - TRAINING - Epoch: [80][250/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.7216 (0.8129)	Prec@1 74.000 (72.769)	Prec@5 99.000 (97.980)
2019-05-04 16:57:41 - INFO - TRAINING - Epoch: [80][300/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.8364 (0.8140)	Prec@1 69.000 (72.757)	Prec@5 100.000 (97.940)
2019-05-04 16:57:42 - INFO - TRAINING - Epoch: [80][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7627 (0.8190)	Prec@1 74.000 (72.521)	Prec@5 98.000 (97.895)
2019-05-04 16:57:43 - INFO - TRAINING - Epoch: [80][400/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.8381 (0.8202)	Prec@1 71.000 (72.469)	Prec@5 98.000 (97.875)
2019-05-04 16:57:44 - INFO - TRAINING - Epoch: [80][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7642 (0.8181)	Prec@1 73.000 (72.519)	Prec@5 99.000 (97.927)
2019-05-04 16:57:45 - INFO - EVALUATING - Epoch: [80][0/100]	Time 0.353 (0.353)	Data 0.344 (0.344)	Loss 2.0060 (2.0060)	Prec@1 47.000 (47.000)	Prec@5 84.000 (84.000)
2019-05-04 16:57:45 - INFO - EVALUATING - Epoch: [80][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 1.8274 (1.7947)	Prec@1 47.000 (50.588)	Prec@5 85.000 (86.529)
2019-05-04 16:57:46 - INFO - 
 Epoch: 81	Training Loss 0.8166 	Training Prec@1 72.614 	Training Prec@5 97.898 	Validation Loss 1.7993 	Validation Prec@1 50.360 	Validation Prec@5 86.650 	
2019-05-04 16:57:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:46 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:46 - INFO - TRAINING - Epoch: [81][0/500]	Time 0.265 (0.265)	Data 0.240 (0.240)	Loss 0.8880 (0.8880)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-04 16:57:47 - INFO - TRAINING - Epoch: [81][50/500]	Time 0.021 (0.023)	Data 0.000 (0.005)	Loss 0.7994 (0.8445)	Prec@1 73.000 (71.451)	Prec@5 97.000 (97.765)
2019-05-04 16:57:48 - INFO - TRAINING - Epoch: [81][100/500]	Time 0.019 (0.021)	Data 0.000 (0.003)	Loss 0.8576 (0.8413)	Prec@1 71.000 (71.564)	Prec@5 96.000 (97.792)
2019-05-04 16:57:49 - INFO - TRAINING - Epoch: [81][150/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.8148 (0.8379)	Prec@1 75.000 (71.848)	Prec@5 97.000 (97.775)
2019-05-04 16:57:50 - INFO - TRAINING - Epoch: [81][200/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8278 (0.8243)	Prec@1 71.000 (72.383)	Prec@5 100.000 (97.841)
2019-05-04 16:57:51 - INFO - TRAINING - Epoch: [81][250/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7863 (0.8271)	Prec@1 73.000 (72.299)	Prec@5 98.000 (97.733)
2019-05-04 16:57:52 - INFO - TRAINING - Epoch: [81][300/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.8265 (0.8223)	Prec@1 75.000 (72.505)	Prec@5 98.000 (97.764)
2019-05-04 16:57:53 - INFO - TRAINING - Epoch: [81][350/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7563 (0.8142)	Prec@1 78.000 (72.812)	Prec@5 97.000 (97.826)
2019-05-04 16:57:54 - INFO - TRAINING - Epoch: [81][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8894 (0.8132)	Prec@1 66.000 (72.895)	Prec@5 97.000 (97.810)
2019-05-04 16:57:55 - INFO - TRAINING - Epoch: [81][450/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.7989 (0.8115)	Prec@1 69.000 (72.838)	Prec@5 99.000 (97.847)
2019-05-04 16:57:56 - INFO - EVALUATING - Epoch: [81][0/100]	Time 0.372 (0.372)	Data 0.362 (0.362)	Loss 1.1426 (1.1426)	Prec@1 64.000 (64.000)	Prec@5 94.000 (94.000)
2019-05-04 16:57:56 - INFO - EVALUATING - Epoch: [81][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.0788 (1.0941)	Prec@1 61.000 (61.804)	Prec@5 94.000 (96.000)
2019-05-04 16:57:57 - INFO - 
 Epoch: 82	Training Loss 0.8122 	Training Prec@1 72.848 	Training Prec@5 97.826 	Validation Loss 1.1017 	Validation Prec@1 61.630 	Validation Prec@5 95.780 	
2019-05-04 16:57:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:57:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:57:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:57:57 - INFO - TRAINING - Epoch: [82][0/500]	Time 0.283 (0.283)	Data 0.254 (0.254)	Loss 0.9125 (0.9125)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-04 16:57:58 - INFO - TRAINING - Epoch: [82][50/500]	Time 0.020 (0.025)	Data 0.000 (0.005)	Loss 1.0538 (0.8538)	Prec@1 65.000 (70.784)	Prec@5 97.000 (97.765)
2019-05-04 16:57:59 - INFO - TRAINING - Epoch: [82][100/500]	Time 0.019 (0.022)	Data 0.000 (0.003)	Loss 0.6425 (0.8247)	Prec@1 78.000 (72.099)	Prec@5 99.000 (97.743)
2019-05-04 16:58:00 - INFO - TRAINING - Epoch: [82][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.9088 (0.8206)	Prec@1 65.000 (72.159)	Prec@5 99.000 (97.742)
2019-05-04 16:58:01 - INFO - TRAINING - Epoch: [82][200/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.9593 (0.8189)	Prec@1 69.000 (72.299)	Prec@5 98.000 (97.786)
2019-05-04 16:58:02 - INFO - TRAINING - Epoch: [82][250/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8011 (0.8188)	Prec@1 75.000 (72.359)	Prec@5 96.000 (97.813)
2019-05-04 16:58:03 - INFO - TRAINING - Epoch: [82][300/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7292 (0.8160)	Prec@1 73.000 (72.495)	Prec@5 98.000 (97.821)
2019-05-04 16:58:04 - INFO - TRAINING - Epoch: [82][350/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.9008 (0.8178)	Prec@1 72.000 (72.422)	Prec@5 97.000 (97.792)
2019-05-04 16:58:04 - INFO - TRAINING - Epoch: [82][400/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.8195 (0.8167)	Prec@1 67.000 (72.476)	Prec@5 98.000 (97.830)
2019-05-04 16:58:05 - INFO - TRAINING - Epoch: [82][450/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.9623 (0.8170)	Prec@1 67.000 (72.539)	Prec@5 97.000 (97.823)
2019-05-04 16:58:07 - INFO - EVALUATING - Epoch: [82][0/100]	Time 0.385 (0.385)	Data 0.375 (0.375)	Loss 0.9615 (0.9615)	Prec@1 72.000 (72.000)	Prec@5 95.000 (95.000)
2019-05-04 16:58:07 - INFO - EVALUATING - Epoch: [82][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 1.1328 (1.1061)	Prec@1 63.000 (63.176)	Prec@5 95.000 (95.373)
2019-05-04 16:58:07 - INFO - 
 Epoch: 83	Training Loss 0.8169 	Training Prec@1 72.496 	Training Prec@5 97.842 	Validation Loss 1.1050 	Validation Prec@1 63.160 	Validation Prec@5 95.730 	
2019-05-04 16:58:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:58:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:58:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:58:08 - INFO - TRAINING - Epoch: [83][0/500]	Time 0.306 (0.306)	Data 0.286 (0.286)	Loss 0.7502 (0.7502)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-04 16:58:09 - INFO - TRAINING - Epoch: [83][50/500]	Time 0.019 (0.024)	Data 0.000 (0.006)	Loss 0.8965 (0.8381)	Prec@1 74.000 (71.412)	Prec@5 97.000 (97.745)
2019-05-04 16:58:10 - INFO - TRAINING - Epoch: [83][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.9284 (0.8331)	Prec@1 69.000 (72.277)	Prec@5 98.000 (97.455)
2019-05-04 16:58:11 - INFO - TRAINING - Epoch: [83][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.7454 (0.8292)	Prec@1 76.000 (72.166)	Prec@5 98.000 (97.570)
2019-05-04 16:58:12 - INFO - TRAINING - Epoch: [83][200/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.9318 (0.8238)	Prec@1 67.000 (72.403)	Prec@5 96.000 (97.662)
2019-05-04 16:58:13 - INFO - TRAINING - Epoch: [83][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7193 (0.8160)	Prec@1 76.000 (72.737)	Prec@5 98.000 (97.705)
2019-05-04 16:58:13 - INFO - TRAINING - Epoch: [83][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.6970 (0.8187)	Prec@1 80.000 (72.638)	Prec@5 98.000 (97.694)
2019-05-04 16:58:14 - INFO - TRAINING - Epoch: [83][350/500]	Time 0.013 (0.019)	Data 0.000 (0.001)	Loss 0.6526 (0.8120)	Prec@1 78.000 (72.886)	Prec@5 100.000 (97.701)
2019-05-04 16:58:15 - INFO - TRAINING - Epoch: [83][400/500]	Time 0.025 (0.019)	Data 0.000 (0.001)	Loss 0.7789 (0.8126)	Prec@1 74.000 (72.873)	Prec@5 98.000 (97.721)
2019-05-04 16:58:16 - INFO - TRAINING - Epoch: [83][450/500]	Time 0.024 (0.019)	Data 0.000 (0.001)	Loss 0.8037 (0.8121)	Prec@1 76.000 (72.889)	Prec@5 98.000 (97.732)
2019-05-04 16:58:18 - INFO - EVALUATING - Epoch: [83][0/100]	Time 0.373 (0.373)	Data 0.362 (0.362)	Loss 1.6456 (1.6456)	Prec@1 50.000 (50.000)	Prec@5 92.000 (92.000)
2019-05-04 16:58:18 - INFO - EVALUATING - Epoch: [83][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.6971 (1.5709)	Prec@1 44.000 (50.608)	Prec@5 88.000 (91.333)
2019-05-04 16:58:18 - INFO - 
 Epoch: 84	Training Loss 0.8113 	Training Prec@1 72.870 	Training Prec@5 97.736 	Validation Loss 1.5707 	Validation Prec@1 50.520 	Validation Prec@5 91.210 	
2019-05-04 16:58:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:58:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:58:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:58:19 - INFO - TRAINING - Epoch: [84][0/500]	Time 0.286 (0.286)	Data 0.261 (0.261)	Loss 0.7588 (0.7588)	Prec@1 76.000 (76.000)	Prec@5 96.000 (96.000)
2019-05-04 16:58:20 - INFO - TRAINING - Epoch: [84][50/500]	Time 0.026 (0.025)	Data 0.000 (0.005)	Loss 0.9603 (0.8238)	Prec@1 70.000 (72.902)	Prec@5 97.000 (97.275)
2019-05-04 16:58:21 - INFO - TRAINING - Epoch: [84][100/500]	Time 0.022 (0.022)	Data 0.000 (0.003)	Loss 0.8484 (0.8219)	Prec@1 72.000 (72.663)	Prec@5 100.000 (97.584)
2019-05-04 16:58:22 - INFO - TRAINING - Epoch: [84][150/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.8419 (0.8305)	Prec@1 73.000 (72.517)	Prec@5 97.000 (97.570)
2019-05-04 16:58:23 - INFO - TRAINING - Epoch: [84][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7815 (0.8278)	Prec@1 74.000 (72.532)	Prec@5 99.000 (97.632)
2019-05-04 16:58:24 - INFO - TRAINING - Epoch: [84][250/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.8041 (0.8221)	Prec@1 72.000 (72.538)	Prec@5 98.000 (97.685)
2019-05-04 16:58:25 - INFO - TRAINING - Epoch: [84][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8817 (0.8173)	Prec@1 72.000 (72.625)	Prec@5 99.000 (97.744)
2019-05-04 16:58:25 - INFO - TRAINING - Epoch: [84][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7802 (0.8181)	Prec@1 70.000 (72.672)	Prec@5 99.000 (97.758)
2019-05-04 16:58:26 - INFO - TRAINING - Epoch: [84][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7446 (0.8163)	Prec@1 72.000 (72.743)	Prec@5 99.000 (97.736)
2019-05-04 16:58:27 - INFO - TRAINING - Epoch: [84][450/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.9278 (0.8153)	Prec@1 65.000 (72.787)	Prec@5 96.000 (97.758)
2019-05-04 16:58:29 - INFO - EVALUATING - Epoch: [84][0/100]	Time 0.376 (0.376)	Data 0.369 (0.369)	Loss 1.5114 (1.5114)	Prec@1 43.000 (43.000)	Prec@5 94.000 (94.000)
2019-05-04 16:58:29 - INFO - EVALUATING - Epoch: [84][50/100]	Time 0.007 (0.014)	Data 0.000 (0.008)	Loss 1.5225 (1.6391)	Prec@1 48.000 (45.608)	Prec@5 91.000 (90.314)
2019-05-04 16:58:29 - INFO - 
 Epoch: 85	Training Loss 0.8133 	Training Prec@1 72.798 	Training Prec@5 97.784 	Validation Loss 1.6409 	Validation Prec@1 45.780 	Validation Prec@5 90.500 	
2019-05-04 16:58:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:58:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:58:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:58:30 - INFO - TRAINING - Epoch: [85][0/500]	Time 0.274 (0.274)	Data 0.253 (0.253)	Loss 0.6496 (0.6496)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-04 16:58:31 - INFO - TRAINING - Epoch: [85][50/500]	Time 0.016 (0.022)	Data 0.000 (0.005)	Loss 0.9183 (0.8305)	Prec@1 71.000 (72.255)	Prec@5 96.000 (97.412)
2019-05-04 16:58:31 - INFO - TRAINING - Epoch: [85][100/500]	Time 0.024 (0.020)	Data 0.000 (0.003)	Loss 0.7208 (0.8208)	Prec@1 75.000 (72.525)	Prec@5 99.000 (97.614)
2019-05-04 16:58:32 - INFO - TRAINING - Epoch: [85][150/500]	Time 0.016 (0.019)	Data 0.000 (0.002)	Loss 0.6068 (0.8207)	Prec@1 78.000 (72.391)	Prec@5 99.000 (97.682)
2019-05-04 16:58:33 - INFO - TRAINING - Epoch: [85][200/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.6491 (0.8198)	Prec@1 80.000 (72.627)	Prec@5 96.000 (97.687)
2019-05-04 16:58:35 - INFO - TRAINING - Epoch: [85][250/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6877 (0.8149)	Prec@1 77.000 (72.773)	Prec@5 98.000 (97.745)
2019-05-04 16:58:35 - INFO - TRAINING - Epoch: [85][300/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.7784 (0.8105)	Prec@1 76.000 (72.957)	Prec@5 97.000 (97.787)
2019-05-04 16:58:36 - INFO - TRAINING - Epoch: [85][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6931 (0.8106)	Prec@1 78.000 (72.994)	Prec@5 98.000 (97.806)
2019-05-04 16:58:37 - INFO - TRAINING - Epoch: [85][400/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7533 (0.8118)	Prec@1 75.000 (72.873)	Prec@5 96.000 (97.813)
2019-05-04 16:58:38 - INFO - TRAINING - Epoch: [85][450/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.9197 (0.8131)	Prec@1 72.000 (72.820)	Prec@5 96.000 (97.829)
2019-05-04 16:58:39 - INFO - EVALUATING - Epoch: [85][0/100]	Time 0.392 (0.392)	Data 0.381 (0.381)	Loss 0.8645 (0.8645)	Prec@1 70.000 (70.000)	Prec@5 98.000 (98.000)
2019-05-04 16:58:40 - INFO - EVALUATING - Epoch: [85][50/100]	Time 0.008 (0.014)	Data 0.000 (0.008)	Loss 0.8241 (0.9433)	Prec@1 73.000 (69.255)	Prec@5 96.000 (95.941)
2019-05-04 16:58:40 - INFO - 
 Epoch: 86	Training Loss 0.8105 	Training Prec@1 72.920 	Training Prec@5 97.858 	Validation Loss 0.9611 	Validation Prec@1 68.810 	Validation Prec@5 96.010 	
2019-05-04 16:58:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:58:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:58:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:58:40 - INFO - TRAINING - Epoch: [86][0/500]	Time 0.264 (0.264)	Data 0.240 (0.240)	Loss 0.8687 (0.8687)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-04 16:58:41 - INFO - TRAINING - Epoch: [86][50/500]	Time 0.015 (0.021)	Data 0.000 (0.005)	Loss 0.9265 (0.8456)	Prec@1 71.000 (71.373)	Prec@5 96.000 (97.549)
2019-05-04 16:58:42 - INFO - TRAINING - Epoch: [86][100/500]	Time 0.014 (0.019)	Data 0.000 (0.003)	Loss 0.7953 (0.8263)	Prec@1 76.000 (72.475)	Prec@5 95.000 (97.723)
2019-05-04 16:58:43 - INFO - TRAINING - Epoch: [86][150/500]	Time 0.022 (0.019)	Data 0.000 (0.002)	Loss 0.7967 (0.8128)	Prec@1 74.000 (72.841)	Prec@5 97.000 (97.801)
2019-05-04 16:58:44 - INFO - TRAINING - Epoch: [86][200/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.8155 (0.8180)	Prec@1 69.000 (72.562)	Prec@5 97.000 (97.771)
2019-05-04 16:58:45 - INFO - TRAINING - Epoch: [86][250/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.7968 (0.8157)	Prec@1 72.000 (72.542)	Prec@5 96.000 (97.845)
2019-05-04 16:58:46 - INFO - TRAINING - Epoch: [86][300/500]	Time 0.015 (0.018)	Data 0.000 (0.001)	Loss 0.7497 (0.8144)	Prec@1 75.000 (72.628)	Prec@5 98.000 (97.880)
2019-05-04 16:58:46 - INFO - TRAINING - Epoch: [86][350/500]	Time 0.018 (0.018)	Data 0.000 (0.001)	Loss 0.8925 (0.8166)	Prec@1 66.000 (72.538)	Prec@5 95.000 (97.835)
2019-05-04 16:58:47 - INFO - TRAINING - Epoch: [86][400/500]	Time 0.017 (0.018)	Data 0.000 (0.001)	Loss 0.8754 (0.8161)	Prec@1 73.000 (72.579)	Prec@5 99.000 (97.848)
2019-05-04 16:58:48 - INFO - TRAINING - Epoch: [86][450/500]	Time 0.014 (0.018)	Data 0.000 (0.001)	Loss 0.7993 (0.8160)	Prec@1 74.000 (72.596)	Prec@5 97.000 (97.858)
2019-05-04 16:58:50 - INFO - EVALUATING - Epoch: [86][0/100]	Time 0.284 (0.284)	Data 0.277 (0.277)	Loss 1.1498 (1.1498)	Prec@1 63.000 (63.000)	Prec@5 94.000 (94.000)
2019-05-04 16:58:50 - INFO - EVALUATING - Epoch: [86][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.9558 (1.0735)	Prec@1 74.000 (63.843)	Prec@5 96.000 (95.686)
2019-05-04 16:58:50 - INFO - 
 Epoch: 87	Training Loss 0.8161 	Training Prec@1 72.604 	Training Prec@5 97.882 	Validation Loss 1.0898 	Validation Prec@1 62.720 	Validation Prec@5 95.970 	
2019-05-04 16:58:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:58:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:58:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:58:51 - INFO - TRAINING - Epoch: [87][0/500]	Time 0.306 (0.306)	Data 0.283 (0.283)	Loss 0.6364 (0.6364)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-04 16:58:51 - INFO - TRAINING - Epoch: [87][50/500]	Time 0.015 (0.022)	Data 0.000 (0.006)	Loss 0.8611 (0.8210)	Prec@1 72.000 (72.255)	Prec@5 99.000 (98.020)
2019-05-04 16:58:52 - INFO - TRAINING - Epoch: [87][100/500]	Time 0.029 (0.020)	Data 0.000 (0.003)	Loss 0.5899 (0.8094)	Prec@1 81.000 (72.545)	Prec@5 99.000 (98.188)
2019-05-04 16:58:53 - INFO - TRAINING - Epoch: [87][150/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.8501 (0.8085)	Prec@1 69.000 (72.576)	Prec@5 98.000 (98.172)
2019-05-04 16:58:54 - INFO - TRAINING - Epoch: [87][200/500]	Time 0.024 (0.019)	Data 0.000 (0.002)	Loss 0.6757 (0.8113)	Prec@1 77.000 (72.517)	Prec@5 100.000 (98.065)
2019-05-04 16:58:55 - INFO - TRAINING - Epoch: [87][250/500]	Time 0.021 (0.019)	Data 0.000 (0.001)	Loss 1.0145 (0.8105)	Prec@1 64.000 (72.474)	Prec@5 96.000 (98.032)
2019-05-04 16:58:56 - INFO - TRAINING - Epoch: [87][300/500]	Time 0.017 (0.019)	Data 0.000 (0.001)	Loss 0.8577 (0.8112)	Prec@1 68.000 (72.512)	Prec@5 96.000 (98.033)
2019-05-04 16:58:57 - INFO - TRAINING - Epoch: [87][350/500]	Time 0.024 (0.019)	Data 0.000 (0.001)	Loss 0.7798 (0.8114)	Prec@1 72.000 (72.479)	Prec@5 99.000 (98.017)
2019-05-04 16:58:58 - INFO - TRAINING - Epoch: [87][400/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.6490 (0.8100)	Prec@1 78.000 (72.524)	Prec@5 99.000 (97.993)
2019-05-04 16:58:59 - INFO - TRAINING - Epoch: [87][450/500]	Time 0.024 (0.019)	Data 0.000 (0.001)	Loss 0.8768 (0.8106)	Prec@1 69.000 (72.461)	Prec@5 98.000 (97.945)
2019-05-04 16:59:00 - INFO - EVALUATING - Epoch: [87][0/100]	Time 0.412 (0.412)	Data 0.404 (0.404)	Loss 1.2355 (1.2355)	Prec@1 62.000 (62.000)	Prec@5 92.000 (92.000)
2019-05-04 16:59:01 - INFO - EVALUATING - Epoch: [87][50/100]	Time 0.004 (0.014)	Data 0.000 (0.008)	Loss 1.3284 (1.2371)	Prec@1 56.000 (58.000)	Prec@5 95.000 (94.725)
2019-05-04 16:59:01 - INFO - 
 Epoch: 88	Training Loss 0.8086 	Training Prec@1 72.590 	Training Prec@5 97.952 	Validation Loss 1.2500 	Validation Prec@1 57.440 	Validation Prec@5 94.450 	
2019-05-04 16:59:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 16:59:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 16:59:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 16:59:01 - INFO - TRAINING - Epoch: [88][0/500]	Time 0.287 (0.287)	Data 0.265 (0.265)	Loss 1.0641 (1.0641)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-05-04 16:59:02 - INFO - TRAINING - Epoch: [88][50/500]	Time 0.017 (0.027)	Data 0.000 (0.005)	Loss 0.7306 (0.8263)	Prec@1 74.000 (72.196)	Prec@5 99.000 (97.784)
2019-05-04 16:59:03 - INFO - TRAINING - Epoch: [88][100/500]	Time 0.012 (0.023)	Data 0.000 (0.003)	Loss 0.8495 (0.8074)	Prec@1 75.000 (73.099)	Prec@5 97.000 (97.901)
2019-05-04 17:14:00 - INFO - saving to ./results/teacher_results/resnet_preact_quan_test_1
2019-05-04 17:14:00 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='resnet_preact_quan_test', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 17:14:00 - INFO - creating model resnet_preact_quan_test
2019-05-04 17:14:00 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 17:14:00 - INFO - number of parameters: 272612
2019-05-04 17:14:01 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-04 17:14:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 17:14:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 17:14:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 17:14:48 - INFO - saving to ./results/teacher_results/resnet_preact_quan_test_2
2019-05-04 17:14:48 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='resnet_preact_quan_test', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 17:14:48 - INFO - creating model resnet_preact_quan_test
2019-05-04 17:14:48 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 17:14:48 - INFO - number of parameters: 272612
2019-05-04 17:14:49 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-04 17:14:49 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 17:14:49 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 17:14:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 17:15:35 - INFO - saving to ./results/teacher_results/resnet_preact_quan_test_3
2019-05-04 17:15:35 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='resnet_preact_quan_test', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 17:15:35 - INFO - creating model resnet_preact_quan_test
2019-05-04 17:15:35 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 17:15:35 - INFO - number of parameters: 272612
2019-05-04 17:15:36 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-04 17:15:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 17:15:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 17:15:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-04 17:59:03 - INFO - saving to ./results/teacher_student_results/2019-05-04_17-59-03
2019-05-04 17:59:03 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', epochs=200, evaluate=None, gpus='0', input_size=None, lr=0.02, momentum=0.9, optimizer='SGD', print_freq=50, regularizer_coff=0.7, results_dir='./results/teacher_student_results', resume='', save='2019-05-04_17-59-03', start_epoch=0, student_model='resnet_preact_quan_test', students_depth=20, students_inflate=1, students_model_config='', teacher_model='resnet', teacher_model_dir='./results/teacher_results/resnet_cifar10_inflate4', teachers_depth=20, teachers_inflate=1, temperature=3.0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-04 17:59:03 - INFO - creating model resnet_preact_quan_test
2019-05-04 17:59:03 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 17:59:03 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-04 17:59:05 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.02, 'weight_decay': 0}}
2019-05-04 17:59:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-04 17:59:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-04 17:59:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
