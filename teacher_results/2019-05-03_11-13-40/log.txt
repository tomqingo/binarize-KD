2019-05-03 11:13:40 - INFO - saving to ./results/teacher_results/2019-05-03_11-13-40
2019-05-03 11:13:40 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=4, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='2019-05-03_11-13-40', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-03 11:13:40 - INFO - creating model resnet_preact_quan_test
2019-05-03 11:13:40 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 4, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-03 11:13:40 - INFO - number of parameters: 4300388
2019-05-03 11:19:15 - INFO - saving to ./results/teacher_results/2019-05-03_11-19-15
2019-05-03 11:19:15 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=4, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='2019-05-03_11-19-15', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-03 11:19:15 - INFO - creating model resnet_preact_quan_test
2019-05-03 11:19:15 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 4, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-03 11:19:15 - INFO - number of parameters: 4300388
2019-05-03 11:19:17 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-03 11:19:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:19:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:19:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:19:18 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.767 (0.767)	Data 0.311 (0.311)	Loss 2.6301 (2.6301)	Prec@1 5.000 (5.000)	Prec@5 50.000 (50.000)
2019-05-03 11:19:21 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.051 (0.066)	Data 0.000 (0.006)	Loss 2.1549 (2.1910)	Prec@1 21.000 (18.980)	Prec@5 75.000 (68.627)
2019-05-03 11:19:23 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.056 (0.059)	Data 0.000 (0.004)	Loss 2.0253 (2.1204)	Prec@1 24.000 (21.218)	Prec@5 78.000 (73.089)
2019-05-03 11:19:26 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.046 (0.056)	Data 0.000 (0.003)	Loss 1.9699 (2.0782)	Prec@1 26.000 (22.921)	Prec@5 82.000 (75.384)
2019-05-03 11:19:29 - INFO - TRAINING - Epoch: [0][200/500]	Time 0.037 (0.055)	Data 0.000 (0.002)	Loss 1.9335 (2.0417)	Prec@1 26.000 (24.338)	Prec@5 79.000 (77.209)
2019-05-03 11:19:31 - INFO - TRAINING - Epoch: [0][250/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 1.8457 (2.0102)	Prec@1 31.000 (25.669)	Prec@5 80.000 (78.681)
2019-05-03 11:19:34 - INFO - TRAINING - Epoch: [0][300/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 1.8050 (1.9839)	Prec@1 32.000 (26.684)	Prec@5 90.000 (79.721)
2019-05-03 11:19:36 - INFO - TRAINING - Epoch: [0][350/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 1.8034 (1.9592)	Prec@1 34.000 (27.661)	Prec@5 90.000 (80.769)
2019-05-03 11:19:39 - INFO - TRAINING - Epoch: [0][400/500]	Time 0.058 (0.054)	Data 0.000 (0.001)	Loss 1.8304 (1.9406)	Prec@1 33.000 (28.409)	Prec@5 84.000 (81.434)
2019-05-03 11:19:42 - INFO - TRAINING - Epoch: [0][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 1.6737 (1.9212)	Prec@1 38.000 (29.113)	Prec@5 87.000 (82.195)
2019-05-03 11:19:44 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.346 (0.346)	Data 0.336 (0.336)	Loss 1.6302 (1.6302)	Prec@1 40.000 (40.000)	Prec@5 93.000 (93.000)
2019-05-03 11:19:45 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.017 (0.023)	Data 0.000 (0.007)	Loss 1.6698 (1.6918)	Prec@1 40.000 (39.255)	Prec@5 89.000 (90.176)
2019-05-03 11:20:15 - INFO - saving to ./results/teacher_results/2019-05-03_11-20-15
2019-05-03 11:20:15 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=4, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='2019-05-03_11-20-15', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-03 11:20:15 - INFO - creating model resnet_preact_quan_test
2019-05-03 11:20:15 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 4, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-03 11:20:15 - INFO - number of parameters: 4300388
2019-05-03 11:20:16 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-03 11:20:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:20:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:20:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:20:16 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.288 (0.288)	Data 0.265 (0.265)	Loss 2.4040 (2.4040)	Prec@1 16.000 (16.000)	Prec@5 49.000 (49.000)
2019-05-03 11:20:19 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.046 (0.057)	Data 0.000 (0.006)	Loss 2.0982 (2.1724)	Prec@1 20.000 (18.843)	Prec@5 78.000 (71.804)
2019-05-03 11:20:22 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.058 (0.055)	Data 0.000 (0.003)	Loss 1.9974 (2.1184)	Prec@1 35.000 (21.158)	Prec@5 84.000 (75.574)
2019-05-03 11:20:24 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.047 (0.054)	Data 0.000 (0.003)	Loss 1.9016 (2.0841)	Prec@1 35.000 (22.603)	Prec@5 88.000 (77.748)
2019-05-03 11:20:27 - INFO - TRAINING - Epoch: [0][200/500]	Time 0.056 (0.053)	Data 0.000 (0.002)	Loss 1.8406 (2.0488)	Prec@1 33.000 (24.512)	Prec@5 88.000 (79.512)
2019-05-03 11:20:29 - INFO - TRAINING - Epoch: [0][250/500]	Time 0.052 (0.053)	Data 0.000 (0.002)	Loss 1.8514 (2.0188)	Prec@1 33.000 (25.797)	Prec@5 91.000 (80.793)
2019-05-03 11:20:32 - INFO - TRAINING - Epoch: [0][300/500]	Time 0.047 (0.053)	Data 0.000 (0.002)	Loss 1.8164 (1.9947)	Prec@1 37.000 (26.854)	Prec@5 88.000 (81.701)
2019-05-03 11:20:35 - INFO - TRAINING - Epoch: [0][350/500]	Time 0.053 (0.053)	Data 0.000 (0.002)	Loss 1.8241 (1.9713)	Prec@1 33.000 (27.969)	Prec@5 90.000 (82.427)
2019-05-03 11:20:37 - INFO - TRAINING - Epoch: [0][400/500]	Time 0.045 (0.053)	Data 0.000 (0.002)	Loss 1.8345 (1.9497)	Prec@1 37.000 (28.990)	Prec@5 86.000 (83.127)
2019-05-03 11:20:40 - INFO - TRAINING - Epoch: [0][450/500]	Time 0.043 (0.053)	Data 0.000 (0.001)	Loss 1.6310 (1.9293)	Prec@1 42.000 (29.827)	Prec@5 91.000 (83.681)
2019-05-03 11:20:43 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.257 (0.257)	Data 0.247 (0.247)	Loss 1.7287 (1.7287)	Prec@1 39.000 (39.000)	Prec@5 88.000 (88.000)
2019-05-03 11:20:44 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.015 (0.022)	Data 0.000 (0.005)	Loss 1.6858 (1.7083)	Prec@1 43.000 (40.059)	Prec@5 91.000 (89.902)
2019-05-03 11:20:45 - INFO - 
 Epoch: 1	Training Loss 1.9128 	Training Prec@1 30.458 	Training Prec@5 84.094 	Validation Loss 1.7134 	Validation Prec@1 39.180 	Validation Prec@5 89.540 	
2019-05-03 11:20:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:20:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:20:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:20:45 - INFO - TRAINING - Epoch: [1][0/500]	Time 0.288 (0.288)	Data 0.260 (0.260)	Loss 1.7741 (1.7741)	Prec@1 35.000 (35.000)	Prec@5 92.000 (92.000)
2019-05-03 11:20:48 - INFO - TRAINING - Epoch: [1][50/500]	Time 0.051 (0.057)	Data 0.000 (0.006)	Loss 1.7386 (1.7447)	Prec@1 43.000 (36.627)	Prec@5 86.000 (88.000)
2019-05-03 11:20:50 - INFO - TRAINING - Epoch: [1][100/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 1.7069 (1.7217)	Prec@1 38.000 (38.059)	Prec@5 86.000 (88.149)
2019-05-03 11:20:53 - INFO - TRAINING - Epoch: [1][150/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 1.6913 (1.7020)	Prec@1 37.000 (38.801)	Prec@5 91.000 (88.331)
2019-05-03 11:20:55 - INFO - TRAINING - Epoch: [1][200/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 1.6175 (1.6929)	Prec@1 40.000 (39.045)	Prec@5 89.000 (88.507)
2019-05-03 11:20:58 - INFO - TRAINING - Epoch: [1][250/500]	Time 0.039 (0.053)	Data 0.000 (0.002)	Loss 1.5884 (1.6795)	Prec@1 40.000 (39.402)	Prec@5 91.000 (88.932)
2019-05-03 11:21:01 - INFO - TRAINING - Epoch: [1][300/500]	Time 0.062 (0.053)	Data 0.000 (0.002)	Loss 1.4001 (1.6688)	Prec@1 52.000 (39.764)	Prec@5 96.000 (89.123)
2019-05-03 11:21:03 - INFO - TRAINING - Epoch: [1][350/500]	Time 0.055 (0.053)	Data 0.000 (0.002)	Loss 1.7707 (1.6552)	Prec@1 34.000 (40.231)	Prec@5 85.000 (89.419)
2019-05-03 11:21:06 - INFO - TRAINING - Epoch: [1][400/500]	Time 0.047 (0.053)	Data 0.000 (0.001)	Loss 1.5638 (1.6430)	Prec@1 44.000 (40.701)	Prec@5 91.000 (89.613)
2019-05-03 11:21:08 - INFO - TRAINING - Epoch: [1][450/500]	Time 0.059 (0.053)	Data 0.000 (0.001)	Loss 1.5363 (1.6320)	Prec@1 42.000 (41.102)	Prec@5 93.000 (89.738)
2019-05-03 11:21:11 - INFO - EVALUATING - Epoch: [1][0/100]	Time 0.333 (0.333)	Data 0.326 (0.326)	Loss 1.4128 (1.4128)	Prec@1 52.000 (52.000)	Prec@5 94.000 (94.000)
2019-05-03 11:21:12 - INFO - EVALUATING - Epoch: [1][50/100]	Time 0.022 (0.023)	Data 0.000 (0.007)	Loss 1.4789 (1.4763)	Prec@1 45.000 (46.608)	Prec@5 92.000 (92.098)
2019-05-03 11:21:13 - INFO - 
 Epoch: 2	Training Loss 1.6221 	Training Prec@1 41.362 	Training Prec@5 89.900 	Validation Loss 1.4769 	Validation Prec@1 46.220 	Validation Prec@5 92.430 	
2019-05-03 11:21:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:21:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:21:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:21:13 - INFO - TRAINING - Epoch: [2][0/500]	Time 0.279 (0.279)	Data 0.242 (0.242)	Loss 1.5430 (1.5430)	Prec@1 44.000 (44.000)	Prec@5 90.000 (90.000)
2019-05-03 11:21:16 - INFO - TRAINING - Epoch: [2][50/500]	Time 0.047 (0.056)	Data 0.000 (0.005)	Loss 1.5218 (1.5698)	Prec@1 43.000 (43.118)	Prec@5 90.000 (90.451)
2019-05-03 11:21:19 - INFO - TRAINING - Epoch: [2][100/500]	Time 0.051 (0.055)	Data 0.000 (0.003)	Loss 1.5138 (1.5406)	Prec@1 48.000 (44.347)	Prec@5 88.000 (91.119)
2019-05-03 11:21:21 - INFO - TRAINING - Epoch: [2][150/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 1.4562 (1.5260)	Prec@1 47.000 (44.854)	Prec@5 93.000 (91.265)
2019-05-03 11:21:24 - INFO - TRAINING - Epoch: [2][200/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 1.3402 (1.5118)	Prec@1 56.000 (45.353)	Prec@5 94.000 (91.517)
2019-05-03 11:21:27 - INFO - TRAINING - Epoch: [2][250/500]	Time 0.064 (0.053)	Data 0.000 (0.002)	Loss 1.5171 (1.5058)	Prec@1 46.000 (45.410)	Prec@5 95.000 (91.665)
2019-05-03 11:21:29 - INFO - TRAINING - Epoch: [2][300/500]	Time 0.059 (0.053)	Data 0.000 (0.002)	Loss 1.3312 (1.4989)	Prec@1 53.000 (45.581)	Prec@5 93.000 (91.711)
2019-05-03 11:21:32 - INFO - TRAINING - Epoch: [2][350/500]	Time 0.055 (0.053)	Data 0.000 (0.001)	Loss 1.4299 (1.4883)	Prec@1 52.000 (46.003)	Prec@5 94.000 (91.815)
2019-05-03 11:21:34 - INFO - TRAINING - Epoch: [2][400/500]	Time 0.056 (0.053)	Data 0.000 (0.001)	Loss 1.3485 (1.4804)	Prec@1 51.000 (46.424)	Prec@5 94.000 (91.853)
2019-05-03 11:21:37 - INFO - TRAINING - Epoch: [2][450/500]	Time 0.057 (0.053)	Data 0.000 (0.001)	Loss 1.3496 (1.4740)	Prec@1 50.000 (46.559)	Prec@5 96.000 (91.940)
2019-05-03 11:21:40 - INFO - EVALUATING - Epoch: [2][0/100]	Time 0.369 (0.369)	Data 0.356 (0.356)	Loss 1.2276 (1.2276)	Prec@1 59.000 (59.000)	Prec@5 92.000 (92.000)
2019-05-03 11:21:41 - INFO - EVALUATING - Epoch: [2][50/100]	Time 0.019 (0.024)	Data 0.000 (0.007)	Loss 1.2911 (1.3893)	Prec@1 56.000 (49.824)	Prec@5 97.000 (93.137)
2019-05-03 11:21:42 - INFO - 
 Epoch: 3	Training Loss 1.4644 	Training Prec@1 46.918 	Training Prec@5 92.076 	Validation Loss 1.3900 	Validation Prec@1 49.620 	Validation Prec@5 93.430 	
2019-05-03 11:21:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:21:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:21:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:21:42 - INFO - TRAINING - Epoch: [3][0/500]	Time 0.278 (0.278)	Data 0.253 (0.253)	Loss 1.4061 (1.4061)	Prec@1 54.000 (54.000)	Prec@5 91.000 (91.000)
2019-05-03 11:21:45 - INFO - TRAINING - Epoch: [3][50/500]	Time 0.053 (0.057)	Data 0.000 (0.006)	Loss 1.4384 (1.3971)	Prec@1 51.000 (50.059)	Prec@5 90.000 (92.275)
2019-05-03 11:21:47 - INFO - TRAINING - Epoch: [3][100/500]	Time 0.062 (0.055)	Data 0.000 (0.003)	Loss 1.4626 (1.3909)	Prec@1 48.000 (49.752)	Prec@5 89.000 (92.752)
2019-05-03 11:21:50 - INFO - TRAINING - Epoch: [3][150/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 1.3789 (1.3791)	Prec@1 53.000 (50.126)	Prec@5 92.000 (92.834)
2019-05-03 11:21:53 - INFO - TRAINING - Epoch: [3][200/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 1.4855 (1.3681)	Prec@1 46.000 (50.517)	Prec@5 97.000 (93.065)
2019-05-03 11:21:55 - INFO - TRAINING - Epoch: [3][250/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 1.3271 (1.3623)	Prec@1 59.000 (50.777)	Prec@5 97.000 (93.096)
2019-05-03 11:21:58 - INFO - TRAINING - Epoch: [3][300/500]	Time 0.054 (0.053)	Data 0.000 (0.002)	Loss 1.2716 (1.3561)	Prec@1 56.000 (51.056)	Prec@5 94.000 (93.216)
2019-05-03 11:22:01 - INFO - TRAINING - Epoch: [3][350/500]	Time 0.067 (0.053)	Data 0.000 (0.001)	Loss 1.3223 (1.3448)	Prec@1 53.000 (51.493)	Prec@5 93.000 (93.396)
2019-05-03 11:22:03 - INFO - TRAINING - Epoch: [3][400/500]	Time 0.051 (0.053)	Data 0.000 (0.001)	Loss 1.2464 (1.3382)	Prec@1 54.000 (51.771)	Prec@5 95.000 (93.496)
2019-05-03 11:22:06 - INFO - TRAINING - Epoch: [3][450/500]	Time 0.056 (0.053)	Data 0.000 (0.001)	Loss 1.2978 (1.3288)	Prec@1 59.000 (52.251)	Prec@5 93.000 (93.674)
2019-05-03 11:22:09 - INFO - EVALUATING - Epoch: [3][0/100]	Time 0.394 (0.394)	Data 0.383 (0.383)	Loss 1.1305 (1.1305)	Prec@1 60.000 (60.000)	Prec@5 94.000 (94.000)
2019-05-03 11:22:10 - INFO - EVALUATING - Epoch: [3][50/100]	Time 0.019 (0.025)	Data 0.000 (0.008)	Loss 1.1744 (1.1869)	Prec@1 60.000 (57.490)	Prec@5 94.000 (95.549)
2019-05-03 11:22:11 - INFO - 
 Epoch: 4	Training Loss 1.3219 	Training Prec@1 52.514 	Training Prec@5 93.794 	Validation Loss 1.1928 	Validation Prec@1 57.230 	Validation Prec@5 95.570 	
2019-05-03 11:22:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:22:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:22:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:22:11 - INFO - TRAINING - Epoch: [4][0/500]	Time 0.268 (0.268)	Data 0.240 (0.240)	Loss 0.9289 (0.9289)	Prec@1 66.000 (66.000)	Prec@5 99.000 (99.000)
2019-05-03 11:22:14 - INFO - TRAINING - Epoch: [4][50/500]	Time 0.061 (0.057)	Data 0.000 (0.005)	Loss 1.0723 (1.2672)	Prec@1 59.000 (54.706)	Prec@5 98.000 (94.647)
2019-05-03 11:22:16 - INFO - TRAINING - Epoch: [4][100/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 1.1297 (1.2537)	Prec@1 58.000 (55.109)	Prec@5 96.000 (94.564)
2019-05-03 11:22:19 - INFO - TRAINING - Epoch: [4][150/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 1.2200 (1.2447)	Prec@1 57.000 (55.483)	Prec@5 93.000 (94.695)
2019-05-03 11:22:21 - INFO - TRAINING - Epoch: [4][200/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 1.1371 (1.2333)	Prec@1 59.000 (55.925)	Prec@5 95.000 (94.816)
2019-05-03 11:22:24 - INFO - TRAINING - Epoch: [4][250/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 1.1154 (1.2260)	Prec@1 62.000 (56.219)	Prec@5 94.000 (94.948)
2019-05-03 11:22:27 - INFO - TRAINING - Epoch: [4][300/500]	Time 0.051 (0.053)	Data 0.000 (0.001)	Loss 1.1296 (1.2179)	Prec@1 56.000 (56.498)	Prec@5 95.000 (95.066)
2019-05-03 11:22:29 - INFO - TRAINING - Epoch: [4][350/500]	Time 0.046 (0.053)	Data 0.000 (0.001)	Loss 1.1970 (1.2108)	Prec@1 60.000 (56.692)	Prec@5 97.000 (95.120)
2019-05-03 11:22:32 - INFO - TRAINING - Epoch: [4][400/500]	Time 0.062 (0.053)	Data 0.000 (0.001)	Loss 1.0354 (1.1997)	Prec@1 64.000 (57.117)	Prec@5 97.000 (95.242)
2019-05-03 11:22:35 - INFO - TRAINING - Epoch: [4][450/500]	Time 0.059 (0.053)	Data 0.000 (0.001)	Loss 1.4243 (1.1932)	Prec@1 54.000 (57.286)	Prec@5 95.000 (95.308)
2019-05-03 11:22:38 - INFO - EVALUATING - Epoch: [4][0/100]	Time 0.331 (0.331)	Data 0.316 (0.316)	Loss 1.0649 (1.0649)	Prec@1 58.000 (58.000)	Prec@5 97.000 (97.000)
2019-05-03 11:22:38 - INFO - EVALUATING - Epoch: [4][50/100]	Time 0.020 (0.023)	Data 0.000 (0.006)	Loss 1.0759 (1.1324)	Prec@1 68.000 (60.510)	Prec@5 92.000 (95.431)
2019-05-03 11:22:39 - INFO - 
 Epoch: 5	Training Loss 1.1868 	Training Prec@1 57.564 	Training Prec@5 95.350 	Validation Loss 1.1361 	Validation Prec@1 60.220 	Validation Prec@5 95.640 	
2019-05-03 11:22:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:22:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:22:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:22:40 - INFO - TRAINING - Epoch: [5][0/500]	Time 0.375 (0.375)	Data 0.355 (0.355)	Loss 0.9088 (0.9088)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-05-03 11:22:42 - INFO - TRAINING - Epoch: [5][50/500]	Time 0.054 (0.059)	Data 0.000 (0.008)	Loss 1.0805 (1.1465)	Prec@1 60.000 (59.176)	Prec@5 99.000 (96.098)
2019-05-03 11:22:45 - INFO - TRAINING - Epoch: [5][100/500]	Time 0.052 (0.056)	Data 0.000 (0.004)	Loss 0.8883 (1.1310)	Prec@1 66.000 (59.624)	Prec@5 99.000 (95.970)
2019-05-03 11:22:48 - INFO - TRAINING - Epoch: [5][150/500]	Time 0.047 (0.055)	Data 0.000 (0.003)	Loss 1.0812 (1.1145)	Prec@1 59.000 (60.020)	Prec@5 97.000 (96.026)
2019-05-03 11:22:50 - INFO - TRAINING - Epoch: [5][200/500]	Time 0.051 (0.054)	Data 0.000 (0.003)	Loss 1.0659 (1.1052)	Prec@1 59.000 (60.498)	Prec@5 97.000 (96.164)
2019-05-03 11:22:53 - INFO - TRAINING - Epoch: [5][250/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 1.0787 (1.0967)	Prec@1 66.000 (61.056)	Prec@5 95.000 (96.163)
2019-05-03 11:22:56 - INFO - TRAINING - Epoch: [5][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 1.1384 (1.0912)	Prec@1 59.000 (61.249)	Prec@5 97.000 (96.226)
2019-05-03 11:22:58 - INFO - TRAINING - Epoch: [5][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 1.0461 (1.0855)	Prec@1 66.000 (61.456)	Prec@5 96.000 (96.219)
2019-05-03 11:23:01 - INFO - TRAINING - Epoch: [5][400/500]	Time 0.062 (0.054)	Data 0.000 (0.002)	Loss 1.1946 (1.0837)	Prec@1 60.000 (61.566)	Prec@5 92.000 (96.229)
2019-05-03 11:23:04 - INFO - TRAINING - Epoch: [5][450/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 1.1076 (1.0809)	Prec@1 61.000 (61.710)	Prec@5 97.000 (96.266)
2019-05-03 11:23:07 - INFO - EVALUATING - Epoch: [5][0/100]	Time 0.367 (0.367)	Data 0.355 (0.355)	Loss 0.9163 (0.9163)	Prec@1 67.000 (67.000)	Prec@5 98.000 (98.000)
2019-05-03 11:23:07 - INFO - EVALUATING - Epoch: [5][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 1.0485 (1.0259)	Prec@1 70.000 (64.078)	Prec@5 96.000 (96.647)
2019-05-03 11:23:08 - INFO - 
 Epoch: 6	Training Loss 1.0763 	Training Prec@1 61.864 	Training Prec@5 96.290 	Validation Loss 1.0367 	Validation Prec@1 63.640 	Validation Prec@5 96.420 	
2019-05-03 11:23:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:23:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:23:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:23:09 - INFO - TRAINING - Epoch: [6][0/500]	Time 0.385 (0.385)	Data 0.364 (0.364)	Loss 1.1409 (1.1409)	Prec@1 56.000 (56.000)	Prec@5 96.000 (96.000)
2019-05-03 11:23:11 - INFO - TRAINING - Epoch: [6][50/500]	Time 0.046 (0.060)	Data 0.000 (0.008)	Loss 1.0615 (1.0678)	Prec@1 63.000 (62.451)	Prec@5 96.000 (96.098)
2019-05-03 11:23:14 - INFO - TRAINING - Epoch: [6][100/500]	Time 0.055 (0.057)	Data 0.000 (0.004)	Loss 0.8568 (1.0454)	Prec@1 70.000 (62.970)	Prec@5 99.000 (96.584)
2019-05-03 11:23:17 - INFO - TRAINING - Epoch: [6][150/500]	Time 0.051 (0.056)	Data 0.000 (0.003)	Loss 1.1303 (1.0416)	Prec@1 61.000 (63.192)	Prec@5 94.000 (96.589)
2019-05-03 11:23:19 - INFO - TRAINING - Epoch: [6][200/500]	Time 0.044 (0.055)	Data 0.000 (0.003)	Loss 1.0349 (1.0276)	Prec@1 61.000 (63.582)	Prec@5 98.000 (96.766)
2019-05-03 11:23:22 - INFO - TRAINING - Epoch: [6][250/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.9256 (1.0194)	Prec@1 64.000 (63.920)	Prec@5 97.000 (96.809)
2019-05-03 11:23:25 - INFO - TRAINING - Epoch: [6][300/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.9441 (1.0160)	Prec@1 61.000 (63.890)	Prec@5 98.000 (96.887)
2019-05-03 11:23:27 - INFO - TRAINING - Epoch: [6][350/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 1.0192 (1.0122)	Prec@1 66.000 (64.028)	Prec@5 97.000 (96.883)
2019-05-03 11:23:30 - INFO - TRAINING - Epoch: [6][400/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 1.0149 (1.0076)	Prec@1 67.000 (64.227)	Prec@5 97.000 (96.895)
2019-05-03 11:23:33 - INFO - TRAINING - Epoch: [6][450/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.7463 (1.0051)	Prec@1 75.000 (64.324)	Prec@5 98.000 (96.882)
2019-05-03 11:23:36 - INFO - EVALUATING - Epoch: [6][0/100]	Time 0.371 (0.371)	Data 0.360 (0.360)	Loss 0.8053 (0.8053)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-05-03 11:23:37 - INFO - EVALUATING - Epoch: [6][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.9288 (0.9824)	Prec@1 67.000 (65.510)	Prec@5 96.000 (96.725)
2019-05-03 11:23:38 - INFO - 
 Epoch: 7	Training Loss 0.9993 	Training Prec@1 64.602 	Training Prec@5 96.896 	Validation Loss 0.9918 	Validation Prec@1 65.310 	Validation Prec@5 96.860 	
2019-05-03 11:23:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:23:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:23:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:23:38 - INFO - TRAINING - Epoch: [7][0/500]	Time 0.402 (0.402)	Data 0.378 (0.378)	Loss 0.9040 (0.9040)	Prec@1 69.000 (69.000)	Prec@5 97.000 (97.000)
2019-05-03 11:23:41 - INFO - TRAINING - Epoch: [7][50/500]	Time 0.046 (0.060)	Data 0.000 (0.008)	Loss 0.9335 (0.9847)	Prec@1 65.000 (65.098)	Prec@5 96.000 (96.765)
2019-05-03 11:23:43 - INFO - TRAINING - Epoch: [7][100/500]	Time 0.057 (0.057)	Data 0.000 (0.005)	Loss 0.8745 (0.9776)	Prec@1 67.000 (65.238)	Prec@5 100.000 (97.000)
2019-05-03 11:23:46 - INFO - TRAINING - Epoch: [7][150/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.9664 (0.9635)	Prec@1 68.000 (65.596)	Prec@5 95.000 (97.093)
2019-05-03 11:23:49 - INFO - TRAINING - Epoch: [7][200/500]	Time 0.052 (0.055)	Data 0.000 (0.003)	Loss 1.0165 (0.9597)	Prec@1 62.000 (66.060)	Prec@5 98.000 (97.100)
2019-05-03 11:23:51 - INFO - TRAINING - Epoch: [7][250/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.8955 (0.9515)	Prec@1 70.000 (66.287)	Prec@5 96.000 (97.179)
2019-05-03 11:23:54 - INFO - TRAINING - Epoch: [7][300/500]	Time 0.050 (0.055)	Data 0.000 (0.002)	Loss 0.8534 (0.9473)	Prec@1 69.000 (66.591)	Prec@5 98.000 (97.136)
2019-05-03 11:23:57 - INFO - TRAINING - Epoch: [7][350/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.8931 (0.9411)	Prec@1 68.000 (66.909)	Prec@5 99.000 (97.217)
2019-05-03 11:23:59 - INFO - TRAINING - Epoch: [7][400/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.9828 (0.9347)	Prec@1 62.000 (67.047)	Prec@5 97.000 (97.252)
2019-05-03 11:24:02 - INFO - TRAINING - Epoch: [7][450/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.8948 (0.9313)	Prec@1 68.000 (67.146)	Prec@5 98.000 (97.271)
2019-05-03 11:24:05 - INFO - EVALUATING - Epoch: [7][0/100]	Time 0.396 (0.396)	Data 0.385 (0.385)	Loss 1.3003 (1.3003)	Prec@1 54.000 (54.000)	Prec@5 96.000 (96.000)
2019-05-03 11:24:06 - INFO - EVALUATING - Epoch: [7][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 1.4254 (1.3994)	Prec@1 54.000 (53.569)	Prec@5 94.000 (94.373)
2019-05-03 11:24:07 - INFO - 
 Epoch: 8	Training Loss 0.9303 	Training Prec@1 67.258 	Training Prec@5 97.272 	Validation Loss 1.4237 	Validation Prec@1 52.820 	Validation Prec@5 94.190 	
2019-05-03 11:24:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:24:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:24:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:24:07 - INFO - TRAINING - Epoch: [8][0/500]	Time 0.380 (0.380)	Data 0.355 (0.355)	Loss 0.7322 (0.7322)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-03 11:24:10 - INFO - TRAINING - Epoch: [8][50/500]	Time 0.054 (0.060)	Data 0.000 (0.008)	Loss 0.6050 (0.9148)	Prec@1 82.000 (67.373)	Prec@5 100.000 (97.373)
2019-05-03 11:24:13 - INFO - TRAINING - Epoch: [8][100/500]	Time 0.047 (0.058)	Data 0.000 (0.004)	Loss 1.0625 (0.9191)	Prec@1 61.000 (67.515)	Prec@5 99.000 (97.455)
2019-05-03 11:24:15 - INFO - TRAINING - Epoch: [8][150/500]	Time 0.054 (0.057)	Data 0.000 (0.003)	Loss 0.9051 (0.9034)	Prec@1 70.000 (68.318)	Prec@5 98.000 (97.563)
2019-05-03 11:24:18 - INFO - TRAINING - Epoch: [8][200/500]	Time 0.061 (0.056)	Data 0.000 (0.003)	Loss 0.9537 (0.8961)	Prec@1 59.000 (68.667)	Prec@5 96.000 (97.552)
2019-05-03 11:24:21 - INFO - TRAINING - Epoch: [8][250/500]	Time 0.058 (0.056)	Data 0.000 (0.002)	Loss 0.9216 (0.8949)	Prec@1 66.000 (68.494)	Prec@5 96.000 (97.546)
2019-05-03 11:24:24 - INFO - TRAINING - Epoch: [8][300/500]	Time 0.043 (0.056)	Data 0.000 (0.002)	Loss 1.0453 (0.8953)	Prec@1 65.000 (68.555)	Prec@5 95.000 (97.415)
2019-05-03 11:24:26 - INFO - TRAINING - Epoch: [8][350/500]	Time 0.054 (0.056)	Data 0.000 (0.002)	Loss 0.7611 (0.8929)	Prec@1 74.000 (68.672)	Prec@5 99.000 (97.453)
2019-05-03 11:24:29 - INFO - TRAINING - Epoch: [8][400/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.6854 (0.8852)	Prec@1 74.000 (68.930)	Prec@5 100.000 (97.531)
2019-05-03 11:24:32 - INFO - TRAINING - Epoch: [8][450/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.8704 (0.8822)	Prec@1 63.000 (69.115)	Prec@5 100.000 (97.543)
2019-05-03 11:24:35 - INFO - EVALUATING - Epoch: [8][0/100]	Time 0.373 (0.373)	Data 0.357 (0.357)	Loss 0.8995 (0.8995)	Prec@1 67.000 (67.000)	Prec@5 96.000 (96.000)
2019-05-03 11:24:36 - INFO - EVALUATING - Epoch: [8][50/100]	Time 0.015 (0.024)	Data 0.000 (0.007)	Loss 0.9877 (0.9538)	Prec@1 69.000 (67.412)	Prec@5 96.000 (96.529)
2019-05-03 11:24:37 - INFO - 
 Epoch: 9	Training Loss 0.8766 	Training Prec@1 69.274 	Training Prec@5 97.576 	Validation Loss 0.9597 	Validation Prec@1 66.940 	Validation Prec@5 96.640 	
2019-05-03 11:24:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:24:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:24:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:24:37 - INFO - TRAINING - Epoch: [9][0/500]	Time 0.283 (0.283)	Data 0.257 (0.257)	Loss 0.8851 (0.8851)	Prec@1 68.000 (68.000)	Prec@5 100.000 (100.000)
2019-05-03 11:24:40 - INFO - TRAINING - Epoch: [9][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.7359 (0.8484)	Prec@1 76.000 (70.471)	Prec@5 100.000 (97.863)
2019-05-03 11:24:42 - INFO - TRAINING - Epoch: [9][100/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.7965 (0.8525)	Prec@1 69.000 (70.178)	Prec@5 100.000 (98.099)
2019-05-03 11:24:45 - INFO - TRAINING - Epoch: [9][150/500]	Time 0.050 (0.055)	Data 0.000 (0.002)	Loss 0.7589 (0.8517)	Prec@1 74.000 (70.219)	Prec@5 99.000 (98.000)
2019-05-03 11:24:48 - INFO - TRAINING - Epoch: [9][200/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.7475 (0.8477)	Prec@1 78.000 (70.408)	Prec@5 100.000 (98.000)
2019-05-03 11:24:50 - INFO - TRAINING - Epoch: [9][250/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.9533 (0.8405)	Prec@1 70.000 (70.849)	Prec@5 96.000 (97.976)
2019-05-03 11:24:53 - INFO - TRAINING - Epoch: [9][300/500]	Time 0.062 (0.054)	Data 0.000 (0.002)	Loss 0.8163 (0.8440)	Prec@1 72.000 (70.678)	Prec@5 95.000 (97.947)
2019-05-03 11:24:56 - INFO - TRAINING - Epoch: [9][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.9176 (0.8418)	Prec@1 66.000 (70.758)	Prec@5 95.000 (97.892)
2019-05-03 11:24:58 - INFO - TRAINING - Epoch: [9][400/500]	Time 0.063 (0.054)	Data 0.000 (0.001)	Loss 0.9321 (0.8386)	Prec@1 69.000 (70.848)	Prec@5 96.000 (97.860)
2019-05-03 11:25:01 - INFO - TRAINING - Epoch: [9][450/500]	Time 0.064 (0.054)	Data 0.000 (0.001)	Loss 0.8206 (0.8348)	Prec@1 74.000 (70.980)	Prec@5 96.000 (97.874)
2019-05-03 11:25:04 - INFO - EVALUATING - Epoch: [9][0/100]	Time 0.363 (0.363)	Data 0.347 (0.347)	Loss 0.7961 (0.7961)	Prec@1 68.000 (68.000)	Prec@5 99.000 (99.000)
2019-05-03 11:25:05 - INFO - EVALUATING - Epoch: [9][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.7581 (0.8236)	Prec@1 72.000 (70.490)	Prec@5 97.000 (97.980)
2019-05-03 11:25:06 - INFO - 
 Epoch: 10	Training Loss 0.8300 	Training Prec@1 71.188 	Training Prec@5 97.862 	Validation Loss 0.8378 	Validation Prec@1 69.910 	Validation Prec@5 98.110 	
2019-05-03 11:25:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:25:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:25:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:25:06 - INFO - TRAINING - Epoch: [10][0/500]	Time 0.278 (0.278)	Data 0.252 (0.252)	Loss 0.5314 (0.5314)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 11:25:09 - INFO - TRAINING - Epoch: [10][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.8787 (0.8086)	Prec@1 70.000 (72.078)	Prec@5 98.000 (98.176)
2019-05-03 11:25:11 - INFO - TRAINING - Epoch: [10][100/500]	Time 0.057 (0.056)	Data 0.000 (0.003)	Loss 0.8656 (0.8016)	Prec@1 66.000 (72.525)	Prec@5 97.000 (98.228)
2019-05-03 11:25:14 - INFO - TRAINING - Epoch: [10][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.8812 (0.7990)	Prec@1 68.000 (72.503)	Prec@5 100.000 (98.291)
2019-05-03 11:25:17 - INFO - TRAINING - Epoch: [10][200/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.8121 (0.7906)	Prec@1 67.000 (72.756)	Prec@5 97.000 (98.259)
2019-05-03 11:25:19 - INFO - TRAINING - Epoch: [10][250/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.7919 (0.7920)	Prec@1 74.000 (72.725)	Prec@5 98.000 (98.171)
2019-05-03 11:25:22 - INFO - TRAINING - Epoch: [10][300/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 0.6541 (0.7941)	Prec@1 79.000 (72.575)	Prec@5 98.000 (98.179)
2019-05-03 11:25:25 - INFO - TRAINING - Epoch: [10][350/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.7622 (0.7931)	Prec@1 72.000 (72.581)	Prec@5 99.000 (98.197)
2019-05-03 11:25:28 - INFO - TRAINING - Epoch: [10][400/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.6608 (0.7920)	Prec@1 75.000 (72.638)	Prec@5 100.000 (98.237)
2019-05-03 11:25:30 - INFO - TRAINING - Epoch: [10][450/500]	Time 0.045 (0.054)	Data 0.000 (0.001)	Loss 0.7899 (0.7885)	Prec@1 71.000 (72.758)	Prec@5 97.000 (98.231)
2019-05-03 11:25:33 - INFO - EVALUATING - Epoch: [10][0/100]	Time 0.361 (0.361)	Data 0.350 (0.350)	Loss 0.7977 (0.7977)	Prec@1 68.000 (68.000)	Prec@5 98.000 (98.000)
2019-05-03 11:25:34 - INFO - EVALUATING - Epoch: [10][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.8129 (0.9582)	Prec@1 72.000 (66.863)	Prec@5 97.000 (96.863)
2019-05-03 11:25:35 - INFO - 
 Epoch: 11	Training Loss 0.7870 	Training Prec@1 72.778 	Training Prec@5 98.238 	Validation Loss 0.9600 	Validation Prec@1 67.040 	Validation Prec@5 97.110 	
2019-05-03 11:25:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:25:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:25:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:25:35 - INFO - TRAINING - Epoch: [11][0/500]	Time 0.392 (0.392)	Data 0.366 (0.366)	Loss 0.6791 (0.6791)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-05-03 11:25:38 - INFO - TRAINING - Epoch: [11][50/500]	Time 0.047 (0.060)	Data 0.000 (0.008)	Loss 0.8554 (0.7739)	Prec@1 71.000 (73.647)	Prec@5 99.000 (97.941)
2019-05-03 11:25:41 - INFO - TRAINING - Epoch: [11][100/500]	Time 0.041 (0.057)	Data 0.000 (0.004)	Loss 0.8029 (0.7685)	Prec@1 77.000 (73.525)	Prec@5 94.000 (98.079)
2019-05-03 11:25:43 - INFO - TRAINING - Epoch: [11][150/500]	Time 0.049 (0.056)	Data 0.000 (0.003)	Loss 0.7501 (0.7579)	Prec@1 70.000 (73.702)	Prec@5 100.000 (98.238)
2019-05-03 11:25:46 - INFO - TRAINING - Epoch: [11][200/500]	Time 0.039 (0.055)	Data 0.000 (0.003)	Loss 0.9124 (0.7449)	Prec@1 66.000 (74.109)	Prec@5 98.000 (98.413)
2019-05-03 11:25:49 - INFO - TRAINING - Epoch: [11][250/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.8598 (0.7466)	Prec@1 68.000 (74.072)	Prec@5 98.000 (98.398)
2019-05-03 11:25:51 - INFO - TRAINING - Epoch: [11][300/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.8985 (0.7479)	Prec@1 69.000 (74.007)	Prec@5 98.000 (98.382)
2019-05-03 11:25:54 - INFO - TRAINING - Epoch: [11][350/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.9236 (0.7449)	Prec@1 67.000 (74.125)	Prec@5 97.000 (98.424)
2019-05-03 11:25:57 - INFO - TRAINING - Epoch: [11][400/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.6102 (0.7470)	Prec@1 75.000 (74.132)	Prec@5 100.000 (98.387)
2019-05-03 11:25:59 - INFO - TRAINING - Epoch: [11][450/500]	Time 0.066 (0.054)	Data 0.000 (0.002)	Loss 0.6453 (0.7482)	Prec@1 78.000 (74.124)	Prec@5 99.000 (98.355)
2019-05-03 11:26:02 - INFO - EVALUATING - Epoch: [11][0/100]	Time 0.359 (0.359)	Data 0.351 (0.351)	Loss 0.9312 (0.9312)	Prec@1 70.000 (70.000)	Prec@5 97.000 (97.000)
2019-05-03 11:26:03 - INFO - EVALUATING - Epoch: [11][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 1.1040 (1.0918)	Prec@1 63.000 (63.373)	Prec@5 99.000 (96.098)
2019-05-03 11:26:04 - INFO - 
 Epoch: 12	Training Loss 0.7488 	Training Prec@1 74.086 	Training Prec@5 98.388 	Validation Loss 1.0981 	Validation Prec@1 63.260 	Validation Prec@5 95.890 	
2019-05-03 11:26:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:26:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:26:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:26:05 - INFO - TRAINING - Epoch: [12][0/500]	Time 0.354 (0.354)	Data 0.332 (0.332)	Loss 0.7707 (0.7707)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 11:26:07 - INFO - TRAINING - Epoch: [12][50/500]	Time 0.061 (0.062)	Data 0.000 (0.007)	Loss 0.7953 (0.7540)	Prec@1 72.000 (74.451)	Prec@5 98.000 (98.157)
2019-05-03 11:26:10 - INFO - TRAINING - Epoch: [12][100/500]	Time 0.060 (0.059)	Data 0.000 (0.004)	Loss 0.8638 (0.7613)	Prec@1 71.000 (73.921)	Prec@5 96.000 (98.030)
2019-05-03 11:26:13 - INFO - TRAINING - Epoch: [12][150/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.8395 (0.7429)	Prec@1 69.000 (74.305)	Prec@5 99.000 (98.192)
2019-05-03 11:26:16 - INFO - TRAINING - Epoch: [12][200/500]	Time 0.048 (0.056)	Data 0.000 (0.002)	Loss 0.7444 (0.7346)	Prec@1 72.000 (74.622)	Prec@5 98.000 (98.269)
2019-05-03 11:26:18 - INFO - TRAINING - Epoch: [12][250/500]	Time 0.064 (0.056)	Data 0.000 (0.002)	Loss 0.7316 (0.7328)	Prec@1 74.000 (74.661)	Prec@5 98.000 (98.323)
2019-05-03 11:26:21 - INFO - TRAINING - Epoch: [12][300/500]	Time 0.061 (0.056)	Data 0.000 (0.002)	Loss 0.7008 (0.7293)	Prec@1 75.000 (74.794)	Prec@5 100.000 (98.365)
2019-05-03 11:26:24 - INFO - TRAINING - Epoch: [12][350/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.8590 (0.7308)	Prec@1 72.000 (74.772)	Prec@5 98.000 (98.382)
2019-05-03 11:26:26 - INFO - TRAINING - Epoch: [12][400/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.8727 (0.7238)	Prec@1 71.000 (74.958)	Prec@5 97.000 (98.429)
2019-05-03 11:26:29 - INFO - TRAINING - Epoch: [12][450/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.7585 (0.7222)	Prec@1 74.000 (74.998)	Prec@5 98.000 (98.432)
2019-05-03 11:26:32 - INFO - EVALUATING - Epoch: [12][0/100]	Time 0.347 (0.347)	Data 0.338 (0.338)	Loss 0.9681 (0.9681)	Prec@1 70.000 (70.000)	Prec@5 96.000 (96.000)
2019-05-03 11:26:33 - INFO - EVALUATING - Epoch: [12][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.9254 (0.9089)	Prec@1 69.000 (69.412)	Prec@5 95.000 (96.608)
2019-05-03 11:26:34 - INFO - 
 Epoch: 13	Training Loss 0.7183 	Training Prec@1 75.078 	Training Prec@5 98.456 	Validation Loss 0.9244 	Validation Prec@1 68.810 	Validation Prec@5 96.720 	
2019-05-03 11:26:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:26:34 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:26:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:26:34 - INFO - TRAINING - Epoch: [13][0/500]	Time 0.382 (0.382)	Data 0.359 (0.359)	Loss 0.6909 (0.6909)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 11:26:37 - INFO - TRAINING - Epoch: [13][50/500]	Time 0.063 (0.060)	Data 0.000 (0.008)	Loss 0.6409 (0.7130)	Prec@1 81.000 (75.667)	Prec@5 99.000 (98.314)
2019-05-03 11:26:40 - INFO - TRAINING - Epoch: [13][100/500]	Time 0.059 (0.057)	Data 0.000 (0.004)	Loss 0.6647 (0.7105)	Prec@1 74.000 (75.743)	Prec@5 99.000 (98.426)
2019-05-03 11:26:42 - INFO - TRAINING - Epoch: [13][150/500]	Time 0.049 (0.056)	Data 0.000 (0.003)	Loss 0.6719 (0.7049)	Prec@1 77.000 (75.874)	Prec@5 98.000 (98.424)
2019-05-03 11:26:45 - INFO - TRAINING - Epoch: [13][200/500]	Time 0.046 (0.055)	Data 0.000 (0.003)	Loss 0.7351 (0.6997)	Prec@1 75.000 (76.199)	Prec@5 99.000 (98.448)
2019-05-03 11:26:48 - INFO - TRAINING - Epoch: [13][250/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.7775 (0.6966)	Prec@1 76.000 (76.199)	Prec@5 98.000 (98.462)
2019-05-03 11:26:50 - INFO - TRAINING - Epoch: [13][300/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.5086 (0.6959)	Prec@1 81.000 (76.156)	Prec@5 100.000 (98.502)
2019-05-03 11:26:53 - INFO - TRAINING - Epoch: [13][350/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.6972 (0.6938)	Prec@1 78.000 (76.128)	Prec@5 96.000 (98.524)
2019-05-03 11:26:56 - INFO - TRAINING - Epoch: [13][400/500]	Time 0.051 (0.054)	Data 0.000 (0.002)	Loss 0.6402 (0.6910)	Prec@1 77.000 (76.249)	Prec@5 100.000 (98.536)
2019-05-03 11:26:58 - INFO - TRAINING - Epoch: [13][450/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 0.5383 (0.6886)	Prec@1 81.000 (76.361)	Prec@5 100.000 (98.545)
2019-05-03 11:27:01 - INFO - EVALUATING - Epoch: [13][0/100]	Time 0.358 (0.358)	Data 0.347 (0.347)	Loss 0.7099 (0.7099)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-03 11:27:02 - INFO - EVALUATING - Epoch: [13][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.8389 (0.8787)	Prec@1 72.000 (68.941)	Prec@5 98.000 (98.000)
2019-05-03 11:27:03 - INFO - 
 Epoch: 14	Training Loss 0.6899 	Training Prec@1 76.338 	Training Prec@5 98.540 	Validation Loss 0.8839 	Validation Prec@1 68.820 	Validation Prec@5 97.970 	
2019-05-03 11:27:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:27:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:27:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:27:03 - INFO - TRAINING - Epoch: [14][0/500]	Time 0.377 (0.377)	Data 0.342 (0.342)	Loss 0.5731 (0.5731)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 11:27:06 - INFO - TRAINING - Epoch: [14][50/500]	Time 0.060 (0.062)	Data 0.000 (0.007)	Loss 0.6355 (0.6776)	Prec@1 71.000 (75.902)	Prec@5 100.000 (99.020)
2019-05-03 11:27:09 - INFO - TRAINING - Epoch: [14][100/500]	Time 0.055 (0.058)	Data 0.000 (0.004)	Loss 0.9448 (0.6751)	Prec@1 70.000 (76.168)	Prec@5 97.000 (98.772)
2019-05-03 11:27:12 - INFO - TRAINING - Epoch: [14][150/500]	Time 0.054 (0.057)	Data 0.000 (0.003)	Loss 0.5993 (0.6696)	Prec@1 83.000 (76.490)	Prec@5 99.000 (98.808)
2019-05-03 11:27:14 - INFO - TRAINING - Epoch: [14][200/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.6764 (0.6653)	Prec@1 81.000 (76.781)	Prec@5 98.000 (98.731)
2019-05-03 11:27:17 - INFO - TRAINING - Epoch: [14][250/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.6240 (0.6671)	Prec@1 76.000 (76.829)	Prec@5 100.000 (98.641)
2019-05-03 11:27:20 - INFO - TRAINING - Epoch: [14][300/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.5939 (0.6666)	Prec@1 79.000 (76.764)	Prec@5 100.000 (98.648)
2019-05-03 11:27:22 - INFO - TRAINING - Epoch: [14][350/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.5493 (0.6637)	Prec@1 79.000 (76.917)	Prec@5 100.000 (98.664)
2019-05-03 11:27:25 - INFO - TRAINING - Epoch: [14][400/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.7469 (0.6657)	Prec@1 70.000 (76.798)	Prec@5 97.000 (98.663)
2019-05-03 11:27:28 - INFO - TRAINING - Epoch: [14][450/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.7349 (0.6663)	Prec@1 74.000 (76.780)	Prec@5 99.000 (98.676)
2019-05-03 11:27:31 - INFO - EVALUATING - Epoch: [14][0/100]	Time 0.364 (0.364)	Data 0.349 (0.349)	Loss 0.9435 (0.9435)	Prec@1 64.000 (64.000)	Prec@5 96.000 (96.000)
2019-05-03 11:27:32 - INFO - EVALUATING - Epoch: [14][50/100]	Time 0.013 (0.025)	Data 0.000 (0.007)	Loss 0.8904 (0.8422)	Prec@1 72.000 (70.902)	Prec@5 96.000 (97.784)
2019-05-03 11:27:32 - INFO - 
 Epoch: 15	Training Loss 0.6649 	Training Prec@1 76.864 	Training Prec@5 98.680 	Validation Loss 0.8471 	Validation Prec@1 70.550 	Validation Prec@5 97.810 	
2019-05-03 11:27:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:27:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:27:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:27:33 - INFO - TRAINING - Epoch: [15][0/500]	Time 0.291 (0.291)	Data 0.259 (0.259)	Loss 0.7352 (0.7352)	Prec@1 74.000 (74.000)	Prec@5 97.000 (97.000)
2019-05-03 11:27:36 - INFO - TRAINING - Epoch: [15][50/500]	Time 0.052 (0.060)	Data 0.000 (0.006)	Loss 0.7578 (0.6648)	Prec@1 72.000 (77.078)	Prec@5 98.000 (98.784)
2019-05-03 11:27:38 - INFO - TRAINING - Epoch: [15][100/500]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 0.7266 (0.6685)	Prec@1 78.000 (76.921)	Prec@5 98.000 (98.634)
2019-05-03 11:27:41 - INFO - TRAINING - Epoch: [15][150/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.6478 (0.6560)	Prec@1 79.000 (77.285)	Prec@5 100.000 (98.715)
2019-05-03 11:27:44 - INFO - TRAINING - Epoch: [15][200/500]	Time 0.059 (0.057)	Data 0.000 (0.002)	Loss 0.5547 (0.6619)	Prec@1 81.000 (77.119)	Prec@5 100.000 (98.627)
2019-05-03 11:27:47 - INFO - TRAINING - Epoch: [15][250/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.6380 (0.6596)	Prec@1 76.000 (77.414)	Prec@5 100.000 (98.637)
2019-05-03 11:27:50 - INFO - TRAINING - Epoch: [15][300/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.4173 (0.6548)	Prec@1 85.000 (77.641)	Prec@5 100.000 (98.691)
2019-05-03 11:27:52 - INFO - TRAINING - Epoch: [15][350/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.6288 (0.6497)	Prec@1 75.000 (77.729)	Prec@5 98.000 (98.709)
2019-05-03 11:27:55 - INFO - TRAINING - Epoch: [15][400/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.5889 (0.6480)	Prec@1 78.000 (77.708)	Prec@5 100.000 (98.743)
2019-05-03 11:27:58 - INFO - TRAINING - Epoch: [15][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.8554 (0.6466)	Prec@1 71.000 (77.785)	Prec@5 99.000 (98.723)
2019-05-03 11:28:01 - INFO - EVALUATING - Epoch: [15][0/100]	Time 0.355 (0.355)	Data 0.348 (0.348)	Loss 0.8116 (0.8116)	Prec@1 73.000 (73.000)	Prec@5 96.000 (96.000)
2019-05-03 11:28:02 - INFO - EVALUATING - Epoch: [15][50/100]	Time 0.014 (0.024)	Data 0.000 (0.007)	Loss 0.7297 (0.8749)	Prec@1 76.000 (70.784)	Prec@5 99.000 (97.745)
2019-05-03 11:28:03 - INFO - 
 Epoch: 16	Training Loss 0.6465 	Training Prec@1 77.796 	Training Prec@5 98.720 	Validation Loss 0.8961 	Validation Prec@1 69.600 	Validation Prec@5 97.660 	
2019-05-03 11:28:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:28:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:28:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:28:03 - INFO - TRAINING - Epoch: [16][0/500]	Time 0.385 (0.385)	Data 0.359 (0.359)	Loss 0.6632 (0.6632)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 11:28:06 - INFO - TRAINING - Epoch: [16][50/500]	Time 0.052 (0.060)	Data 0.000 (0.008)	Loss 0.6518 (0.6312)	Prec@1 76.000 (78.196)	Prec@5 100.000 (98.804)
2019-05-03 11:28:09 - INFO - TRAINING - Epoch: [16][100/500]	Time 0.062 (0.057)	Data 0.000 (0.004)	Loss 0.5464 (0.6350)	Prec@1 79.000 (78.228)	Prec@5 99.000 (98.653)
2019-05-03 11:28:11 - INFO - TRAINING - Epoch: [16][150/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.7574 (0.6262)	Prec@1 76.000 (78.444)	Prec@5 97.000 (98.742)
2019-05-03 11:28:14 - INFO - TRAINING - Epoch: [16][200/500]	Time 0.053 (0.055)	Data 0.000 (0.003)	Loss 0.5817 (0.6309)	Prec@1 80.000 (78.403)	Prec@5 98.000 (98.781)
2019-05-03 11:28:17 - INFO - TRAINING - Epoch: [16][250/500]	Time 0.050 (0.055)	Data 0.000 (0.002)	Loss 0.7858 (0.6278)	Prec@1 73.000 (78.578)	Prec@5 99.000 (98.765)
2019-05-03 11:28:19 - INFO - TRAINING - Epoch: [16][300/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.7205 (0.6245)	Prec@1 75.000 (78.751)	Prec@5 97.000 (98.807)
2019-05-03 11:28:22 - INFO - TRAINING - Epoch: [16][350/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.4869 (0.6226)	Prec@1 86.000 (78.806)	Prec@5 99.000 (98.855)
2019-05-03 11:28:25 - INFO - TRAINING - Epoch: [16][400/500]	Time 0.057 (0.054)	Data 0.000 (0.002)	Loss 0.8477 (0.6261)	Prec@1 72.000 (78.656)	Prec@5 98.000 (98.838)
2019-05-03 11:28:27 - INFO - TRAINING - Epoch: [16][450/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.5585 (0.6249)	Prec@1 82.000 (78.636)	Prec@5 99.000 (98.858)
2019-05-03 11:28:30 - INFO - EVALUATING - Epoch: [16][0/100]	Time 0.367 (0.367)	Data 0.352 (0.352)	Loss 1.1264 (1.1264)	Prec@1 59.000 (59.000)	Prec@5 96.000 (96.000)
2019-05-03 11:28:31 - INFO - EVALUATING - Epoch: [16][50/100]	Time 0.014 (0.025)	Data 0.000 (0.007)	Loss 1.1958 (1.1684)	Prec@1 56.000 (60.725)	Prec@5 98.000 (96.118)
2019-05-03 11:28:32 - INFO - 
 Epoch: 17	Training Loss 0.6255 	Training Prec@1 78.576 	Training Prec@5 98.860 	Validation Loss 1.1786 	Validation Prec@1 60.500 	Validation Prec@5 96.030 	
2019-05-03 11:28:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:28:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:28:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:28:33 - INFO - TRAINING - Epoch: [17][0/500]	Time 0.286 (0.286)	Data 0.260 (0.260)	Loss 0.5495 (0.5495)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 11:28:35 - INFO - TRAINING - Epoch: [17][50/500]	Time 0.058 (0.058)	Data 0.000 (0.006)	Loss 0.4700 (0.6349)	Prec@1 84.000 (78.216)	Prec@5 100.000 (98.745)
2019-05-03 11:28:38 - INFO - TRAINING - Epoch: [17][100/500]	Time 0.055 (0.056)	Data 0.000 (0.003)	Loss 0.4957 (0.6173)	Prec@1 85.000 (78.911)	Prec@5 99.000 (98.782)
2019-05-03 11:28:41 - INFO - TRAINING - Epoch: [17][150/500]	Time 0.053 (0.055)	Data 0.000 (0.003)	Loss 0.4698 (0.6123)	Prec@1 84.000 (79.146)	Prec@5 100.000 (98.821)
2019-05-03 11:28:43 - INFO - TRAINING - Epoch: [17][200/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.6324 (0.6149)	Prec@1 79.000 (79.035)	Prec@5 99.000 (98.846)
2019-05-03 11:28:46 - INFO - TRAINING - Epoch: [17][250/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.4821 (0.6197)	Prec@1 84.000 (78.789)	Prec@5 99.000 (98.841)
2019-05-03 11:28:49 - INFO - TRAINING - Epoch: [17][300/500]	Time 0.062 (0.054)	Data 0.000 (0.002)	Loss 0.4786 (0.6179)	Prec@1 84.000 (78.831)	Prec@5 100.000 (98.847)
2019-05-03 11:28:51 - INFO - TRAINING - Epoch: [17][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.5012 (0.6220)	Prec@1 81.000 (78.675)	Prec@5 100.000 (98.823)
2019-05-03 11:28:54 - INFO - TRAINING - Epoch: [17][400/500]	Time 0.060 (0.054)	Data 0.000 (0.001)	Loss 0.5726 (0.6218)	Prec@1 83.000 (78.718)	Prec@5 99.000 (98.830)
2019-05-03 11:28:57 - INFO - TRAINING - Epoch: [17][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.7142 (0.6208)	Prec@1 73.000 (78.701)	Prec@5 98.000 (98.843)
2019-05-03 11:29:00 - INFO - EVALUATING - Epoch: [17][0/100]	Time 0.383 (0.383)	Data 0.368 (0.368)	Loss 1.0371 (1.0371)	Prec@1 62.000 (62.000)	Prec@5 97.000 (97.000)
2019-05-03 11:29:00 - INFO - EVALUATING - Epoch: [17][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.9867 (0.9880)	Prec@1 66.000 (68.392)	Prec@5 94.000 (95.745)
2019-05-03 11:29:01 - INFO - 
 Epoch: 18	Training Loss 0.6199 	Training Prec@1 78.742 	Training Prec@5 98.832 	Validation Loss 0.9862 	Validation Prec@1 67.990 	Validation Prec@5 95.890 	
2019-05-03 11:29:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:29:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:29:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:29:02 - INFO - TRAINING - Epoch: [18][0/500]	Time 0.377 (0.377)	Data 0.357 (0.357)	Loss 0.4632 (0.4632)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 11:29:05 - INFO - TRAINING - Epoch: [18][50/500]	Time 0.055 (0.063)	Data 0.000 (0.008)	Loss 0.7423 (0.6482)	Prec@1 77.000 (77.510)	Prec@5 98.000 (98.824)
2019-05-03 11:29:07 - INFO - TRAINING - Epoch: [18][100/500]	Time 0.058 (0.060)	Data 0.000 (0.004)	Loss 0.4852 (0.6361)	Prec@1 84.000 (78.228)	Prec@5 99.000 (98.871)
2019-05-03 11:29:10 - INFO - TRAINING - Epoch: [18][150/500]	Time 0.060 (0.059)	Data 0.000 (0.003)	Loss 0.7686 (0.6262)	Prec@1 72.000 (78.490)	Prec@5 94.000 (98.861)
2019-05-03 11:29:13 - INFO - TRAINING - Epoch: [18][200/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.6907 (0.6164)	Prec@1 79.000 (78.940)	Prec@5 100.000 (98.876)
2019-05-03 11:29:16 - INFO - TRAINING - Epoch: [18][250/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.8322 (0.6169)	Prec@1 75.000 (79.028)	Prec@5 99.000 (98.876)
2019-05-03 11:29:19 - INFO - TRAINING - Epoch: [18][300/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.6752 (0.6150)	Prec@1 80.000 (79.106)	Prec@5 100.000 (98.867)
2019-05-03 11:29:22 - INFO - TRAINING - Epoch: [18][350/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.7710 (0.6157)	Prec@1 69.000 (79.080)	Prec@5 100.000 (98.877)
2019-05-03 11:29:24 - INFO - TRAINING - Epoch: [18][400/500]	Time 0.046 (0.058)	Data 0.000 (0.002)	Loss 0.4872 (0.6152)	Prec@1 84.000 (79.102)	Prec@5 100.000 (98.843)
2019-05-03 11:29:27 - INFO - TRAINING - Epoch: [18][450/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.7695 (0.6133)	Prec@1 72.000 (79.208)	Prec@5 100.000 (98.865)
2019-05-03 11:29:30 - INFO - EVALUATING - Epoch: [18][0/100]	Time 0.345 (0.345)	Data 0.332 (0.332)	Loss 0.7973 (0.7973)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 11:29:31 - INFO - EVALUATING - Epoch: [18][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.7074 (0.8327)	Prec@1 80.000 (72.588)	Prec@5 98.000 (97.686)
2019-05-03 11:29:32 - INFO - 
 Epoch: 19	Training Loss 0.6166 	Training Prec@1 79.078 	Training Prec@5 98.834 	Validation Loss 0.8440 	Validation Prec@1 71.920 	Validation Prec@5 97.770 	
2019-05-03 11:29:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:29:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:29:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:29:32 - INFO - TRAINING - Epoch: [19][0/500]	Time 0.289 (0.289)	Data 0.259 (0.259)	Loss 0.6348 (0.6348)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 11:29:35 - INFO - TRAINING - Epoch: [19][50/500]	Time 0.045 (0.057)	Data 0.000 (0.006)	Loss 0.6207 (0.6256)	Prec@1 77.000 (78.314)	Prec@5 100.000 (98.745)
2019-05-03 11:29:38 - INFO - TRAINING - Epoch: [19][100/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.6370 (0.6113)	Prec@1 79.000 (78.743)	Prec@5 99.000 (98.990)
2019-05-03 11:29:40 - INFO - TRAINING - Epoch: [19][150/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.7379 (0.6079)	Prec@1 74.000 (78.980)	Prec@5 97.000 (98.980)
2019-05-03 11:29:43 - INFO - TRAINING - Epoch: [19][200/500]	Time 0.061 (0.054)	Data 0.000 (0.002)	Loss 0.6154 (0.6124)	Prec@1 81.000 (78.970)	Prec@5 99.000 (98.935)
2019-05-03 11:29:46 - INFO - TRAINING - Epoch: [19][250/500]	Time 0.057 (0.054)	Data 0.000 (0.002)	Loss 0.5390 (0.6066)	Prec@1 82.000 (79.283)	Prec@5 100.000 (98.928)
2019-05-03 11:29:48 - INFO - TRAINING - Epoch: [19][300/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.5756 (0.6068)	Prec@1 80.000 (79.329)	Prec@5 99.000 (98.900)
2019-05-03 11:29:51 - INFO - TRAINING - Epoch: [19][350/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.5760 (0.6115)	Prec@1 82.000 (79.214)	Prec@5 99.000 (98.886)
2019-05-03 11:29:54 - INFO - TRAINING - Epoch: [19][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.6407 (0.6124)	Prec@1 77.000 (79.162)	Prec@5 99.000 (98.880)
2019-05-03 11:29:57 - INFO - TRAINING - Epoch: [19][450/500]	Time 0.066 (0.054)	Data 0.000 (0.001)	Loss 0.5325 (0.6143)	Prec@1 80.000 (79.124)	Prec@5 98.000 (98.882)
2019-05-03 11:29:59 - INFO - EVALUATING - Epoch: [19][0/100]	Time 0.326 (0.326)	Data 0.320 (0.320)	Loss 0.7964 (0.7964)	Prec@1 76.000 (76.000)	Prec@5 96.000 (96.000)
2019-05-03 11:30:00 - INFO - EVALUATING - Epoch: [19][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.7437 (0.8260)	Prec@1 77.000 (72.824)	Prec@5 99.000 (96.745)
2019-05-03 11:30:01 - INFO - 
 Epoch: 20	Training Loss 0.6146 	Training Prec@1 79.166 	Training Prec@5 98.884 	Validation Loss 0.8322 	Validation Prec@1 72.740 	Validation Prec@5 96.870 	
2019-05-03 11:30:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:30:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:30:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:30:02 - INFO - TRAINING - Epoch: [20][0/500]	Time 0.278 (0.278)	Data 0.252 (0.252)	Loss 0.6166 (0.6166)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 11:30:04 - INFO - TRAINING - Epoch: [20][50/500]	Time 0.058 (0.061)	Data 0.000 (0.006)	Loss 0.6560 (0.6312)	Prec@1 78.000 (78.294)	Prec@5 99.000 (98.863)
2019-05-03 11:30:07 - INFO - TRAINING - Epoch: [20][100/500]	Time 0.054 (0.059)	Data 0.000 (0.003)	Loss 0.5432 (0.6155)	Prec@1 83.000 (78.832)	Prec@5 100.000 (98.861)
2019-05-03 11:30:10 - INFO - TRAINING - Epoch: [20][150/500]	Time 0.054 (0.058)	Data 0.000 (0.003)	Loss 0.5813 (0.6091)	Prec@1 80.000 (79.245)	Prec@5 98.000 (98.887)
2019-05-03 11:30:13 - INFO - TRAINING - Epoch: [20][200/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.7265 (0.6075)	Prec@1 71.000 (79.284)	Prec@5 98.000 (98.831)
2019-05-03 11:30:16 - INFO - TRAINING - Epoch: [20][250/500]	Time 0.043 (0.058)	Data 0.000 (0.002)	Loss 0.5703 (0.6017)	Prec@1 82.000 (79.359)	Prec@5 98.000 (98.857)
2019-05-03 11:30:19 - INFO - TRAINING - Epoch: [20][300/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.6660 (0.5953)	Prec@1 74.000 (79.578)	Prec@5 99.000 (98.904)
2019-05-03 11:30:21 - INFO - TRAINING - Epoch: [20][350/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.7466 (0.5931)	Prec@1 77.000 (79.664)	Prec@5 99.000 (98.937)
2019-05-03 11:30:24 - INFO - TRAINING - Epoch: [20][400/500]	Time 0.067 (0.057)	Data 0.000 (0.002)	Loss 0.4242 (0.5951)	Prec@1 84.000 (79.599)	Prec@5 99.000 (98.930)
2019-05-03 11:30:27 - INFO - TRAINING - Epoch: [20][450/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.4705 (0.5943)	Prec@1 86.000 (79.652)	Prec@5 99.000 (98.931)
2019-05-03 11:30:30 - INFO - EVALUATING - Epoch: [20][0/100]	Time 0.348 (0.348)	Data 0.333 (0.333)	Loss 0.7556 (0.7556)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-03 11:30:31 - INFO - EVALUATING - Epoch: [20][50/100]	Time 0.021 (0.024)	Data 0.000 (0.007)	Loss 0.7671 (0.7987)	Prec@1 77.000 (73.216)	Prec@5 96.000 (97.667)
2019-05-03 11:30:32 - INFO - 
 Epoch: 21	Training Loss 0.5961 	Training Prec@1 79.588 	Training Prec@5 98.932 	Validation Loss 0.8069 	Validation Prec@1 72.980 	Validation Prec@5 97.920 	
2019-05-03 11:30:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:30:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:30:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:30:32 - INFO - TRAINING - Epoch: [21][0/500]	Time 0.300 (0.300)	Data 0.264 (0.264)	Loss 0.7343 (0.7343)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 11:30:35 - INFO - TRAINING - Epoch: [21][50/500]	Time 0.045 (0.058)	Data 0.000 (0.006)	Loss 0.6297 (0.6027)	Prec@1 75.000 (79.451)	Prec@5 99.000 (98.863)
2019-05-03 11:30:37 - INFO - TRAINING - Epoch: [21][100/500]	Time 0.055 (0.056)	Data 0.000 (0.003)	Loss 0.5563 (0.6008)	Prec@1 81.000 (79.089)	Prec@5 100.000 (98.960)
2019-05-03 11:30:40 - INFO - TRAINING - Epoch: [21][150/500]	Time 0.068 (0.055)	Data 0.000 (0.003)	Loss 0.4793 (0.5928)	Prec@1 83.000 (79.325)	Prec@5 98.000 (99.060)
2019-05-03 11:30:43 - INFO - TRAINING - Epoch: [21][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.3952 (0.5836)	Prec@1 84.000 (79.866)	Prec@5 100.000 (99.050)
2019-05-03 11:30:45 - INFO - TRAINING - Epoch: [21][250/500]	Time 0.044 (0.054)	Data 0.000 (0.002)	Loss 0.5261 (0.5823)	Prec@1 81.000 (80.080)	Prec@5 99.000 (99.004)
2019-05-03 11:30:48 - INFO - TRAINING - Epoch: [21][300/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.5948 (0.5827)	Prec@1 79.000 (80.096)	Prec@5 99.000 (98.980)
2019-05-03 11:30:51 - INFO - TRAINING - Epoch: [21][350/500]	Time 0.040 (0.054)	Data 0.000 (0.002)	Loss 0.4804 (0.5826)	Prec@1 85.000 (80.026)	Prec@5 98.000 (98.972)
2019-05-03 11:30:53 - INFO - TRAINING - Epoch: [21][400/500]	Time 0.056 (0.054)	Data 0.000 (0.001)	Loss 0.5298 (0.5793)	Prec@1 86.000 (80.195)	Prec@5 97.000 (98.968)
2019-05-03 11:30:56 - INFO - TRAINING - Epoch: [21][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.7079 (0.5799)	Prec@1 76.000 (80.208)	Prec@5 98.000 (98.920)
2019-05-03 11:30:59 - INFO - EVALUATING - Epoch: [21][0/100]	Time 0.367 (0.367)	Data 0.362 (0.362)	Loss 1.0559 (1.0559)	Prec@1 64.000 (64.000)	Prec@5 97.000 (97.000)
2019-05-03 11:31:00 - INFO - EVALUATING - Epoch: [21][50/100]	Time 0.018 (0.025)	Data 0.000 (0.008)	Loss 1.0802 (1.0484)	Prec@1 61.000 (65.216)	Prec@5 98.000 (96.765)
2019-05-03 11:31:01 - INFO - 
 Epoch: 22	Training Loss 0.5829 	Training Prec@1 80.118 	Training Prec@5 98.920 	Validation Loss 1.0588 	Validation Prec@1 64.480 	Validation Prec@5 96.890 	
2019-05-03 11:31:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:31:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:31:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:31:01 - INFO - TRAINING - Epoch: [22][0/500]	Time 0.290 (0.290)	Data 0.259 (0.259)	Loss 0.6271 (0.6271)	Prec@1 84.000 (84.000)	Prec@5 95.000 (95.000)
2019-05-03 11:31:04 - INFO - TRAINING - Epoch: [22][50/500]	Time 0.046 (0.058)	Data 0.000 (0.006)	Loss 0.5905 (0.5763)	Prec@1 79.000 (80.745)	Prec@5 99.000 (99.059)
2019-05-03 11:31:07 - INFO - TRAINING - Epoch: [22][100/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.5296 (0.5798)	Prec@1 79.000 (80.485)	Prec@5 100.000 (99.168)
2019-05-03 11:31:09 - INFO - TRAINING - Epoch: [22][150/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 0.4609 (0.5628)	Prec@1 81.000 (81.086)	Prec@5 100.000 (99.179)
2019-05-03 11:31:12 - INFO - TRAINING - Epoch: [22][200/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.6216 (0.5693)	Prec@1 79.000 (80.826)	Prec@5 100.000 (99.119)
2019-05-03 11:31:15 - INFO - TRAINING - Epoch: [22][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.4630 (0.5663)	Prec@1 84.000 (81.040)	Prec@5 100.000 (99.088)
2019-05-03 11:31:17 - INFO - TRAINING - Epoch: [22][300/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.6178 (0.5675)	Prec@1 78.000 (80.980)	Prec@5 98.000 (99.063)
2019-05-03 11:31:20 - INFO - TRAINING - Epoch: [22][350/500]	Time 0.061 (0.054)	Data 0.000 (0.002)	Loss 0.6105 (0.5667)	Prec@1 79.000 (80.920)	Prec@5 97.000 (99.063)
2019-05-03 11:31:23 - INFO - TRAINING - Epoch: [22][400/500]	Time 0.050 (0.054)	Data 0.000 (0.001)	Loss 0.5830 (0.5670)	Prec@1 77.000 (80.840)	Prec@5 99.000 (99.050)
2019-05-03 11:31:25 - INFO - TRAINING - Epoch: [22][450/500]	Time 0.046 (0.054)	Data 0.000 (0.001)	Loss 0.4449 (0.5640)	Prec@1 84.000 (80.916)	Prec@5 100.000 (99.067)
2019-05-03 11:31:28 - INFO - EVALUATING - Epoch: [22][0/100]	Time 0.383 (0.383)	Data 0.371 (0.371)	Loss 1.0349 (1.0349)	Prec@1 66.000 (66.000)	Prec@5 96.000 (96.000)
2019-05-03 11:31:29 - INFO - EVALUATING - Epoch: [22][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 1.1095 (1.1849)	Prec@1 62.000 (62.431)	Prec@5 96.000 (95.863)
2019-05-03 11:31:30 - INFO - 
 Epoch: 23	Training Loss 0.5673 	Training Prec@1 80.796 	Training Prec@5 99.052 	Validation Loss 1.1796 	Validation Prec@1 62.380 	Validation Prec@5 96.100 	
2019-05-03 11:31:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:31:30 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:31:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:31:30 - INFO - TRAINING - Epoch: [23][0/500]	Time 0.382 (0.382)	Data 0.354 (0.354)	Loss 0.7149 (0.7149)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-05-03 11:31:33 - INFO - TRAINING - Epoch: [23][50/500]	Time 0.070 (0.063)	Data 0.000 (0.008)	Loss 0.4914 (0.5601)	Prec@1 85.000 (81.039)	Prec@5 99.000 (99.137)
2019-05-03 11:31:36 - INFO - TRAINING - Epoch: [23][100/500]	Time 0.067 (0.060)	Data 0.000 (0.004)	Loss 0.5824 (0.5536)	Prec@1 81.000 (81.168)	Prec@5 100.000 (99.198)
2019-05-03 11:31:39 - INFO - TRAINING - Epoch: [23][150/500]	Time 0.063 (0.059)	Data 0.000 (0.003)	Loss 0.6320 (0.5521)	Prec@1 76.000 (81.404)	Prec@5 99.000 (99.192)
2019-05-03 11:31:42 - INFO - TRAINING - Epoch: [23][200/500]	Time 0.060 (0.058)	Data 0.000 (0.003)	Loss 0.6157 (0.5496)	Prec@1 76.000 (81.313)	Prec@5 100.000 (99.219)
2019-05-03 11:31:45 - INFO - TRAINING - Epoch: [23][250/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.5996 (0.5517)	Prec@1 78.000 (81.227)	Prec@5 100.000 (99.223)
2019-05-03 11:31:48 - INFO - TRAINING - Epoch: [23][300/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.6476 (0.5502)	Prec@1 77.000 (81.336)	Prec@5 99.000 (99.216)
2019-05-03 11:31:50 - INFO - TRAINING - Epoch: [23][350/500]	Time 0.047 (0.058)	Data 0.000 (0.002)	Loss 0.5955 (0.5470)	Prec@1 82.000 (81.422)	Prec@5 99.000 (99.205)
2019-05-03 11:31:53 - INFO - TRAINING - Epoch: [23][400/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.5976 (0.5460)	Prec@1 81.000 (81.479)	Prec@5 99.000 (99.180)
2019-05-03 11:31:56 - INFO - TRAINING - Epoch: [23][450/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.5746 (0.5482)	Prec@1 83.000 (81.361)	Prec@5 99.000 (99.166)
2019-05-03 11:31:59 - INFO - EVALUATING - Epoch: [23][0/100]	Time 0.342 (0.342)	Data 0.328 (0.328)	Loss 0.7472 (0.7472)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 11:32:00 - INFO - EVALUATING - Epoch: [23][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.5966 (0.7395)	Prec@1 83.000 (75.176)	Prec@5 98.000 (98.216)
2019-05-03 11:32:01 - INFO - 
 Epoch: 24	Training Loss 0.5507 	Training Prec@1 81.300 	Training Prec@5 99.146 	Validation Loss 0.7287 	Validation Prec@1 75.230 	Validation Prec@5 98.370 	
2019-05-03 11:32:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:32:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:32:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:32:01 - INFO - TRAINING - Epoch: [24][0/500]	Time 0.296 (0.296)	Data 0.264 (0.264)	Loss 0.5219 (0.5219)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 11:32:04 - INFO - TRAINING - Epoch: [24][50/500]	Time 0.048 (0.058)	Data 0.000 (0.006)	Loss 0.4885 (0.5442)	Prec@1 84.000 (81.392)	Prec@5 100.000 (99.059)
2019-05-03 11:32:07 - INFO - TRAINING - Epoch: [24][100/500]	Time 0.056 (0.056)	Data 0.000 (0.003)	Loss 0.4957 (0.5311)	Prec@1 84.000 (81.802)	Prec@5 100.000 (99.178)
2019-05-03 11:32:09 - INFO - TRAINING - Epoch: [24][150/500]	Time 0.061 (0.055)	Data 0.000 (0.003)	Loss 0.3936 (0.5316)	Prec@1 87.000 (81.695)	Prec@5 100.000 (99.159)
2019-05-03 11:32:12 - INFO - TRAINING - Epoch: [24][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.5205 (0.5371)	Prec@1 80.000 (81.433)	Prec@5 99.000 (99.154)
2019-05-03 11:32:15 - INFO - TRAINING - Epoch: [24][250/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.4930 (0.5398)	Prec@1 80.000 (81.367)	Prec@5 100.000 (99.120)
2019-05-03 11:32:17 - INFO - TRAINING - Epoch: [24][300/500]	Time 0.045 (0.054)	Data 0.000 (0.002)	Loss 0.3719 (0.5412)	Prec@1 88.000 (81.425)	Prec@5 99.000 (99.093)
2019-05-03 11:32:20 - INFO - TRAINING - Epoch: [24][350/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.4304 (0.5380)	Prec@1 84.000 (81.527)	Prec@5 99.000 (99.142)
2019-05-03 11:32:23 - INFO - TRAINING - Epoch: [24][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.4854 (0.5392)	Prec@1 83.000 (81.546)	Prec@5 99.000 (99.155)
2019-05-03 11:32:25 - INFO - TRAINING - Epoch: [24][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.4955 (0.5386)	Prec@1 84.000 (81.539)	Prec@5 99.000 (99.155)
2019-05-03 11:32:28 - INFO - EVALUATING - Epoch: [24][0/100]	Time 0.349 (0.349)	Data 0.341 (0.341)	Loss 0.8804 (0.8804)	Prec@1 65.000 (65.000)	Prec@5 100.000 (100.000)
2019-05-03 11:32:29 - INFO - EVALUATING - Epoch: [24][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.8605 (0.8607)	Prec@1 72.000 (71.451)	Prec@5 96.000 (97.510)
2019-05-03 11:32:30 - INFO - 
 Epoch: 25	Training Loss 0.5389 	Training Prec@1 81.564 	Training Prec@5 99.156 	Validation Loss 0.8672 	Validation Prec@1 71.130 	Validation Prec@5 97.560 	
2019-05-03 11:32:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:32:30 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:32:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:32:30 - INFO - TRAINING - Epoch: [25][0/500]	Time 0.368 (0.368)	Data 0.332 (0.332)	Loss 0.4024 (0.4024)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-05-03 11:32:33 - INFO - TRAINING - Epoch: [25][50/500]	Time 0.052 (0.060)	Data 0.000 (0.007)	Loss 0.6262 (0.5418)	Prec@1 76.000 (81.255)	Prec@5 100.000 (99.098)
2019-05-03 11:32:36 - INFO - TRAINING - Epoch: [25][100/500]	Time 0.040 (0.057)	Data 0.000 (0.004)	Loss 0.5733 (0.5217)	Prec@1 82.000 (81.931)	Prec@5 98.000 (99.248)
2019-05-03 11:32:39 - INFO - TRAINING - Epoch: [25][150/500]	Time 0.058 (0.056)	Data 0.000 (0.003)	Loss 0.5448 (0.5280)	Prec@1 80.000 (81.550)	Prec@5 99.000 (99.258)
2019-05-03 11:32:41 - INFO - TRAINING - Epoch: [25][200/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.6046 (0.5264)	Prec@1 81.000 (81.706)	Prec@5 98.000 (99.209)
2019-05-03 11:32:44 - INFO - TRAINING - Epoch: [25][250/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.5291 (0.5278)	Prec@1 81.000 (81.713)	Prec@5 97.000 (99.159)
2019-05-03 11:32:47 - INFO - TRAINING - Epoch: [25][300/500]	Time 0.064 (0.055)	Data 0.000 (0.002)	Loss 0.6139 (0.5295)	Prec@1 83.000 (81.731)	Prec@5 100.000 (99.159)
2019-05-03 11:32:49 - INFO - TRAINING - Epoch: [25][350/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.6383 (0.5352)	Prec@1 76.000 (81.496)	Prec@5 99.000 (99.137)
2019-05-03 11:32:52 - INFO - TRAINING - Epoch: [25][400/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.5880 (0.5337)	Prec@1 82.000 (81.549)	Prec@5 98.000 (99.135)
2019-05-03 11:32:55 - INFO - TRAINING - Epoch: [25][450/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.5188 (0.5313)	Prec@1 81.000 (81.616)	Prec@5 99.000 (99.131)
2019-05-03 11:32:57 - INFO - EVALUATING - Epoch: [25][0/100]	Time 0.253 (0.253)	Data 0.238 (0.238)	Loss 0.6457 (0.6457)	Prec@1 78.000 (78.000)	Prec@5 98.000 (98.000)
2019-05-03 11:32:58 - INFO - EVALUATING - Epoch: [25][50/100]	Time 0.024 (0.022)	Data 0.000 (0.005)	Loss 0.5453 (0.6708)	Prec@1 81.000 (77.725)	Prec@5 98.000 (97.843)
2019-05-03 11:32:59 - INFO - 
 Epoch: 26	Training Loss 0.5313 	Training Prec@1 81.630 	Training Prec@5 99.126 	Validation Loss 0.6783 	Validation Prec@1 77.540 	Validation Prec@5 97.900 	
2019-05-03 11:32:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:32:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:32:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:33:00 - INFO - TRAINING - Epoch: [26][0/500]	Time 0.265 (0.265)	Data 0.233 (0.233)	Loss 0.4357 (0.4357)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 11:33:02 - INFO - TRAINING - Epoch: [26][50/500]	Time 0.055 (0.059)	Data 0.000 (0.005)	Loss 0.3061 (0.5211)	Prec@1 90.000 (82.608)	Prec@5 100.000 (99.275)
2019-05-03 11:33:05 - INFO - TRAINING - Epoch: [26][100/500]	Time 0.060 (0.057)	Data 0.000 (0.003)	Loss 0.6354 (0.5091)	Prec@1 80.000 (82.970)	Prec@5 100.000 (99.287)
2019-05-03 11:33:08 - INFO - TRAINING - Epoch: [26][150/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.4627 (0.5064)	Prec@1 85.000 (82.927)	Prec@5 100.000 (99.291)
2019-05-03 11:33:10 - INFO - TRAINING - Epoch: [26][200/500]	Time 0.065 (0.055)	Data 0.000 (0.002)	Loss 0.4145 (0.5106)	Prec@1 85.000 (82.562)	Prec@5 100.000 (99.289)
2019-05-03 11:33:13 - INFO - TRAINING - Epoch: [26][250/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.3998 (0.5086)	Prec@1 88.000 (82.598)	Prec@5 99.000 (99.299)
2019-05-03 11:33:16 - INFO - TRAINING - Epoch: [26][300/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.5992 (0.5087)	Prec@1 81.000 (82.684)	Prec@5 98.000 (99.249)
2019-05-03 11:33:18 - INFO - TRAINING - Epoch: [26][350/500]	Time 0.048 (0.054)	Data 0.000 (0.001)	Loss 0.5950 (0.5079)	Prec@1 84.000 (82.758)	Prec@5 98.000 (99.236)
2019-05-03 11:33:21 - INFO - TRAINING - Epoch: [26][400/500]	Time 0.039 (0.054)	Data 0.000 (0.001)	Loss 0.4284 (0.5082)	Prec@1 85.000 (82.713)	Prec@5 100.000 (99.249)
2019-05-03 11:33:24 - INFO - TRAINING - Epoch: [26][450/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.6334 (0.5114)	Prec@1 79.000 (82.645)	Prec@5 100.000 (99.228)
2019-05-03 11:33:27 - INFO - EVALUATING - Epoch: [26][0/100]	Time 0.366 (0.366)	Data 0.351 (0.351)	Loss 0.7064 (0.7064)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 11:33:28 - INFO - EVALUATING - Epoch: [26][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.5819 (0.6360)	Prec@1 80.000 (77.824)	Prec@5 98.000 (98.627)
2019-05-03 11:33:29 - INFO - 
 Epoch: 27	Training Loss 0.5105 	Training Prec@1 82.708 	Training Prec@5 99.212 	Validation Loss 0.6465 	Validation Prec@1 77.590 	Validation Prec@5 98.800 	
2019-05-03 11:33:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:33:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:33:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:33:29 - INFO - TRAINING - Epoch: [27][0/500]	Time 0.287 (0.287)	Data 0.255 (0.255)	Loss 0.5532 (0.5532)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 11:33:32 - INFO - TRAINING - Epoch: [27][50/500]	Time 0.058 (0.061)	Data 0.000 (0.006)	Loss 0.4458 (0.5124)	Prec@1 85.000 (82.745)	Prec@5 100.000 (99.157)
2019-05-03 11:33:35 - INFO - TRAINING - Epoch: [27][100/500]	Time 0.066 (0.059)	Data 0.000 (0.003)	Loss 0.4346 (0.5056)	Prec@1 87.000 (82.673)	Prec@5 99.000 (99.238)
2019-05-03 11:33:38 - INFO - TRAINING - Epoch: [27][150/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.5076 (0.5021)	Prec@1 83.000 (82.947)	Prec@5 99.000 (99.258)
2019-05-03 11:33:40 - INFO - TRAINING - Epoch: [27][200/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.6648 (0.4997)	Prec@1 79.000 (83.015)	Prec@5 98.000 (99.274)
2019-05-03 11:33:43 - INFO - TRAINING - Epoch: [27][250/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.3749 (0.4960)	Prec@1 87.000 (83.167)	Prec@5 100.000 (99.315)
2019-05-03 11:33:46 - INFO - TRAINING - Epoch: [27][300/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.4937 (0.5032)	Prec@1 82.000 (82.930)	Prec@5 100.000 (99.302)
2019-05-03 11:33:49 - INFO - TRAINING - Epoch: [27][350/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.5118 (0.4992)	Prec@1 83.000 (83.131)	Prec@5 100.000 (99.279)
2019-05-03 11:33:52 - INFO - TRAINING - Epoch: [27][400/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.5140 (0.4987)	Prec@1 84.000 (83.067)	Prec@5 98.000 (99.277)
2019-05-03 11:33:55 - INFO - TRAINING - Epoch: [27][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.5480 (0.5008)	Prec@1 84.000 (82.998)	Prec@5 97.000 (99.262)
2019-05-03 11:33:58 - INFO - EVALUATING - Epoch: [27][0/100]	Time 0.366 (0.366)	Data 0.354 (0.354)	Loss 0.6974 (0.6974)	Prec@1 76.000 (76.000)	Prec@5 97.000 (97.000)
2019-05-03 11:33:59 - INFO - EVALUATING - Epoch: [27][50/100]	Time 0.019 (0.024)	Data 0.000 (0.007)	Loss 0.6511 (0.7444)	Prec@1 76.000 (75.314)	Prec@5 96.000 (97.961)
2019-05-03 11:34:00 - INFO - 
 Epoch: 28	Training Loss 0.4979 	Training Prec@1 83.086 	Training Prec@5 99.282 	Validation Loss 0.7410 	Validation Prec@1 75.600 	Validation Prec@5 97.980 	
2019-05-03 11:34:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:34:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:34:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:34:00 - INFO - TRAINING - Epoch: [28][0/500]	Time 0.388 (0.388)	Data 0.358 (0.358)	Loss 0.4808 (0.4808)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 11:34:03 - INFO - TRAINING - Epoch: [28][50/500]	Time 0.051 (0.060)	Data 0.000 (0.008)	Loss 0.6528 (0.4945)	Prec@1 79.000 (83.196)	Prec@5 95.000 (99.078)
2019-05-03 11:34:05 - INFO - TRAINING - Epoch: [28][100/500]	Time 0.045 (0.057)	Data 0.000 (0.004)	Loss 0.7549 (0.4804)	Prec@1 74.000 (83.931)	Prec@5 99.000 (99.267)
2019-05-03 11:34:08 - INFO - TRAINING - Epoch: [28][150/500]	Time 0.047 (0.055)	Data 0.000 (0.003)	Loss 0.5488 (0.4786)	Prec@1 80.000 (83.881)	Prec@5 99.000 (99.258)
2019-05-03 11:34:11 - INFO - TRAINING - Epoch: [28][200/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.6334 (0.4788)	Prec@1 81.000 (83.935)	Prec@5 99.000 (99.229)
2019-05-03 11:34:13 - INFO - TRAINING - Epoch: [28][250/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.3662 (0.4792)	Prec@1 88.000 (83.880)	Prec@5 98.000 (99.255)
2019-05-03 11:34:16 - INFO - TRAINING - Epoch: [28][300/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.7227 (0.4792)	Prec@1 78.000 (83.844)	Prec@5 100.000 (99.289)
2019-05-03 11:34:19 - INFO - TRAINING - Epoch: [28][350/500]	Time 0.040 (0.054)	Data 0.000 (0.002)	Loss 0.5683 (0.4806)	Prec@1 79.000 (83.761)	Prec@5 100.000 (99.293)
2019-05-03 11:34:21 - INFO - TRAINING - Epoch: [28][400/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.4186 (0.4803)	Prec@1 86.000 (83.726)	Prec@5 99.000 (99.272)
2019-05-03 11:34:24 - INFO - TRAINING - Epoch: [28][450/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 0.3330 (0.4805)	Prec@1 90.000 (83.716)	Prec@5 100.000 (99.271)
2019-05-03 11:34:27 - INFO - EVALUATING - Epoch: [28][0/100]	Time 0.376 (0.376)	Data 0.361 (0.361)	Loss 0.6124 (0.6124)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 11:34:28 - INFO - EVALUATING - Epoch: [28][50/100]	Time 0.020 (0.025)	Data 0.000 (0.007)	Loss 0.6096 (0.6307)	Prec@1 81.000 (79.216)	Prec@5 98.000 (98.176)
2019-05-03 11:34:29 - INFO - 
 Epoch: 29	Training Loss 0.4796 	Training Prec@1 83.752 	Training Prec@5 99.276 	Validation Loss 0.6446 	Validation Prec@1 78.600 	Validation Prec@5 98.360 	
2019-05-03 11:34:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:34:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:34:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:34:29 - INFO - TRAINING - Epoch: [29][0/500]	Time 0.306 (0.306)	Data 0.276 (0.276)	Loss 0.5004 (0.5004)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 11:34:32 - INFO - TRAINING - Epoch: [29][50/500]	Time 0.047 (0.062)	Data 0.000 (0.006)	Loss 0.5730 (0.4669)	Prec@1 77.000 (84.471)	Prec@5 99.000 (99.471)
2019-05-03 11:34:35 - INFO - TRAINING - Epoch: [29][100/500]	Time 0.058 (0.059)	Data 0.000 (0.004)	Loss 0.7366 (0.4691)	Prec@1 74.000 (84.129)	Prec@5 99.000 (99.436)
2019-05-03 11:34:38 - INFO - TRAINING - Epoch: [29][150/500]	Time 0.061 (0.059)	Data 0.000 (0.003)	Loss 0.4128 (0.4689)	Prec@1 89.000 (83.974)	Prec@5 100.000 (99.490)
2019-05-03 11:34:41 - INFO - TRAINING - Epoch: [29][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.2852 (0.4699)	Prec@1 89.000 (83.980)	Prec@5 100.000 (99.498)
2019-05-03 11:34:44 - INFO - TRAINING - Epoch: [29][250/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.4529 (0.4665)	Prec@1 83.000 (84.084)	Prec@5 100.000 (99.482)
2019-05-03 11:34:46 - INFO - TRAINING - Epoch: [29][300/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.2824 (0.4670)	Prec@1 91.000 (84.086)	Prec@5 100.000 (99.452)
2019-05-03 11:34:49 - INFO - TRAINING - Epoch: [29][350/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.4797 (0.4632)	Prec@1 86.000 (84.174)	Prec@5 98.000 (99.442)
2019-05-03 11:34:52 - INFO - TRAINING - Epoch: [29][400/500]	Time 0.053 (0.057)	Data 0.000 (0.002)	Loss 0.4078 (0.4661)	Prec@1 86.000 (84.152)	Prec@5 99.000 (99.399)
2019-05-03 11:34:55 - INFO - TRAINING - Epoch: [29][450/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.3814 (0.4636)	Prec@1 87.000 (84.286)	Prec@5 100.000 (99.377)
2019-05-03 11:34:58 - INFO - EVALUATING - Epoch: [29][0/100]	Time 0.364 (0.364)	Data 0.357 (0.357)	Loss 0.8188 (0.8188)	Prec@1 76.000 (76.000)	Prec@5 97.000 (97.000)
2019-05-03 11:34:59 - INFO - EVALUATING - Epoch: [29][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.7336 (0.9003)	Prec@1 79.000 (71.902)	Prec@5 97.000 (96.471)
2019-05-03 11:35:00 - INFO - 
 Epoch: 30	Training Loss 0.4644 	Training Prec@1 84.244 	Training Prec@5 99.348 	Validation Loss 0.8977 	Validation Prec@1 71.650 	Validation Prec@5 96.380 	
2019-05-03 11:35:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:35:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:35:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:35:00 - INFO - TRAINING - Epoch: [30][0/500]	Time 0.375 (0.375)	Data 0.349 (0.349)	Loss 0.3693 (0.3693)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:35:03 - INFO - TRAINING - Epoch: [30][50/500]	Time 0.054 (0.060)	Data 0.000 (0.008)	Loss 0.5212 (0.4701)	Prec@1 85.000 (84.137)	Prec@5 99.000 (99.255)
2019-05-03 11:35:05 - INFO - TRAINING - Epoch: [30][100/500]	Time 0.046 (0.057)	Data 0.000 (0.004)	Loss 0.4542 (0.4592)	Prec@1 84.000 (84.624)	Prec@5 100.000 (99.297)
2019-05-03 11:35:08 - INFO - TRAINING - Epoch: [30][150/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.3081 (0.4594)	Prec@1 89.000 (84.543)	Prec@5 99.000 (99.278)
2019-05-03 11:35:11 - INFO - TRAINING - Epoch: [30][200/500]	Time 0.063 (0.055)	Data 0.000 (0.003)	Loss 0.4232 (0.4579)	Prec@1 84.000 (84.493)	Prec@5 100.000 (99.264)
2019-05-03 11:35:13 - INFO - TRAINING - Epoch: [30][250/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.3877 (0.4596)	Prec@1 89.000 (84.454)	Prec@5 99.000 (99.267)
2019-05-03 11:35:16 - INFO - TRAINING - Epoch: [30][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.5202 (0.4584)	Prec@1 82.000 (84.439)	Prec@5 99.000 (99.289)
2019-05-03 11:35:19 - INFO - TRAINING - Epoch: [30][350/500]	Time 0.042 (0.054)	Data 0.000 (0.002)	Loss 0.2358 (0.4581)	Prec@1 92.000 (84.424)	Prec@5 100.000 (99.299)
2019-05-03 11:35:21 - INFO - TRAINING - Epoch: [30][400/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.4793 (0.4575)	Prec@1 83.000 (84.499)	Prec@5 100.000 (99.317)
2019-05-03 11:35:24 - INFO - TRAINING - Epoch: [30][450/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.4839 (0.4571)	Prec@1 83.000 (84.532)	Prec@5 99.000 (99.322)
2019-05-03 11:35:27 - INFO - EVALUATING - Epoch: [30][0/100]	Time 0.369 (0.369)	Data 0.352 (0.352)	Loss 0.6331 (0.6331)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 11:35:28 - INFO - EVALUATING - Epoch: [30][50/100]	Time 0.019 (0.024)	Data 0.000 (0.007)	Loss 0.6107 (0.6352)	Prec@1 81.000 (78.882)	Prec@5 98.000 (98.863)
2019-05-03 11:35:29 - INFO - 
 Epoch: 31	Training Loss 0.4562 	Training Prec@1 84.570 	Training Prec@5 99.326 	Validation Loss 0.6355 	Validation Prec@1 78.660 	Validation Prec@5 98.950 	
2019-05-03 11:35:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:35:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:35:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:35:29 - INFO - TRAINING - Epoch: [31][0/500]	Time 0.263 (0.263)	Data 0.231 (0.231)	Loss 0.4634 (0.4634)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 11:35:32 - INFO - TRAINING - Epoch: [31][50/500]	Time 0.059 (0.058)	Data 0.000 (0.005)	Loss 0.4011 (0.4622)	Prec@1 88.000 (84.667)	Prec@5 100.000 (99.353)
2019-05-03 11:35:35 - INFO - TRAINING - Epoch: [31][100/500]	Time 0.057 (0.056)	Data 0.000 (0.003)	Loss 0.4300 (0.4488)	Prec@1 81.000 (84.822)	Prec@5 100.000 (99.406)
2019-05-03 11:35:37 - INFO - TRAINING - Epoch: [31][150/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.5980 (0.4491)	Prec@1 80.000 (84.894)	Prec@5 99.000 (99.411)
2019-05-03 11:35:40 - INFO - TRAINING - Epoch: [31][200/500]	Time 0.065 (0.055)	Data 0.000 (0.002)	Loss 0.2798 (0.4469)	Prec@1 92.000 (84.766)	Prec@5 100.000 (99.413)
2019-05-03 11:35:43 - INFO - TRAINING - Epoch: [31][250/500]	Time 0.067 (0.055)	Data 0.000 (0.002)	Loss 0.5372 (0.4473)	Prec@1 82.000 (84.841)	Prec@5 100.000 (99.434)
2019-05-03 11:35:45 - INFO - TRAINING - Epoch: [31][300/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.5494 (0.4444)	Prec@1 81.000 (84.894)	Prec@5 99.000 (99.458)
2019-05-03 11:35:48 - INFO - TRAINING - Epoch: [31][350/500]	Time 0.060 (0.054)	Data 0.000 (0.001)	Loss 0.4740 (0.4411)	Prec@1 83.000 (85.023)	Prec@5 100.000 (99.433)
2019-05-03 11:35:51 - INFO - TRAINING - Epoch: [31][400/500]	Time 0.058 (0.054)	Data 0.000 (0.001)	Loss 0.6496 (0.4421)	Prec@1 75.000 (84.948)	Prec@5 100.000 (99.469)
2019-05-03 11:35:53 - INFO - TRAINING - Epoch: [31][450/500]	Time 0.064 (0.054)	Data 0.000 (0.001)	Loss 0.4034 (0.4425)	Prec@1 86.000 (84.925)	Prec@5 100.000 (99.475)
2019-05-03 11:35:56 - INFO - EVALUATING - Epoch: [31][0/100]	Time 0.360 (0.360)	Data 0.346 (0.346)	Loss 0.5998 (0.5998)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 11:35:57 - INFO - EVALUATING - Epoch: [31][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.5208 (0.5686)	Prec@1 84.000 (81.353)	Prec@5 98.000 (98.882)
2019-05-03 11:35:58 - INFO - 
 Epoch: 32	Training Loss 0.4420 	Training Prec@1 84.932 	Training Prec@5 99.474 	Validation Loss 0.5746 	Validation Prec@1 81.000 	Validation Prec@5 98.960 	
2019-05-03 11:35:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:35:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:35:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:35:58 - INFO - TRAINING - Epoch: [32][0/500]	Time 0.292 (0.292)	Data 0.270 (0.270)	Loss 0.5367 (0.5367)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 11:36:01 - INFO - TRAINING - Epoch: [32][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.3588 (0.4285)	Prec@1 93.000 (85.157)	Prec@5 100.000 (99.490)
2019-05-03 11:36:04 - INFO - TRAINING - Epoch: [32][100/500]	Time 0.051 (0.059)	Data 0.000 (0.004)	Loss 0.3915 (0.4255)	Prec@1 88.000 (84.990)	Prec@5 100.000 (99.446)
2019-05-03 11:36:07 - INFO - TRAINING - Epoch: [32][150/500]	Time 0.053 (0.058)	Data 0.000 (0.003)	Loss 0.3031 (0.4214)	Prec@1 91.000 (85.318)	Prec@5 100.000 (99.483)
2019-05-03 11:36:10 - INFO - TRAINING - Epoch: [32][200/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.6561 (0.4225)	Prec@1 76.000 (85.368)	Prec@5 99.000 (99.478)
2019-05-03 11:36:13 - INFO - TRAINING - Epoch: [32][250/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.5196 (0.4207)	Prec@1 81.000 (85.506)	Prec@5 98.000 (99.450)
2019-05-03 11:36:16 - INFO - TRAINING - Epoch: [32][300/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.3139 (0.4249)	Prec@1 88.000 (85.402)	Prec@5 100.000 (99.452)
2019-05-03 11:36:18 - INFO - TRAINING - Epoch: [32][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.3677 (0.4270)	Prec@1 89.000 (85.333)	Prec@5 100.000 (99.447)
2019-05-03 11:36:21 - INFO - TRAINING - Epoch: [32][400/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.4662 (0.4306)	Prec@1 83.000 (85.224)	Prec@5 100.000 (99.444)
2019-05-03 11:36:24 - INFO - TRAINING - Epoch: [32][450/500]	Time 0.066 (0.057)	Data 0.000 (0.002)	Loss 0.4520 (0.4316)	Prec@1 82.000 (85.251)	Prec@5 100.000 (99.441)
2019-05-03 11:36:27 - INFO - EVALUATING - Epoch: [32][0/100]	Time 0.367 (0.367)	Data 0.355 (0.355)	Loss 0.4948 (0.4948)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 11:36:28 - INFO - EVALUATING - Epoch: [32][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.5306 (0.5726)	Prec@1 80.000 (80.745)	Prec@5 99.000 (98.863)
2019-05-03 11:36:29 - INFO - 
 Epoch: 33	Training Loss 0.4308 	Training Prec@1 85.300 	Training Prec@5 99.446 	Validation Loss 0.5633 	Validation Prec@1 80.990 	Validation Prec@5 99.060 	
2019-05-03 11:36:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:36:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:36:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:36:29 - INFO - TRAINING - Epoch: [33][0/500]	Time 0.281 (0.281)	Data 0.258 (0.258)	Loss 0.4417 (0.4417)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 11:36:32 - INFO - TRAINING - Epoch: [33][50/500]	Time 0.046 (0.057)	Data 0.000 (0.006)	Loss 0.4049 (0.4243)	Prec@1 89.000 (85.588)	Prec@5 100.000 (99.569)
2019-05-03 11:36:35 - INFO - TRAINING - Epoch: [33][100/500]	Time 0.062 (0.055)	Data 0.000 (0.003)	Loss 0.4046 (0.4174)	Prec@1 86.000 (85.832)	Prec@5 99.000 (99.545)
2019-05-03 11:36:37 - INFO - TRAINING - Epoch: [33][150/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.4067 (0.4143)	Prec@1 83.000 (86.000)	Prec@5 100.000 (99.517)
2019-05-03 11:36:40 - INFO - TRAINING - Epoch: [33][200/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.4904 (0.4156)	Prec@1 84.000 (85.766)	Prec@5 99.000 (99.532)
2019-05-03 11:36:43 - INFO - TRAINING - Epoch: [33][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.5918 (0.4191)	Prec@1 78.000 (85.522)	Prec@5 100.000 (99.510)
2019-05-03 11:36:45 - INFO - TRAINING - Epoch: [33][300/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.4240 (0.4210)	Prec@1 87.000 (85.548)	Prec@5 100.000 (99.528)
2019-05-03 11:36:48 - INFO - TRAINING - Epoch: [33][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.2346 (0.4192)	Prec@1 93.000 (85.638)	Prec@5 100.000 (99.547)
2019-05-03 11:36:51 - INFO - TRAINING - Epoch: [33][400/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.3310 (0.4212)	Prec@1 86.000 (85.534)	Prec@5 100.000 (99.539)
2019-05-03 11:36:53 - INFO - TRAINING - Epoch: [33][450/500]	Time 0.056 (0.054)	Data 0.000 (0.001)	Loss 0.4066 (0.4207)	Prec@1 87.000 (85.557)	Prec@5 100.000 (99.528)
2019-05-03 11:36:56 - INFO - EVALUATING - Epoch: [33][0/100]	Time 0.372 (0.372)	Data 0.362 (0.362)	Loss 0.6219 (0.6219)	Prec@1 78.000 (78.000)	Prec@5 97.000 (97.000)
2019-05-03 11:36:57 - INFO - EVALUATING - Epoch: [33][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.6067 (0.5662)	Prec@1 83.000 (81.078)	Prec@5 97.000 (98.824)
2019-05-03 11:36:58 - INFO - 
 Epoch: 34	Training Loss 0.4202 	Training Prec@1 85.592 	Training Prec@5 99.532 	Validation Loss 0.5567 	Validation Prec@1 81.300 	Validation Prec@5 99.020 	
2019-05-03 11:36:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:36:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:36:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:36:59 - INFO - TRAINING - Epoch: [34][0/500]	Time 0.292 (0.292)	Data 0.264 (0.264)	Loss 0.3565 (0.3565)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-03 11:37:01 - INFO - TRAINING - Epoch: [34][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.4502 (0.4097)	Prec@1 83.000 (85.588)	Prec@5 100.000 (99.490)
2019-05-03 11:37:04 - INFO - TRAINING - Epoch: [34][100/500]	Time 0.051 (0.059)	Data 0.000 (0.003)	Loss 0.2712 (0.3975)	Prec@1 91.000 (86.158)	Prec@5 100.000 (99.554)
2019-05-03 11:37:07 - INFO - TRAINING - Epoch: [34][150/500]	Time 0.058 (0.058)	Data 0.000 (0.003)	Loss 0.4644 (0.4042)	Prec@1 83.000 (86.126)	Prec@5 97.000 (99.530)
2019-05-03 11:37:10 - INFO - TRAINING - Epoch: [34][200/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.4405 (0.4023)	Prec@1 87.000 (86.303)	Prec@5 100.000 (99.527)
2019-05-03 11:37:13 - INFO - TRAINING - Epoch: [34][250/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.3821 (0.4075)	Prec@1 85.000 (86.056)	Prec@5 99.000 (99.510)
2019-05-03 11:37:16 - INFO - TRAINING - Epoch: [34][300/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.4143 (0.4070)	Prec@1 86.000 (86.020)	Prec@5 100.000 (99.525)
2019-05-03 11:37:18 - INFO - TRAINING - Epoch: [34][350/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.3295 (0.4070)	Prec@1 90.000 (86.014)	Prec@5 99.000 (99.521)
2019-05-03 11:37:21 - INFO - TRAINING - Epoch: [34][400/500]	Time 0.054 (0.057)	Data 0.000 (0.001)	Loss 0.3790 (0.4075)	Prec@1 86.000 (86.072)	Prec@5 100.000 (99.526)
2019-05-03 11:37:24 - INFO - TRAINING - Epoch: [34][450/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.5062 (0.4094)	Prec@1 84.000 (86.067)	Prec@5 98.000 (99.512)
2019-05-03 11:37:27 - INFO - EVALUATING - Epoch: [34][0/100]	Time 0.393 (0.393)	Data 0.381 (0.381)	Loss 0.5268 (0.5268)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 11:37:28 - INFO - EVALUATING - Epoch: [34][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.5186 (0.5758)	Prec@1 84.000 (80.608)	Prec@5 98.000 (98.765)
2019-05-03 11:37:29 - INFO - 
 Epoch: 35	Training Loss 0.4112 	Training Prec@1 85.996 	Training Prec@5 99.506 	Validation Loss 0.5742 	Validation Prec@1 80.690 	Validation Prec@5 98.890 	
2019-05-03 11:37:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:37:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:37:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:37:29 - INFO - TRAINING - Epoch: [35][0/500]	Time 0.267 (0.267)	Data 0.243 (0.243)	Loss 0.3024 (0.3024)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:37:32 - INFO - TRAINING - Epoch: [35][50/500]	Time 0.054 (0.057)	Data 0.000 (0.006)	Loss 0.2922 (0.3922)	Prec@1 90.000 (86.451)	Prec@5 100.000 (99.510)
2019-05-03 11:37:35 - INFO - TRAINING - Epoch: [35][100/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.2089 (0.3904)	Prec@1 92.000 (86.634)	Prec@5 100.000 (99.515)
2019-05-03 11:37:37 - INFO - TRAINING - Epoch: [35][150/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.3691 (0.3856)	Prec@1 85.000 (86.815)	Prec@5 100.000 (99.530)
2019-05-03 11:37:40 - INFO - TRAINING - Epoch: [35][200/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.4309 (0.3818)	Prec@1 88.000 (86.881)	Prec@5 100.000 (99.552)
2019-05-03 11:37:43 - INFO - TRAINING - Epoch: [35][250/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.3755 (0.3863)	Prec@1 85.000 (86.773)	Prec@5 100.000 (99.534)
2019-05-03 11:37:45 - INFO - TRAINING - Epoch: [35][300/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.3822 (0.3867)	Prec@1 84.000 (86.741)	Prec@5 100.000 (99.535)
2019-05-03 11:37:48 - INFO - TRAINING - Epoch: [35][350/500]	Time 0.040 (0.054)	Data 0.000 (0.001)	Loss 0.4126 (0.3858)	Prec@1 88.000 (86.766)	Prec@5 98.000 (99.541)
2019-05-03 11:37:51 - INFO - TRAINING - Epoch: [35][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.4013 (0.3877)	Prec@1 86.000 (86.758)	Prec@5 100.000 (99.541)
2019-05-03 11:37:53 - INFO - TRAINING - Epoch: [35][450/500]	Time 0.059 (0.054)	Data 0.000 (0.001)	Loss 0.3915 (0.3901)	Prec@1 88.000 (86.712)	Prec@5 100.000 (99.532)
2019-05-03 11:37:56 - INFO - EVALUATING - Epoch: [35][0/100]	Time 0.401 (0.401)	Data 0.390 (0.390)	Loss 0.4767 (0.4767)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 11:37:57 - INFO - EVALUATING - Epoch: [35][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.4159 (0.4473)	Prec@1 82.000 (85.000)	Prec@5 100.000 (99.314)
2019-05-03 11:37:58 - INFO - 
 Epoch: 36	Training Loss 0.3917 	Training Prec@1 86.622 	Training Prec@5 99.540 	Validation Loss 0.4531 	Validation Prec@1 84.530 	Validation Prec@5 99.400 	
2019-05-03 11:37:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:37:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:37:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:37:59 - INFO - TRAINING - Epoch: [36][0/500]	Time 0.296 (0.296)	Data 0.270 (0.270)	Loss 0.3050 (0.3050)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:38:01 - INFO - TRAINING - Epoch: [36][50/500]	Time 0.055 (0.059)	Data 0.000 (0.006)	Loss 0.4790 (0.3874)	Prec@1 82.000 (86.549)	Prec@5 100.000 (99.667)
2019-05-03 11:38:04 - INFO - TRAINING - Epoch: [36][100/500]	Time 0.060 (0.057)	Data 0.000 (0.003)	Loss 0.3593 (0.3828)	Prec@1 89.000 (86.861)	Prec@5 98.000 (99.584)
2019-05-03 11:38:07 - INFO - TRAINING - Epoch: [36][150/500]	Time 0.049 (0.056)	Data 0.000 (0.003)	Loss 0.4274 (0.3841)	Prec@1 84.000 (86.788)	Prec@5 100.000 (99.609)
2019-05-03 11:38:09 - INFO - TRAINING - Epoch: [36][200/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.3946 (0.3836)	Prec@1 89.000 (86.816)	Prec@5 100.000 (99.582)
2019-05-03 11:38:12 - INFO - TRAINING - Epoch: [36][250/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.3493 (0.3859)	Prec@1 87.000 (86.761)	Prec@5 100.000 (99.570)
2019-05-03 11:38:15 - INFO - TRAINING - Epoch: [36][300/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.3313 (0.3841)	Prec@1 86.000 (86.910)	Prec@5 100.000 (99.578)
2019-05-03 11:38:17 - INFO - TRAINING - Epoch: [36][350/500]	Time 0.064 (0.054)	Data 0.000 (0.002)	Loss 0.3474 (0.3825)	Prec@1 88.000 (86.957)	Prec@5 100.000 (99.587)
2019-05-03 11:38:20 - INFO - TRAINING - Epoch: [36][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.4231 (0.3843)	Prec@1 85.000 (86.875)	Prec@5 100.000 (99.581)
2019-05-03 11:38:23 - INFO - TRAINING - Epoch: [36][450/500]	Time 0.048 (0.054)	Data 0.000 (0.001)	Loss 0.3376 (0.3822)	Prec@1 87.000 (86.953)	Prec@5 99.000 (99.592)
2019-05-03 11:38:26 - INFO - EVALUATING - Epoch: [36][0/100]	Time 0.262 (0.262)	Data 0.256 (0.256)	Loss 0.7129 (0.7129)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-05-03 11:38:27 - INFO - EVALUATING - Epoch: [36][50/100]	Time 0.013 (0.023)	Data 0.000 (0.005)	Loss 0.6225 (0.6163)	Prec@1 79.000 (79.275)	Prec@5 98.000 (98.824)
2019-05-03 11:38:27 - INFO - 
 Epoch: 37	Training Loss 0.3830 	Training Prec@1 86.928 	Training Prec@5 99.592 	Validation Loss 0.6189 	Validation Prec@1 79.180 	Validation Prec@5 98.870 	
2019-05-03 11:38:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:38:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:38:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:38:28 - INFO - TRAINING - Epoch: [37][0/500]	Time 0.290 (0.290)	Data 0.263 (0.263)	Loss 0.2964 (0.2964)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-05-03 11:38:31 - INFO - TRAINING - Epoch: [37][50/500]	Time 0.063 (0.061)	Data 0.000 (0.006)	Loss 0.3649 (0.3806)	Prec@1 88.000 (86.843)	Prec@5 100.000 (99.686)
2019-05-03 11:38:34 - INFO - TRAINING - Epoch: [37][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.2953 (0.3780)	Prec@1 89.000 (87.178)	Prec@5 100.000 (99.604)
2019-05-03 11:38:36 - INFO - TRAINING - Epoch: [37][150/500]	Time 0.059 (0.058)	Data 0.000 (0.003)	Loss 0.5042 (0.3825)	Prec@1 81.000 (86.841)	Prec@5 99.000 (99.589)
2019-05-03 11:38:39 - INFO - TRAINING - Epoch: [37][200/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.3181 (0.3823)	Prec@1 89.000 (86.891)	Prec@5 99.000 (99.577)
2019-05-03 11:38:42 - INFO - TRAINING - Epoch: [37][250/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.2681 (0.3785)	Prec@1 92.000 (86.996)	Prec@5 100.000 (99.622)
2019-05-03 11:38:45 - INFO - TRAINING - Epoch: [37][300/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.3610 (0.3768)	Prec@1 91.000 (87.116)	Prec@5 99.000 (99.615)
2019-05-03 11:38:48 - INFO - TRAINING - Epoch: [37][350/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.3569 (0.3761)	Prec@1 88.000 (87.125)	Prec@5 100.000 (99.615)
2019-05-03 11:38:51 - INFO - TRAINING - Epoch: [37][400/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.5799 (0.3764)	Prec@1 78.000 (87.120)	Prec@5 99.000 (99.606)
2019-05-03 11:38:53 - INFO - TRAINING - Epoch: [37][450/500]	Time 0.065 (0.057)	Data 0.000 (0.001)	Loss 0.2907 (0.3775)	Prec@1 92.000 (87.089)	Prec@5 100.000 (99.612)
2019-05-03 11:38:57 - INFO - EVALUATING - Epoch: [37][0/100]	Time 0.339 (0.339)	Data 0.332 (0.332)	Loss 0.5501 (0.5501)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 11:38:57 - INFO - EVALUATING - Epoch: [37][50/100]	Time 0.014 (0.024)	Data 0.000 (0.007)	Loss 0.6892 (0.6699)	Prec@1 77.000 (78.078)	Prec@5 99.000 (98.843)
2019-05-03 11:38:58 - INFO - 
 Epoch: 38	Training Loss 0.3788 	Training Prec@1 87.076 	Training Prec@5 99.608 	Validation Loss 0.6716 	Validation Prec@1 77.660 	Validation Prec@5 98.950 	
2019-05-03 11:38:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:38:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:38:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:38:59 - INFO - TRAINING - Epoch: [38][0/500]	Time 0.265 (0.265)	Data 0.235 (0.235)	Loss 0.3269 (0.3269)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 11:39:02 - INFO - TRAINING - Epoch: [38][50/500]	Time 0.067 (0.061)	Data 0.000 (0.005)	Loss 0.3493 (0.3980)	Prec@1 84.000 (86.098)	Prec@5 100.000 (99.549)
2019-05-03 11:39:04 - INFO - TRAINING - Epoch: [38][100/500]	Time 0.052 (0.059)	Data 0.000 (0.003)	Loss 0.4770 (0.3794)	Prec@1 83.000 (86.911)	Prec@5 99.000 (99.515)
2019-05-03 11:39:07 - INFO - TRAINING - Epoch: [38][150/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.3521 (0.3688)	Prec@1 91.000 (87.377)	Prec@5 99.000 (99.596)
2019-05-03 11:39:10 - INFO - TRAINING - Epoch: [38][200/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.3456 (0.3677)	Prec@1 89.000 (87.408)	Prec@5 100.000 (99.577)
2019-05-03 11:39:13 - INFO - TRAINING - Epoch: [38][250/500]	Time 0.065 (0.057)	Data 0.000 (0.002)	Loss 0.2873 (0.3648)	Prec@1 93.000 (87.602)	Prec@5 100.000 (99.574)
2019-05-03 11:39:16 - INFO - TRAINING - Epoch: [38][300/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.3632 (0.3637)	Prec@1 87.000 (87.698)	Prec@5 100.000 (99.585)
2019-05-03 11:39:18 - INFO - TRAINING - Epoch: [38][350/500]	Time 0.050 (0.057)	Data 0.000 (0.001)	Loss 0.3332 (0.3650)	Prec@1 85.000 (87.661)	Prec@5 100.000 (99.598)
2019-05-03 11:39:21 - INFO - TRAINING - Epoch: [38][400/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.3722 (0.3651)	Prec@1 89.000 (87.656)	Prec@5 99.000 (99.594)
2019-05-03 11:39:24 - INFO - TRAINING - Epoch: [38][450/500]	Time 0.045 (0.056)	Data 0.000 (0.001)	Loss 0.3759 (0.3671)	Prec@1 87.000 (87.581)	Prec@5 100.000 (99.565)
2019-05-03 11:39:27 - INFO - EVALUATING - Epoch: [38][0/100]	Time 0.356 (0.356)	Data 0.344 (0.344)	Loss 0.4896 (0.4896)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 11:39:28 - INFO - EVALUATING - Epoch: [38][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.5086 (0.5842)	Prec@1 83.000 (80.843)	Prec@5 100.000 (98.490)
2019-05-03 11:39:29 - INFO - 
 Epoch: 39	Training Loss 0.3684 	Training Prec@1 87.518 	Training Prec@5 99.556 	Validation Loss 0.5823 	Validation Prec@1 80.890 	Validation Prec@5 98.610 	
2019-05-03 11:39:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:39:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:39:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:39:29 - INFO - TRAINING - Epoch: [39][0/500]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.3104 (0.3104)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:39:32 - INFO - TRAINING - Epoch: [39][50/500]	Time 0.063 (0.062)	Data 0.000 (0.008)	Loss 0.3940 (0.3484)	Prec@1 83.000 (87.882)	Prec@5 100.000 (99.784)
2019-05-03 11:39:35 - INFO - TRAINING - Epoch: [39][100/500]	Time 0.050 (0.059)	Data 0.000 (0.004)	Loss 0.3158 (0.3415)	Prec@1 85.000 (88.248)	Prec@5 100.000 (99.733)
2019-05-03 11:39:37 - INFO - TRAINING - Epoch: [39][150/500]	Time 0.054 (0.058)	Data 0.000 (0.003)	Loss 0.3351 (0.3519)	Prec@1 89.000 (87.887)	Prec@5 100.000 (99.735)
2019-05-03 11:39:40 - INFO - TRAINING - Epoch: [39][200/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.2887 (0.3520)	Prec@1 89.000 (87.940)	Prec@5 100.000 (99.677)
2019-05-03 11:39:43 - INFO - TRAINING - Epoch: [39][250/500]	Time 0.047 (0.057)	Data 0.000 (0.002)	Loss 0.4457 (0.3554)	Prec@1 86.000 (87.809)	Prec@5 99.000 (99.685)
2019-05-03 11:39:46 - INFO - TRAINING - Epoch: [39][300/500]	Time 0.056 (0.056)	Data 0.000 (0.002)	Loss 0.2116 (0.3528)	Prec@1 93.000 (87.957)	Prec@5 100.000 (99.681)
2019-05-03 11:39:48 - INFO - TRAINING - Epoch: [39][350/500]	Time 0.048 (0.056)	Data 0.000 (0.002)	Loss 0.4301 (0.3565)	Prec@1 89.000 (87.880)	Prec@5 99.000 (99.661)
2019-05-03 11:39:51 - INFO - TRAINING - Epoch: [39][400/500]	Time 0.053 (0.056)	Data 0.000 (0.002)	Loss 0.2652 (0.3569)	Prec@1 91.000 (87.878)	Prec@5 100.000 (99.653)
2019-05-03 11:39:54 - INFO - TRAINING - Epoch: [39][450/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.3762 (0.3561)	Prec@1 88.000 (87.909)	Prec@5 99.000 (99.650)
2019-05-03 11:39:57 - INFO - EVALUATING - Epoch: [39][0/100]	Time 0.354 (0.354)	Data 0.346 (0.346)	Loss 0.5246 (0.5246)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 11:39:57 - INFO - EVALUATING - Epoch: [39][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.3951 (0.6132)	Prec@1 88.000 (80.608)	Prec@5 98.000 (98.157)
2019-05-03 11:39:58 - INFO - 
 Epoch: 40	Training Loss 0.3559 	Training Prec@1 87.896 	Training Prec@5 99.660 	Validation Loss 0.6223 	Validation Prec@1 80.280 	Validation Prec@5 98.210 	
2019-05-03 11:39:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:39:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:39:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:39:59 - INFO - TRAINING - Epoch: [40][0/500]	Time 0.294 (0.294)	Data 0.267 (0.267)	Loss 0.3068 (0.3068)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-03 11:40:01 - INFO - TRAINING - Epoch: [40][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.1807 (0.3302)	Prec@1 92.000 (88.824)	Prec@5 100.000 (99.804)
2019-05-03 11:40:04 - INFO - TRAINING - Epoch: [40][100/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.2280 (0.3267)	Prec@1 89.000 (88.921)	Prec@5 100.000 (99.782)
2019-05-03 11:40:07 - INFO - TRAINING - Epoch: [40][150/500]	Time 0.046 (0.055)	Data 0.000 (0.003)	Loss 0.4597 (0.3383)	Prec@1 82.000 (88.483)	Prec@5 99.000 (99.728)
2019-05-03 11:40:09 - INFO - TRAINING - Epoch: [40][200/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.3668 (0.3419)	Prec@1 88.000 (88.348)	Prec@5 100.000 (99.711)
2019-05-03 11:40:12 - INFO - TRAINING - Epoch: [40][250/500]	Time 0.062 (0.054)	Data 0.000 (0.002)	Loss 0.2666 (0.3384)	Prec@1 91.000 (88.454)	Prec@5 100.000 (99.693)
2019-05-03 11:40:15 - INFO - TRAINING - Epoch: [40][300/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.2848 (0.3410)	Prec@1 90.000 (88.296)	Prec@5 100.000 (99.681)
2019-05-03 11:40:17 - INFO - TRAINING - Epoch: [40][350/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.1984 (0.3413)	Prec@1 96.000 (88.276)	Prec@5 100.000 (99.692)
2019-05-03 11:40:20 - INFO - TRAINING - Epoch: [40][400/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.3826 (0.3431)	Prec@1 88.000 (88.212)	Prec@5 99.000 (99.688)
2019-05-03 11:40:23 - INFO - TRAINING - Epoch: [40][450/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.3855 (0.3418)	Prec@1 86.000 (88.328)	Prec@5 100.000 (99.690)
2019-05-03 11:40:26 - INFO - EVALUATING - Epoch: [40][0/100]	Time 0.374 (0.374)	Data 0.366 (0.366)	Loss 0.5435 (0.5435)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 11:40:27 - INFO - EVALUATING - Epoch: [40][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.2972 (0.4984)	Prec@1 90.000 (83.882)	Prec@5 99.000 (98.941)
2019-05-03 11:40:28 - INFO - 
 Epoch: 41	Training Loss 0.3436 	Training Prec@1 88.258 	Training Prec@5 99.682 	Validation Loss 0.4865 	Validation Prec@1 84.070 	Validation Prec@5 99.100 	
2019-05-03 11:40:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:40:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:40:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:40:28 - INFO - TRAINING - Epoch: [41][0/500]	Time 0.255 (0.255)	Data 0.229 (0.229)	Loss 0.3400 (0.3400)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:40:31 - INFO - TRAINING - Epoch: [41][50/500]	Time 0.067 (0.060)	Data 0.000 (0.005)	Loss 0.3974 (0.3187)	Prec@1 86.000 (89.314)	Prec@5 100.000 (99.804)
2019-05-03 11:40:34 - INFO - TRAINING - Epoch: [41][100/500]	Time 0.053 (0.058)	Data 0.000 (0.003)	Loss 0.2751 (0.3316)	Prec@1 93.000 (88.703)	Prec@5 98.000 (99.752)
2019-05-03 11:40:36 - INFO - TRAINING - Epoch: [41][150/500]	Time 0.043 (0.057)	Data 0.000 (0.002)	Loss 0.3691 (0.3330)	Prec@1 85.000 (88.603)	Prec@5 100.000 (99.742)
2019-05-03 11:40:39 - INFO - TRAINING - Epoch: [41][200/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.3430 (0.3385)	Prec@1 90.000 (88.537)	Prec@5 100.000 (99.687)
2019-05-03 11:40:42 - INFO - TRAINING - Epoch: [41][250/500]	Time 0.054 (0.056)	Data 0.000 (0.002)	Loss 0.2624 (0.3362)	Prec@1 93.000 (88.622)	Prec@5 100.000 (99.669)
2019-05-03 11:40:44 - INFO - TRAINING - Epoch: [41][300/500]	Time 0.045 (0.056)	Data 0.000 (0.002)	Loss 0.3398 (0.3367)	Prec@1 84.000 (88.518)	Prec@5 100.000 (99.688)
2019-05-03 11:40:47 - INFO - TRAINING - Epoch: [41][350/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.3248 (0.3408)	Prec@1 89.000 (88.407)	Prec@5 100.000 (99.672)
2019-05-03 11:40:50 - INFO - TRAINING - Epoch: [41][400/500]	Time 0.037 (0.055)	Data 0.000 (0.001)	Loss 0.2852 (0.3430)	Prec@1 92.000 (88.339)	Prec@5 100.000 (99.668)
2019-05-03 11:40:52 - INFO - TRAINING - Epoch: [41][450/500]	Time 0.051 (0.055)	Data 0.000 (0.001)	Loss 0.2949 (0.3398)	Prec@1 91.000 (88.426)	Prec@5 100.000 (99.665)
2019-05-03 11:40:55 - INFO - EVALUATING - Epoch: [41][0/100]	Time 0.277 (0.277)	Data 0.270 (0.270)	Loss 0.5415 (0.5415)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 11:40:56 - INFO - EVALUATING - Epoch: [41][50/100]	Time 0.017 (0.023)	Data 0.000 (0.006)	Loss 0.4060 (0.5500)	Prec@1 84.000 (82.216)	Prec@5 99.000 (98.804)
2019-05-03 11:40:57 - INFO - 
 Epoch: 42	Training Loss 0.3388 	Training Prec@1 88.424 	Training Prec@5 99.674 	Validation Loss 0.5515 	Validation Prec@1 82.080 	Validation Prec@5 98.860 	
2019-05-03 11:40:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:40:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:40:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:40:57 - INFO - TRAINING - Epoch: [42][0/500]	Time 0.287 (0.287)	Data 0.260 (0.260)	Loss 0.3851 (0.3851)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:41:00 - INFO - TRAINING - Epoch: [42][50/500]	Time 0.052 (0.059)	Data 0.000 (0.006)	Loss 0.3563 (0.3372)	Prec@1 88.000 (88.490)	Prec@5 100.000 (99.706)
2019-05-03 11:41:03 - INFO - TRAINING - Epoch: [42][100/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.1689 (0.3227)	Prec@1 94.000 (89.248)	Prec@5 100.000 (99.683)
2019-05-03 11:41:06 - INFO - TRAINING - Epoch: [42][150/500]	Time 0.056 (0.057)	Data 0.000 (0.003)	Loss 0.2553 (0.3183)	Prec@1 90.000 (89.344)	Prec@5 100.000 (99.735)
2019-05-03 11:41:09 - INFO - TRAINING - Epoch: [42][200/500]	Time 0.046 (0.057)	Data 0.000 (0.002)	Loss 0.3275 (0.3157)	Prec@1 89.000 (89.403)	Prec@5 100.000 (99.766)
2019-05-03 11:41:11 - INFO - TRAINING - Epoch: [42][250/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.2014 (0.3157)	Prec@1 94.000 (89.359)	Prec@5 99.000 (99.749)
2019-05-03 11:41:14 - INFO - TRAINING - Epoch: [42][300/500]	Time 0.065 (0.057)	Data 0.000 (0.002)	Loss 0.1398 (0.3189)	Prec@1 96.000 (89.209)	Prec@5 100.000 (99.738)
2019-05-03 11:41:17 - INFO - TRAINING - Epoch: [42][350/500]	Time 0.044 (0.057)	Data 0.000 (0.002)	Loss 0.1530 (0.3174)	Prec@1 95.000 (89.222)	Prec@5 100.000 (99.744)
2019-05-03 11:41:20 - INFO - TRAINING - Epoch: [42][400/500]	Time 0.064 (0.057)	Data 0.000 (0.002)	Loss 0.3486 (0.3195)	Prec@1 87.000 (89.137)	Prec@5 100.000 (99.723)
2019-05-03 11:41:23 - INFO - TRAINING - Epoch: [42][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.2175 (0.3221)	Prec@1 93.000 (89.069)	Prec@5 100.000 (99.723)
2019-05-03 11:41:26 - INFO - EVALUATING - Epoch: [42][0/100]	Time 0.343 (0.343)	Data 0.336 (0.336)	Loss 0.3520 (0.3520)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:41:27 - INFO - EVALUATING - Epoch: [42][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3339 (0.4709)	Prec@1 89.000 (84.961)	Prec@5 100.000 (99.059)
2019-05-03 11:41:28 - INFO - 
 Epoch: 43	Training Loss 0.3221 	Training Prec@1 89.026 	Training Prec@5 99.730 	Validation Loss 0.4623 	Validation Prec@1 84.840 	Validation Prec@5 99.260 	
2019-05-03 11:41:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:41:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:41:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:41:28 - INFO - TRAINING - Epoch: [43][0/500]	Time 0.290 (0.290)	Data 0.263 (0.263)	Loss 0.2262 (0.2262)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:41:31 - INFO - TRAINING - Epoch: [43][50/500]	Time 0.061 (0.058)	Data 0.000 (0.006)	Loss 0.3808 (0.3204)	Prec@1 87.000 (88.824)	Prec@5 100.000 (99.745)
2019-05-03 11:41:34 - INFO - TRAINING - Epoch: [43][100/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.3582 (0.3225)	Prec@1 89.000 (88.871)	Prec@5 99.000 (99.733)
2019-05-03 11:41:36 - INFO - TRAINING - Epoch: [43][150/500]	Time 0.046 (0.055)	Data 0.000 (0.003)	Loss 0.3287 (0.3243)	Prec@1 92.000 (88.934)	Prec@5 99.000 (99.755)
2019-05-03 11:41:39 - INFO - TRAINING - Epoch: [43][200/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.4026 (0.3221)	Prec@1 89.000 (88.960)	Prec@5 99.000 (99.751)
2019-05-03 11:41:42 - INFO - TRAINING - Epoch: [43][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.3508 (0.3196)	Prec@1 88.000 (89.052)	Prec@5 100.000 (99.761)
2019-05-03 11:41:44 - INFO - TRAINING - Epoch: [43][300/500]	Time 0.051 (0.054)	Data 0.000 (0.002)	Loss 0.3118 (0.3216)	Prec@1 88.000 (88.987)	Prec@5 100.000 (99.734)
2019-05-03 11:41:47 - INFO - TRAINING - Epoch: [43][350/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.4097 (0.3211)	Prec@1 83.000 (89.031)	Prec@5 100.000 (99.729)
2019-05-03 11:41:50 - INFO - TRAINING - Epoch: [43][400/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.3553 (0.3201)	Prec@1 86.000 (89.055)	Prec@5 99.000 (99.731)
2019-05-03 11:41:52 - INFO - TRAINING - Epoch: [43][450/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.1947 (0.3201)	Prec@1 93.000 (89.040)	Prec@5 100.000 (99.716)
2019-05-03 11:41:55 - INFO - EVALUATING - Epoch: [43][0/100]	Time 0.353 (0.353)	Data 0.345 (0.345)	Loss 0.4636 (0.4636)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 11:41:56 - INFO - EVALUATING - Epoch: [43][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.4115 (0.4577)	Prec@1 82.000 (84.882)	Prec@5 100.000 (99.078)
2019-05-03 11:41:57 - INFO - 
 Epoch: 44	Training Loss 0.3205 	Training Prec@1 89.046 	Training Prec@5 99.706 	Validation Loss 0.4445 	Validation Prec@1 85.210 	Validation Prec@5 99.200 	
2019-05-03 11:41:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:41:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:41:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:41:57 - INFO - TRAINING - Epoch: [44][0/500]	Time 0.276 (0.276)	Data 0.248 (0.248)	Loss 0.3616 (0.3616)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:42:00 - INFO - TRAINING - Epoch: [44][50/500]	Time 0.051 (0.060)	Data 0.000 (0.006)	Loss 0.2572 (0.3064)	Prec@1 91.000 (89.353)	Prec@5 100.000 (99.843)
2019-05-03 11:42:03 - INFO - TRAINING - Epoch: [44][100/500]	Time 0.063 (0.058)	Data 0.000 (0.003)	Loss 0.3203 (0.3043)	Prec@1 89.000 (89.515)	Prec@5 100.000 (99.812)
2019-05-03 11:42:06 - INFO - TRAINING - Epoch: [44][150/500]	Time 0.046 (0.056)	Data 0.000 (0.002)	Loss 0.3342 (0.3008)	Prec@1 87.000 (89.563)	Prec@5 100.000 (99.775)
2019-05-03 11:42:08 - INFO - TRAINING - Epoch: [44][200/500]	Time 0.047 (0.056)	Data 0.000 (0.002)	Loss 0.2253 (0.3038)	Prec@1 91.000 (89.522)	Prec@5 99.000 (99.756)
2019-05-03 11:42:11 - INFO - TRAINING - Epoch: [44][250/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.2612 (0.2997)	Prec@1 90.000 (89.685)	Prec@5 100.000 (99.753)
2019-05-03 11:42:14 - INFO - TRAINING - Epoch: [44][300/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.2822 (0.2990)	Prec@1 90.000 (89.694)	Prec@5 100.000 (99.764)
2019-05-03 11:42:16 - INFO - TRAINING - Epoch: [44][350/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.2943 (0.3021)	Prec@1 92.000 (89.635)	Prec@5 99.000 (99.732)
2019-05-03 11:42:19 - INFO - TRAINING - Epoch: [44][400/500]	Time 0.061 (0.055)	Data 0.000 (0.001)	Loss 0.2219 (0.3046)	Prec@1 94.000 (89.646)	Prec@5 100.000 (99.716)
2019-05-03 11:42:22 - INFO - TRAINING - Epoch: [44][450/500]	Time 0.061 (0.055)	Data 0.000 (0.001)	Loss 0.2632 (0.3050)	Prec@1 92.000 (89.608)	Prec@5 100.000 (99.705)
2019-05-03 11:42:25 - INFO - EVALUATING - Epoch: [44][0/100]	Time 0.373 (0.373)	Data 0.367 (0.367)	Loss 0.3953 (0.3953)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 11:42:26 - INFO - EVALUATING - Epoch: [44][50/100]	Time 0.025 (0.025)	Data 0.000 (0.008)	Loss 0.4227 (0.4431)	Prec@1 85.000 (85.137)	Prec@5 100.000 (99.275)
2019-05-03 11:42:27 - INFO - 
 Epoch: 45	Training Loss 0.3072 	Training Prec@1 89.570 	Training Prec@5 99.704 	Validation Loss 0.4371 	Validation Prec@1 85.370 	Validation Prec@5 99.400 	
2019-05-03 11:42:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:42:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:42:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:42:27 - INFO - TRAINING - Epoch: [45][0/500]	Time 0.277 (0.277)	Data 0.248 (0.248)	Loss 0.2858 (0.2858)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:42:30 - INFO - TRAINING - Epoch: [45][50/500]	Time 0.055 (0.060)	Data 0.000 (0.006)	Loss 0.3077 (0.2963)	Prec@1 90.000 (89.843)	Prec@5 100.000 (99.745)
2019-05-03 11:42:32 - INFO - TRAINING - Epoch: [45][100/500]	Time 0.061 (0.057)	Data 0.000 (0.003)	Loss 0.2767 (0.2917)	Prec@1 92.000 (89.990)	Prec@5 100.000 (99.812)
2019-05-03 11:42:35 - INFO - TRAINING - Epoch: [45][150/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.3227 (0.2880)	Prec@1 92.000 (90.185)	Prec@5 100.000 (99.808)
2019-05-03 11:42:38 - INFO - TRAINING - Epoch: [45][200/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.2951 (0.2887)	Prec@1 90.000 (90.169)	Prec@5 100.000 (99.801)
2019-05-03 11:42:40 - INFO - TRAINING - Epoch: [45][250/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.2956 (0.2951)	Prec@1 90.000 (89.960)	Prec@5 99.000 (99.781)
2019-05-03 11:42:43 - INFO - TRAINING - Epoch: [45][300/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.4471 (0.2936)	Prec@1 84.000 (90.000)	Prec@5 100.000 (99.771)
2019-05-03 11:42:46 - INFO - TRAINING - Epoch: [45][350/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.2864 (0.2922)	Prec@1 91.000 (90.043)	Prec@5 100.000 (99.789)
2019-05-03 11:42:49 - INFO - TRAINING - Epoch: [45][400/500]	Time 0.055 (0.055)	Data 0.000 (0.001)	Loss 0.2670 (0.2918)	Prec@1 91.000 (90.085)	Prec@5 100.000 (99.788)
2019-05-03 11:42:51 - INFO - TRAINING - Epoch: [45][450/500]	Time 0.055 (0.055)	Data 0.000 (0.001)	Loss 0.2216 (0.2941)	Prec@1 91.000 (89.962)	Prec@5 100.000 (99.778)
2019-05-03 11:42:54 - INFO - EVALUATING - Epoch: [45][0/100]	Time 0.361 (0.361)	Data 0.347 (0.347)	Loss 0.4161 (0.4161)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 11:42:55 - INFO - EVALUATING - Epoch: [45][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.4258 (0.5277)	Prec@1 86.000 (82.941)	Prec@5 99.000 (99.137)
2019-05-03 11:42:56 - INFO - 
 Epoch: 46	Training Loss 0.2962 	Training Prec@1 89.926 	Training Prec@5 99.776 	Validation Loss 0.5271 	Validation Prec@1 82.860 	Validation Prec@5 99.150 	
2019-05-03 11:42:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:42:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:42:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:42:57 - INFO - TRAINING - Epoch: [46][0/500]	Time 0.378 (0.378)	Data 0.347 (0.347)	Loss 0.2213 (0.2213)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:42:59 - INFO - TRAINING - Epoch: [46][50/500]	Time 0.069 (0.063)	Data 0.000 (0.007)	Loss 0.2544 (0.2850)	Prec@1 88.000 (90.333)	Prec@5 100.000 (99.745)
2019-05-03 11:43:02 - INFO - TRAINING - Epoch: [46][100/500]	Time 0.049 (0.060)	Data 0.000 (0.004)	Loss 0.4489 (0.2863)	Prec@1 84.000 (90.277)	Prec@5 99.000 (99.752)
2019-05-03 11:43:05 - INFO - TRAINING - Epoch: [46][150/500]	Time 0.061 (0.059)	Data 0.000 (0.003)	Loss 0.1854 (0.2867)	Prec@1 96.000 (90.311)	Prec@5 100.000 (99.742)
2019-05-03 11:43:08 - INFO - TRAINING - Epoch: [46][200/500]	Time 0.055 (0.059)	Data 0.000 (0.003)	Loss 0.1901 (0.2849)	Prec@1 95.000 (90.343)	Prec@5 100.000 (99.746)
2019-05-03 11:43:11 - INFO - TRAINING - Epoch: [46][250/500]	Time 0.038 (0.058)	Data 0.000 (0.002)	Loss 0.1934 (0.2807)	Prec@1 94.000 (90.522)	Prec@5 100.000 (99.769)
2019-05-03 11:43:14 - INFO - TRAINING - Epoch: [46][300/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.2895 (0.2859)	Prec@1 89.000 (90.302)	Prec@5 100.000 (99.751)
2019-05-03 11:43:16 - INFO - TRAINING - Epoch: [46][350/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.3344 (0.2879)	Prec@1 88.000 (90.279)	Prec@5 100.000 (99.755)
2019-05-03 11:43:19 - INFO - TRAINING - Epoch: [46][400/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.1768 (0.2878)	Prec@1 96.000 (90.252)	Prec@5 100.000 (99.766)
2019-05-03 11:43:22 - INFO - TRAINING - Epoch: [46][450/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.2574 (0.2893)	Prec@1 90.000 (90.215)	Prec@5 100.000 (99.763)
2019-05-03 11:43:25 - INFO - EVALUATING - Epoch: [46][0/100]	Time 0.276 (0.276)	Data 0.270 (0.270)	Loss 0.4449 (0.4449)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 11:43:26 - INFO - EVALUATING - Epoch: [46][50/100]	Time 0.014 (0.023)	Data 0.000 (0.006)	Loss 0.4933 (0.5682)	Prec@1 83.000 (81.922)	Prec@5 99.000 (98.667)
2019-05-03 11:43:27 - INFO - 
 Epoch: 47	Training Loss 0.2900 	Training Prec@1 90.166 	Training Prec@5 99.772 	Validation Loss 0.5602 	Validation Prec@1 81.920 	Validation Prec@5 98.860 	
2019-05-03 11:43:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:43:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:43:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:43:27 - INFO - TRAINING - Epoch: [47][0/500]	Time 0.278 (0.278)	Data 0.249 (0.249)	Loss 0.2162 (0.2162)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:43:30 - INFO - TRAINING - Epoch: [47][50/500]	Time 0.064 (0.061)	Data 0.000 (0.006)	Loss 0.3537 (0.2568)	Prec@1 86.000 (91.059)	Prec@5 100.000 (99.882)
2019-05-03 11:43:33 - INFO - TRAINING - Epoch: [47][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.2014 (0.2687)	Prec@1 93.000 (90.832)	Prec@5 100.000 (99.812)
2019-05-03 11:43:36 - INFO - TRAINING - Epoch: [47][150/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.2759 (0.2703)	Prec@1 90.000 (90.715)	Prec@5 100.000 (99.821)
2019-05-03 11:43:38 - INFO - TRAINING - Epoch: [47][200/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.2307 (0.2682)	Prec@1 91.000 (90.766)	Prec@5 100.000 (99.821)
2019-05-03 11:43:41 - INFO - TRAINING - Epoch: [47][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.2733 (0.2714)	Prec@1 91.000 (90.685)	Prec@5 100.000 (99.825)
2019-05-03 11:43:44 - INFO - TRAINING - Epoch: [47][300/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.1952 (0.2721)	Prec@1 94.000 (90.618)	Prec@5 100.000 (99.817)
2019-05-03 11:43:47 - INFO - TRAINING - Epoch: [47][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.2005 (0.2760)	Prec@1 93.000 (90.564)	Prec@5 100.000 (99.806)
2019-05-03 11:43:50 - INFO - TRAINING - Epoch: [47][400/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.1633 (0.2784)	Prec@1 97.000 (90.481)	Prec@5 100.000 (99.796)
2019-05-03 11:43:53 - INFO - TRAINING - Epoch: [47][450/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.3744 (0.2805)	Prec@1 84.000 (90.404)	Prec@5 100.000 (99.787)
2019-05-03 11:43:56 - INFO - EVALUATING - Epoch: [47][0/100]	Time 0.371 (0.371)	Data 0.358 (0.358)	Loss 0.3659 (0.3659)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:43:57 - INFO - EVALUATING - Epoch: [47][50/100]	Time 0.014 (0.025)	Data 0.000 (0.007)	Loss 0.2661 (0.4320)	Prec@1 92.000 (86.039)	Prec@5 99.000 (99.451)
2019-05-03 11:43:58 - INFO - 
 Epoch: 48	Training Loss 0.2819 	Training Prec@1 90.398 	Training Prec@5 99.768 	Validation Loss 0.4319 	Validation Prec@1 85.890 	Validation Prec@5 99.410 	
2019-05-03 11:43:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:43:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:43:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:43:58 - INFO - TRAINING - Epoch: [48][0/500]	Time 0.287 (0.287)	Data 0.265 (0.265)	Loss 0.2011 (0.2011)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 11:44:01 - INFO - TRAINING - Epoch: [48][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.2285 (0.2701)	Prec@1 93.000 (90.902)	Prec@5 100.000 (99.804)
2019-05-03 11:44:03 - INFO - TRAINING - Epoch: [48][100/500]	Time 0.045 (0.056)	Data 0.000 (0.003)	Loss 0.2521 (0.2693)	Prec@1 89.000 (91.050)	Prec@5 100.000 (99.792)
2019-05-03 11:44:06 - INFO - TRAINING - Epoch: [48][150/500]	Time 0.055 (0.055)	Data 0.000 (0.003)	Loss 0.1787 (0.2668)	Prec@1 94.000 (90.987)	Prec@5 100.000 (99.808)
2019-05-03 11:44:09 - INFO - TRAINING - Epoch: [48][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.3300 (0.2680)	Prec@1 88.000 (91.015)	Prec@5 100.000 (99.781)
2019-05-03 11:44:11 - INFO - TRAINING - Epoch: [48][250/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.3110 (0.2687)	Prec@1 90.000 (91.032)	Prec@5 100.000 (99.793)
2019-05-03 11:44:14 - INFO - TRAINING - Epoch: [48][300/500]	Time 0.061 (0.054)	Data 0.000 (0.002)	Loss 0.2561 (0.2702)	Prec@1 92.000 (90.924)	Prec@5 100.000 (99.804)
2019-05-03 11:44:17 - INFO - TRAINING - Epoch: [48][350/500]	Time 0.045 (0.054)	Data 0.000 (0.002)	Loss 0.2777 (0.2698)	Prec@1 90.000 (90.875)	Prec@5 100.000 (99.821)
2019-05-03 11:44:19 - INFO - TRAINING - Epoch: [48][400/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.3569 (0.2749)	Prec@1 87.000 (90.686)	Prec@5 100.000 (99.805)
2019-05-03 11:44:22 - INFO - TRAINING - Epoch: [48][450/500]	Time 0.058 (0.054)	Data 0.000 (0.001)	Loss 0.3715 (0.2728)	Prec@1 87.000 (90.732)	Prec@5 100.000 (99.807)
2019-05-03 11:44:25 - INFO - EVALUATING - Epoch: [48][0/100]	Time 0.358 (0.358)	Data 0.346 (0.346)	Loss 0.5092 (0.5092)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-03 11:44:26 - INFO - EVALUATING - Epoch: [48][50/100]	Time 0.020 (0.026)	Data 0.000 (0.009)	Loss 0.4287 (0.5043)	Prec@1 85.000 (83.863)	Prec@5 100.000 (99.235)
2019-05-03 11:44:27 - INFO - 
 Epoch: 49	Training Loss 0.2748 	Training Prec@1 90.636 	Training Prec@5 99.808 	Validation Loss 0.5088 	Validation Prec@1 83.230 	Validation Prec@5 99.380 	
2019-05-03 11:44:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:44:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:44:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:44:27 - INFO - TRAINING - Epoch: [49][0/500]	Time 0.353 (0.353)	Data 0.323 (0.323)	Loss 0.2624 (0.2624)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:44:30 - INFO - TRAINING - Epoch: [49][50/500]	Time 0.052 (0.060)	Data 0.000 (0.007)	Loss 0.1933 (0.2783)	Prec@1 94.000 (90.765)	Prec@5 100.000 (99.706)
2019-05-03 11:44:33 - INFO - TRAINING - Epoch: [49][100/500]	Time 0.052 (0.057)	Data 0.000 (0.004)	Loss 0.1939 (0.2654)	Prec@1 93.000 (90.921)	Prec@5 100.000 (99.772)
2019-05-03 11:44:35 - INFO - TRAINING - Epoch: [49][150/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.2456 (0.2611)	Prec@1 93.000 (91.159)	Prec@5 100.000 (99.795)
2019-05-03 11:44:38 - INFO - TRAINING - Epoch: [49][200/500]	Time 0.067 (0.055)	Data 0.000 (0.002)	Loss 0.1296 (0.2586)	Prec@1 97.000 (91.199)	Prec@5 100.000 (99.786)
2019-05-03 11:44:41 - INFO - TRAINING - Epoch: [49][250/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.2794 (0.2596)	Prec@1 92.000 (91.207)	Prec@5 100.000 (99.809)
2019-05-03 11:44:43 - INFO - TRAINING - Epoch: [49][300/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.1387 (0.2603)	Prec@1 96.000 (91.173)	Prec@5 100.000 (99.811)
2019-05-03 11:44:46 - INFO - TRAINING - Epoch: [49][350/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.3683 (0.2604)	Prec@1 85.000 (91.225)	Prec@5 100.000 (99.803)
2019-05-03 11:44:49 - INFO - TRAINING - Epoch: [49][400/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.2463 (0.2614)	Prec@1 90.000 (91.197)	Prec@5 100.000 (99.776)
2019-05-03 11:44:51 - INFO - TRAINING - Epoch: [49][450/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.2862 (0.2649)	Prec@1 92.000 (91.069)	Prec@5 100.000 (99.783)
2019-05-03 11:44:54 - INFO - EVALUATING - Epoch: [49][0/100]	Time 0.371 (0.371)	Data 0.361 (0.361)	Loss 0.5211 (0.5211)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 11:44:55 - INFO - EVALUATING - Epoch: [49][50/100]	Time 0.014 (0.026)	Data 0.000 (0.008)	Loss 0.4380 (0.5338)	Prec@1 89.000 (82.451)	Prec@5 100.000 (99.176)
2019-05-03 11:44:56 - INFO - 
 Epoch: 50	Training Loss 0.2663 	Training Prec@1 91.030 	Training Prec@5 99.786 	Validation Loss 0.5292 	Validation Prec@1 82.670 	Validation Prec@5 99.280 	
2019-05-03 11:44:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:44:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:44:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:44:57 - INFO - TRAINING - Epoch: [50][0/500]	Time 0.302 (0.302)	Data 0.277 (0.277)	Loss 0.2249 (0.2249)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:45:00 - INFO - TRAINING - Epoch: [50][50/500]	Time 0.059 (0.061)	Data 0.000 (0.006)	Loss 0.2403 (0.2467)	Prec@1 91.000 (91.647)	Prec@5 100.000 (99.922)
2019-05-03 11:45:02 - INFO - TRAINING - Epoch: [50][100/500]	Time 0.050 (0.059)	Data 0.000 (0.004)	Loss 0.3879 (0.2547)	Prec@1 88.000 (91.188)	Prec@5 100.000 (99.921)
2019-05-03 11:45:05 - INFO - TRAINING - Epoch: [50][150/500]	Time 0.048 (0.058)	Data 0.000 (0.003)	Loss 0.2844 (0.2580)	Prec@1 92.000 (91.166)	Prec@5 100.000 (99.868)
2019-05-03 11:45:08 - INFO - TRAINING - Epoch: [50][200/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.2268 (0.2561)	Prec@1 92.000 (91.184)	Prec@5 100.000 (99.846)
2019-05-03 11:45:11 - INFO - TRAINING - Epoch: [50][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.2513 (0.2558)	Prec@1 91.000 (91.135)	Prec@5 99.000 (99.857)
2019-05-03 11:45:14 - INFO - TRAINING - Epoch: [50][300/500]	Time 0.059 (0.057)	Data 0.000 (0.002)	Loss 0.2407 (0.2564)	Prec@1 91.000 (91.163)	Prec@5 99.000 (99.847)
2019-05-03 11:45:16 - INFO - TRAINING - Epoch: [50][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.2494 (0.2570)	Prec@1 94.000 (91.162)	Prec@5 100.000 (99.840)
2019-05-03 11:45:19 - INFO - TRAINING - Epoch: [50][400/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.1444 (0.2571)	Prec@1 94.000 (91.177)	Prec@5 100.000 (99.838)
2019-05-03 11:45:22 - INFO - TRAINING - Epoch: [50][450/500]	Time 0.059 (0.056)	Data 0.000 (0.001)	Loss 0.2266 (0.2579)	Prec@1 93.000 (91.173)	Prec@5 100.000 (99.838)
2019-05-03 11:45:25 - INFO - EVALUATING - Epoch: [50][0/100]	Time 0.374 (0.374)	Data 0.366 (0.366)	Loss 0.3671 (0.3671)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 11:45:26 - INFO - EVALUATING - Epoch: [50][50/100]	Time 0.020 (0.026)	Data 0.000 (0.009)	Loss 0.2872 (0.4063)	Prec@1 90.000 (86.431)	Prec@5 100.000 (99.373)
2019-05-03 11:45:27 - INFO - 
 Epoch: 51	Training Loss 0.2583 	Training Prec@1 91.192 	Training Prec@5 99.838 	Validation Loss 0.4060 	Validation Prec@1 86.320 	Validation Prec@5 99.450 	
2019-05-03 11:45:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:45:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:45:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:45:27 - INFO - TRAINING - Epoch: [51][0/500]	Time 0.263 (0.263)	Data 0.230 (0.230)	Loss 0.4688 (0.4688)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 11:45:30 - INFO - TRAINING - Epoch: [51][50/500]	Time 0.054 (0.057)	Data 0.000 (0.005)	Loss 0.3116 (0.2665)	Prec@1 87.000 (90.882)	Prec@5 100.000 (99.765)
2019-05-03 11:45:32 - INFO - TRAINING - Epoch: [51][100/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.3609 (0.2584)	Prec@1 91.000 (91.168)	Prec@5 99.000 (99.842)
2019-05-03 11:45:35 - INFO - TRAINING - Epoch: [51][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.2736 (0.2567)	Prec@1 89.000 (91.232)	Prec@5 100.000 (99.841)
2019-05-03 11:45:38 - INFO - TRAINING - Epoch: [51][200/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.1994 (0.2579)	Prec@1 94.000 (91.259)	Prec@5 100.000 (99.841)
2019-05-03 11:45:40 - INFO - TRAINING - Epoch: [51][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.1768 (0.2555)	Prec@1 95.000 (91.390)	Prec@5 100.000 (99.853)
2019-05-03 11:45:43 - INFO - TRAINING - Epoch: [51][300/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.2623 (0.2562)	Prec@1 93.000 (91.316)	Prec@5 100.000 (99.854)
2019-05-03 11:45:46 - INFO - TRAINING - Epoch: [51][350/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.2131 (0.2603)	Prec@1 93.000 (91.188)	Prec@5 99.000 (99.832)
2019-05-03 11:45:48 - INFO - TRAINING - Epoch: [51][400/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.4886 (0.2588)	Prec@1 83.000 (91.237)	Prec@5 100.000 (99.840)
2019-05-03 11:45:51 - INFO - TRAINING - Epoch: [51][450/500]	Time 0.045 (0.054)	Data 0.000 (0.001)	Loss 0.1102 (0.2584)	Prec@1 97.000 (91.279)	Prec@5 100.000 (99.834)
2019-05-03 11:45:54 - INFO - EVALUATING - Epoch: [51][0/100]	Time 0.358 (0.358)	Data 0.351 (0.351)	Loss 0.6136 (0.6136)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 11:45:55 - INFO - EVALUATING - Epoch: [51][50/100]	Time 0.013 (0.025)	Data 0.000 (0.008)	Loss 0.4944 (0.4994)	Prec@1 82.000 (83.529)	Prec@5 99.000 (99.333)
2019-05-03 11:45:56 - INFO - 
 Epoch: 52	Training Loss 0.2588 	Training Prec@1 91.274 	Training Prec@5 99.832 	Validation Loss 0.4831 	Validation Prec@1 83.610 	Validation Prec@5 99.460 	
2019-05-03 11:45:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:45:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:45:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:45:56 - INFO - TRAINING - Epoch: [52][0/500]	Time 0.297 (0.297)	Data 0.270 (0.270)	Loss 0.2799 (0.2799)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:45:59 - INFO - TRAINING - Epoch: [52][50/500]	Time 0.058 (0.062)	Data 0.000 (0.006)	Loss 0.3864 (0.2607)	Prec@1 88.000 (91.392)	Prec@5 99.000 (99.804)
2019-05-03 11:46:02 - INFO - TRAINING - Epoch: [52][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.2438 (0.2483)	Prec@1 92.000 (91.752)	Prec@5 100.000 (99.842)
2019-05-03 11:46:05 - INFO - TRAINING - Epoch: [52][150/500]	Time 0.044 (0.059)	Data 0.000 (0.003)	Loss 0.2318 (0.2503)	Prec@1 93.000 (91.709)	Prec@5 100.000 (99.834)
2019-05-03 11:46:08 - INFO - TRAINING - Epoch: [52][200/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.2267 (0.2452)	Prec@1 90.000 (91.841)	Prec@5 100.000 (99.836)
2019-05-03 11:46:11 - INFO - TRAINING - Epoch: [52][250/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.2782 (0.2446)	Prec@1 92.000 (91.821)	Prec@5 100.000 (99.841)
2019-05-03 11:46:14 - INFO - TRAINING - Epoch: [52][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1645 (0.2478)	Prec@1 95.000 (91.668)	Prec@5 100.000 (99.827)
2019-05-03 11:46:16 - INFO - TRAINING - Epoch: [52][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1759 (0.2480)	Prec@1 93.000 (91.667)	Prec@5 100.000 (99.815)
2019-05-03 11:46:19 - INFO - TRAINING - Epoch: [52][400/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.3433 (0.2495)	Prec@1 90.000 (91.618)	Prec@5 100.000 (99.820)
2019-05-03 11:46:22 - INFO - TRAINING - Epoch: [52][450/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.2399 (0.2502)	Prec@1 93.000 (91.583)	Prec@5 100.000 (99.814)
2019-05-03 11:46:25 - INFO - EVALUATING - Epoch: [52][0/100]	Time 0.404 (0.404)	Data 0.392 (0.392)	Loss 0.3030 (0.3030)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-03 11:46:26 - INFO - EVALUATING - Epoch: [52][50/100]	Time 0.017 (0.026)	Data 0.000 (0.008)	Loss 0.3871 (0.4047)	Prec@1 88.000 (86.510)	Prec@5 100.000 (99.608)
2019-05-03 11:46:27 - INFO - 
 Epoch: 53	Training Loss 0.2492 	Training Prec@1 91.616 	Training Prec@5 99.818 	Validation Loss 0.4055 	Validation Prec@1 86.440 	Validation Prec@5 99.680 	
2019-05-03 11:46:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:46:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:46:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:46:27 - INFO - TRAINING - Epoch: [53][0/500]	Time 0.278 (0.278)	Data 0.250 (0.250)	Loss 0.1274 (0.1274)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 11:46:30 - INFO - TRAINING - Epoch: [53][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.1630 (0.2298)	Prec@1 94.000 (92.098)	Prec@5 100.000 (99.961)
2019-05-03 11:46:33 - INFO - TRAINING - Epoch: [53][100/500]	Time 0.055 (0.056)	Data 0.000 (0.003)	Loss 0.1776 (0.2338)	Prec@1 94.000 (91.802)	Prec@5 100.000 (99.901)
2019-05-03 11:46:35 - INFO - TRAINING - Epoch: [53][150/500]	Time 0.063 (0.055)	Data 0.000 (0.002)	Loss 0.2788 (0.2342)	Prec@1 91.000 (91.795)	Prec@5 100.000 (99.901)
2019-05-03 11:46:38 - INFO - TRAINING - Epoch: [53][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.1639 (0.2339)	Prec@1 92.000 (91.920)	Prec@5 100.000 (99.896)
2019-05-03 11:46:41 - INFO - TRAINING - Epoch: [53][250/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.2429 (0.2324)	Prec@1 90.000 (91.984)	Prec@5 99.000 (99.880)
2019-05-03 11:46:44 - INFO - TRAINING - Epoch: [53][300/500]	Time 0.051 (0.054)	Data 0.000 (0.002)	Loss 0.1733 (0.2331)	Prec@1 94.000 (91.927)	Prec@5 100.000 (99.880)
2019-05-03 11:46:46 - INFO - TRAINING - Epoch: [53][350/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.3432 (0.2338)	Prec@1 88.000 (91.960)	Prec@5 100.000 (99.866)
2019-05-03 11:46:49 - INFO - TRAINING - Epoch: [53][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.3615 (0.2333)	Prec@1 90.000 (91.953)	Prec@5 99.000 (99.855)
2019-05-03 11:46:52 - INFO - TRAINING - Epoch: [53][450/500]	Time 0.024 (0.054)	Data 0.000 (0.001)	Loss 0.3003 (0.2360)	Prec@1 88.000 (91.874)	Prec@5 100.000 (99.843)
2019-05-03 11:46:54 - INFO - EVALUATING - Epoch: [53][0/100]	Time 0.378 (0.378)	Data 0.365 (0.365)	Loss 0.3505 (0.3505)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:46:55 - INFO - EVALUATING - Epoch: [53][50/100]	Time 0.025 (0.026)	Data 0.000 (0.008)	Loss 0.3644 (0.3919)	Prec@1 90.000 (87.902)	Prec@5 97.000 (99.412)
2019-05-03 11:46:56 - INFO - 
 Epoch: 54	Training Loss 0.2378 	Training Prec@1 91.818 	Training Prec@5 99.846 	Validation Loss 0.3731 	Validation Prec@1 87.950 	Validation Prec@5 99.530 	
2019-05-03 11:46:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:46:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:46:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:46:57 - INFO - TRAINING - Epoch: [54][0/500]	Time 0.290 (0.290)	Data 0.263 (0.263)	Loss 0.2193 (0.2193)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 11:47:00 - INFO - TRAINING - Epoch: [54][50/500]	Time 0.058 (0.062)	Data 0.000 (0.006)	Loss 0.1378 (0.2259)	Prec@1 95.000 (92.216)	Prec@5 100.000 (99.863)
2019-05-03 11:47:02 - INFO - TRAINING - Epoch: [54][100/500]	Time 0.053 (0.059)	Data 0.000 (0.003)	Loss 0.1971 (0.2252)	Prec@1 95.000 (92.356)	Prec@5 100.000 (99.931)
2019-05-03 11:47:05 - INFO - TRAINING - Epoch: [54][150/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.2337 (0.2225)	Prec@1 90.000 (92.444)	Prec@5 100.000 (99.921)
2019-05-03 11:47:08 - INFO - TRAINING - Epoch: [54][200/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.2145 (0.2240)	Prec@1 94.000 (92.473)	Prec@5 100.000 (99.905)
2019-05-03 11:47:11 - INFO - TRAINING - Epoch: [54][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.3273 (0.2278)	Prec@1 88.000 (92.279)	Prec@5 100.000 (99.900)
2019-05-03 11:47:14 - INFO - TRAINING - Epoch: [54][300/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.1842 (0.2299)	Prec@1 95.000 (92.209)	Prec@5 100.000 (99.887)
2019-05-03 11:47:17 - INFO - TRAINING - Epoch: [54][350/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.2298 (0.2284)	Prec@1 93.000 (92.262)	Prec@5 100.000 (99.877)
2019-05-03 11:47:20 - INFO - TRAINING - Epoch: [54][400/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1676 (0.2283)	Prec@1 94.000 (92.267)	Prec@5 100.000 (99.873)
2019-05-03 11:47:22 - INFO - TRAINING - Epoch: [54][450/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.5330 (0.2290)	Prec@1 86.000 (92.235)	Prec@5 98.000 (99.874)
2019-05-03 11:47:26 - INFO - EVALUATING - Epoch: [54][0/100]	Time 0.398 (0.398)	Data 0.390 (0.390)	Loss 0.5655 (0.5655)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 11:47:27 - INFO - EVALUATING - Epoch: [54][50/100]	Time 0.017 (0.026)	Data 0.000 (0.009)	Loss 0.5625 (0.4760)	Prec@1 83.000 (84.569)	Prec@5 99.000 (99.255)
2019-05-03 11:47:27 - INFO - 
 Epoch: 55	Training Loss 0.2303 	Training Prec@1 92.220 	Training Prec@5 99.872 	Validation Loss 0.4660 	Validation Prec@1 84.870 	Validation Prec@5 99.430 	
2019-05-03 11:47:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:47:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:47:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:47:28 - INFO - TRAINING - Epoch: [55][0/500]	Time 0.266 (0.266)	Data 0.243 (0.243)	Loss 0.3306 (0.3306)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:47:30 - INFO - TRAINING - Epoch: [55][50/500]	Time 0.057 (0.058)	Data 0.000 (0.006)	Loss 0.1388 (0.2276)	Prec@1 97.000 (92.176)	Prec@5 100.000 (99.843)
2019-05-03 11:47:33 - INFO - TRAINING - Epoch: [55][100/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.1601 (0.2256)	Prec@1 94.000 (92.337)	Prec@5 100.000 (99.851)
2019-05-03 11:47:36 - INFO - TRAINING - Epoch: [55][150/500]	Time 0.040 (0.055)	Data 0.000 (0.002)	Loss 0.2298 (0.2221)	Prec@1 93.000 (92.391)	Prec@5 100.000 (99.834)
2019-05-03 11:47:38 - INFO - TRAINING - Epoch: [55][200/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.1548 (0.2193)	Prec@1 95.000 (92.597)	Prec@5 100.000 (99.831)
2019-05-03 11:47:41 - INFO - TRAINING - Epoch: [55][250/500]	Time 0.064 (0.054)	Data 0.000 (0.002)	Loss 0.2848 (0.2208)	Prec@1 86.000 (92.534)	Prec@5 100.000 (99.853)
2019-05-03 11:47:44 - INFO - TRAINING - Epoch: [55][300/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.2521 (0.2219)	Prec@1 91.000 (92.518)	Prec@5 100.000 (99.847)
2019-05-03 11:47:46 - INFO - TRAINING - Epoch: [55][350/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.1239 (0.2203)	Prec@1 95.000 (92.550)	Prec@5 100.000 (99.866)
2019-05-03 11:47:49 - INFO - TRAINING - Epoch: [55][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.2002 (0.2218)	Prec@1 93.000 (92.459)	Prec@5 100.000 (99.878)
2019-05-03 11:47:52 - INFO - TRAINING - Epoch: [55][450/500]	Time 0.051 (0.054)	Data 0.000 (0.001)	Loss 0.1463 (0.2211)	Prec@1 95.000 (92.494)	Prec@5 100.000 (99.880)
2019-05-03 11:47:55 - INFO - EVALUATING - Epoch: [55][0/100]	Time 0.361 (0.361)	Data 0.344 (0.344)	Loss 0.2983 (0.2983)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:47:56 - INFO - EVALUATING - Epoch: [55][50/100]	Time 0.028 (0.027)	Data 0.000 (0.008)	Loss 0.2845 (0.3978)	Prec@1 91.000 (87.529)	Prec@5 99.000 (99.353)
2019-05-03 11:47:57 - INFO - 
 Epoch: 56	Training Loss 0.2209 	Training Prec@1 92.488 	Training Prec@5 99.880 	Validation Loss 0.3988 	Validation Prec@1 87.260 	Validation Prec@5 99.430 	
2019-05-03 11:47:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:47:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:47:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:47:57 - INFO - TRAINING - Epoch: [56][0/500]	Time 0.303 (0.303)	Data 0.265 (0.265)	Loss 0.1779 (0.1779)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 11:48:00 - INFO - TRAINING - Epoch: [56][50/500]	Time 0.050 (0.062)	Data 0.000 (0.006)	Loss 0.1343 (0.2188)	Prec@1 95.000 (92.098)	Prec@5 100.000 (99.882)
2019-05-03 11:48:03 - INFO - TRAINING - Epoch: [56][100/500]	Time 0.061 (0.059)	Data 0.000 (0.003)	Loss 0.1901 (0.2156)	Prec@1 95.000 (92.604)	Prec@5 100.000 (99.881)
2019-05-03 11:48:06 - INFO - TRAINING - Epoch: [56][150/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1901 (0.2103)	Prec@1 94.000 (92.788)	Prec@5 100.000 (99.901)
2019-05-03 11:48:09 - INFO - TRAINING - Epoch: [56][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.1053 (0.2103)	Prec@1 97.000 (92.841)	Prec@5 100.000 (99.891)
2019-05-03 11:48:12 - INFO - TRAINING - Epoch: [56][250/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.2379 (0.2090)	Prec@1 94.000 (92.880)	Prec@5 100.000 (99.900)
2019-05-03 11:48:14 - INFO - TRAINING - Epoch: [56][300/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.2518 (0.2091)	Prec@1 90.000 (92.894)	Prec@5 100.000 (99.904)
2019-05-03 11:48:17 - INFO - TRAINING - Epoch: [56][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1551 (0.2105)	Prec@1 95.000 (92.815)	Prec@5 100.000 (99.903)
2019-05-03 11:48:20 - INFO - TRAINING - Epoch: [56][400/500]	Time 0.062 (0.058)	Data 0.000 (0.001)	Loss 0.1970 (0.2126)	Prec@1 93.000 (92.766)	Prec@5 100.000 (99.903)
2019-05-03 11:48:23 - INFO - TRAINING - Epoch: [56][450/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.2495 (0.2146)	Prec@1 92.000 (92.723)	Prec@5 100.000 (99.894)
2019-05-03 11:48:26 - INFO - EVALUATING - Epoch: [56][0/100]	Time 0.362 (0.362)	Data 0.354 (0.354)	Loss 0.2317 (0.2317)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:48:27 - INFO - EVALUATING - Epoch: [56][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.3306 (0.4154)	Prec@1 92.000 (87.039)	Prec@5 100.000 (99.608)
2019-05-03 11:48:28 - INFO - 
 Epoch: 57	Training Loss 0.2150 	Training Prec@1 92.684 	Training Prec@5 99.890 	Validation Loss 0.3975 	Validation Prec@1 87.020 	Validation Prec@5 99.640 	
2019-05-03 11:48:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:48:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:48:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:48:28 - INFO - TRAINING - Epoch: [57][0/500]	Time 0.266 (0.266)	Data 0.240 (0.240)	Loss 0.2158 (0.2158)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:48:31 - INFO - TRAINING - Epoch: [57][50/500]	Time 0.056 (0.057)	Data 0.000 (0.005)	Loss 0.2989 (0.2166)	Prec@1 89.000 (92.353)	Prec@5 100.000 (99.902)
2019-05-03 11:48:34 - INFO - TRAINING - Epoch: [57][100/500]	Time 0.047 (0.055)	Data 0.000 (0.003)	Loss 0.2727 (0.2068)	Prec@1 92.000 (92.881)	Prec@5 100.000 (99.941)
2019-05-03 11:48:36 - INFO - TRAINING - Epoch: [57][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.1864 (0.2106)	Prec@1 95.000 (92.669)	Prec@5 99.000 (99.921)
2019-05-03 11:48:39 - INFO - TRAINING - Epoch: [57][200/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 0.1965 (0.2087)	Prec@1 93.000 (92.716)	Prec@5 100.000 (99.925)
2019-05-03 11:48:42 - INFO - TRAINING - Epoch: [57][250/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.1965 (0.2078)	Prec@1 91.000 (92.761)	Prec@5 100.000 (99.916)
2019-05-03 11:48:44 - INFO - TRAINING - Epoch: [57][300/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.1734 (0.2098)	Prec@1 97.000 (92.701)	Prec@5 99.000 (99.907)
2019-05-03 11:48:47 - INFO - TRAINING - Epoch: [57][350/500]	Time 0.038 (0.054)	Data 0.000 (0.001)	Loss 0.0879 (0.2107)	Prec@1 98.000 (92.724)	Prec@5 100.000 (99.912)
2019-05-03 11:48:50 - INFO - TRAINING - Epoch: [57][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.2435 (0.2098)	Prec@1 91.000 (92.805)	Prec@5 100.000 (99.900)
2019-05-03 11:48:52 - INFO - TRAINING - Epoch: [57][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.1887 (0.2108)	Prec@1 93.000 (92.761)	Prec@5 100.000 (99.900)
2019-05-03 11:48:55 - INFO - EVALUATING - Epoch: [57][0/100]	Time 0.384 (0.384)	Data 0.372 (0.372)	Loss 0.2912 (0.2912)	Prec@1 91.000 (91.000)	Prec@5 98.000 (98.000)
2019-05-03 11:48:56 - INFO - EVALUATING - Epoch: [57][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.4061 (0.3864)	Prec@1 84.000 (87.765)	Prec@5 100.000 (99.255)
2019-05-03 11:48:57 - INFO - 
 Epoch: 58	Training Loss 0.2112 	Training Prec@1 92.748 	Training Prec@5 99.896 	Validation Loss 0.3733 	Validation Prec@1 88.020 	Validation Prec@5 99.460 	
2019-05-03 11:48:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:48:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:48:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:48:57 - INFO - TRAINING - Epoch: [58][0/500]	Time 0.295 (0.295)	Data 0.270 (0.270)	Loss 0.1356 (0.1356)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:49:00 - INFO - TRAINING - Epoch: [58][50/500]	Time 0.062 (0.061)	Data 0.000 (0.006)	Loss 0.1047 (0.2009)	Prec@1 97.000 (93.216)	Prec@5 100.000 (99.902)
2019-05-03 11:49:03 - INFO - TRAINING - Epoch: [58][100/500]	Time 0.056 (0.059)	Data 0.000 (0.004)	Loss 0.1783 (0.1935)	Prec@1 92.000 (93.376)	Prec@5 100.000 (99.891)
2019-05-03 11:49:06 - INFO - TRAINING - Epoch: [58][150/500]	Time 0.054 (0.058)	Data 0.000 (0.003)	Loss 0.1172 (0.1964)	Prec@1 98.000 (93.238)	Prec@5 100.000 (99.901)
2019-05-03 11:49:09 - INFO - TRAINING - Epoch: [58][200/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.1501 (0.2001)	Prec@1 94.000 (93.164)	Prec@5 100.000 (99.900)
2019-05-03 11:49:12 - INFO - TRAINING - Epoch: [58][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1666 (0.2038)	Prec@1 93.000 (93.040)	Prec@5 100.000 (99.904)
2019-05-03 11:49:14 - INFO - TRAINING - Epoch: [58][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.2261 (0.2062)	Prec@1 91.000 (93.023)	Prec@5 100.000 (99.900)
2019-05-03 11:49:17 - INFO - TRAINING - Epoch: [58][350/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.2053 (0.2056)	Prec@1 93.000 (93.088)	Prec@5 100.000 (99.903)
2019-05-03 11:49:20 - INFO - TRAINING - Epoch: [58][400/500]	Time 0.067 (0.058)	Data 0.000 (0.002)	Loss 0.2262 (0.2067)	Prec@1 90.000 (93.037)	Prec@5 99.000 (99.900)
2019-05-03 11:49:23 - INFO - TRAINING - Epoch: [58][450/500]	Time 0.063 (0.057)	Data 0.000 (0.001)	Loss 0.2133 (0.2067)	Prec@1 94.000 (93.031)	Prec@5 100.000 (99.896)
2019-05-03 11:49:26 - INFO - EVALUATING - Epoch: [58][0/100]	Time 0.284 (0.284)	Data 0.276 (0.276)	Loss 0.3993 (0.3993)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 11:49:27 - INFO - EVALUATING - Epoch: [58][50/100]	Time 0.014 (0.023)	Data 0.000 (0.006)	Loss 0.2512 (0.4410)	Prec@1 90.000 (86.882)	Prec@5 99.000 (99.373)
2019-05-03 11:49:28 - INFO - 
 Epoch: 59	Training Loss 0.2057 	Training Prec@1 93.036 	Training Prec@5 99.896 	Validation Loss 0.4465 	Validation Prec@1 86.210 	Validation Prec@5 99.410 	
2019-05-03 11:49:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:49:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:49:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:49:28 - INFO - TRAINING - Epoch: [59][0/500]	Time 0.262 (0.262)	Data 0.238 (0.238)	Loss 0.1302 (0.1302)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 11:49:31 - INFO - TRAINING - Epoch: [59][50/500]	Time 0.063 (0.059)	Data 0.000 (0.005)	Loss 0.2537 (0.1850)	Prec@1 92.000 (93.804)	Prec@5 100.000 (99.961)
2019-05-03 11:49:34 - INFO - TRAINING - Epoch: [59][100/500]	Time 0.060 (0.057)	Data 0.000 (0.003)	Loss 0.2258 (0.1818)	Prec@1 92.000 (93.802)	Prec@5 100.000 (99.960)
2019-05-03 11:49:37 - INFO - TRAINING - Epoch: [59][150/500]	Time 0.054 (0.057)	Data 0.000 (0.002)	Loss 0.2283 (0.1837)	Prec@1 93.000 (93.781)	Prec@5 100.000 (99.954)
2019-05-03 11:49:39 - INFO - TRAINING - Epoch: [59][200/500]	Time 0.049 (0.056)	Data 0.000 (0.002)	Loss 0.2355 (0.1838)	Prec@1 91.000 (93.801)	Prec@5 100.000 (99.955)
2019-05-03 11:49:42 - INFO - TRAINING - Epoch: [59][250/500]	Time 0.054 (0.056)	Data 0.000 (0.002)	Loss 0.0896 (0.1875)	Prec@1 98.000 (93.669)	Prec@5 100.000 (99.944)
2019-05-03 11:49:45 - INFO - TRAINING - Epoch: [59][300/500]	Time 0.050 (0.056)	Data 0.000 (0.002)	Loss 0.3801 (0.1908)	Prec@1 93.000 (93.538)	Prec@5 99.000 (99.934)
2019-05-03 11:49:48 - INFO - TRAINING - Epoch: [59][350/500]	Time 0.056 (0.056)	Data 0.000 (0.002)	Loss 0.1066 (0.1941)	Prec@1 96.000 (93.473)	Prec@5 100.000 (99.929)
2019-05-03 11:49:50 - INFO - TRAINING - Epoch: [59][400/500]	Time 0.054 (0.056)	Data 0.000 (0.001)	Loss 0.1513 (0.1968)	Prec@1 96.000 (93.367)	Prec@5 100.000 (99.913)
2019-05-03 11:49:53 - INFO - TRAINING - Epoch: [59][450/500]	Time 0.056 (0.056)	Data 0.000 (0.001)	Loss 0.2058 (0.1964)	Prec@1 93.000 (93.322)	Prec@5 100.000 (99.914)
2019-05-03 11:49:56 - INFO - EVALUATING - Epoch: [59][0/100]	Time 0.336 (0.336)	Data 0.324 (0.324)	Loss 0.1726 (0.1726)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:49:57 - INFO - EVALUATING - Epoch: [59][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.2864 (0.3893)	Prec@1 90.000 (88.157)	Prec@5 99.000 (99.451)
2019-05-03 11:49:58 - INFO - 
 Epoch: 60	Training Loss 0.1972 	Training Prec@1 93.270 	Training Prec@5 99.914 	Validation Loss 0.3790 	Validation Prec@1 88.180 	Validation Prec@5 99.500 	
2019-05-03 11:49:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:49:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:49:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:49:59 - INFO - TRAINING - Epoch: [60][0/500]	Time 0.268 (0.268)	Data 0.240 (0.240)	Loss 0.2344 (0.2344)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:50:01 - INFO - TRAINING - Epoch: [60][50/500]	Time 0.055 (0.059)	Data 0.000 (0.005)	Loss 0.1863 (0.1787)	Prec@1 93.000 (94.000)	Prec@5 100.000 (99.961)
2019-05-03 11:50:04 - INFO - TRAINING - Epoch: [60][100/500]	Time 0.056 (0.056)	Data 0.000 (0.003)	Loss 0.2328 (0.1833)	Prec@1 92.000 (93.941)	Prec@5 100.000 (99.970)
2019-05-03 11:50:07 - INFO - TRAINING - Epoch: [60][150/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.2178 (0.1841)	Prec@1 94.000 (93.894)	Prec@5 100.000 (99.967)
2019-05-03 11:50:09 - INFO - TRAINING - Epoch: [60][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.1276 (0.1822)	Prec@1 96.000 (93.975)	Prec@5 100.000 (99.945)
2019-05-03 11:50:12 - INFO - TRAINING - Epoch: [60][250/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.1456 (0.1819)	Prec@1 95.000 (93.873)	Prec@5 100.000 (99.944)
2019-05-03 11:50:15 - INFO - TRAINING - Epoch: [60][300/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.1755 (0.1839)	Prec@1 95.000 (93.767)	Prec@5 100.000 (99.940)
2019-05-03 11:50:17 - INFO - TRAINING - Epoch: [60][350/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 0.3316 (0.1854)	Prec@1 86.000 (93.732)	Prec@5 100.000 (99.932)
2019-05-03 11:50:20 - INFO - TRAINING - Epoch: [60][400/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.1632 (0.1878)	Prec@1 90.000 (93.683)	Prec@5 100.000 (99.928)
2019-05-03 11:50:23 - INFO - TRAINING - Epoch: [60][450/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.2293 (0.1885)	Prec@1 94.000 (93.612)	Prec@5 100.000 (99.933)
2019-05-03 11:50:26 - INFO - EVALUATING - Epoch: [60][0/100]	Time 0.363 (0.363)	Data 0.352 (0.352)	Loss 0.3325 (0.3325)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:50:27 - INFO - EVALUATING - Epoch: [60][50/100]	Time 0.013 (0.024)	Data 0.000 (0.007)	Loss 0.4022 (0.4188)	Prec@1 88.000 (87.431)	Prec@5 98.000 (99.353)
2019-05-03 11:50:27 - INFO - 
 Epoch: 61	Training Loss 0.1873 	Training Prec@1 93.650 	Training Prec@5 99.932 	Validation Loss 0.4114 	Validation Prec@1 87.210 	Validation Prec@5 99.510 	
2019-05-03 11:50:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:50:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:50:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:50:28 - INFO - TRAINING - Epoch: [61][0/500]	Time 0.265 (0.265)	Data 0.246 (0.246)	Loss 0.1129 (0.1129)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 11:50:30 - INFO - TRAINING - Epoch: [61][50/500]	Time 0.046 (0.057)	Data 0.000 (0.006)	Loss 0.1067 (0.1921)	Prec@1 97.000 (93.255)	Prec@5 100.000 (99.902)
2019-05-03 11:50:33 - INFO - TRAINING - Epoch: [61][100/500]	Time 0.042 (0.055)	Data 0.000 (0.003)	Loss 0.0700 (0.1877)	Prec@1 97.000 (93.426)	Prec@5 100.000 (99.891)
2019-05-03 11:50:36 - INFO - TRAINING - Epoch: [61][150/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.1402 (0.1819)	Prec@1 95.000 (93.596)	Prec@5 100.000 (99.894)
2019-05-03 11:50:39 - INFO - TRAINING - Epoch: [61][200/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.1549 (0.1785)	Prec@1 94.000 (93.721)	Prec@5 100.000 (99.905)
2019-05-03 11:50:41 - INFO - TRAINING - Epoch: [61][250/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.2006 (0.1812)	Prec@1 95.000 (93.773)	Prec@5 100.000 (99.904)
2019-05-03 11:50:44 - INFO - TRAINING - Epoch: [61][300/500]	Time 0.062 (0.054)	Data 0.000 (0.002)	Loss 0.1284 (0.1820)	Prec@1 96.000 (93.834)	Prec@5 100.000 (99.907)
2019-05-03 11:50:47 - INFO - TRAINING - Epoch: [61][350/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.2836 (0.1861)	Prec@1 90.000 (93.752)	Prec@5 100.000 (99.903)
2019-05-03 11:50:49 - INFO - TRAINING - Epoch: [61][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.3559 (0.1852)	Prec@1 91.000 (93.766)	Prec@5 100.000 (99.898)
2019-05-03 11:50:52 - INFO - TRAINING - Epoch: [61][450/500]	Time 0.045 (0.054)	Data 0.000 (0.001)	Loss 0.2656 (0.1866)	Prec@1 93.000 (93.712)	Prec@5 100.000 (99.898)
2019-05-03 11:50:55 - INFO - EVALUATING - Epoch: [61][0/100]	Time 0.386 (0.386)	Data 0.372 (0.372)	Loss 0.2626 (0.2626)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-05-03 11:50:56 - INFO - EVALUATING - Epoch: [61][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.2860 (0.3504)	Prec@1 92.000 (88.980)	Prec@5 99.000 (99.549)
2019-05-03 11:50:57 - INFO - 
 Epoch: 62	Training Loss 0.1888 	Training Prec@1 93.654 	Training Prec@5 99.894 	Validation Loss 0.3423 	Validation Prec@1 88.950 	Validation Prec@5 99.640 	
2019-05-03 11:50:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:50:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:50:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:50:57 - INFO - TRAINING - Epoch: [62][0/500]	Time 0.264 (0.264)	Data 0.233 (0.233)	Loss 0.1456 (0.1456)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:51:00 - INFO - TRAINING - Epoch: [62][50/500]	Time 0.048 (0.057)	Data 0.000 (0.005)	Loss 0.2984 (0.1855)	Prec@1 89.000 (93.451)	Prec@5 99.000 (99.922)
2019-05-03 11:51:03 - INFO - TRAINING - Epoch: [62][100/500]	Time 0.064 (0.056)	Data 0.000 (0.003)	Loss 0.2041 (0.1813)	Prec@1 94.000 (93.624)	Prec@5 100.000 (99.911)
2019-05-03 11:51:05 - INFO - TRAINING - Epoch: [62][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.1924 (0.1793)	Prec@1 92.000 (93.808)	Prec@5 100.000 (99.940)
2019-05-03 11:51:08 - INFO - TRAINING - Epoch: [62][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.2174 (0.1785)	Prec@1 94.000 (93.801)	Prec@5 100.000 (99.930)
2019-05-03 11:51:11 - INFO - TRAINING - Epoch: [62][250/500]	Time 0.069 (0.055)	Data 0.000 (0.002)	Loss 0.1303 (0.1786)	Prec@1 94.000 (93.765)	Prec@5 100.000 (99.924)
2019-05-03 11:51:14 - INFO - TRAINING - Epoch: [62][300/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.2065 (0.1803)	Prec@1 95.000 (93.721)	Prec@5 99.000 (99.920)
2019-05-03 11:51:16 - INFO - TRAINING - Epoch: [62][350/500]	Time 0.062 (0.055)	Data 0.000 (0.001)	Loss 0.2047 (0.1818)	Prec@1 93.000 (93.692)	Prec@5 100.000 (99.917)
2019-05-03 11:51:19 - INFO - TRAINING - Epoch: [62][400/500]	Time 0.050 (0.055)	Data 0.000 (0.001)	Loss 0.2546 (0.1825)	Prec@1 91.000 (93.663)	Prec@5 99.000 (99.910)
2019-05-03 11:51:22 - INFO - TRAINING - Epoch: [62][450/500]	Time 0.052 (0.055)	Data 0.000 (0.001)	Loss 0.0966 (0.1828)	Prec@1 97.000 (93.670)	Prec@5 100.000 (99.905)
2019-05-03 11:51:25 - INFO - EVALUATING - Epoch: [62][0/100]	Time 0.367 (0.367)	Data 0.356 (0.356)	Loss 0.2592 (0.2592)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:51:26 - INFO - EVALUATING - Epoch: [62][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.4030 (0.3877)	Prec@1 89.000 (88.059)	Prec@5 99.000 (99.667)
2019-05-03 11:51:27 - INFO - 
 Epoch: 63	Training Loss 0.1829 	Training Prec@1 93.692 	Training Prec@5 99.910 	Validation Loss 0.3777 	Validation Prec@1 87.780 	Validation Prec@5 99.690 	
2019-05-03 11:51:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:51:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:51:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:51:27 - INFO - TRAINING - Epoch: [63][0/500]	Time 0.294 (0.294)	Data 0.258 (0.258)	Loss 0.1019 (0.1019)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:51:30 - INFO - TRAINING - Epoch: [63][50/500]	Time 0.057 (0.060)	Data 0.000 (0.006)	Loss 0.1028 (0.1648)	Prec@1 96.000 (94.490)	Prec@5 100.000 (99.941)
2019-05-03 11:51:33 - INFO - TRAINING - Epoch: [63][100/500]	Time 0.069 (0.058)	Data 0.000 (0.003)	Loss 0.2191 (0.1714)	Prec@1 92.000 (94.139)	Prec@5 100.000 (99.921)
2019-05-03 11:51:36 - INFO - TRAINING - Epoch: [63][150/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.1397 (0.1705)	Prec@1 94.000 (94.219)	Prec@5 100.000 (99.921)
2019-05-03 11:51:38 - INFO - TRAINING - Epoch: [63][200/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.2016 (0.1720)	Prec@1 94.000 (94.080)	Prec@5 100.000 (99.930)
2019-05-03 11:51:41 - INFO - TRAINING - Epoch: [63][250/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.1491 (0.1723)	Prec@1 95.000 (94.147)	Prec@5 100.000 (99.924)
2019-05-03 11:51:44 - INFO - TRAINING - Epoch: [63][300/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.1255 (0.1728)	Prec@1 98.000 (94.080)	Prec@5 100.000 (99.920)
2019-05-03 11:51:47 - INFO - TRAINING - Epoch: [63][350/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.1523 (0.1728)	Prec@1 97.000 (94.114)	Prec@5 100.000 (99.920)
2019-05-03 11:51:50 - INFO - TRAINING - Epoch: [63][400/500]	Time 0.051 (0.057)	Data 0.000 (0.002)	Loss 0.1121 (0.1718)	Prec@1 96.000 (94.165)	Prec@5 100.000 (99.918)
2019-05-03 11:51:53 - INFO - TRAINING - Epoch: [63][450/500]	Time 0.065 (0.057)	Data 0.000 (0.001)	Loss 0.3187 (0.1736)	Prec@1 87.000 (94.104)	Prec@5 100.000 (99.922)
2019-05-03 11:51:56 - INFO - EVALUATING - Epoch: [63][0/100]	Time 0.351 (0.351)	Data 0.344 (0.344)	Loss 0.3051 (0.3051)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:51:57 - INFO - EVALUATING - Epoch: [63][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.4247 (0.3517)	Prec@1 85.000 (88.510)	Prec@5 100.000 (99.647)
2019-05-03 11:51:58 - INFO - 
 Epoch: 64	Training Loss 0.1742 	Training Prec@1 94.066 	Training Prec@5 99.920 	Validation Loss 0.3530 	Validation Prec@1 88.610 	Validation Prec@5 99.600 	
2019-05-03 11:51:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:51:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:51:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:51:58 - INFO - TRAINING - Epoch: [64][0/500]	Time 0.273 (0.273)	Data 0.242 (0.242)	Loss 0.1497 (0.1497)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:52:01 - INFO - TRAINING - Epoch: [64][50/500]	Time 0.066 (0.058)	Data 0.000 (0.005)	Loss 0.1056 (0.1525)	Prec@1 96.000 (94.784)	Prec@5 100.000 (99.922)
2019-05-03 11:52:03 - INFO - TRAINING - Epoch: [64][100/500]	Time 0.056 (0.055)	Data 0.000 (0.003)	Loss 0.1617 (0.1557)	Prec@1 96.000 (94.693)	Prec@5 100.000 (99.921)
2019-05-03 11:52:06 - INFO - TRAINING - Epoch: [64][150/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.1056 (0.1624)	Prec@1 95.000 (94.444)	Prec@5 100.000 (99.921)
2019-05-03 11:52:09 - INFO - TRAINING - Epoch: [64][200/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.0712 (0.1608)	Prec@1 95.000 (94.443)	Prec@5 100.000 (99.930)
2019-05-03 11:52:11 - INFO - TRAINING - Epoch: [64][250/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.1188 (0.1613)	Prec@1 96.000 (94.450)	Prec@5 100.000 (99.944)
2019-05-03 11:52:14 - INFO - TRAINING - Epoch: [64][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0722 (0.1631)	Prec@1 99.000 (94.372)	Prec@5 100.000 (99.944)
2019-05-03 11:52:17 - INFO - TRAINING - Epoch: [64][350/500]	Time 0.058 (0.054)	Data 0.000 (0.001)	Loss 0.0817 (0.1642)	Prec@1 97.000 (94.353)	Prec@5 100.000 (99.940)
2019-05-03 11:52:19 - INFO - TRAINING - Epoch: [64][400/500]	Time 0.045 (0.054)	Data 0.000 (0.001)	Loss 0.0683 (0.1648)	Prec@1 98.000 (94.362)	Prec@5 100.000 (99.935)
2019-05-03 11:52:22 - INFO - TRAINING - Epoch: [64][450/500]	Time 0.058 (0.054)	Data 0.000 (0.001)	Loss 0.1176 (0.1669)	Prec@1 97.000 (94.299)	Prec@5 100.000 (99.933)
2019-05-03 11:52:25 - INFO - EVALUATING - Epoch: [64][0/100]	Time 0.366 (0.366)	Data 0.352 (0.352)	Loss 0.2639 (0.2639)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:52:26 - INFO - EVALUATING - Epoch: [64][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2370 (0.3725)	Prec@1 94.000 (88.235)	Prec@5 100.000 (99.490)
2019-05-03 11:52:27 - INFO - 
 Epoch: 65	Training Loss 0.1663 	Training Prec@1 94.316 	Training Prec@5 99.938 	Validation Loss 0.3592 	Validation Prec@1 88.610 	Validation Prec@5 99.570 	
2019-05-03 11:52:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:52:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:52:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:52:27 - INFO - TRAINING - Epoch: [65][0/500]	Time 0.275 (0.275)	Data 0.250 (0.250)	Loss 0.1282 (0.1282)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 11:52:30 - INFO - TRAINING - Epoch: [65][50/500]	Time 0.061 (0.061)	Data 0.000 (0.006)	Loss 0.0774 (0.1484)	Prec@1 98.000 (94.843)	Prec@5 100.000 (100.000)
2019-05-03 11:52:33 - INFO - TRAINING - Epoch: [65][100/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.1546 (0.1525)	Prec@1 95.000 (94.733)	Prec@5 100.000 (99.980)
2019-05-03 11:52:36 - INFO - TRAINING - Epoch: [65][150/500]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 0.1699 (0.1560)	Prec@1 97.000 (94.616)	Prec@5 99.000 (99.940)
2019-05-03 11:52:39 - INFO - TRAINING - Epoch: [65][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1724 (0.1590)	Prec@1 95.000 (94.567)	Prec@5 100.000 (99.955)
2019-05-03 11:52:41 - INFO - TRAINING - Epoch: [65][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.1623 (0.1628)	Prec@1 94.000 (94.522)	Prec@5 100.000 (99.944)
2019-05-03 11:52:44 - INFO - TRAINING - Epoch: [65][300/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.2896 (0.1618)	Prec@1 88.000 (94.458)	Prec@5 100.000 (99.947)
2019-05-03 11:52:47 - INFO - TRAINING - Epoch: [65][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1508 (0.1611)	Prec@1 95.000 (94.496)	Prec@5 100.000 (99.954)
2019-05-03 11:52:50 - INFO - TRAINING - Epoch: [65][400/500]	Time 0.045 (0.058)	Data 0.000 (0.002)	Loss 0.1580 (0.1609)	Prec@1 96.000 (94.506)	Prec@5 100.000 (99.950)
2019-05-03 11:52:53 - INFO - TRAINING - Epoch: [65][450/500]	Time 0.059 (0.057)	Data 0.000 (0.001)	Loss 0.1821 (0.1602)	Prec@1 93.000 (94.503)	Prec@5 100.000 (99.949)
2019-05-03 11:52:56 - INFO - EVALUATING - Epoch: [65][0/100]	Time 0.398 (0.398)	Data 0.388 (0.388)	Loss 0.4431 (0.4431)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 11:52:57 - INFO - EVALUATING - Epoch: [65][50/100]	Time 0.016 (0.026)	Data 0.000 (0.008)	Loss 0.3700 (0.4019)	Prec@1 86.000 (88.137)	Prec@5 100.000 (99.471)
2019-05-03 11:52:58 - INFO - 
 Epoch: 66	Training Loss 0.1605 	Training Prec@1 94.506 	Training Prec@5 99.944 	Validation Loss 0.3765 	Validation Prec@1 88.660 	Validation Prec@5 99.580 	
2019-05-03 11:52:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:52:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:52:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:52:58 - INFO - TRAINING - Epoch: [66][0/500]	Time 0.288 (0.288)	Data 0.253 (0.253)	Loss 0.1609 (0.1609)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:53:01 - INFO - TRAINING - Epoch: [66][50/500]	Time 0.049 (0.058)	Data 0.000 (0.006)	Loss 0.0651 (0.1528)	Prec@1 98.000 (95.020)	Prec@5 100.000 (99.941)
2019-05-03 11:53:04 - INFO - TRAINING - Epoch: [66][100/500]	Time 0.051 (0.056)	Data 0.000 (0.003)	Loss 0.1399 (0.1565)	Prec@1 96.000 (94.941)	Prec@5 100.000 (99.931)
2019-05-03 11:53:06 - INFO - TRAINING - Epoch: [66][150/500]	Time 0.058 (0.055)	Data 0.000 (0.002)	Loss 0.1560 (0.1549)	Prec@1 94.000 (94.795)	Prec@5 100.000 (99.947)
2019-05-03 11:53:09 - INFO - TRAINING - Epoch: [66][200/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.2033 (0.1559)	Prec@1 94.000 (94.711)	Prec@5 100.000 (99.935)
2019-05-03 11:53:12 - INFO - TRAINING - Epoch: [66][250/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.1232 (0.1546)	Prec@1 95.000 (94.745)	Prec@5 100.000 (99.920)
2019-05-03 11:53:14 - INFO - TRAINING - Epoch: [66][300/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.1393 (0.1565)	Prec@1 94.000 (94.674)	Prec@5 100.000 (99.934)
2019-05-03 11:53:17 - INFO - TRAINING - Epoch: [66][350/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.1285 (0.1573)	Prec@1 97.000 (94.652)	Prec@5 100.000 (99.934)
2019-05-03 11:53:20 - INFO - TRAINING - Epoch: [66][400/500]	Time 0.066 (0.054)	Data 0.000 (0.001)	Loss 0.1382 (0.1569)	Prec@1 95.000 (94.663)	Prec@5 100.000 (99.935)
2019-05-03 11:53:22 - INFO - TRAINING - Epoch: [66][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.1488 (0.1562)	Prec@1 92.000 (94.667)	Prec@5 100.000 (99.936)
2019-05-03 11:53:25 - INFO - EVALUATING - Epoch: [66][0/100]	Time 0.341 (0.341)	Data 0.334 (0.334)	Loss 0.1992 (0.1992)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:53:26 - INFO - EVALUATING - Epoch: [66][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.1497 (0.3700)	Prec@1 95.000 (88.882)	Prec@5 100.000 (99.431)
2019-05-03 11:53:27 - INFO - 
 Epoch: 67	Training Loss 0.1575 	Training Prec@1 94.680 	Training Prec@5 99.930 	Validation Loss 0.3622 	Validation Prec@1 88.680 	Validation Prec@5 99.590 	
2019-05-03 11:53:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:53:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:53:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:53:27 - INFO - TRAINING - Epoch: [67][0/500]	Time 0.261 (0.261)	Data 0.235 (0.235)	Loss 0.1288 (0.1288)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:53:30 - INFO - TRAINING - Epoch: [67][50/500]	Time 0.056 (0.061)	Data 0.000 (0.005)	Loss 0.0884 (0.1531)	Prec@1 96.000 (94.765)	Prec@5 100.000 (99.980)
2019-05-03 11:53:33 - INFO - TRAINING - Epoch: [67][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.1108 (0.1512)	Prec@1 96.000 (94.970)	Prec@5 100.000 (99.970)
2019-05-03 11:53:36 - INFO - TRAINING - Epoch: [67][150/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.1038 (0.1489)	Prec@1 96.000 (94.980)	Prec@5 100.000 (99.940)
2019-05-03 11:53:39 - INFO - TRAINING - Epoch: [67][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.2080 (0.1468)	Prec@1 92.000 (95.025)	Prec@5 100.000 (99.950)
2019-05-03 11:53:42 - INFO - TRAINING - Epoch: [67][250/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.1627 (0.1469)	Prec@1 95.000 (94.992)	Prec@5 100.000 (99.960)
2019-05-03 11:53:44 - INFO - TRAINING - Epoch: [67][300/500]	Time 0.067 (0.058)	Data 0.000 (0.002)	Loss 0.1238 (0.1479)	Prec@1 94.000 (95.003)	Prec@5 100.000 (99.950)
2019-05-03 11:53:47 - INFO - TRAINING - Epoch: [67][350/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.2932 (0.1488)	Prec@1 88.000 (94.952)	Prec@5 100.000 (99.952)
2019-05-03 11:53:50 - INFO - TRAINING - Epoch: [67][400/500]	Time 0.063 (0.057)	Data 0.000 (0.001)	Loss 0.2034 (0.1495)	Prec@1 93.000 (94.955)	Prec@5 100.000 (99.953)
2019-05-03 11:53:53 - INFO - TRAINING - Epoch: [67][450/500]	Time 0.052 (0.057)	Data 0.000 (0.001)	Loss 0.0472 (0.1502)	Prec@1 98.000 (94.933)	Prec@5 100.000 (99.949)
2019-05-03 11:53:56 - INFO - EVALUATING - Epoch: [67][0/100]	Time 0.353 (0.353)	Data 0.341 (0.341)	Loss 0.2816 (0.2816)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:53:57 - INFO - EVALUATING - Epoch: [67][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2657 (0.3800)	Prec@1 92.000 (88.882)	Prec@5 100.000 (99.471)
2019-05-03 11:53:58 - INFO - 
 Epoch: 68	Training Loss 0.1509 	Training Prec@1 94.914 	Training Prec@5 99.950 	Validation Loss 0.3721 	Validation Prec@1 88.690 	Validation Prec@5 99.590 	
2019-05-03 11:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:53:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:53:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:53:58 - INFO - TRAINING - Epoch: [68][0/500]	Time 0.292 (0.292)	Data 0.267 (0.267)	Loss 0.1043 (0.1043)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 11:54:01 - INFO - TRAINING - Epoch: [68][50/500]	Time 0.056 (0.058)	Data 0.000 (0.006)	Loss 0.0846 (0.1586)	Prec@1 97.000 (94.608)	Prec@5 100.000 (99.961)
2019-05-03 11:54:04 - INFO - TRAINING - Epoch: [68][100/500]	Time 0.045 (0.056)	Data 0.000 (0.003)	Loss 0.1437 (0.1516)	Prec@1 96.000 (94.792)	Prec@5 99.000 (99.931)
2019-05-03 11:54:06 - INFO - TRAINING - Epoch: [68][150/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.1202 (0.1493)	Prec@1 95.000 (94.808)	Prec@5 100.000 (99.940)
2019-05-03 11:54:09 - INFO - TRAINING - Epoch: [68][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.2860 (0.1477)	Prec@1 93.000 (94.905)	Prec@5 100.000 (99.945)
2019-05-03 11:54:12 - INFO - TRAINING - Epoch: [68][250/500]	Time 0.066 (0.054)	Data 0.000 (0.002)	Loss 0.0448 (0.1476)	Prec@1 100.000 (94.932)	Prec@5 100.000 (99.948)
2019-05-03 11:54:14 - INFO - TRAINING - Epoch: [68][300/500]	Time 0.069 (0.054)	Data 0.000 (0.002)	Loss 0.1468 (0.1518)	Prec@1 93.000 (94.834)	Prec@5 100.000 (99.953)
2019-05-03 11:54:17 - INFO - TRAINING - Epoch: [68][350/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.1383 (0.1527)	Prec@1 94.000 (94.772)	Prec@5 100.000 (99.957)
2019-05-03 11:54:20 - INFO - TRAINING - Epoch: [68][400/500]	Time 0.050 (0.054)	Data 0.000 (0.001)	Loss 0.1497 (0.1529)	Prec@1 94.000 (94.778)	Prec@5 100.000 (99.958)
2019-05-03 11:54:22 - INFO - TRAINING - Epoch: [68][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.1503 (0.1519)	Prec@1 95.000 (94.798)	Prec@5 100.000 (99.960)
2019-05-03 11:54:25 - INFO - EVALUATING - Epoch: [68][0/100]	Time 0.274 (0.274)	Data 0.264 (0.264)	Loss 0.3290 (0.3290)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:54:26 - INFO - EVALUATING - Epoch: [68][50/100]	Time 0.013 (0.023)	Data 0.000 (0.006)	Loss 0.4107 (0.3845)	Prec@1 90.000 (88.196)	Prec@5 99.000 (99.647)
2019-05-03 11:54:27 - INFO - 
 Epoch: 69	Training Loss 0.1517 	Training Prec@1 94.778 	Training Prec@5 99.964 	Validation Loss 0.3702 	Validation Prec@1 88.290 	Validation Prec@5 99.640 	
2019-05-03 11:54:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:54:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:54:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:54:28 - INFO - TRAINING - Epoch: [69][0/500]	Time 0.278 (0.278)	Data 0.259 (0.259)	Loss 0.1208 (0.1208)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:54:30 - INFO - TRAINING - Epoch: [69][50/500]	Time 0.056 (0.061)	Data 0.000 (0.006)	Loss 0.2129 (0.1703)	Prec@1 92.000 (94.137)	Prec@5 100.000 (99.980)
2019-05-03 11:54:33 - INFO - TRAINING - Epoch: [69][100/500]	Time 0.060 (0.059)	Data 0.000 (0.003)	Loss 0.1951 (0.1525)	Prec@1 93.000 (94.772)	Prec@5 100.000 (99.980)
2019-05-03 11:54:36 - INFO - TRAINING - Epoch: [69][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.1562 (0.1476)	Prec@1 93.000 (94.960)	Prec@5 100.000 (99.980)
2019-05-03 11:54:39 - INFO - TRAINING - Epoch: [69][200/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.1362 (0.1430)	Prec@1 95.000 (95.090)	Prec@5 100.000 (99.980)
2019-05-03 11:54:42 - INFO - TRAINING - Epoch: [69][250/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0946 (0.1409)	Prec@1 96.000 (95.203)	Prec@5 100.000 (99.972)
2019-05-03 11:54:45 - INFO - TRAINING - Epoch: [69][300/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.1815 (0.1402)	Prec@1 92.000 (95.223)	Prec@5 100.000 (99.970)
2019-05-03 11:54:47 - INFO - TRAINING - Epoch: [69][350/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.1834 (0.1412)	Prec@1 98.000 (95.222)	Prec@5 100.000 (99.963)
2019-05-03 11:54:50 - INFO - TRAINING - Epoch: [69][400/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.1254 (0.1407)	Prec@1 95.000 (95.239)	Prec@5 100.000 (99.963)
2019-05-03 11:54:53 - INFO - TRAINING - Epoch: [69][450/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.1893 (0.1427)	Prec@1 94.000 (95.213)	Prec@5 100.000 (99.953)
2019-05-03 11:54:56 - INFO - EVALUATING - Epoch: [69][0/100]	Time 0.356 (0.356)	Data 0.342 (0.342)	Loss 0.2442 (0.2442)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 11:54:57 - INFO - EVALUATING - Epoch: [69][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.2637 (0.3474)	Prec@1 92.000 (89.922)	Prec@5 99.000 (99.549)
2019-05-03 11:54:58 - INFO - 
 Epoch: 70	Training Loss 0.1416 	Training Prec@1 95.240 	Training Prec@5 99.950 	Validation Loss 0.3478 	Validation Prec@1 89.630 	Validation Prec@5 99.510 	
2019-05-03 11:54:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:54:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:54:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:54:58 - INFO - TRAINING - Epoch: [70][0/500]	Time 0.263 (0.263)	Data 0.238 (0.238)	Loss 0.1960 (0.1960)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:55:01 - INFO - TRAINING - Epoch: [70][50/500]	Time 0.058 (0.060)	Data 0.000 (0.005)	Loss 0.2175 (0.1362)	Prec@1 92.000 (95.039)	Prec@5 100.000 (99.941)
2019-05-03 11:55:04 - INFO - TRAINING - Epoch: [70][100/500]	Time 0.053 (0.059)	Data 0.000 (0.003)	Loss 0.0707 (0.1398)	Prec@1 99.000 (95.000)	Prec@5 100.000 (99.960)
2019-05-03 11:55:07 - INFO - TRAINING - Epoch: [70][150/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.1213 (0.1376)	Prec@1 97.000 (95.159)	Prec@5 100.000 (99.967)
2019-05-03 11:55:10 - INFO - TRAINING - Epoch: [70][200/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.1090 (0.1349)	Prec@1 98.000 (95.249)	Prec@5 100.000 (99.960)
2019-05-03 11:55:13 - INFO - TRAINING - Epoch: [70][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.1332 (0.1333)	Prec@1 94.000 (95.347)	Prec@5 100.000 (99.960)
2019-05-03 11:55:15 - INFO - TRAINING - Epoch: [70][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1911 (0.1333)	Prec@1 95.000 (95.409)	Prec@5 100.000 (99.963)
2019-05-03 11:55:18 - INFO - TRAINING - Epoch: [70][350/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0897 (0.1343)	Prec@1 97.000 (95.385)	Prec@5 100.000 (99.966)
2019-05-03 11:55:21 - INFO - TRAINING - Epoch: [70][400/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.0966 (0.1340)	Prec@1 95.000 (95.377)	Prec@5 100.000 (99.965)
2019-05-03 11:55:24 - INFO - TRAINING - Epoch: [70][450/500]	Time 0.071 (0.057)	Data 0.000 (0.001)	Loss 0.1237 (0.1345)	Prec@1 95.000 (95.370)	Prec@5 100.000 (99.965)
2019-05-03 11:55:27 - INFO - EVALUATING - Epoch: [70][0/100]	Time 0.357 (0.357)	Data 0.351 (0.351)	Loss 0.3158 (0.3158)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:55:28 - INFO - EVALUATING - Epoch: [70][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.4442 (0.4354)	Prec@1 89.000 (87.902)	Prec@5 99.000 (99.392)
2019-05-03 11:55:29 - INFO - 
 Epoch: 71	Training Loss 0.1347 	Training Prec@1 95.358 	Training Prec@5 99.962 	Validation Loss 0.4227 	Validation Prec@1 87.820 	Validation Prec@5 99.540 	
2019-05-03 11:55:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:55:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:55:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:55:29 - INFO - TRAINING - Epoch: [71][0/500]	Time 0.288 (0.288)	Data 0.259 (0.259)	Loss 0.0671 (0.0671)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 11:55:32 - INFO - TRAINING - Epoch: [71][50/500]	Time 0.055 (0.059)	Data 0.000 (0.006)	Loss 0.1034 (0.1238)	Prec@1 97.000 (95.647)	Prec@5 100.000 (99.961)
2019-05-03 11:55:35 - INFO - TRAINING - Epoch: [71][100/500]	Time 0.048 (0.056)	Data 0.000 (0.003)	Loss 0.1084 (0.1237)	Prec@1 97.000 (95.851)	Prec@5 100.000 (99.960)
2019-05-03 11:55:37 - INFO - TRAINING - Epoch: [71][150/500]	Time 0.049 (0.055)	Data 0.000 (0.003)	Loss 0.0913 (0.1304)	Prec@1 96.000 (95.570)	Prec@5 100.000 (99.974)
2019-05-03 11:55:40 - INFO - TRAINING - Epoch: [71][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.1156 (0.1275)	Prec@1 98.000 (95.726)	Prec@5 100.000 (99.975)
2019-05-03 11:55:43 - INFO - TRAINING - Epoch: [71][250/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.2245 (0.1317)	Prec@1 90.000 (95.558)	Prec@5 100.000 (99.976)
2019-05-03 11:55:45 - INFO - TRAINING - Epoch: [71][300/500]	Time 0.039 (0.055)	Data 0.000 (0.002)	Loss 0.2436 (0.1320)	Prec@1 93.000 (95.532)	Prec@5 100.000 (99.977)
2019-05-03 11:55:48 - INFO - TRAINING - Epoch: [71][350/500]	Time 0.063 (0.055)	Data 0.000 (0.002)	Loss 0.1333 (0.1319)	Prec@1 95.000 (95.541)	Prec@5 100.000 (99.977)
2019-05-03 11:55:51 - INFO - TRAINING - Epoch: [71][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.1300 (0.1337)	Prec@1 97.000 (95.479)	Prec@5 100.000 (99.978)
2019-05-03 11:55:53 - INFO - TRAINING - Epoch: [71][450/500]	Time 0.045 (0.054)	Data 0.000 (0.001)	Loss 0.1118 (0.1327)	Prec@1 96.000 (95.510)	Prec@5 100.000 (99.973)
2019-05-03 11:55:56 - INFO - EVALUATING - Epoch: [71][0/100]	Time 0.372 (0.372)	Data 0.360 (0.360)	Loss 0.3062 (0.3062)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:55:57 - INFO - EVALUATING - Epoch: [71][50/100]	Time 0.020 (0.025)	Data 0.000 (0.007)	Loss 0.2747 (0.3728)	Prec@1 93.000 (88.549)	Prec@5 99.000 (99.569)
2019-05-03 11:55:58 - INFO - 
 Epoch: 72	Training Loss 0.1333 	Training Prec@1 95.500 	Training Prec@5 99.974 	Validation Loss 0.3578 	Validation Prec@1 88.960 	Validation Prec@5 99.660 	
2019-05-03 11:55:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:55:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:55:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:55:59 - INFO - TRAINING - Epoch: [72][0/500]	Time 0.295 (0.295)	Data 0.274 (0.274)	Loss 0.1133 (0.1133)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 11:56:01 - INFO - TRAINING - Epoch: [72][50/500]	Time 0.053 (0.062)	Data 0.000 (0.006)	Loss 0.0732 (0.1355)	Prec@1 97.000 (95.569)	Prec@5 100.000 (99.980)
2019-05-03 11:56:04 - INFO - TRAINING - Epoch: [72][100/500]	Time 0.060 (0.059)	Data 0.000 (0.004)	Loss 0.1446 (0.1311)	Prec@1 95.000 (95.703)	Prec@5 99.000 (99.970)
2019-05-03 11:56:07 - INFO - TRAINING - Epoch: [72][150/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.1105 (0.1278)	Prec@1 95.000 (95.742)	Prec@5 100.000 (99.967)
2019-05-03 11:56:10 - INFO - TRAINING - Epoch: [72][200/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.1833 (0.1283)	Prec@1 96.000 (95.726)	Prec@5 100.000 (99.970)
2019-05-03 11:56:13 - INFO - TRAINING - Epoch: [72][250/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.1765 (0.1287)	Prec@1 94.000 (95.713)	Prec@5 100.000 (99.976)
2019-05-03 11:56:16 - INFO - TRAINING - Epoch: [72][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.1182 (0.1283)	Prec@1 95.000 (95.734)	Prec@5 100.000 (99.973)
2019-05-03 11:56:19 - INFO - TRAINING - Epoch: [72][350/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1390 (0.1282)	Prec@1 94.000 (95.678)	Prec@5 100.000 (99.969)
2019-05-03 11:56:21 - INFO - TRAINING - Epoch: [72][400/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.2335 (0.1289)	Prec@1 93.000 (95.653)	Prec@5 100.000 (99.968)
2019-05-03 11:56:24 - INFO - TRAINING - Epoch: [72][450/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.1066 (0.1302)	Prec@1 94.000 (95.559)	Prec@5 100.000 (99.969)
2019-05-03 11:56:27 - INFO - EVALUATING - Epoch: [72][0/100]	Time 0.364 (0.364)	Data 0.354 (0.354)	Loss 0.4207 (0.4207)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 11:56:28 - INFO - EVALUATING - Epoch: [72][50/100]	Time 0.025 (0.025)	Data 0.000 (0.007)	Loss 0.3513 (0.3999)	Prec@1 89.000 (88.000)	Prec@5 100.000 (99.451)
2019-05-03 11:56:29 - INFO - 
 Epoch: 73	Training Loss 0.1322 	Training Prec@1 95.502 	Training Prec@5 99.966 	Validation Loss 0.3774 	Validation Prec@1 88.170 	Validation Prec@5 99.510 	
2019-05-03 11:56:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:56:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:56:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:56:30 - INFO - TRAINING - Epoch: [73][0/500]	Time 0.280 (0.280)	Data 0.256 (0.256)	Loss 0.1317 (0.1317)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:56:32 - INFO - TRAINING - Epoch: [73][50/500]	Time 0.052 (0.058)	Data 0.000 (0.006)	Loss 0.0868 (0.1211)	Prec@1 97.000 (96.196)	Prec@5 100.000 (99.961)
2019-05-03 11:56:35 - INFO - TRAINING - Epoch: [73][100/500]	Time 0.058 (0.056)	Data 0.000 (0.003)	Loss 0.1417 (0.1150)	Prec@1 94.000 (96.297)	Prec@5 100.000 (99.970)
2019-05-03 11:56:38 - INFO - TRAINING - Epoch: [73][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.1089 (0.1199)	Prec@1 95.000 (96.007)	Prec@5 100.000 (99.967)
2019-05-03 11:56:40 - INFO - TRAINING - Epoch: [73][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.1259 (0.1215)	Prec@1 95.000 (95.841)	Prec@5 100.000 (99.970)
2019-05-03 11:56:43 - INFO - TRAINING - Epoch: [73][250/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 0.0963 (0.1213)	Prec@1 96.000 (95.821)	Prec@5 100.000 (99.972)
2019-05-03 11:56:46 - INFO - TRAINING - Epoch: [73][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.1046 (0.1217)	Prec@1 97.000 (95.844)	Prec@5 100.000 (99.963)
2019-05-03 11:56:48 - INFO - TRAINING - Epoch: [73][350/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.1232 (0.1228)	Prec@1 94.000 (95.801)	Prec@5 100.000 (99.966)
2019-05-03 11:56:51 - INFO - TRAINING - Epoch: [73][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0648 (0.1242)	Prec@1 97.000 (95.763)	Prec@5 100.000 (99.968)
2019-05-03 11:56:54 - INFO - TRAINING - Epoch: [73][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0905 (0.1257)	Prec@1 96.000 (95.707)	Prec@5 100.000 (99.965)
2019-05-03 11:56:56 - INFO - EVALUATING - Epoch: [73][0/100]	Time 0.376 (0.376)	Data 0.367 (0.367)	Loss 0.3136 (0.3136)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:56:57 - INFO - EVALUATING - Epoch: [73][50/100]	Time 0.020 (0.025)	Data 0.000 (0.008)	Loss 0.1829 (0.3701)	Prec@1 96.000 (89.353)	Prec@5 99.000 (99.510)
2019-05-03 11:56:58 - INFO - 
 Epoch: 74	Training Loss 0.1268 	Training Prec@1 95.642 	Training Prec@5 99.966 	Validation Loss 0.3695 	Validation Prec@1 89.130 	Validation Prec@5 99.540 	
2019-05-03 11:56:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:56:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:56:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:56:59 - INFO - TRAINING - Epoch: [74][0/500]	Time 0.281 (0.281)	Data 0.252 (0.252)	Loss 0.1058 (0.1058)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 11:57:02 - INFO - TRAINING - Epoch: [74][50/500]	Time 0.063 (0.061)	Data 0.000 (0.006)	Loss 0.1866 (0.1292)	Prec@1 90.000 (95.686)	Prec@5 100.000 (99.961)
2019-05-03 11:57:04 - INFO - TRAINING - Epoch: [74][100/500]	Time 0.066 (0.059)	Data 0.000 (0.003)	Loss 0.1194 (0.1250)	Prec@1 93.000 (95.653)	Prec@5 100.000 (99.950)
2019-05-03 11:57:07 - INFO - TRAINING - Epoch: [74][150/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.1154 (0.1262)	Prec@1 94.000 (95.576)	Prec@5 100.000 (99.960)
2019-05-03 11:57:10 - INFO - TRAINING - Epoch: [74][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1006 (0.1246)	Prec@1 99.000 (95.617)	Prec@5 100.000 (99.970)
2019-05-03 11:57:13 - INFO - TRAINING - Epoch: [74][250/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.1161 (0.1229)	Prec@1 95.000 (95.669)	Prec@5 100.000 (99.964)
2019-05-03 11:57:16 - INFO - TRAINING - Epoch: [74][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0886 (0.1216)	Prec@1 98.000 (95.724)	Prec@5 100.000 (99.967)
2019-05-03 11:57:19 - INFO - TRAINING - Epoch: [74][350/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.1072 (0.1224)	Prec@1 97.000 (95.698)	Prec@5 100.000 (99.963)
2019-05-03 11:57:21 - INFO - TRAINING - Epoch: [74][400/500]	Time 0.065 (0.058)	Data 0.000 (0.001)	Loss 0.2024 (0.1228)	Prec@1 93.000 (95.673)	Prec@5 100.000 (99.968)
2019-05-03 11:57:24 - INFO - TRAINING - Epoch: [74][450/500]	Time 0.061 (0.057)	Data 0.000 (0.001)	Loss 0.0727 (0.1220)	Prec@1 97.000 (95.690)	Prec@5 100.000 (99.969)
2019-05-03 11:57:27 - INFO - EVALUATING - Epoch: [74][0/100]	Time 0.354 (0.354)	Data 0.347 (0.347)	Loss 0.3380 (0.3380)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:57:28 - INFO - EVALUATING - Epoch: [74][50/100]	Time 0.013 (0.024)	Data 0.000 (0.007)	Loss 0.2342 (0.3656)	Prec@1 94.000 (89.529)	Prec@5 100.000 (99.529)
2019-05-03 11:57:29 - INFO - 
 Epoch: 75	Training Loss 0.1241 	Training Prec@1 95.618 	Training Prec@5 99.968 	Validation Loss 0.3577 	Validation Prec@1 89.370 	Validation Prec@5 99.620 	
2019-05-03 11:57:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:57:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:57:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:57:30 - INFO - TRAINING - Epoch: [75][0/500]	Time 0.263 (0.263)	Data 0.239 (0.239)	Loss 0.0997 (0.0997)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:57:32 - INFO - TRAINING - Epoch: [75][50/500]	Time 0.054 (0.061)	Data 0.000 (0.005)	Loss 0.0992 (0.1293)	Prec@1 98.000 (95.373)	Prec@5 100.000 (99.961)
2019-05-03 11:57:35 - INFO - TRAINING - Epoch: [75][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0860 (0.1278)	Prec@1 98.000 (95.495)	Prec@5 100.000 (99.970)
2019-05-03 11:57:38 - INFO - TRAINING - Epoch: [75][150/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0804 (0.1230)	Prec@1 98.000 (95.715)	Prec@5 100.000 (99.974)
2019-05-03 11:57:41 - INFO - TRAINING - Epoch: [75][200/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0524 (0.1237)	Prec@1 99.000 (95.781)	Prec@5 100.000 (99.975)
2019-05-03 11:57:44 - INFO - TRAINING - Epoch: [75][250/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.1887 (0.1216)	Prec@1 94.000 (95.892)	Prec@5 100.000 (99.972)
2019-05-03 11:57:47 - INFO - TRAINING - Epoch: [75][300/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0949 (0.1195)	Prec@1 97.000 (95.934)	Prec@5 100.000 (99.970)
2019-05-03 11:57:49 - INFO - TRAINING - Epoch: [75][350/500]	Time 0.062 (0.057)	Data 0.000 (0.001)	Loss 0.0672 (0.1193)	Prec@1 98.000 (95.909)	Prec@5 100.000 (99.963)
2019-05-03 11:57:52 - INFO - TRAINING - Epoch: [75][400/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0654 (0.1197)	Prec@1 99.000 (95.898)	Prec@5 100.000 (99.965)
2019-05-03 11:57:55 - INFO - TRAINING - Epoch: [75][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.1861 (0.1197)	Prec@1 94.000 (95.898)	Prec@5 100.000 (99.967)
2019-05-03 11:57:58 - INFO - EVALUATING - Epoch: [75][0/100]	Time 0.384 (0.384)	Data 0.366 (0.366)	Loss 0.2543 (0.2543)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:57:59 - INFO - EVALUATING - Epoch: [75][50/100]	Time 0.020 (0.025)	Data 0.000 (0.007)	Loss 0.3228 (0.3620)	Prec@1 91.000 (89.725)	Prec@5 100.000 (99.588)
2019-05-03 11:58:00 - INFO - 
 Epoch: 76	Training Loss 0.1203 	Training Prec@1 95.884 	Training Prec@5 99.966 	Validation Loss 0.3476 	Validation Prec@1 89.770 	Validation Prec@5 99.670 	
2019-05-03 11:58:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:58:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:58:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:58:00 - INFO - TRAINING - Epoch: [76][0/500]	Time 0.285 (0.285)	Data 0.259 (0.259)	Loss 0.1844 (0.1844)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:58:03 - INFO - TRAINING - Epoch: [76][50/500]	Time 0.060 (0.058)	Data 0.000 (0.006)	Loss 0.1505 (0.1104)	Prec@1 94.000 (96.275)	Prec@5 100.000 (99.980)
2019-05-03 11:58:06 - INFO - TRAINING - Epoch: [76][100/500]	Time 0.048 (0.056)	Data 0.000 (0.003)	Loss 0.0759 (0.1079)	Prec@1 98.000 (96.287)	Prec@5 100.000 (99.980)
2019-05-03 11:58:08 - INFO - TRAINING - Epoch: [76][150/500]	Time 0.049 (0.055)	Data 0.000 (0.003)	Loss 0.0690 (0.1084)	Prec@1 98.000 (96.265)	Prec@5 100.000 (99.980)
2019-05-03 11:58:11 - INFO - TRAINING - Epoch: [76][200/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.1123 (0.1087)	Prec@1 97.000 (96.239)	Prec@5 100.000 (99.970)
2019-05-03 11:58:14 - INFO - TRAINING - Epoch: [76][250/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.1628 (0.1131)	Prec@1 93.000 (96.100)	Prec@5 100.000 (99.964)
2019-05-03 11:58:17 - INFO - TRAINING - Epoch: [76][300/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.1022 (0.1130)	Prec@1 95.000 (96.113)	Prec@5 100.000 (99.967)
2019-05-03 11:58:19 - INFO - TRAINING - Epoch: [76][350/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0387 (0.1141)	Prec@1 99.000 (96.100)	Prec@5 100.000 (99.969)
2019-05-03 11:58:22 - INFO - TRAINING - Epoch: [76][400/500]	Time 0.064 (0.054)	Data 0.000 (0.001)	Loss 0.1439 (0.1156)	Prec@1 95.000 (96.040)	Prec@5 100.000 (99.970)
2019-05-03 11:58:25 - INFO - TRAINING - Epoch: [76][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.1720 (0.1154)	Prec@1 92.000 (96.033)	Prec@5 100.000 (99.967)
2019-05-03 11:58:28 - INFO - EVALUATING - Epoch: [76][0/100]	Time 0.364 (0.364)	Data 0.355 (0.355)	Loss 0.2720 (0.2720)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 11:58:28 - INFO - EVALUATING - Epoch: [76][50/100]	Time 0.026 (0.025)	Data 0.000 (0.007)	Loss 0.1681 (0.3773)	Prec@1 95.000 (89.275)	Prec@5 100.000 (99.588)
2019-05-03 11:58:29 - INFO - 
 Epoch: 77	Training Loss 0.1154 	Training Prec@1 96.030 	Training Prec@5 99.970 	Validation Loss 0.3602 	Validation Prec@1 89.450 	Validation Prec@5 99.630 	
2019-05-03 11:58:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:58:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:58:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:58:30 - INFO - TRAINING - Epoch: [77][0/500]	Time 0.270 (0.270)	Data 0.245 (0.245)	Loss 0.1164 (0.1164)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 11:58:33 - INFO - TRAINING - Epoch: [77][50/500]	Time 0.066 (0.061)	Data 0.000 (0.006)	Loss 0.0455 (0.1202)	Prec@1 98.000 (96.000)	Prec@5 100.000 (99.961)
2019-05-03 11:58:35 - INFO - TRAINING - Epoch: [77][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.1343 (0.1158)	Prec@1 96.000 (96.178)	Prec@5 100.000 (99.960)
2019-05-03 11:58:38 - INFO - TRAINING - Epoch: [77][150/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.1005 (0.1130)	Prec@1 97.000 (96.245)	Prec@5 100.000 (99.967)
2019-05-03 11:58:41 - INFO - TRAINING - Epoch: [77][200/500]	Time 0.043 (0.058)	Data 0.000 (0.002)	Loss 0.0719 (0.1109)	Prec@1 98.000 (96.224)	Prec@5 100.000 (99.965)
2019-05-03 11:58:44 - INFO - TRAINING - Epoch: [77][250/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.1502 (0.1104)	Prec@1 96.000 (96.259)	Prec@5 100.000 (99.972)
2019-05-03 11:58:47 - INFO - TRAINING - Epoch: [77][300/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.1615 (0.1109)	Prec@1 95.000 (96.246)	Prec@5 100.000 (99.977)
2019-05-03 11:58:50 - INFO - TRAINING - Epoch: [77][350/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0833 (0.1119)	Prec@1 96.000 (96.199)	Prec@5 100.000 (99.980)
2019-05-03 11:58:53 - INFO - TRAINING - Epoch: [77][400/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1552 (0.1112)	Prec@1 94.000 (96.227)	Prec@5 100.000 (99.978)
2019-05-03 11:58:55 - INFO - TRAINING - Epoch: [77][450/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.0729 (0.1114)	Prec@1 97.000 (96.224)	Prec@5 100.000 (99.978)
2019-05-03 11:58:59 - INFO - EVALUATING - Epoch: [77][0/100]	Time 0.358 (0.358)	Data 0.352 (0.352)	Loss 0.3881 (0.3881)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 11:58:59 - INFO - EVALUATING - Epoch: [77][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.2255 (0.3677)	Prec@1 90.000 (89.510)	Prec@5 100.000 (99.588)
2019-05-03 11:59:00 - INFO - 
 Epoch: 78	Training Loss 0.1120 	Training Prec@1 96.198 	Training Prec@5 99.976 	Validation Loss 0.3544 	Validation Prec@1 89.620 	Validation Prec@5 99.670 	
2019-05-03 11:59:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:59:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:59:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:59:01 - INFO - TRAINING - Epoch: [78][0/500]	Time 0.282 (0.282)	Data 0.257 (0.257)	Loss 0.1732 (0.1732)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 11:59:03 - INFO - TRAINING - Epoch: [78][50/500]	Time 0.042 (0.057)	Data 0.000 (0.006)	Loss 0.1908 (0.1034)	Prec@1 96.000 (96.510)	Prec@5 99.000 (99.941)
2019-05-03 11:59:06 - INFO - TRAINING - Epoch: [78][100/500]	Time 0.053 (0.055)	Data 0.000 (0.003)	Loss 0.0862 (0.1092)	Prec@1 98.000 (96.208)	Prec@5 100.000 (99.970)
2019-05-03 11:59:09 - INFO - TRAINING - Epoch: [78][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0998 (0.1103)	Prec@1 96.000 (96.179)	Prec@5 100.000 (99.960)
2019-05-03 11:59:11 - INFO - TRAINING - Epoch: [78][200/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.0764 (0.1100)	Prec@1 98.000 (96.229)	Prec@5 100.000 (99.965)
2019-05-03 11:59:14 - INFO - TRAINING - Epoch: [78][250/500]	Time 0.061 (0.054)	Data 0.000 (0.002)	Loss 0.0665 (0.1095)	Prec@1 96.000 (96.307)	Prec@5 100.000 (99.972)
2019-05-03 11:59:17 - INFO - TRAINING - Epoch: [78][300/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0797 (0.1097)	Prec@1 96.000 (96.292)	Prec@5 100.000 (99.977)
2019-05-03 11:59:19 - INFO - TRAINING - Epoch: [78][350/500]	Time 0.037 (0.054)	Data 0.000 (0.002)	Loss 0.0932 (0.1100)	Prec@1 96.000 (96.271)	Prec@5 100.000 (99.980)
2019-05-03 11:59:22 - INFO - TRAINING - Epoch: [78][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0583 (0.1101)	Prec@1 98.000 (96.249)	Prec@5 100.000 (99.980)
2019-05-03 11:59:25 - INFO - TRAINING - Epoch: [78][450/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.0934 (0.1114)	Prec@1 96.000 (96.213)	Prec@5 100.000 (99.980)
2019-05-03 11:59:28 - INFO - EVALUATING - Epoch: [78][0/100]	Time 0.266 (0.266)	Data 0.258 (0.258)	Loss 0.2888 (0.2888)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 11:59:28 - INFO - EVALUATING - Epoch: [78][50/100]	Time 0.015 (0.022)	Data 0.000 (0.005)	Loss 0.3218 (0.3613)	Prec@1 91.000 (89.804)	Prec@5 100.000 (99.627)
2019-05-03 11:59:29 - INFO - 
 Epoch: 79	Training Loss 0.1115 	Training Prec@1 96.214 	Training Prec@5 99.982 	Validation Loss 0.3475 	Validation Prec@1 89.780 	Validation Prec@5 99.710 	
2019-05-03 11:59:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 11:59:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 11:59:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 11:59:30 - INFO - TRAINING - Epoch: [79][0/500]	Time 0.283 (0.283)	Data 0.253 (0.253)	Loss 0.1358 (0.1358)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 11:59:33 - INFO - TRAINING - Epoch: [79][50/500]	Time 0.061 (0.061)	Data 0.000 (0.006)	Loss 0.0651 (0.1111)	Prec@1 98.000 (96.176)	Prec@5 100.000 (99.922)
2019-05-03 11:59:35 - INFO - TRAINING - Epoch: [79][100/500]	Time 0.052 (0.059)	Data 0.000 (0.003)	Loss 0.0748 (0.1045)	Prec@1 96.000 (96.366)	Prec@5 100.000 (99.950)
2019-05-03 11:59:38 - INFO - TRAINING - Epoch: [79][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0609 (0.1043)	Prec@1 98.000 (96.417)	Prec@5 100.000 (99.960)
2019-05-03 11:59:41 - INFO - TRAINING - Epoch: [79][200/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.1133 (0.1046)	Prec@1 95.000 (96.393)	Prec@5 100.000 (99.965)
2019-05-03 11:59:44 - INFO - TRAINING - Epoch: [79][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1811 (0.1056)	Prec@1 93.000 (96.382)	Prec@5 100.000 (99.964)
2019-05-03 11:59:47 - INFO - TRAINING - Epoch: [79][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1279 (0.1062)	Prec@1 96.000 (96.379)	Prec@5 100.000 (99.970)
2019-05-03 11:59:50 - INFO - TRAINING - Epoch: [79][350/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0945 (0.1055)	Prec@1 97.000 (96.368)	Prec@5 100.000 (99.974)
2019-05-03 11:59:53 - INFO - TRAINING - Epoch: [79][400/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0803 (0.1055)	Prec@1 97.000 (96.367)	Prec@5 100.000 (99.975)
2019-05-03 11:59:55 - INFO - TRAINING - Epoch: [79][450/500]	Time 0.054 (0.057)	Data 0.000 (0.001)	Loss 0.0921 (0.1056)	Prec@1 97.000 (96.373)	Prec@5 100.000 (99.973)
2019-05-03 11:59:59 - INFO - EVALUATING - Epoch: [79][0/100]	Time 0.360 (0.360)	Data 0.349 (0.349)	Loss 0.2723 (0.2723)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 11:59:59 - INFO - EVALUATING - Epoch: [79][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2585 (0.3376)	Prec@1 95.000 (90.275)	Prec@5 100.000 (99.647)
2019-05-03 12:00:00 - INFO - 
 Epoch: 80	Training Loss 0.1065 	Training Prec@1 96.352 	Training Prec@5 99.976 	Validation Loss 0.3360 	Validation Prec@1 90.150 	Validation Prec@5 99.660 	
2019-05-03 12:00:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:00:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:00:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:00:01 - INFO - TRAINING - Epoch: [80][0/500]	Time 0.267 (0.267)	Data 0.234 (0.234)	Loss 0.1664 (0.1664)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:00:04 - INFO - TRAINING - Epoch: [80][50/500]	Time 0.049 (0.060)	Data 0.000 (0.005)	Loss 0.1524 (0.1126)	Prec@1 94.000 (96.235)	Prec@5 100.000 (99.980)
2019-05-03 12:00:06 - INFO - TRAINING - Epoch: [80][100/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.1099 (0.1030)	Prec@1 96.000 (96.574)	Prec@5 100.000 (99.990)
2019-05-03 12:00:09 - INFO - TRAINING - Epoch: [80][150/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.1154 (0.1029)	Prec@1 95.000 (96.616)	Prec@5 100.000 (99.980)
2019-05-03 12:00:12 - INFO - TRAINING - Epoch: [80][200/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0898 (0.1038)	Prec@1 97.000 (96.562)	Prec@5 100.000 (99.985)
2019-05-03 12:00:15 - INFO - TRAINING - Epoch: [80][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0872 (0.1038)	Prec@1 97.000 (96.550)	Prec@5 100.000 (99.988)
2019-05-03 12:00:18 - INFO - TRAINING - Epoch: [80][300/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1554 (0.1045)	Prec@1 95.000 (96.518)	Prec@5 100.000 (99.983)
2019-05-03 12:00:21 - INFO - TRAINING - Epoch: [80][350/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.1429 (0.1043)	Prec@1 92.000 (96.487)	Prec@5 100.000 (99.986)
2019-05-03 12:00:23 - INFO - TRAINING - Epoch: [80][400/500]	Time 0.047 (0.057)	Data 0.000 (0.001)	Loss 0.1190 (0.1039)	Prec@1 95.000 (96.504)	Prec@5 100.000 (99.985)
2019-05-03 12:00:26 - INFO - TRAINING - Epoch: [80][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0443 (0.1033)	Prec@1 99.000 (96.512)	Prec@5 100.000 (99.984)
2019-05-03 12:00:29 - INFO - EVALUATING - Epoch: [80][0/100]	Time 0.356 (0.356)	Data 0.340 (0.340)	Loss 0.2418 (0.2418)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 12:00:30 - INFO - EVALUATING - Epoch: [80][50/100]	Time 0.021 (0.024)	Data 0.000 (0.007)	Loss 0.2887 (0.3461)	Prec@1 94.000 (89.824)	Prec@5 100.000 (99.510)
2019-05-03 12:00:31 - INFO - 
 Epoch: 81	Training Loss 0.1036 	Training Prec@1 96.482 	Training Prec@5 99.984 	Validation Loss 0.3334 	Validation Prec@1 90.160 	Validation Prec@5 99.620 	
2019-05-03 12:00:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:00:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:00:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:00:31 - INFO - TRAINING - Epoch: [81][0/500]	Time 0.282 (0.282)	Data 0.260 (0.260)	Loss 0.1996 (0.1996)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:00:34 - INFO - TRAINING - Epoch: [81][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.1342 (0.1010)	Prec@1 95.000 (96.627)	Prec@5 100.000 (100.000)
2019-05-03 12:00:37 - INFO - TRAINING - Epoch: [81][100/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.0901 (0.1000)	Prec@1 97.000 (96.564)	Prec@5 100.000 (100.000)
2019-05-03 12:00:39 - INFO - TRAINING - Epoch: [81][150/500]	Time 0.061 (0.055)	Data 0.000 (0.003)	Loss 0.0655 (0.0986)	Prec@1 98.000 (96.649)	Prec@5 100.000 (99.993)
2019-05-03 12:00:42 - INFO - TRAINING - Epoch: [81][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.1390 (0.0990)	Prec@1 96.000 (96.692)	Prec@5 100.000 (99.990)
2019-05-03 12:00:45 - INFO - TRAINING - Epoch: [81][250/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.1124 (0.1017)	Prec@1 97.000 (96.625)	Prec@5 100.000 (99.980)
2019-05-03 12:00:47 - INFO - TRAINING - Epoch: [81][300/500]	Time 0.041 (0.054)	Data 0.000 (0.002)	Loss 0.1052 (0.1006)	Prec@1 95.000 (96.648)	Prec@5 100.000 (99.980)
2019-05-03 12:00:50 - INFO - TRAINING - Epoch: [81][350/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.1136 (0.1007)	Prec@1 97.000 (96.627)	Prec@5 100.000 (99.983)
2019-05-03 12:00:53 - INFO - TRAINING - Epoch: [81][400/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.0999 (0.1022)	Prec@1 94.000 (96.541)	Prec@5 100.000 (99.983)
2019-05-03 12:00:55 - INFO - TRAINING - Epoch: [81][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0704 (0.1025)	Prec@1 98.000 (96.519)	Prec@5 100.000 (99.984)
2019-05-03 12:00:58 - INFO - EVALUATING - Epoch: [81][0/100]	Time 0.380 (0.380)	Data 0.371 (0.371)	Loss 0.3424 (0.3424)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:00:59 - INFO - EVALUATING - Epoch: [81][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.2379 (0.3790)	Prec@1 92.000 (89.176)	Prec@5 100.000 (99.471)
2019-05-03 12:01:00 - INFO - 
 Epoch: 82	Training Loss 0.1020 	Training Prec@1 96.532 	Training Prec@5 99.984 	Validation Loss 0.3651 	Validation Prec@1 89.460 	Validation Prec@5 99.540 	
2019-05-03 12:01:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:01:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:01:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:01:00 - INFO - TRAINING - Epoch: [82][0/500]	Time 0.303 (0.303)	Data 0.274 (0.274)	Loss 0.0913 (0.0913)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:01:03 - INFO - TRAINING - Epoch: [82][50/500]	Time 0.056 (0.062)	Data 0.000 (0.006)	Loss 0.1905 (0.0974)	Prec@1 95.000 (96.608)	Prec@5 100.000 (100.000)
2019-05-03 12:01:06 - INFO - TRAINING - Epoch: [82][100/500]	Time 0.061 (0.059)	Data 0.000 (0.004)	Loss 0.0510 (0.0967)	Prec@1 97.000 (96.663)	Prec@5 100.000 (100.000)
2019-05-03 12:01:09 - INFO - TRAINING - Epoch: [82][150/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.1166 (0.0993)	Prec@1 94.000 (96.616)	Prec@5 100.000 (99.993)
2019-05-03 12:01:12 - INFO - TRAINING - Epoch: [82][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0955 (0.0969)	Prec@1 97.000 (96.627)	Prec@5 100.000 (99.990)
2019-05-03 12:01:15 - INFO - TRAINING - Epoch: [82][250/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.0985 (0.0963)	Prec@1 96.000 (96.653)	Prec@5 100.000 (99.992)
2019-05-03 12:01:17 - INFO - TRAINING - Epoch: [82][300/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0746 (0.0962)	Prec@1 99.000 (96.651)	Prec@5 100.000 (99.993)
2019-05-03 12:01:20 - INFO - TRAINING - Epoch: [82][350/500]	Time 0.068 (0.056)	Data 0.000 (0.002)	Loss 0.0409 (0.0967)	Prec@1 98.000 (96.647)	Prec@5 100.000 (99.989)
2019-05-03 12:01:23 - INFO - TRAINING - Epoch: [82][400/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.1484 (0.0979)	Prec@1 94.000 (96.621)	Prec@5 100.000 (99.985)
2019-05-03 12:01:25 - INFO - TRAINING - Epoch: [82][450/500]	Time 0.054 (0.056)	Data 0.000 (0.001)	Loss 0.1651 (0.0982)	Prec@1 94.000 (96.601)	Prec@5 100.000 (99.982)
2019-05-03 12:01:28 - INFO - EVALUATING - Epoch: [82][0/100]	Time 0.363 (0.363)	Data 0.353 (0.353)	Loss 0.3170 (0.3170)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-03 12:01:29 - INFO - EVALUATING - Epoch: [82][50/100]	Time 0.015 (0.024)	Data 0.000 (0.007)	Loss 0.3359 (0.3869)	Prec@1 91.000 (88.980)	Prec@5 100.000 (99.549)
2019-05-03 12:01:30 - INFO - 
 Epoch: 83	Training Loss 0.0992 	Training Prec@1 96.564 	Training Prec@5 99.982 	Validation Loss 0.3749 	Validation Prec@1 89.110 	Validation Prec@5 99.670 	
2019-05-03 12:01:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:01:30 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:01:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:01:30 - INFO - TRAINING - Epoch: [83][0/500]	Time 0.266 (0.266)	Data 0.239 (0.239)	Loss 0.0602 (0.0602)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:01:33 - INFO - TRAINING - Epoch: [83][50/500]	Time 0.054 (0.058)	Data 0.000 (0.005)	Loss 0.1171 (0.0994)	Prec@1 95.000 (96.392)	Prec@5 100.000 (99.980)
2019-05-03 12:01:36 - INFO - TRAINING - Epoch: [83][100/500]	Time 0.046 (0.056)	Data 0.000 (0.003)	Loss 0.0461 (0.0914)	Prec@1 99.000 (96.802)	Prec@5 100.000 (99.990)
2019-05-03 12:01:38 - INFO - TRAINING - Epoch: [83][150/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.1798 (0.0922)	Prec@1 93.000 (96.821)	Prec@5 100.000 (99.993)
2019-05-03 12:01:41 - INFO - TRAINING - Epoch: [83][200/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.1379 (0.0919)	Prec@1 94.000 (96.871)	Prec@5 100.000 (99.995)
2019-05-03 12:01:44 - INFO - TRAINING - Epoch: [83][250/500]	Time 0.063 (0.055)	Data 0.000 (0.002)	Loss 0.2130 (0.0942)	Prec@1 94.000 (96.793)	Prec@5 100.000 (99.992)
2019-05-03 12:01:47 - INFO - TRAINING - Epoch: [83][300/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0375 (0.0931)	Prec@1 100.000 (96.877)	Prec@5 100.000 (99.993)
2019-05-03 12:01:49 - INFO - TRAINING - Epoch: [83][350/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.1403 (0.0935)	Prec@1 94.000 (96.877)	Prec@5 99.000 (99.986)
2019-05-03 12:01:52 - INFO - TRAINING - Epoch: [83][400/500]	Time 0.059 (0.055)	Data 0.000 (0.001)	Loss 0.1064 (0.0941)	Prec@1 97.000 (96.873)	Prec@5 100.000 (99.980)
2019-05-03 12:01:55 - INFO - TRAINING - Epoch: [83][450/500]	Time 0.057 (0.055)	Data 0.000 (0.001)	Loss 0.1040 (0.0954)	Prec@1 97.000 (96.834)	Prec@5 100.000 (99.980)
2019-05-03 12:01:58 - INFO - EVALUATING - Epoch: [83][0/100]	Time 0.380 (0.380)	Data 0.372 (0.372)	Loss 0.3273 (0.3273)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:01:59 - INFO - EVALUATING - Epoch: [83][50/100]	Time 0.018 (0.026)	Data 0.000 (0.008)	Loss 0.3004 (0.3566)	Prec@1 90.000 (90.137)	Prec@5 100.000 (99.647)
2019-05-03 12:02:00 - INFO - 
 Epoch: 84	Training Loss 0.0942 	Training Prec@1 96.872 	Training Prec@5 99.982 	Validation Loss 0.3499 	Validation Prec@1 90.030 	Validation Prec@5 99.680 	
2019-05-03 12:02:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:02:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:02:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:02:00 - INFO - TRAINING - Epoch: [84][0/500]	Time 0.284 (0.284)	Data 0.250 (0.250)	Loss 0.0807 (0.0807)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:02:03 - INFO - TRAINING - Epoch: [84][50/500]	Time 0.059 (0.058)	Data 0.000 (0.005)	Loss 0.0733 (0.0885)	Prec@1 97.000 (97.412)	Prec@5 100.000 (99.961)
2019-05-03 12:02:06 - INFO - TRAINING - Epoch: [84][100/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.0760 (0.0845)	Prec@1 98.000 (97.376)	Prec@5 100.000 (99.980)
2019-05-03 12:02:09 - INFO - TRAINING - Epoch: [84][150/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.1970 (0.0893)	Prec@1 94.000 (97.099)	Prec@5 100.000 (99.980)
2019-05-03 12:02:11 - INFO - TRAINING - Epoch: [84][200/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.1063 (0.0896)	Prec@1 96.000 (97.060)	Prec@5 100.000 (99.985)
2019-05-03 12:02:14 - INFO - TRAINING - Epoch: [84][250/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.1500 (0.0908)	Prec@1 92.000 (96.984)	Prec@5 100.000 (99.988)
2019-05-03 12:02:17 - INFO - TRAINING - Epoch: [84][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0911 (0.0906)	Prec@1 96.000 (96.953)	Prec@5 100.000 (99.990)
2019-05-03 12:02:19 - INFO - TRAINING - Epoch: [84][350/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.0737 (0.0908)	Prec@1 98.000 (96.934)	Prec@5 100.000 (99.989)
2019-05-03 12:02:22 - INFO - TRAINING - Epoch: [84][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0930 (0.0913)	Prec@1 97.000 (96.880)	Prec@5 100.000 (99.988)
2019-05-03 12:02:25 - INFO - TRAINING - Epoch: [84][450/500]	Time 0.043 (0.054)	Data 0.000 (0.001)	Loss 0.0906 (0.0919)	Prec@1 97.000 (96.831)	Prec@5 100.000 (99.987)
2019-05-03 12:02:28 - INFO - EVALUATING - Epoch: [84][0/100]	Time 0.363 (0.363)	Data 0.356 (0.356)	Loss 0.1913 (0.1913)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:02:29 - INFO - EVALUATING - Epoch: [84][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2483 (0.3647)	Prec@1 95.000 (89.510)	Prec@5 99.000 (99.529)
2019-05-03 12:02:30 - INFO - 
 Epoch: 85	Training Loss 0.0919 	Training Prec@1 96.824 	Training Prec@5 99.988 	Validation Loss 0.3536 	Validation Prec@1 89.820 	Validation Prec@5 99.630 	
2019-05-03 12:02:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:02:30 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:02:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:02:30 - INFO - TRAINING - Epoch: [85][0/500]	Time 0.297 (0.297)	Data 0.272 (0.272)	Loss 0.0452 (0.0452)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:02:33 - INFO - TRAINING - Epoch: [85][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.1273 (0.0900)	Prec@1 95.000 (96.765)	Prec@5 100.000 (99.980)
2019-05-03 12:02:36 - INFO - TRAINING - Epoch: [85][100/500]	Time 0.062 (0.059)	Data 0.000 (0.004)	Loss 0.1516 (0.0900)	Prec@1 94.000 (97.010)	Prec@5 100.000 (99.980)
2019-05-03 12:02:39 - INFO - TRAINING - Epoch: [85][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.1494 (0.0878)	Prec@1 95.000 (97.060)	Prec@5 100.000 (99.987)
2019-05-03 12:02:41 - INFO - TRAINING - Epoch: [85][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0587 (0.0899)	Prec@1 98.000 (96.990)	Prec@5 100.000 (99.990)
2019-05-03 12:02:44 - INFO - TRAINING - Epoch: [85][250/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0935 (0.0921)	Prec@1 98.000 (96.940)	Prec@5 100.000 (99.988)
2019-05-03 12:02:47 - INFO - TRAINING - Epoch: [85][300/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.0926 (0.0903)	Prec@1 97.000 (96.997)	Prec@5 100.000 (99.987)
2019-05-03 12:02:50 - INFO - TRAINING - Epoch: [85][350/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0607 (0.0905)	Prec@1 98.000 (96.969)	Prec@5 100.000 (99.986)
2019-05-03 12:02:53 - INFO - TRAINING - Epoch: [85][400/500]	Time 0.048 (0.057)	Data 0.000 (0.002)	Loss 0.0582 (0.0897)	Prec@1 98.000 (96.953)	Prec@5 100.000 (99.983)
2019-05-03 12:02:56 - INFO - TRAINING - Epoch: [85][450/500]	Time 0.051 (0.057)	Data 0.000 (0.002)	Loss 0.0376 (0.0889)	Prec@1 99.000 (96.960)	Prec@5 100.000 (99.984)
2019-05-03 12:02:59 - INFO - EVALUATING - Epoch: [85][0/100]	Time 0.384 (0.384)	Data 0.375 (0.375)	Loss 0.2512 (0.2512)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:03:00 - INFO - EVALUATING - Epoch: [85][50/100]	Time 0.022 (0.025)	Data 0.000 (0.008)	Loss 0.2765 (0.3719)	Prec@1 90.000 (89.922)	Prec@5 100.000 (99.647)
2019-05-03 12:03:01 - INFO - 
 Epoch: 86	Training Loss 0.0895 	Training Prec@1 96.932 	Training Prec@5 99.984 	Validation Loss 0.3558 	Validation Prec@1 90.160 	Validation Prec@5 99.710 	
2019-05-03 12:03:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:03:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:03:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:03:01 - INFO - TRAINING - Epoch: [86][0/500]	Time 0.282 (0.282)	Data 0.260 (0.260)	Loss 0.0634 (0.0634)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:03:04 - INFO - TRAINING - Epoch: [86][50/500]	Time 0.062 (0.061)	Data 0.000 (0.006)	Loss 0.0678 (0.0894)	Prec@1 98.000 (96.941)	Prec@5 100.000 (100.000)
2019-05-03 12:03:07 - INFO - TRAINING - Epoch: [86][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.1535 (0.0887)	Prec@1 94.000 (96.911)	Prec@5 100.000 (99.990)
2019-05-03 12:03:10 - INFO - TRAINING - Epoch: [86][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0935 (0.0913)	Prec@1 98.000 (96.934)	Prec@5 100.000 (99.987)
2019-05-03 12:03:12 - INFO - TRAINING - Epoch: [86][200/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.1066 (0.0919)	Prec@1 95.000 (96.876)	Prec@5 100.000 (99.985)
2019-05-03 12:03:15 - INFO - TRAINING - Epoch: [86][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0421 (0.0927)	Prec@1 99.000 (96.801)	Prec@5 100.000 (99.980)
2019-05-03 12:03:18 - INFO - TRAINING - Epoch: [86][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.1510 (0.0940)	Prec@1 94.000 (96.714)	Prec@5 100.000 (99.983)
2019-05-03 12:03:21 - INFO - TRAINING - Epoch: [86][350/500]	Time 0.071 (0.058)	Data 0.000 (0.002)	Loss 0.0749 (0.0938)	Prec@1 98.000 (96.726)	Prec@5 100.000 (99.986)
2019-05-03 12:03:24 - INFO - TRAINING - Epoch: [86][400/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0696 (0.0918)	Prec@1 98.000 (96.800)	Prec@5 100.000 (99.985)
2019-05-03 12:03:27 - INFO - TRAINING - Epoch: [86][450/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.0666 (0.0909)	Prec@1 97.000 (96.847)	Prec@5 100.000 (99.984)
2019-05-03 12:03:30 - INFO - EVALUATING - Epoch: [86][0/100]	Time 0.360 (0.360)	Data 0.349 (0.349)	Loss 0.2899 (0.2899)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:03:31 - INFO - EVALUATING - Epoch: [86][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2928 (0.3801)	Prec@1 91.000 (89.765)	Prec@5 100.000 (99.471)
2019-05-03 12:03:31 - INFO - 
 Epoch: 87	Training Loss 0.0907 	Training Prec@1 96.878 	Training Prec@5 99.986 	Validation Loss 0.3606 	Validation Prec@1 90.100 	Validation Prec@5 99.560 	
2019-05-03 12:03:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:03:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:03:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:03:32 - INFO - TRAINING - Epoch: [87][0/500]	Time 0.302 (0.302)	Data 0.277 (0.277)	Loss 0.0871 (0.0871)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:03:35 - INFO - TRAINING - Epoch: [87][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.0365 (0.0929)	Prec@1 98.000 (96.667)	Prec@5 100.000 (99.980)
2019-05-03 12:03:37 - INFO - TRAINING - Epoch: [87][100/500]	Time 0.053 (0.056)	Data 0.000 (0.004)	Loss 0.0613 (0.0852)	Prec@1 98.000 (97.010)	Prec@5 100.000 (99.990)
2019-05-03 12:03:40 - INFO - TRAINING - Epoch: [87][150/500]	Time 0.062 (0.055)	Data 0.000 (0.003)	Loss 0.0985 (0.0877)	Prec@1 96.000 (96.934)	Prec@5 100.000 (99.987)
2019-05-03 12:03:43 - INFO - TRAINING - Epoch: [87][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0588 (0.0887)	Prec@1 98.000 (96.866)	Prec@5 100.000 (99.990)
2019-05-03 12:03:45 - INFO - TRAINING - Epoch: [87][250/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.0560 (0.0890)	Prec@1 97.000 (96.857)	Prec@5 100.000 (99.992)
2019-05-03 12:03:48 - INFO - TRAINING - Epoch: [87][300/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.0578 (0.0870)	Prec@1 98.000 (96.944)	Prec@5 100.000 (99.993)
2019-05-03 12:03:51 - INFO - TRAINING - Epoch: [87][350/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.0365 (0.0872)	Prec@1 98.000 (96.952)	Prec@5 100.000 (99.994)
2019-05-03 12:03:53 - INFO - TRAINING - Epoch: [87][400/500]	Time 0.048 (0.054)	Data 0.000 (0.001)	Loss 0.0666 (0.0860)	Prec@1 97.000 (96.980)	Prec@5 100.000 (99.995)
2019-05-03 12:03:56 - INFO - TRAINING - Epoch: [87][450/500]	Time 0.037 (0.054)	Data 0.000 (0.001)	Loss 0.1237 (0.0865)	Prec@1 99.000 (96.978)	Prec@5 100.000 (99.993)
2019-05-03 12:03:59 - INFO - EVALUATING - Epoch: [87][0/100]	Time 0.372 (0.372)	Data 0.362 (0.362)	Loss 0.3033 (0.3033)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:04:00 - INFO - EVALUATING - Epoch: [87][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3574 (0.3769)	Prec@1 87.000 (89.157)	Prec@5 100.000 (99.588)
2019-05-03 12:04:01 - INFO - 
 Epoch: 88	Training Loss 0.0868 	Training Prec@1 96.976 	Training Prec@5 99.994 	Validation Loss 0.3656 	Validation Prec@1 89.150 	Validation Prec@5 99.640 	
2019-05-03 12:04:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:04:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:04:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:04:01 - INFO - TRAINING - Epoch: [88][0/500]	Time 0.292 (0.292)	Data 0.266 (0.266)	Loss 0.0735 (0.0735)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:04:04 - INFO - TRAINING - Epoch: [88][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.1557 (0.0879)	Prec@1 96.000 (97.137)	Prec@5 99.000 (99.961)
2019-05-03 12:04:07 - INFO - TRAINING - Epoch: [88][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.0318 (0.0893)	Prec@1 99.000 (97.079)	Prec@5 100.000 (99.960)
2019-05-03 12:04:10 - INFO - TRAINING - Epoch: [88][150/500]	Time 0.065 (0.058)	Data 0.000 (0.003)	Loss 0.0537 (0.0853)	Prec@1 99.000 (97.245)	Prec@5 100.000 (99.974)
2019-05-03 12:04:13 - INFO - TRAINING - Epoch: [88][200/500]	Time 0.067 (0.058)	Data 0.000 (0.002)	Loss 0.2050 (0.0861)	Prec@1 96.000 (97.219)	Prec@5 100.000 (99.980)
2019-05-03 12:04:15 - INFO - TRAINING - Epoch: [88][250/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.1569 (0.0869)	Prec@1 96.000 (97.104)	Prec@5 100.000 (99.980)
2019-05-03 12:04:18 - INFO - TRAINING - Epoch: [88][300/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0378 (0.0860)	Prec@1 99.000 (97.100)	Prec@5 100.000 (99.983)
2019-05-03 12:04:21 - INFO - TRAINING - Epoch: [88][350/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0525 (0.0859)	Prec@1 97.000 (97.071)	Prec@5 100.000 (99.986)
2019-05-03 12:04:24 - INFO - TRAINING - Epoch: [88][400/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0870 (0.0846)	Prec@1 96.000 (97.135)	Prec@5 100.000 (99.985)
2019-05-03 12:04:27 - INFO - TRAINING - Epoch: [88][450/500]	Time 0.059 (0.057)	Data 0.000 (0.001)	Loss 0.0286 (0.0843)	Prec@1 99.000 (97.155)	Prec@5 100.000 (99.984)
2019-05-03 12:04:30 - INFO - EVALUATING - Epoch: [88][0/100]	Time 0.364 (0.364)	Data 0.348 (0.348)	Loss 0.2277 (0.2277)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 12:04:31 - INFO - EVALUATING - Epoch: [88][50/100]	Time 0.024 (0.025)	Data 0.000 (0.007)	Loss 0.2275 (0.3691)	Prec@1 93.000 (89.784)	Prec@5 100.000 (99.608)
2019-05-03 12:04:32 - INFO - 
 Epoch: 89	Training Loss 0.0842 	Training Prec@1 97.164 	Training Prec@5 99.984 	Validation Loss 0.3551 	Validation Prec@1 89.860 	Validation Prec@5 99.550 	
2019-05-03 12:04:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:04:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:04:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:04:32 - INFO - TRAINING - Epoch: [89][0/500]	Time 0.273 (0.273)	Data 0.250 (0.250)	Loss 0.1212 (0.1212)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:04:35 - INFO - TRAINING - Epoch: [89][50/500]	Time 0.053 (0.059)	Data 0.000 (0.006)	Loss 0.0244 (0.0814)	Prec@1 100.000 (97.412)	Prec@5 100.000 (100.000)
2019-05-03 12:04:37 - INFO - TRAINING - Epoch: [89][100/500]	Time 0.052 (0.056)	Data 0.000 (0.003)	Loss 0.1619 (0.0852)	Prec@1 94.000 (97.228)	Prec@5 100.000 (99.990)
2019-05-03 12:04:40 - INFO - TRAINING - Epoch: [89][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0610 (0.0806)	Prec@1 98.000 (97.331)	Prec@5 100.000 (99.993)
2019-05-03 12:04:43 - INFO - TRAINING - Epoch: [89][200/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.1036 (0.0812)	Prec@1 97.000 (97.338)	Prec@5 100.000 (99.990)
2019-05-03 12:04:45 - INFO - TRAINING - Epoch: [89][250/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.0676 (0.0810)	Prec@1 97.000 (97.307)	Prec@5 100.000 (99.992)
2019-05-03 12:04:48 - INFO - TRAINING - Epoch: [89][300/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.1910 (0.0816)	Prec@1 93.000 (97.299)	Prec@5 100.000 (99.993)
2019-05-03 12:04:51 - INFO - TRAINING - Epoch: [89][350/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.1177 (0.0835)	Prec@1 97.000 (97.225)	Prec@5 100.000 (99.994)
2019-05-03 12:04:54 - INFO - TRAINING - Epoch: [89][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0722 (0.0834)	Prec@1 97.000 (97.219)	Prec@5 100.000 (99.995)
2019-05-03 12:04:56 - INFO - TRAINING - Epoch: [89][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0699 (0.0827)	Prec@1 97.000 (97.231)	Prec@5 100.000 (99.996)
2019-05-03 12:04:59 - INFO - EVALUATING - Epoch: [89][0/100]	Time 0.351 (0.351)	Data 0.344 (0.344)	Loss 0.3107 (0.3107)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:05:00 - INFO - EVALUATING - Epoch: [89][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.2711 (0.3624)	Prec@1 92.000 (90.000)	Prec@5 100.000 (99.569)
2019-05-03 12:05:01 - INFO - 
 Epoch: 90	Training Loss 0.0830 	Training Prec@1 97.226 	Training Prec@5 99.994 	Validation Loss 0.3449 	Validation Prec@1 90.380 	Validation Prec@5 99.650 	
2019-05-03 12:05:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:05:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:05:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:05:02 - INFO - TRAINING - Epoch: [90][0/500]	Time 0.268 (0.268)	Data 0.243 (0.243)	Loss 0.0847 (0.0847)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:05:05 - INFO - TRAINING - Epoch: [90][50/500]	Time 0.056 (0.061)	Data 0.000 (0.006)	Loss 0.1404 (0.0737)	Prec@1 96.000 (97.529)	Prec@5 100.000 (100.000)
2019-05-03 12:05:07 - INFO - TRAINING - Epoch: [90][100/500]	Time 0.062 (0.059)	Data 0.000 (0.003)	Loss 0.1006 (0.0764)	Prec@1 97.000 (97.327)	Prec@5 100.000 (100.000)
2019-05-03 12:05:10 - INFO - TRAINING - Epoch: [90][150/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0387 (0.0784)	Prec@1 99.000 (97.371)	Prec@5 100.000 (99.993)
2019-05-03 12:05:13 - INFO - TRAINING - Epoch: [90][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0818 (0.0793)	Prec@1 97.000 (97.318)	Prec@5 100.000 (99.990)
2019-05-03 12:05:16 - INFO - TRAINING - Epoch: [90][250/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0093 (0.0794)	Prec@1 100.000 (97.319)	Prec@5 100.000 (99.988)
2019-05-03 12:05:19 - INFO - TRAINING - Epoch: [90][300/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0862 (0.0803)	Prec@1 97.000 (97.299)	Prec@5 100.000 (99.987)
2019-05-03 12:05:22 - INFO - TRAINING - Epoch: [90][350/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.1942 (0.0806)	Prec@1 93.000 (97.268)	Prec@5 100.000 (99.986)
2019-05-03 12:05:24 - INFO - TRAINING - Epoch: [90][400/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0634 (0.0792)	Prec@1 97.000 (97.324)	Prec@5 100.000 (99.985)
2019-05-03 12:05:27 - INFO - TRAINING - Epoch: [90][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0497 (0.0791)	Prec@1 98.000 (97.330)	Prec@5 100.000 (99.987)
2019-05-03 12:05:30 - INFO - EVALUATING - Epoch: [90][0/100]	Time 0.336 (0.336)	Data 0.320 (0.320)	Loss 0.3073 (0.3073)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:05:31 - INFO - EVALUATING - Epoch: [90][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.3044 (0.3630)	Prec@1 91.000 (90.098)	Prec@5 100.000 (99.431)
2019-05-03 12:05:32 - INFO - 
 Epoch: 91	Training Loss 0.0794 	Training Prec@1 97.316 	Training Prec@5 99.988 	Validation Loss 0.3551 	Validation Prec@1 90.030 	Validation Prec@5 99.570 	
2019-05-03 12:05:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:05:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:05:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:05:33 - INFO - TRAINING - Epoch: [91][0/500]	Time 0.307 (0.307)	Data 0.277 (0.277)	Loss 0.1209 (0.1209)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:05:35 - INFO - TRAINING - Epoch: [91][50/500]	Time 0.053 (0.061)	Data 0.000 (0.006)	Loss 0.0672 (0.0769)	Prec@1 97.000 (97.549)	Prec@5 100.000 (100.000)
2019-05-03 12:05:38 - INFO - TRAINING - Epoch: [91][100/500]	Time 0.060 (0.059)	Data 0.000 (0.004)	Loss 0.0157 (0.0727)	Prec@1 100.000 (97.644)	Prec@5 100.000 (99.990)
2019-05-03 12:05:41 - INFO - TRAINING - Epoch: [91][150/500]	Time 0.051 (0.058)	Data 0.000 (0.003)	Loss 0.0944 (0.0721)	Prec@1 97.000 (97.616)	Prec@5 100.000 (99.993)
2019-05-03 12:05:44 - INFO - TRAINING - Epoch: [91][200/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0309 (0.0729)	Prec@1 99.000 (97.577)	Prec@5 100.000 (99.995)
2019-05-03 12:05:47 - INFO - TRAINING - Epoch: [91][250/500]	Time 0.067 (0.057)	Data 0.000 (0.002)	Loss 0.1040 (0.0718)	Prec@1 96.000 (97.610)	Prec@5 100.000 (99.996)
2019-05-03 12:05:49 - INFO - TRAINING - Epoch: [91][300/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.1644 (0.0739)	Prec@1 95.000 (97.551)	Prec@5 100.000 (99.990)
2019-05-03 12:05:52 - INFO - TRAINING - Epoch: [91][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0784 (0.0744)	Prec@1 98.000 (97.538)	Prec@5 100.000 (99.989)
2019-05-03 12:05:55 - INFO - TRAINING - Epoch: [91][400/500]	Time 0.049 (0.056)	Data 0.000 (0.002)	Loss 0.0734 (0.0737)	Prec@1 98.000 (97.541)	Prec@5 100.000 (99.988)
2019-05-03 12:05:58 - INFO - TRAINING - Epoch: [91][450/500]	Time 0.042 (0.056)	Data 0.000 (0.001)	Loss 0.0812 (0.0730)	Prec@1 97.000 (97.554)	Prec@5 100.000 (99.989)
2019-05-03 12:06:01 - INFO - EVALUATING - Epoch: [91][0/100]	Time 0.347 (0.347)	Data 0.333 (0.333)	Loss 0.2730 (0.2730)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:06:02 - INFO - EVALUATING - Epoch: [91][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.2625 (0.3657)	Prec@1 91.000 (90.333)	Prec@5 100.000 (99.569)
2019-05-03 12:06:02 - INFO - 
 Epoch: 92	Training Loss 0.0723 	Training Prec@1 97.578 	Training Prec@5 99.990 	Validation Loss 0.3467 	Validation Prec@1 90.310 	Validation Prec@5 99.620 	
2019-05-03 12:06:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:06:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:06:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:06:03 - INFO - TRAINING - Epoch: [92][0/500]	Time 0.296 (0.296)	Data 0.272 (0.272)	Loss 0.0196 (0.0196)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:06:06 - INFO - TRAINING - Epoch: [92][50/500]	Time 0.056 (0.058)	Data 0.000 (0.006)	Loss 0.0676 (0.0786)	Prec@1 96.000 (97.569)	Prec@5 100.000 (99.980)
2019-05-03 12:06:08 - INFO - TRAINING - Epoch: [92][100/500]	Time 0.069 (0.056)	Data 0.000 (0.003)	Loss 0.0521 (0.0696)	Prec@1 98.000 (97.733)	Prec@5 100.000 (99.990)
2019-05-03 12:06:11 - INFO - TRAINING - Epoch: [92][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0806 (0.0732)	Prec@1 97.000 (97.583)	Prec@5 100.000 (99.993)
2019-05-03 12:06:14 - INFO - TRAINING - Epoch: [92][200/500]	Time 0.064 (0.055)	Data 0.000 (0.002)	Loss 0.1466 (0.0738)	Prec@1 97.000 (97.562)	Prec@5 100.000 (99.990)
2019-05-03 12:06:16 - INFO - TRAINING - Epoch: [92][250/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0976 (0.0737)	Prec@1 95.000 (97.522)	Prec@5 100.000 (99.992)
2019-05-03 12:06:19 - INFO - TRAINING - Epoch: [92][300/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0604 (0.0725)	Prec@1 99.000 (97.565)	Prec@5 100.000 (99.993)
2019-05-03 12:06:22 - INFO - TRAINING - Epoch: [92][350/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.1086 (0.0737)	Prec@1 97.000 (97.567)	Prec@5 100.000 (99.994)
2019-05-03 12:06:24 - INFO - TRAINING - Epoch: [92][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0981 (0.0739)	Prec@1 96.000 (97.571)	Prec@5 100.000 (99.993)
2019-05-03 12:06:27 - INFO - TRAINING - Epoch: [92][450/500]	Time 0.051 (0.054)	Data 0.000 (0.001)	Loss 0.0707 (0.0749)	Prec@1 98.000 (97.521)	Prec@5 100.000 (99.993)
2019-05-03 12:06:30 - INFO - EVALUATING - Epoch: [92][0/100]	Time 0.269 (0.269)	Data 0.261 (0.261)	Loss 0.3129 (0.3129)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:06:31 - INFO - EVALUATING - Epoch: [92][50/100]	Time 0.012 (0.023)	Data 0.000 (0.005)	Loss 0.3058 (0.3637)	Prec@1 91.000 (90.529)	Prec@5 99.000 (99.608)
2019-05-03 12:06:32 - INFO - 
 Epoch: 93	Training Loss 0.0755 	Training Prec@1 97.502 	Training Prec@5 99.994 	Validation Loss 0.3524 	Validation Prec@1 90.580 	Validation Prec@5 99.610 	
2019-05-03 12:06:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:06:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:06:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:06:32 - INFO - TRAINING - Epoch: [93][0/500]	Time 0.283 (0.283)	Data 0.255 (0.255)	Loss 0.0454 (0.0454)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:06:35 - INFO - TRAINING - Epoch: [93][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.0536 (0.0779)	Prec@1 99.000 (97.353)	Prec@5 100.000 (100.000)
2019-05-03 12:06:37 - INFO - TRAINING - Epoch: [93][100/500]	Time 0.064 (0.056)	Data 0.000 (0.003)	Loss 0.1278 (0.0781)	Prec@1 96.000 (97.218)	Prec@5 100.000 (100.000)
2019-05-03 12:06:40 - INFO - TRAINING - Epoch: [93][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0455 (0.0752)	Prec@1 98.000 (97.331)	Prec@5 100.000 (100.000)
2019-05-03 12:06:43 - INFO - TRAINING - Epoch: [93][200/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.1155 (0.0757)	Prec@1 95.000 (97.343)	Prec@5 100.000 (99.995)
2019-05-03 12:06:45 - INFO - TRAINING - Epoch: [93][250/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.0375 (0.0748)	Prec@1 97.000 (97.390)	Prec@5 100.000 (99.992)
2019-05-03 12:06:48 - INFO - TRAINING - Epoch: [93][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0642 (0.0745)	Prec@1 97.000 (97.399)	Prec@5 100.000 (99.990)
2019-05-03 12:06:51 - INFO - TRAINING - Epoch: [93][350/500]	Time 0.064 (0.054)	Data 0.000 (0.002)	Loss 0.0543 (0.0743)	Prec@1 98.000 (97.413)	Prec@5 100.000 (99.991)
2019-05-03 12:06:53 - INFO - TRAINING - Epoch: [93][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0268 (0.0756)	Prec@1 99.000 (97.369)	Prec@5 100.000 (99.993)
2019-05-03 12:06:56 - INFO - TRAINING - Epoch: [93][450/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.0975 (0.0752)	Prec@1 96.000 (97.379)	Prec@5 100.000 (99.993)
2019-05-03 12:06:59 - INFO - EVALUATING - Epoch: [93][0/100]	Time 0.351 (0.351)	Data 0.342 (0.342)	Loss 0.2661 (0.2661)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:07:00 - INFO - EVALUATING - Epoch: [93][50/100]	Time 0.021 (0.025)	Data 0.000 (0.007)	Loss 0.3048 (0.3641)	Prec@1 90.000 (90.490)	Prec@5 100.000 (99.627)
2019-05-03 12:07:01 - INFO - 
 Epoch: 94	Training Loss 0.0762 	Training Prec@1 97.362 	Training Prec@5 99.992 	Validation Loss 0.3493 	Validation Prec@1 90.540 	Validation Prec@5 99.660 	
2019-05-03 12:07:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:07:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:07:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:07:01 - INFO - TRAINING - Epoch: [94][0/500]	Time 0.319 (0.319)	Data 0.289 (0.289)	Loss 0.0953 (0.0953)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:07:04 - INFO - TRAINING - Epoch: [94][50/500]	Time 0.051 (0.061)	Data 0.000 (0.006)	Loss 0.0567 (0.0688)	Prec@1 97.000 (97.627)	Prec@5 100.000 (99.980)
2019-05-03 12:07:07 - INFO - TRAINING - Epoch: [94][100/500]	Time 0.064 (0.058)	Data 0.000 (0.004)	Loss 0.0498 (0.0696)	Prec@1 98.000 (97.505)	Prec@5 100.000 (99.990)
2019-05-03 12:07:10 - INFO - TRAINING - Epoch: [94][150/500]	Time 0.051 (0.057)	Data 0.000 (0.003)	Loss 0.1265 (0.0697)	Prec@1 96.000 (97.510)	Prec@5 100.000 (99.987)
2019-05-03 12:07:13 - INFO - TRAINING - Epoch: [94][200/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0687 (0.0691)	Prec@1 98.000 (97.552)	Prec@5 100.000 (99.990)
2019-05-03 12:07:15 - INFO - TRAINING - Epoch: [94][250/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.0728 (0.0691)	Prec@1 98.000 (97.582)	Prec@5 100.000 (99.992)
2019-05-03 12:07:18 - INFO - TRAINING - Epoch: [94][300/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0563 (0.0703)	Prec@1 99.000 (97.551)	Prec@5 100.000 (99.993)
2019-05-03 12:07:21 - INFO - TRAINING - Epoch: [94][350/500]	Time 0.070 (0.057)	Data 0.000 (0.002)	Loss 0.0089 (0.0701)	Prec@1 100.000 (97.576)	Prec@5 100.000 (99.994)
2019-05-03 12:07:24 - INFO - TRAINING - Epoch: [94][400/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0901 (0.0708)	Prec@1 95.000 (97.544)	Prec@5 100.000 (99.995)
2019-05-03 12:07:27 - INFO - TRAINING - Epoch: [94][450/500]	Time 0.064 (0.057)	Data 0.000 (0.002)	Loss 0.0506 (0.0725)	Prec@1 98.000 (97.501)	Prec@5 100.000 (99.996)
2019-05-03 12:07:30 - INFO - EVALUATING - Epoch: [94][0/100]	Time 0.257 (0.257)	Data 0.250 (0.250)	Loss 0.1982 (0.1982)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:07:31 - INFO - EVALUATING - Epoch: [94][50/100]	Time 0.019 (0.023)	Data 0.000 (0.005)	Loss 0.1846 (0.3473)	Prec@1 95.000 (90.843)	Prec@5 100.000 (99.608)
2019-05-03 12:07:32 - INFO - 
 Epoch: 95	Training Loss 0.0723 	Training Prec@1 97.520 	Training Prec@5 99.994 	Validation Loss 0.3395 	Validation Prec@1 90.710 	Validation Prec@5 99.600 	
2019-05-03 12:07:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:07:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:07:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:07:32 - INFO - TRAINING - Epoch: [95][0/500]	Time 0.282 (0.282)	Data 0.247 (0.247)	Loss 0.1117 (0.1117)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:07:35 - INFO - TRAINING - Epoch: [95][50/500]	Time 0.046 (0.059)	Data 0.000 (0.005)	Loss 0.0918 (0.0627)	Prec@1 97.000 (97.922)	Prec@5 100.000 (100.000)
2019-05-03 12:07:38 - INFO - TRAINING - Epoch: [95][100/500]	Time 0.059 (0.057)	Data 0.000 (0.003)	Loss 0.0272 (0.0664)	Prec@1 99.000 (97.812)	Prec@5 100.000 (100.000)
2019-05-03 12:07:40 - INFO - TRAINING - Epoch: [95][150/500]	Time 0.059 (0.057)	Data 0.000 (0.002)	Loss 0.0650 (0.0673)	Prec@1 99.000 (97.788)	Prec@5 100.000 (99.993)
2019-05-03 12:07:43 - INFO - TRAINING - Epoch: [95][200/500]	Time 0.050 (0.056)	Data 0.000 (0.002)	Loss 0.0188 (0.0663)	Prec@1 100.000 (97.826)	Prec@5 100.000 (99.985)
2019-05-03 12:07:46 - INFO - TRAINING - Epoch: [95][250/500]	Time 0.056 (0.056)	Data 0.000 (0.002)	Loss 0.0195 (0.0664)	Prec@1 99.000 (97.809)	Prec@5 100.000 (99.988)
2019-05-03 12:07:49 - INFO - TRAINING - Epoch: [95][300/500]	Time 0.055 (0.056)	Data 0.000 (0.002)	Loss 0.1314 (0.0671)	Prec@1 95.000 (97.764)	Prec@5 100.000 (99.990)
2019-05-03 12:07:52 - INFO - TRAINING - Epoch: [95][350/500]	Time 0.061 (0.056)	Data 0.000 (0.002)	Loss 0.0538 (0.0682)	Prec@1 97.000 (97.707)	Prec@5 100.000 (99.991)
2019-05-03 12:07:54 - INFO - TRAINING - Epoch: [95][400/500]	Time 0.058 (0.056)	Data 0.000 (0.002)	Loss 0.0730 (0.0694)	Prec@1 97.000 (97.643)	Prec@5 100.000 (99.990)
2019-05-03 12:07:57 - INFO - TRAINING - Epoch: [95][450/500]	Time 0.066 (0.056)	Data 0.000 (0.001)	Loss 0.0730 (0.0702)	Prec@1 97.000 (97.612)	Prec@5 100.000 (99.991)
2019-05-03 12:08:00 - INFO - EVALUATING - Epoch: [95][0/100]	Time 0.367 (0.367)	Data 0.357 (0.357)	Loss 0.2042 (0.2042)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:08:01 - INFO - EVALUATING - Epoch: [95][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.2082 (0.3523)	Prec@1 94.000 (90.431)	Prec@5 99.000 (99.588)
2019-05-03 12:08:02 - INFO - 
 Epoch: 96	Training Loss 0.0710 	Training Prec@1 97.574 	Training Prec@5 99.990 	Validation Loss 0.3466 	Validation Prec@1 90.610 	Validation Prec@5 99.650 	
2019-05-03 12:08:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:08:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:08:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:08:03 - INFO - TRAINING - Epoch: [96][0/500]	Time 0.302 (0.302)	Data 0.277 (0.277)	Loss 0.0567 (0.0567)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:08:05 - INFO - TRAINING - Epoch: [96][50/500]	Time 0.060 (0.060)	Data 0.000 (0.006)	Loss 0.1400 (0.0716)	Prec@1 95.000 (97.569)	Prec@5 100.000 (99.980)
2019-05-03 12:08:08 - INFO - TRAINING - Epoch: [96][100/500]	Time 0.058 (0.057)	Data 0.000 (0.003)	Loss 0.0237 (0.0684)	Prec@1 100.000 (97.594)	Prec@5 100.000 (99.990)
2019-05-03 12:08:11 - INFO - TRAINING - Epoch: [96][150/500]	Time 0.065 (0.056)	Data 0.000 (0.003)	Loss 0.0512 (0.0658)	Prec@1 99.000 (97.675)	Prec@5 100.000 (99.993)
2019-05-03 12:08:14 - INFO - TRAINING - Epoch: [96][200/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0425 (0.0670)	Prec@1 98.000 (97.562)	Prec@5 100.000 (99.995)
2019-05-03 12:08:16 - INFO - TRAINING - Epoch: [96][250/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.1052 (0.0681)	Prec@1 97.000 (97.570)	Prec@5 100.000 (99.996)
2019-05-03 12:08:19 - INFO - TRAINING - Epoch: [96][300/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0279 (0.0682)	Prec@1 98.000 (97.578)	Prec@5 100.000 (99.997)
2019-05-03 12:08:22 - INFO - TRAINING - Epoch: [96][350/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0772 (0.0682)	Prec@1 97.000 (97.615)	Prec@5 100.000 (99.997)
2019-05-03 12:08:24 - INFO - TRAINING - Epoch: [96][400/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 0.0380 (0.0688)	Prec@1 99.000 (97.626)	Prec@5 100.000 (99.998)
2019-05-03 12:08:27 - INFO - TRAINING - Epoch: [96][450/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.0308 (0.0689)	Prec@1 98.000 (97.645)	Prec@5 100.000 (99.998)
2019-05-03 12:08:30 - INFO - EVALUATING - Epoch: [96][0/100]	Time 0.381 (0.381)	Data 0.369 (0.369)	Loss 0.2453 (0.2453)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:08:31 - INFO - EVALUATING - Epoch: [96][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.1145 (0.3828)	Prec@1 97.000 (90.078)	Prec@5 100.000 (99.647)
2019-05-03 12:08:32 - INFO - 
 Epoch: 97	Training Loss 0.0690 	Training Prec@1 97.636 	Training Prec@5 99.998 	Validation Loss 0.3705 	Validation Prec@1 90.190 	Validation Prec@5 99.660 	
2019-05-03 12:08:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:08:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:08:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:08:32 - INFO - TRAINING - Epoch: [97][0/500]	Time 0.281 (0.281)	Data 0.254 (0.254)	Loss 0.1440 (0.1440)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:08:35 - INFO - TRAINING - Epoch: [97][50/500]	Time 0.055 (0.059)	Data 0.000 (0.006)	Loss 0.0237 (0.0660)	Prec@1 100.000 (97.686)	Prec@5 100.000 (100.000)
2019-05-03 12:08:37 - INFO - TRAINING - Epoch: [97][100/500]	Time 0.047 (0.056)	Data 0.000 (0.003)	Loss 0.0206 (0.0613)	Prec@1 100.000 (97.842)	Prec@5 100.000 (99.990)
2019-05-03 12:08:40 - INFO - TRAINING - Epoch: [97][150/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0916 (0.0654)	Prec@1 97.000 (97.775)	Prec@5 100.000 (99.987)
2019-05-03 12:08:43 - INFO - TRAINING - Epoch: [97][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0135 (0.0630)	Prec@1 100.000 (97.836)	Prec@5 100.000 (99.990)
2019-05-03 12:08:46 - INFO - TRAINING - Epoch: [97][250/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0631 (0.0621)	Prec@1 98.000 (97.861)	Prec@5 100.000 (99.992)
2019-05-03 12:08:48 - INFO - TRAINING - Epoch: [97][300/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.1736 (0.0632)	Prec@1 94.000 (97.801)	Prec@5 100.000 (99.990)
2019-05-03 12:08:51 - INFO - TRAINING - Epoch: [97][350/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0439 (0.0641)	Prec@1 98.000 (97.772)	Prec@5 100.000 (99.991)
2019-05-03 12:08:54 - INFO - TRAINING - Epoch: [97][400/500]	Time 0.062 (0.055)	Data 0.000 (0.001)	Loss 0.1172 (0.0641)	Prec@1 95.000 (97.751)	Prec@5 100.000 (99.993)
2019-05-03 12:08:56 - INFO - TRAINING - Epoch: [97][450/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.1944 (0.0653)	Prec@1 95.000 (97.705)	Prec@5 100.000 (99.993)
2019-05-03 12:08:59 - INFO - EVALUATING - Epoch: [97][0/100]	Time 0.363 (0.363)	Data 0.347 (0.347)	Loss 0.2108 (0.2108)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:09:00 - INFO - EVALUATING - Epoch: [97][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1988 (0.3565)	Prec@1 95.000 (90.412)	Prec@5 100.000 (99.686)
2019-05-03 12:09:01 - INFO - 
 Epoch: 98	Training Loss 0.0654 	Training Prec@1 97.694 	Training Prec@5 99.994 	Validation Loss 0.3499 	Validation Prec@1 90.630 	Validation Prec@5 99.680 	
2019-05-03 12:09:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:09:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:09:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:09:02 - INFO - TRAINING - Epoch: [98][0/500]	Time 0.265 (0.265)	Data 0.237 (0.237)	Loss 0.0422 (0.0422)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:09:04 - INFO - TRAINING - Epoch: [98][50/500]	Time 0.048 (0.058)	Data 0.000 (0.005)	Loss 0.0331 (0.0591)	Prec@1 99.000 (97.922)	Prec@5 100.000 (99.980)
2019-05-03 12:09:07 - INFO - TRAINING - Epoch: [98][100/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.0381 (0.0615)	Prec@1 98.000 (97.832)	Prec@5 100.000 (99.990)
2019-05-03 12:09:10 - INFO - TRAINING - Epoch: [98][150/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.0588 (0.0606)	Prec@1 98.000 (97.881)	Prec@5 100.000 (99.993)
2019-05-03 12:09:12 - INFO - TRAINING - Epoch: [98][200/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.1485 (0.0610)	Prec@1 94.000 (97.876)	Prec@5 100.000 (99.995)
2019-05-03 12:09:15 - INFO - TRAINING - Epoch: [98][250/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.0618 (0.0614)	Prec@1 96.000 (97.857)	Prec@5 100.000 (99.996)
2019-05-03 12:09:18 - INFO - TRAINING - Epoch: [98][300/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0967 (0.0624)	Prec@1 94.000 (97.834)	Prec@5 100.000 (99.993)
2019-05-03 12:09:21 - INFO - TRAINING - Epoch: [98][350/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.1047 (0.0648)	Prec@1 97.000 (97.761)	Prec@5 100.000 (99.991)
2019-05-03 12:09:23 - INFO - TRAINING - Epoch: [98][400/500]	Time 0.046 (0.055)	Data 0.000 (0.001)	Loss 0.0412 (0.0653)	Prec@1 99.000 (97.743)	Prec@5 100.000 (99.990)
2019-05-03 12:09:26 - INFO - TRAINING - Epoch: [98][450/500]	Time 0.055 (0.055)	Data 0.000 (0.001)	Loss 0.0144 (0.0654)	Prec@1 100.000 (97.727)	Prec@5 100.000 (99.991)
2019-05-03 12:09:29 - INFO - EVALUATING - Epoch: [98][0/100]	Time 0.281 (0.281)	Data 0.264 (0.264)	Loss 0.2002 (0.2002)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:09:30 - INFO - EVALUATING - Epoch: [98][50/100]	Time 0.020 (0.023)	Data 0.000 (0.005)	Loss 0.2519 (0.3501)	Prec@1 95.000 (90.725)	Prec@5 100.000 (99.569)
2019-05-03 12:09:31 - INFO - 
 Epoch: 99	Training Loss 0.0658 	Training Prec@1 97.704 	Training Prec@5 99.990 	Validation Loss 0.3495 	Validation Prec@1 90.460 	Validation Prec@5 99.650 	
2019-05-03 12:09:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:09:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:09:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:09:31 - INFO - TRAINING - Epoch: [99][0/500]	Time 0.310 (0.310)	Data 0.282 (0.282)	Loss 0.0387 (0.0387)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:09:34 - INFO - TRAINING - Epoch: [99][50/500]	Time 0.056 (0.062)	Data 0.000 (0.006)	Loss 0.0939 (0.0596)	Prec@1 97.000 (97.784)	Prec@5 100.000 (100.000)
2019-05-03 12:09:37 - INFO - TRAINING - Epoch: [99][100/500]	Time 0.062 (0.059)	Data 0.000 (0.004)	Loss 0.0169 (0.0602)	Prec@1 99.000 (97.851)	Prec@5 100.000 (100.000)
2019-05-03 12:09:40 - INFO - TRAINING - Epoch: [99][150/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.1568 (0.0623)	Prec@1 94.000 (97.788)	Prec@5 100.000 (99.993)
2019-05-03 12:09:43 - INFO - TRAINING - Epoch: [99][200/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.0856 (0.0648)	Prec@1 97.000 (97.731)	Prec@5 100.000 (99.995)
2019-05-03 12:09:46 - INFO - TRAINING - Epoch: [99][250/500]	Time 0.047 (0.058)	Data 0.000 (0.002)	Loss 0.0445 (0.0644)	Prec@1 99.000 (97.789)	Prec@5 100.000 (99.996)
2019-05-03 12:09:48 - INFO - TRAINING - Epoch: [99][300/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.1039 (0.0653)	Prec@1 97.000 (97.761)	Prec@5 100.000 (99.997)
2019-05-03 12:09:51 - INFO - TRAINING - Epoch: [99][350/500]	Time 0.046 (0.058)	Data 0.000 (0.002)	Loss 0.0899 (0.0663)	Prec@1 97.000 (97.724)	Prec@5 100.000 (99.997)
2019-05-03 12:09:54 - INFO - TRAINING - Epoch: [99][400/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.1693 (0.0663)	Prec@1 95.000 (97.726)	Prec@5 100.000 (99.995)
2019-05-03 12:09:57 - INFO - TRAINING - Epoch: [99][450/500]	Time 0.054 (0.058)	Data 0.000 (0.001)	Loss 0.0286 (0.0669)	Prec@1 99.000 (97.712)	Prec@5 100.000 (99.991)
2019-05-03 12:10:00 - INFO - EVALUATING - Epoch: [99][0/100]	Time 0.359 (0.359)	Data 0.348 (0.348)	Loss 0.1386 (0.1386)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:10:01 - INFO - EVALUATING - Epoch: [99][50/100]	Time 0.011 (0.025)	Data 0.000 (0.007)	Loss 0.0875 (0.3553)	Prec@1 97.000 (90.569)	Prec@5 100.000 (99.627)
2019-05-03 12:10:02 - INFO - 
 Epoch: 100	Training Loss 0.0672 	Training Prec@1 97.702 	Training Prec@5 99.988 	Validation Loss 0.3460 	Validation Prec@1 90.750 	Validation Prec@5 99.640 	
2019-05-03 12:10:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:10:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:10:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:10:02 - INFO - TRAINING - Epoch: [100][0/500]	Time 0.270 (0.270)	Data 0.232 (0.232)	Loss 0.0500 (0.0500)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:10:05 - INFO - TRAINING - Epoch: [100][50/500]	Time 0.054 (0.057)	Data 0.000 (0.005)	Loss 0.0297 (0.0580)	Prec@1 100.000 (97.843)	Prec@5 100.000 (100.000)
2019-05-03 12:10:08 - INFO - TRAINING - Epoch: [100][100/500]	Time 0.049 (0.056)	Data 0.000 (0.003)	Loss 0.0473 (0.0597)	Prec@1 98.000 (97.861)	Prec@5 100.000 (100.000)
2019-05-03 12:10:11 - INFO - TRAINING - Epoch: [100][150/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.1283 (0.0604)	Prec@1 97.000 (97.934)	Prec@5 100.000 (100.000)
2019-05-03 12:10:13 - INFO - TRAINING - Epoch: [100][200/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.0399 (0.0598)	Prec@1 99.000 (97.975)	Prec@5 100.000 (100.000)
2019-05-03 12:10:16 - INFO - TRAINING - Epoch: [100][250/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0810 (0.0615)	Prec@1 95.000 (97.892)	Prec@5 100.000 (100.000)
2019-05-03 12:10:19 - INFO - TRAINING - Epoch: [100][300/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.1434 (0.0622)	Prec@1 94.000 (97.897)	Prec@5 100.000 (99.997)
2019-05-03 12:10:21 - INFO - TRAINING - Epoch: [100][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0562 (0.0625)	Prec@1 98.000 (97.886)	Prec@5 100.000 (99.997)
2019-05-03 12:10:24 - INFO - TRAINING - Epoch: [100][400/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.0872 (0.0628)	Prec@1 97.000 (97.858)	Prec@5 100.000 (99.998)
2019-05-03 12:10:27 - INFO - TRAINING - Epoch: [100][450/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.0449 (0.0624)	Prec@1 98.000 (97.882)	Prec@5 100.000 (99.998)
2019-05-03 12:10:30 - INFO - EVALUATING - Epoch: [100][0/100]	Time 0.358 (0.358)	Data 0.348 (0.348)	Loss 0.3235 (0.3235)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-05-03 12:10:30 - INFO - EVALUATING - Epoch: [100][50/100]	Time 0.021 (0.025)	Data 0.000 (0.007)	Loss 0.1820 (0.3546)	Prec@1 90.000 (90.490)	Prec@5 100.000 (99.647)
2019-05-03 12:10:31 - INFO - 
 Epoch: 101	Training Loss 0.0628 	Training Prec@1 97.872 	Training Prec@5 99.998 	Validation Loss 0.3534 	Validation Prec@1 90.600 	Validation Prec@5 99.690 	
2019-05-03 12:10:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:10:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:10:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:10:32 - INFO - TRAINING - Epoch: [101][0/500]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.0549 (0.0549)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:10:35 - INFO - TRAINING - Epoch: [101][50/500]	Time 0.054 (0.060)	Data 0.000 (0.006)	Loss 0.0640 (0.0567)	Prec@1 98.000 (98.196)	Prec@5 100.000 (100.000)
2019-05-03 12:10:37 - INFO - TRAINING - Epoch: [101][100/500]	Time 0.060 (0.057)	Data 0.000 (0.003)	Loss 0.0253 (0.0571)	Prec@1 99.000 (98.040)	Prec@5 100.000 (100.000)
2019-05-03 12:10:40 - INFO - TRAINING - Epoch: [101][150/500]	Time 0.057 (0.056)	Data 0.000 (0.003)	Loss 0.0890 (0.0583)	Prec@1 96.000 (97.987)	Prec@5 100.000 (100.000)
2019-05-03 12:10:43 - INFO - TRAINING - Epoch: [101][200/500]	Time 0.041 (0.056)	Data 0.000 (0.002)	Loss 0.0602 (0.0598)	Prec@1 98.000 (97.990)	Prec@5 100.000 (100.000)
2019-05-03 12:10:45 - INFO - TRAINING - Epoch: [101][250/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.0290 (0.0592)	Prec@1 99.000 (98.016)	Prec@5 100.000 (100.000)
2019-05-03 12:10:48 - INFO - TRAINING - Epoch: [101][300/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.1575 (0.0608)	Prec@1 97.000 (97.977)	Prec@5 100.000 (99.993)
2019-05-03 12:10:51 - INFO - TRAINING - Epoch: [101][350/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0563 (0.0612)	Prec@1 97.000 (97.943)	Prec@5 100.000 (99.994)
2019-05-03 12:10:54 - INFO - TRAINING - Epoch: [101][400/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0400 (0.0625)	Prec@1 98.000 (97.873)	Prec@5 100.000 (99.995)
2019-05-03 12:10:56 - INFO - TRAINING - Epoch: [101][450/500]	Time 0.060 (0.055)	Data 0.000 (0.001)	Loss 0.0310 (0.0618)	Prec@1 100.000 (97.905)	Prec@5 100.000 (99.993)
2019-05-03 12:10:59 - INFO - EVALUATING - Epoch: [101][0/100]	Time 0.371 (0.371)	Data 0.364 (0.364)	Loss 0.3185 (0.3185)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-05-03 12:11:00 - INFO - EVALUATING - Epoch: [101][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2378 (0.3731)	Prec@1 92.000 (90.529)	Prec@5 99.000 (99.431)
2019-05-03 12:11:01 - INFO - 
 Epoch: 102	Training Loss 0.0615 	Training Prec@1 97.890 	Training Prec@5 99.992 	Validation Loss 0.3684 	Validation Prec@1 90.310 	Validation Prec@5 99.560 	
2019-05-03 12:11:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:11:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:11:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:11:02 - INFO - TRAINING - Epoch: [102][0/500]	Time 0.288 (0.288)	Data 0.265 (0.265)	Loss 0.0607 (0.0607)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:11:04 - INFO - TRAINING - Epoch: [102][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.1602 (0.0567)	Prec@1 96.000 (98.059)	Prec@5 100.000 (100.000)
2019-05-03 12:11:07 - INFO - TRAINING - Epoch: [102][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0458 (0.0575)	Prec@1 99.000 (97.970)	Prec@5 100.000 (99.990)
2019-05-03 12:11:10 - INFO - TRAINING - Epoch: [102][150/500]	Time 0.050 (0.058)	Data 0.000 (0.003)	Loss 0.0632 (0.0587)	Prec@1 98.000 (97.974)	Prec@5 100.000 (99.987)
2019-05-03 12:11:13 - INFO - TRAINING - Epoch: [102][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0520 (0.0604)	Prec@1 99.000 (97.930)	Prec@5 100.000 (99.985)
2019-05-03 12:11:16 - INFO - TRAINING - Epoch: [102][250/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0768 (0.0608)	Prec@1 97.000 (97.940)	Prec@5 100.000 (99.988)
2019-05-03 12:11:19 - INFO - TRAINING - Epoch: [102][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0312 (0.0599)	Prec@1 99.000 (97.947)	Prec@5 100.000 (99.990)
2019-05-03 12:11:21 - INFO - TRAINING - Epoch: [102][350/500]	Time 0.047 (0.058)	Data 0.000 (0.002)	Loss 0.0753 (0.0599)	Prec@1 96.000 (97.940)	Prec@5 100.000 (99.991)
2019-05-03 12:11:24 - INFO - TRAINING - Epoch: [102][400/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0169 (0.0603)	Prec@1 100.000 (97.908)	Prec@5 100.000 (99.993)
2019-05-03 12:11:27 - INFO - TRAINING - Epoch: [102][450/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.1269 (0.0604)	Prec@1 97.000 (97.918)	Prec@5 100.000 (99.993)
2019-05-03 12:11:30 - INFO - EVALUATING - Epoch: [102][0/100]	Time 0.267 (0.267)	Data 0.258 (0.258)	Loss 0.2871 (0.2871)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:11:31 - INFO - EVALUATING - Epoch: [102][50/100]	Time 0.019 (0.023)	Data 0.000 (0.005)	Loss 0.2693 (0.3685)	Prec@1 92.000 (90.529)	Prec@5 99.000 (99.627)
2019-05-03 12:11:32 - INFO - 
 Epoch: 103	Training Loss 0.0614 	Training Prec@1 97.872 	Training Prec@5 99.994 	Validation Loss 0.3586 	Validation Prec@1 90.640 	Validation Prec@5 99.670 	
2019-05-03 12:11:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:11:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:11:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:11:32 - INFO - TRAINING - Epoch: [103][0/500]	Time 0.276 (0.276)	Data 0.249 (0.249)	Loss 0.0137 (0.0137)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:11:35 - INFO - TRAINING - Epoch: [103][50/500]	Time 0.051 (0.060)	Data 0.000 (0.006)	Loss 0.0252 (0.0675)	Prec@1 100.000 (97.980)	Prec@5 100.000 (99.980)
2019-05-03 12:11:38 - INFO - TRAINING - Epoch: [103][100/500]	Time 0.062 (0.057)	Data 0.000 (0.003)	Loss 0.0136 (0.0619)	Prec@1 100.000 (98.089)	Prec@5 100.000 (99.990)
2019-05-03 12:11:41 - INFO - TRAINING - Epoch: [103][150/500]	Time 0.066 (0.057)	Data 0.000 (0.002)	Loss 0.0907 (0.0625)	Prec@1 95.000 (98.040)	Prec@5 100.000 (99.993)
2019-05-03 12:11:43 - INFO - TRAINING - Epoch: [103][200/500]	Time 0.057 (0.056)	Data 0.000 (0.002)	Loss 0.1195 (0.0637)	Prec@1 96.000 (97.940)	Prec@5 100.000 (99.990)
2019-05-03 12:11:46 - INFO - TRAINING - Epoch: [103][250/500]	Time 0.050 (0.056)	Data 0.000 (0.002)	Loss 0.0186 (0.0611)	Prec@1 99.000 (97.952)	Prec@5 100.000 (99.992)
2019-05-03 12:11:49 - INFO - TRAINING - Epoch: [103][300/500]	Time 0.057 (0.056)	Data 0.000 (0.002)	Loss 0.0329 (0.0605)	Prec@1 99.000 (97.947)	Prec@5 100.000 (99.990)
2019-05-03 12:11:52 - INFO - TRAINING - Epoch: [103][350/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.0671 (0.0614)	Prec@1 96.000 (97.920)	Prec@5 100.000 (99.991)
2019-05-03 12:11:55 - INFO - TRAINING - Epoch: [103][400/500]	Time 0.058 (0.056)	Data 0.000 (0.001)	Loss 0.0539 (0.0617)	Prec@1 99.000 (97.913)	Prec@5 100.000 (99.993)
2019-05-03 12:11:58 - INFO - TRAINING - Epoch: [103][450/500]	Time 0.058 (0.056)	Data 0.000 (0.001)	Loss 0.1448 (0.0610)	Prec@1 96.000 (97.936)	Prec@5 100.000 (99.993)
2019-05-03 12:12:01 - INFO - EVALUATING - Epoch: [103][0/100]	Time 0.383 (0.383)	Data 0.376 (0.376)	Loss 0.1909 (0.1909)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:12:02 - INFO - EVALUATING - Epoch: [103][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.1661 (0.3652)	Prec@1 95.000 (90.490)	Prec@5 100.000 (99.314)
2019-05-03 12:12:03 - INFO - 
 Epoch: 104	Training Loss 0.0613 	Training Prec@1 97.918 	Training Prec@5 99.994 	Validation Loss 0.3515 	Validation Prec@1 90.560 	Validation Prec@5 99.530 	
2019-05-03 12:12:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:12:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:12:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:12:03 - INFO - TRAINING - Epoch: [104][0/500]	Time 0.275 (0.275)	Data 0.241 (0.241)	Loss 0.0346 (0.0346)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:12:06 - INFO - TRAINING - Epoch: [104][50/500]	Time 0.057 (0.061)	Data 0.000 (0.005)	Loss 0.0770 (0.0597)	Prec@1 96.000 (98.039)	Prec@5 100.000 (100.000)
2019-05-03 12:12:09 - INFO - TRAINING - Epoch: [104][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0775 (0.0547)	Prec@1 97.000 (98.158)	Prec@5 100.000 (100.000)
2019-05-03 12:12:11 - INFO - TRAINING - Epoch: [104][150/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0144 (0.0570)	Prec@1 100.000 (98.066)	Prec@5 100.000 (100.000)
2019-05-03 12:12:14 - INFO - TRAINING - Epoch: [104][200/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0504 (0.0564)	Prec@1 98.000 (98.080)	Prec@5 100.000 (100.000)
2019-05-03 12:12:17 - INFO - TRAINING - Epoch: [104][250/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0447 (0.0557)	Prec@1 98.000 (98.100)	Prec@5 100.000 (99.996)
2019-05-03 12:12:20 - INFO - TRAINING - Epoch: [104][300/500]	Time 0.049 (0.057)	Data 0.000 (0.002)	Loss 0.0729 (0.0556)	Prec@1 98.000 (98.106)	Prec@5 100.000 (99.997)
2019-05-03 12:12:23 - INFO - TRAINING - Epoch: [104][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.1095 (0.0557)	Prec@1 96.000 (98.103)	Prec@5 100.000 (99.997)
2019-05-03 12:12:25 - INFO - TRAINING - Epoch: [104][400/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.0095 (0.0564)	Prec@1 100.000 (98.085)	Prec@5 100.000 (99.995)
2019-05-03 12:12:28 - INFO - TRAINING - Epoch: [104][450/500]	Time 0.050 (0.057)	Data 0.000 (0.001)	Loss 0.0824 (0.0569)	Prec@1 96.000 (98.064)	Prec@5 100.000 (99.993)
2019-05-03 12:12:31 - INFO - EVALUATING - Epoch: [104][0/100]	Time 0.277 (0.277)	Data 0.260 (0.260)	Loss 0.2195 (0.2195)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-03 12:12:32 - INFO - EVALUATING - Epoch: [104][50/100]	Time 0.018 (0.022)	Data 0.000 (0.006)	Loss 0.3135 (0.3773)	Prec@1 92.000 (90.784)	Prec@5 99.000 (99.510)
2019-05-03 12:12:33 - INFO - 
 Epoch: 105	Training Loss 0.0563 	Training Prec@1 98.088 	Training Prec@5 99.994 	Validation Loss 0.3730 	Validation Prec@1 90.510 	Validation Prec@5 99.600 	
2019-05-03 12:12:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:12:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:12:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:12:33 - INFO - TRAINING - Epoch: [105][0/500]	Time 0.292 (0.292)	Data 0.264 (0.264)	Loss 0.0375 (0.0375)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:12:36 - INFO - TRAINING - Epoch: [105][50/500]	Time 0.055 (0.060)	Data 0.000 (0.006)	Loss 0.0622 (0.0584)	Prec@1 99.000 (98.118)	Prec@5 100.000 (100.000)
2019-05-03 12:12:39 - INFO - TRAINING - Epoch: [105][100/500]	Time 0.050 (0.058)	Data 0.000 (0.003)	Loss 0.0649 (0.0554)	Prec@1 97.000 (98.119)	Prec@5 100.000 (100.000)
2019-05-03 12:12:42 - INFO - TRAINING - Epoch: [105][150/500]	Time 0.066 (0.057)	Data 0.000 (0.003)	Loss 0.0290 (0.0532)	Prec@1 99.000 (98.159)	Prec@5 100.000 (100.000)
2019-05-03 12:12:44 - INFO - TRAINING - Epoch: [105][200/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.0175 (0.0512)	Prec@1 100.000 (98.289)	Prec@5 100.000 (100.000)
2019-05-03 12:12:47 - INFO - TRAINING - Epoch: [105][250/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.0176 (0.0523)	Prec@1 100.000 (98.267)	Prec@5 100.000 (100.000)
2019-05-03 12:12:50 - INFO - TRAINING - Epoch: [105][300/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0112 (0.0530)	Prec@1 100.000 (98.243)	Prec@5 100.000 (100.000)
2019-05-03 12:12:53 - INFO - TRAINING - Epoch: [105][350/500]	Time 0.055 (0.056)	Data 0.000 (0.002)	Loss 0.0808 (0.0542)	Prec@1 96.000 (98.191)	Prec@5 100.000 (100.000)
2019-05-03 12:12:56 - INFO - TRAINING - Epoch: [105][400/500]	Time 0.058 (0.056)	Data 0.000 (0.002)	Loss 0.0166 (0.0544)	Prec@1 99.000 (98.172)	Prec@5 100.000 (100.000)
2019-05-03 12:12:58 - INFO - TRAINING - Epoch: [105][450/500]	Time 0.060 (0.056)	Data 0.000 (0.001)	Loss 0.0712 (0.0548)	Prec@1 98.000 (98.155)	Prec@5 100.000 (99.998)
2019-05-03 12:13:02 - INFO - EVALUATING - Epoch: [105][0/100]	Time 0.375 (0.375)	Data 0.360 (0.360)	Loss 0.2880 (0.2880)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:13:02 - INFO - EVALUATING - Epoch: [105][50/100]	Time 0.011 (0.025)	Data 0.000 (0.007)	Loss 0.2427 (0.3718)	Prec@1 94.000 (90.647)	Prec@5 100.000 (99.451)
2019-05-03 12:13:03 - INFO - 
 Epoch: 106	Training Loss 0.0549 	Training Prec@1 98.150 	Training Prec@5 99.998 	Validation Loss 0.3580 	Validation Prec@1 90.600 	Validation Prec@5 99.600 	
2019-05-03 12:13:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:13:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:13:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:13:04 - INFO - TRAINING - Epoch: [106][0/500]	Time 0.271 (0.271)	Data 0.249 (0.249)	Loss 0.1617 (0.1617)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:13:06 - INFO - TRAINING - Epoch: [106][50/500]	Time 0.049 (0.058)	Data 0.000 (0.006)	Loss 0.0348 (0.0590)	Prec@1 99.000 (97.882)	Prec@5 100.000 (99.980)
2019-05-03 12:13:09 - INFO - TRAINING - Epoch: [106][100/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 0.0458 (0.0604)	Prec@1 98.000 (97.871)	Prec@5 100.000 (99.990)
2019-05-03 12:13:12 - INFO - TRAINING - Epoch: [106][150/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.0745 (0.0564)	Prec@1 99.000 (97.987)	Prec@5 100.000 (99.993)
2019-05-03 12:13:14 - INFO - TRAINING - Epoch: [106][200/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0379 (0.0572)	Prec@1 97.000 (97.975)	Prec@5 100.000 (99.995)
2019-05-03 12:13:17 - INFO - TRAINING - Epoch: [106][250/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0496 (0.0576)	Prec@1 98.000 (98.024)	Prec@5 100.000 (99.996)
2019-05-03 12:13:20 - INFO - TRAINING - Epoch: [106][300/500]	Time 0.063 (0.054)	Data 0.000 (0.002)	Loss 0.1198 (0.0584)	Prec@1 96.000 (97.983)	Prec@5 100.000 (99.997)
2019-05-03 12:13:22 - INFO - TRAINING - Epoch: [106][350/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.1064 (0.0578)	Prec@1 96.000 (98.006)	Prec@5 100.000 (99.997)
2019-05-03 12:13:25 - INFO - TRAINING - Epoch: [106][400/500]	Time 0.038 (0.054)	Data 0.000 (0.001)	Loss 0.0576 (0.0577)	Prec@1 99.000 (98.005)	Prec@5 100.000 (99.998)
2019-05-03 12:13:28 - INFO - TRAINING - Epoch: [106][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.1149 (0.0576)	Prec@1 96.000 (98.004)	Prec@5 100.000 (99.998)
2019-05-03 12:13:31 - INFO - EVALUATING - Epoch: [106][0/100]	Time 0.378 (0.378)	Data 0.368 (0.368)	Loss 0.3290 (0.3290)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 12:13:32 - INFO - EVALUATING - Epoch: [106][50/100]	Time 0.016 (0.024)	Data 0.000 (0.008)	Loss 0.2531 (0.3809)	Prec@1 91.000 (89.941)	Prec@5 99.000 (99.529)
2019-05-03 12:13:32 - INFO - 
 Epoch: 107	Training Loss 0.0577 	Training Prec@1 97.996 	Training Prec@5 99.998 	Validation Loss 0.3694 	Validation Prec@1 90.080 	Validation Prec@5 99.600 	
2019-05-03 12:13:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:13:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:13:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:13:33 - INFO - TRAINING - Epoch: [107][0/500]	Time 0.285 (0.285)	Data 0.258 (0.258)	Loss 0.0309 (0.0309)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:13:36 - INFO - TRAINING - Epoch: [107][50/500]	Time 0.040 (0.060)	Data 0.000 (0.006)	Loss 0.0372 (0.0571)	Prec@1 99.000 (98.098)	Prec@5 100.000 (100.000)
2019-05-03 12:13:38 - INFO - TRAINING - Epoch: [107][100/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.0870 (0.0504)	Prec@1 97.000 (98.366)	Prec@5 100.000 (99.990)
2019-05-03 12:13:41 - INFO - TRAINING - Epoch: [107][150/500]	Time 0.051 (0.058)	Data 0.000 (0.003)	Loss 0.0282 (0.0494)	Prec@1 99.000 (98.338)	Prec@5 100.000 (99.993)
2019-05-03 12:13:44 - INFO - TRAINING - Epoch: [107][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0133 (0.0517)	Prec@1 100.000 (98.254)	Prec@5 100.000 (99.995)
2019-05-03 12:13:47 - INFO - TRAINING - Epoch: [107][250/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0739 (0.0536)	Prec@1 98.000 (98.203)	Prec@5 100.000 (99.996)
2019-05-03 12:13:50 - INFO - TRAINING - Epoch: [107][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.1091 (0.0545)	Prec@1 97.000 (98.176)	Prec@5 100.000 (99.997)
2019-05-03 12:13:53 - INFO - TRAINING - Epoch: [107][350/500]	Time 0.059 (0.057)	Data 0.000 (0.002)	Loss 0.0425 (0.0540)	Prec@1 99.000 (98.197)	Prec@5 100.000 (99.997)
2019-05-03 12:13:56 - INFO - TRAINING - Epoch: [107][400/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.0220 (0.0551)	Prec@1 100.000 (98.155)	Prec@5 100.000 (99.995)
2019-05-03 12:13:58 - INFO - TRAINING - Epoch: [107][450/500]	Time 0.054 (0.057)	Data 0.000 (0.001)	Loss 0.0381 (0.0548)	Prec@1 99.000 (98.173)	Prec@5 100.000 (99.996)
2019-05-03 12:14:02 - INFO - EVALUATING - Epoch: [107][0/100]	Time 0.347 (0.347)	Data 0.334 (0.334)	Loss 0.2507 (0.2507)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:14:02 - INFO - EVALUATING - Epoch: [107][50/100]	Time 0.015 (0.024)	Data 0.000 (0.007)	Loss 0.2552 (0.3656)	Prec@1 93.000 (90.804)	Prec@5 99.000 (99.569)
2019-05-03 12:14:03 - INFO - 
 Epoch: 108	Training Loss 0.0554 	Training Prec@1 98.148 	Training Prec@5 99.996 	Validation Loss 0.3506 	Validation Prec@1 90.750 	Validation Prec@5 99.690 	
2019-05-03 12:14:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:14:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:14:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:14:04 - INFO - TRAINING - Epoch: [108][0/500]	Time 0.303 (0.303)	Data 0.264 (0.264)	Loss 0.1006 (0.1006)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:14:07 - INFO - TRAINING - Epoch: [108][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.0459 (0.0507)	Prec@1 98.000 (98.451)	Prec@5 100.000 (100.000)
2019-05-03 12:14:09 - INFO - TRAINING - Epoch: [108][100/500]	Time 0.052 (0.059)	Data 0.000 (0.003)	Loss 0.0473 (0.0488)	Prec@1 99.000 (98.485)	Prec@5 100.000 (100.000)
2019-05-03 12:14:12 - INFO - TRAINING - Epoch: [108][150/500]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 0.0807 (0.0527)	Prec@1 96.000 (98.272)	Prec@5 100.000 (100.000)
2019-05-03 12:14:15 - INFO - TRAINING - Epoch: [108][200/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0564 (0.0533)	Prec@1 98.000 (98.234)	Prec@5 100.000 (100.000)
2019-05-03 12:14:18 - INFO - TRAINING - Epoch: [108][250/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0203 (0.0517)	Prec@1 99.000 (98.279)	Prec@5 100.000 (100.000)
2019-05-03 12:14:21 - INFO - TRAINING - Epoch: [108][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0398 (0.0530)	Prec@1 98.000 (98.193)	Prec@5 100.000 (100.000)
2019-05-03 12:14:24 - INFO - TRAINING - Epoch: [108][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0472 (0.0529)	Prec@1 98.000 (98.197)	Prec@5 100.000 (100.000)
2019-05-03 12:14:26 - INFO - TRAINING - Epoch: [108][400/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.1315 (0.0525)	Prec@1 97.000 (98.200)	Prec@5 100.000 (100.000)
2019-05-03 12:14:29 - INFO - TRAINING - Epoch: [108][450/500]	Time 0.049 (0.057)	Data 0.000 (0.002)	Loss 0.0673 (0.0524)	Prec@1 96.000 (98.202)	Prec@5 100.000 (100.000)
2019-05-03 12:14:32 - INFO - EVALUATING - Epoch: [108][0/100]	Time 0.378 (0.378)	Data 0.368 (0.368)	Loss 0.2471 (0.2471)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:14:33 - INFO - EVALUATING - Epoch: [108][50/100]	Time 0.018 (0.025)	Data 0.000 (0.008)	Loss 0.3053 (0.3683)	Prec@1 94.000 (90.882)	Prec@5 100.000 (99.549)
2019-05-03 12:14:34 - INFO - 
 Epoch: 109	Training Loss 0.0525 	Training Prec@1 98.202 	Training Prec@5 100.000 	Validation Loss 0.3662 	Validation Prec@1 90.560 	Validation Prec@5 99.680 	
2019-05-03 12:14:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:14:34 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:14:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:14:35 - INFO - TRAINING - Epoch: [109][0/500]	Time 0.264 (0.264)	Data 0.225 (0.225)	Loss 0.0319 (0.0319)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:14:37 - INFO - TRAINING - Epoch: [109][50/500]	Time 0.053 (0.058)	Data 0.000 (0.005)	Loss 0.0229 (0.0538)	Prec@1 99.000 (98.333)	Prec@5 100.000 (99.961)
2019-05-03 12:14:40 - INFO - TRAINING - Epoch: [109][100/500]	Time 0.049 (0.055)	Data 0.000 (0.003)	Loss 0.0053 (0.0514)	Prec@1 100.000 (98.317)	Prec@5 100.000 (99.980)
2019-05-03 12:14:43 - INFO - TRAINING - Epoch: [109][150/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.0352 (0.0516)	Prec@1 100.000 (98.331)	Prec@5 100.000 (99.987)
2019-05-03 12:14:45 - INFO - TRAINING - Epoch: [109][200/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.0450 (0.0499)	Prec@1 99.000 (98.358)	Prec@5 100.000 (99.990)
2019-05-03 12:14:48 - INFO - TRAINING - Epoch: [109][250/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.0410 (0.0500)	Prec@1 99.000 (98.323)	Prec@5 100.000 (99.988)
2019-05-03 12:14:51 - INFO - TRAINING - Epoch: [109][300/500]	Time 0.045 (0.054)	Data 0.000 (0.002)	Loss 0.0179 (0.0512)	Prec@1 100.000 (98.259)	Prec@5 100.000 (99.990)
2019-05-03 12:14:53 - INFO - TRAINING - Epoch: [109][350/500]	Time 0.036 (0.054)	Data 0.000 (0.001)	Loss 0.0287 (0.0509)	Prec@1 99.000 (98.271)	Prec@5 100.000 (99.991)
2019-05-03 12:14:56 - INFO - TRAINING - Epoch: [109][400/500]	Time 0.037 (0.054)	Data 0.000 (0.001)	Loss 0.0436 (0.0519)	Prec@1 98.000 (98.207)	Prec@5 100.000 (99.993)
2019-05-03 12:14:59 - INFO - TRAINING - Epoch: [109][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0381 (0.0519)	Prec@1 99.000 (98.215)	Prec@5 100.000 (99.993)
2019-05-03 12:15:01 - INFO - EVALUATING - Epoch: [109][0/100]	Time 0.255 (0.255)	Data 0.245 (0.245)	Loss 0.3802 (0.3802)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 12:15:02 - INFO - EVALUATING - Epoch: [109][50/100]	Time 0.018 (0.023)	Data 0.000 (0.005)	Loss 0.2517 (0.3542)	Prec@1 93.000 (91.216)	Prec@5 100.000 (99.510)
2019-05-03 12:15:03 - INFO - 
 Epoch: 110	Training Loss 0.0513 	Training Prec@1 98.254 	Training Prec@5 99.994 	Validation Loss 0.3602 	Validation Prec@1 91.070 	Validation Prec@5 99.690 	
2019-05-03 12:15:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:15:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:15:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:15:04 - INFO - TRAINING - Epoch: [110][0/500]	Time 0.295 (0.295)	Data 0.265 (0.265)	Loss 0.0313 (0.0313)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:15:07 - INFO - TRAINING - Epoch: [110][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.0649 (0.0475)	Prec@1 98.000 (98.431)	Prec@5 100.000 (100.000)
2019-05-03 12:15:09 - INFO - TRAINING - Epoch: [110][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0781 (0.0463)	Prec@1 98.000 (98.446)	Prec@5 100.000 (100.000)
2019-05-03 12:15:12 - INFO - TRAINING - Epoch: [110][150/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.0481 (0.0489)	Prec@1 99.000 (98.364)	Prec@5 100.000 (100.000)
2019-05-03 12:15:15 - INFO - TRAINING - Epoch: [110][200/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.1363 (0.0487)	Prec@1 95.000 (98.373)	Prec@5 100.000 (100.000)
2019-05-03 12:15:18 - INFO - TRAINING - Epoch: [110][250/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.0266 (0.0497)	Prec@1 99.000 (98.363)	Prec@5 100.000 (99.996)
2019-05-03 12:15:21 - INFO - TRAINING - Epoch: [110][300/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.0314 (0.0514)	Prec@1 100.000 (98.326)	Prec@5 100.000 (99.997)
2019-05-03 12:15:24 - INFO - TRAINING - Epoch: [110][350/500]	Time 0.053 (0.057)	Data 0.000 (0.002)	Loss 0.0122 (0.0508)	Prec@1 100.000 (98.336)	Prec@5 100.000 (99.997)
2019-05-03 12:15:26 - INFO - TRAINING - Epoch: [110][400/500]	Time 0.041 (0.057)	Data 0.000 (0.002)	Loss 0.0296 (0.0516)	Prec@1 99.000 (98.312)	Prec@5 100.000 (99.998)
2019-05-03 12:15:29 - INFO - TRAINING - Epoch: [110][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0730 (0.0514)	Prec@1 97.000 (98.319)	Prec@5 100.000 (99.998)
2019-05-03 12:15:32 - INFO - EVALUATING - Epoch: [110][0/100]	Time 0.359 (0.359)	Data 0.352 (0.352)	Loss 0.2023 (0.2023)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:15:33 - INFO - EVALUATING - Epoch: [110][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.3068 (0.3745)	Prec@1 91.000 (90.255)	Prec@5 100.000 (99.490)
2019-05-03 12:15:34 - INFO - 
 Epoch: 111	Training Loss 0.0524 	Training Prec@1 98.290 	Training Prec@5 99.998 	Validation Loss 0.3658 	Validation Prec@1 90.430 	Validation Prec@5 99.570 	
2019-05-03 12:15:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:15:34 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:15:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:15:35 - INFO - TRAINING - Epoch: [111][0/500]	Time 0.296 (0.296)	Data 0.263 (0.263)	Loss 0.0140 (0.0140)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:15:37 - INFO - TRAINING - Epoch: [111][50/500]	Time 0.048 (0.058)	Data 0.000 (0.006)	Loss 0.0337 (0.0445)	Prec@1 98.000 (98.569)	Prec@5 100.000 (100.000)
2019-05-03 12:15:40 - INFO - TRAINING - Epoch: [111][100/500]	Time 0.049 (0.056)	Data 0.000 (0.003)	Loss 0.0139 (0.0450)	Prec@1 100.000 (98.535)	Prec@5 100.000 (99.980)
2019-05-03 12:15:43 - INFO - TRAINING - Epoch: [111][150/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 0.0677 (0.0511)	Prec@1 98.000 (98.305)	Prec@5 100.000 (99.987)
2019-05-03 12:15:45 - INFO - TRAINING - Epoch: [111][200/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0445 (0.0515)	Prec@1 99.000 (98.274)	Prec@5 100.000 (99.990)
2019-05-03 12:15:48 - INFO - TRAINING - Epoch: [111][250/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0417 (0.0518)	Prec@1 100.000 (98.247)	Prec@5 100.000 (99.992)
2019-05-03 12:15:51 - INFO - TRAINING - Epoch: [111][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0120 (0.0512)	Prec@1 100.000 (98.272)	Prec@5 100.000 (99.993)
2019-05-03 12:15:53 - INFO - TRAINING - Epoch: [111][350/500]	Time 0.056 (0.054)	Data 0.000 (0.002)	Loss 0.0512 (0.0521)	Prec@1 99.000 (98.271)	Prec@5 100.000 (99.991)
2019-05-03 12:15:56 - INFO - TRAINING - Epoch: [111][400/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0134 (0.0517)	Prec@1 99.000 (98.292)	Prec@5 100.000 (99.993)
2019-05-03 12:15:59 - INFO - TRAINING - Epoch: [111][450/500]	Time 0.056 (0.054)	Data 0.000 (0.001)	Loss 0.0815 (0.0517)	Prec@1 97.000 (98.284)	Prec@5 100.000 (99.993)
2019-05-03 12:16:02 - INFO - EVALUATING - Epoch: [111][0/100]	Time 0.356 (0.356)	Data 0.347 (0.347)	Loss 0.2412 (0.2412)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:16:02 - INFO - EVALUATING - Epoch: [111][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.2479 (0.3684)	Prec@1 94.000 (90.843)	Prec@5 100.000 (99.471)
2019-05-03 12:16:03 - INFO - 
 Epoch: 112	Training Loss 0.0519 	Training Prec@1 98.258 	Training Prec@5 99.994 	Validation Loss 0.3635 	Validation Prec@1 90.710 	Validation Prec@5 99.590 	
2019-05-03 12:16:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:16:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:16:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:16:04 - INFO - TRAINING - Epoch: [112][0/500]	Time 0.297 (0.297)	Data 0.266 (0.266)	Loss 0.0248 (0.0248)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:16:06 - INFO - TRAINING - Epoch: [112][50/500]	Time 0.052 (0.058)	Data 0.000 (0.006)	Loss 0.0330 (0.0426)	Prec@1 98.000 (98.431)	Prec@5 100.000 (100.000)
2019-05-03 12:16:09 - INFO - TRAINING - Epoch: [112][100/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.0173 (0.0441)	Prec@1 99.000 (98.455)	Prec@5 100.000 (100.000)
2019-05-03 12:16:12 - INFO - TRAINING - Epoch: [112][150/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.0294 (0.0466)	Prec@1 98.000 (98.404)	Prec@5 100.000 (100.000)
2019-05-03 12:16:15 - INFO - TRAINING - Epoch: [112][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0406 (0.0462)	Prec@1 99.000 (98.448)	Prec@5 100.000 (100.000)
2019-05-03 12:16:17 - INFO - TRAINING - Epoch: [112][250/500]	Time 0.064 (0.055)	Data 0.000 (0.002)	Loss 0.0472 (0.0477)	Prec@1 98.000 (98.390)	Prec@5 100.000 (99.996)
2019-05-03 12:16:20 - INFO - TRAINING - Epoch: [112][300/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.0707 (0.0481)	Prec@1 98.000 (98.372)	Prec@5 100.000 (99.997)
2019-05-03 12:16:23 - INFO - TRAINING - Epoch: [112][350/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.0257 (0.0479)	Prec@1 100.000 (98.376)	Prec@5 100.000 (99.997)
2019-05-03 12:16:25 - INFO - TRAINING - Epoch: [112][400/500]	Time 0.051 (0.054)	Data 0.000 (0.001)	Loss 0.0467 (0.0484)	Prec@1 98.000 (98.367)	Prec@5 100.000 (99.998)
2019-05-03 12:16:28 - INFO - TRAINING - Epoch: [112][450/500]	Time 0.068 (0.054)	Data 0.000 (0.001)	Loss 0.0593 (0.0486)	Prec@1 97.000 (98.373)	Prec@5 100.000 (99.996)
2019-05-03 12:16:31 - INFO - EVALUATING - Epoch: [112][0/100]	Time 0.375 (0.375)	Data 0.364 (0.364)	Loss 0.2784 (0.2784)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:16:32 - INFO - EVALUATING - Epoch: [112][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3472 (0.3796)	Prec@1 87.000 (90.294)	Prec@5 99.000 (99.549)
2019-05-03 12:16:33 - INFO - 
 Epoch: 113	Training Loss 0.0490 	Training Prec@1 98.364 	Training Prec@5 99.996 	Validation Loss 0.3676 	Validation Prec@1 90.540 	Validation Prec@5 99.620 	
2019-05-03 12:16:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:16:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:16:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:16:33 - INFO - TRAINING - Epoch: [113][0/500]	Time 0.278 (0.278)	Data 0.256 (0.256)	Loss 0.1137 (0.1137)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:16:36 - INFO - TRAINING - Epoch: [113][50/500]	Time 0.060 (0.061)	Data 0.000 (0.006)	Loss 0.0289 (0.0494)	Prec@1 99.000 (98.294)	Prec@5 100.000 (99.980)
2019-05-03 12:16:39 - INFO - TRAINING - Epoch: [113][100/500]	Time 0.051 (0.059)	Data 0.000 (0.003)	Loss 0.0255 (0.0517)	Prec@1 100.000 (98.257)	Prec@5 100.000 (99.990)
2019-05-03 12:16:42 - INFO - TRAINING - Epoch: [113][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0122 (0.0518)	Prec@1 100.000 (98.311)	Prec@5 100.000 (99.987)
2019-05-03 12:16:45 - INFO - TRAINING - Epoch: [113][200/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0610 (0.0511)	Prec@1 99.000 (98.318)	Prec@5 100.000 (99.990)
2019-05-03 12:16:47 - INFO - TRAINING - Epoch: [113][250/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.0230 (0.0511)	Prec@1 100.000 (98.319)	Prec@5 100.000 (99.992)
2019-05-03 12:16:50 - INFO - TRAINING - Epoch: [113][300/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0654 (0.0501)	Prec@1 97.000 (98.355)	Prec@5 100.000 (99.993)
2019-05-03 12:16:53 - INFO - TRAINING - Epoch: [113][350/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0143 (0.0503)	Prec@1 100.000 (98.370)	Prec@5 100.000 (99.991)
2019-05-03 12:16:56 - INFO - TRAINING - Epoch: [113][400/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0327 (0.0502)	Prec@1 99.000 (98.369)	Prec@5 100.000 (99.993)
2019-05-03 12:16:59 - INFO - TRAINING - Epoch: [113][450/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0441 (0.0499)	Prec@1 98.000 (98.368)	Prec@5 100.000 (99.993)
2019-05-03 12:17:02 - INFO - EVALUATING - Epoch: [113][0/100]	Time 0.376 (0.376)	Data 0.366 (0.366)	Loss 0.2934 (0.2934)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:17:03 - INFO - EVALUATING - Epoch: [113][50/100]	Time 0.014 (0.025)	Data 0.000 (0.008)	Loss 0.2336 (0.3603)	Prec@1 92.000 (90.745)	Prec@5 100.000 (99.529)
2019-05-03 12:17:04 - INFO - 
 Epoch: 114	Training Loss 0.0512 	Training Prec@1 98.314 	Training Prec@5 99.994 	Validation Loss 0.3516 	Validation Prec@1 90.810 	Validation Prec@5 99.600 	
2019-05-03 12:17:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:17:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:17:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:17:04 - INFO - TRAINING - Epoch: [114][0/500]	Time 0.289 (0.289)	Data 0.266 (0.266)	Loss 0.0411 (0.0411)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:17:07 - INFO - TRAINING - Epoch: [114][50/500]	Time 0.053 (0.061)	Data 0.000 (0.006)	Loss 0.0551 (0.0420)	Prec@1 99.000 (98.529)	Prec@5 100.000 (100.000)
2019-05-03 12:17:10 - INFO - TRAINING - Epoch: [114][100/500]	Time 0.060 (0.058)	Data 0.000 (0.004)	Loss 0.0288 (0.0424)	Prec@1 99.000 (98.594)	Prec@5 100.000 (100.000)
2019-05-03 12:17:13 - INFO - TRAINING - Epoch: [114][150/500]	Time 0.054 (0.057)	Data 0.000 (0.003)	Loss 0.0189 (0.0439)	Prec@1 99.000 (98.510)	Prec@5 100.000 (100.000)
2019-05-03 12:17:15 - INFO - TRAINING - Epoch: [114][200/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.0650 (0.0458)	Prec@1 98.000 (98.418)	Prec@5 100.000 (100.000)
2019-05-03 12:17:18 - INFO - TRAINING - Epoch: [114][250/500]	Time 0.054 (0.057)	Data 0.000 (0.002)	Loss 0.0673 (0.0454)	Prec@1 99.000 (98.474)	Prec@5 100.000 (100.000)
2019-05-03 12:17:21 - INFO - TRAINING - Epoch: [114][300/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.1201 (0.0451)	Prec@1 96.000 (98.478)	Prec@5 100.000 (100.000)
2019-05-03 12:17:24 - INFO - TRAINING - Epoch: [114][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0745 (0.0443)	Prec@1 99.000 (98.521)	Prec@5 100.000 (100.000)
2019-05-03 12:17:27 - INFO - TRAINING - Epoch: [114][400/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0622 (0.0451)	Prec@1 96.000 (98.469)	Prec@5 100.000 (100.000)
2019-05-03 12:17:30 - INFO - TRAINING - Epoch: [114][450/500]	Time 0.068 (0.057)	Data 0.000 (0.001)	Loss 0.1112 (0.0456)	Prec@1 98.000 (98.455)	Prec@5 100.000 (100.000)
2019-05-03 12:17:33 - INFO - EVALUATING - Epoch: [114][0/100]	Time 0.266 (0.266)	Data 0.258 (0.258)	Loss 0.3043 (0.3043)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:17:34 - INFO - EVALUATING - Epoch: [114][50/100]	Time 0.016 (0.023)	Data 0.000 (0.005)	Loss 0.1723 (0.3851)	Prec@1 94.000 (90.314)	Prec@5 100.000 (99.588)
2019-05-03 12:17:34 - INFO - 
 Epoch: 115	Training Loss 0.0466 	Training Prec@1 98.442 	Training Prec@5 100.000 	Validation Loss 0.3737 	Validation Prec@1 90.310 	Validation Prec@5 99.660 	
2019-05-03 12:17:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:17:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:17:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:17:35 - INFO - TRAINING - Epoch: [115][0/500]	Time 0.274 (0.274)	Data 0.251 (0.251)	Loss 0.0208 (0.0208)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:17:37 - INFO - TRAINING - Epoch: [115][50/500]	Time 0.056 (0.057)	Data 0.000 (0.006)	Loss 0.0032 (0.0462)	Prec@1 100.000 (98.627)	Prec@5 100.000 (100.000)
2019-05-03 12:17:40 - INFO - TRAINING - Epoch: [115][100/500]	Time 0.054 (0.055)	Data 0.000 (0.003)	Loss 0.0265 (0.0461)	Prec@1 99.000 (98.535)	Prec@5 100.000 (99.990)
2019-05-03 12:17:43 - INFO - TRAINING - Epoch: [115][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0219 (0.0440)	Prec@1 100.000 (98.609)	Prec@5 100.000 (99.993)
2019-05-03 12:17:45 - INFO - TRAINING - Epoch: [115][200/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0111 (0.0448)	Prec@1 100.000 (98.587)	Prec@5 100.000 (99.995)
2019-05-03 12:17:48 - INFO - TRAINING - Epoch: [115][250/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.0262 (0.0452)	Prec@1 99.000 (98.546)	Prec@5 100.000 (99.996)
2019-05-03 12:17:51 - INFO - TRAINING - Epoch: [115][300/500]	Time 0.051 (0.054)	Data 0.000 (0.002)	Loss 0.0238 (0.0455)	Prec@1 99.000 (98.522)	Prec@5 100.000 (99.997)
2019-05-03 12:17:53 - INFO - TRAINING - Epoch: [115][350/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0207 (0.0458)	Prec@1 99.000 (98.504)	Prec@5 100.000 (99.997)
2019-05-03 12:17:56 - INFO - TRAINING - Epoch: [115][400/500]	Time 0.048 (0.054)	Data 0.000 (0.001)	Loss 0.0764 (0.0461)	Prec@1 98.000 (98.469)	Prec@5 100.000 (99.998)
2019-05-03 12:17:59 - INFO - TRAINING - Epoch: [115][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0243 (0.0460)	Prec@1 99.000 (98.463)	Prec@5 100.000 (99.998)
2019-05-03 12:18:02 - INFO - EVALUATING - Epoch: [115][0/100]	Time 0.372 (0.372)	Data 0.358 (0.358)	Loss 0.1785 (0.1785)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:18:03 - INFO - EVALUATING - Epoch: [115][50/100]	Time 0.014 (0.024)	Data 0.000 (0.007)	Loss 0.2159 (0.3643)	Prec@1 94.000 (91.020)	Prec@5 99.000 (99.549)
2019-05-03 12:18:04 - INFO - 
 Epoch: 116	Training Loss 0.0461 	Training Prec@1 98.456 	Training Prec@5 99.998 	Validation Loss 0.3563 	Validation Prec@1 90.980 	Validation Prec@5 99.600 	
2019-05-03 12:18:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:18:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:18:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:18:04 - INFO - TRAINING - Epoch: [116][0/500]	Time 0.298 (0.298)	Data 0.275 (0.275)	Loss 0.0042 (0.0042)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:18:07 - INFO - TRAINING - Epoch: [116][50/500]	Time 0.044 (0.058)	Data 0.000 (0.006)	Loss 0.0319 (0.0516)	Prec@1 100.000 (98.353)	Prec@5 100.000 (99.980)
2019-05-03 12:18:09 - INFO - TRAINING - Epoch: [116][100/500]	Time 0.054 (0.056)	Data 0.000 (0.004)	Loss 0.0371 (0.0515)	Prec@1 99.000 (98.317)	Prec@5 100.000 (99.990)
2019-05-03 12:18:12 - INFO - TRAINING - Epoch: [116][150/500]	Time 0.048 (0.055)	Data 0.000 (0.003)	Loss 0.0598 (0.0489)	Prec@1 98.000 (98.404)	Prec@5 100.000 (99.993)
2019-05-03 12:18:15 - INFO - TRAINING - Epoch: [116][200/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0138 (0.0485)	Prec@1 100.000 (98.408)	Prec@5 100.000 (99.990)
2019-05-03 12:18:17 - INFO - TRAINING - Epoch: [116][250/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0682 (0.0476)	Prec@1 98.000 (98.462)	Prec@5 100.000 (99.992)
2019-05-03 12:18:20 - INFO - TRAINING - Epoch: [116][300/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0640 (0.0465)	Prec@1 99.000 (98.522)	Prec@5 100.000 (99.993)
2019-05-03 12:18:23 - INFO - TRAINING - Epoch: [116][350/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.0512 (0.0459)	Prec@1 98.000 (98.527)	Prec@5 100.000 (99.994)
2019-05-03 12:18:26 - INFO - TRAINING - Epoch: [116][400/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0294 (0.0459)	Prec@1 100.000 (98.524)	Prec@5 100.000 (99.995)
2019-05-03 12:18:28 - INFO - TRAINING - Epoch: [116][450/500]	Time 0.042 (0.054)	Data 0.000 (0.001)	Loss 0.0181 (0.0450)	Prec@1 100.000 (98.550)	Prec@5 100.000 (99.996)
2019-05-03 12:18:31 - INFO - EVALUATING - Epoch: [116][0/100]	Time 0.357 (0.357)	Data 0.346 (0.346)	Loss 0.2722 (0.2722)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-05-03 12:18:32 - INFO - EVALUATING - Epoch: [116][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2602 (0.3817)	Prec@1 94.000 (90.765)	Prec@5 99.000 (99.529)
2019-05-03 12:18:33 - INFO - 
 Epoch: 117	Training Loss 0.0459 	Training Prec@1 98.496 	Training Prec@5 99.996 	Validation Loss 0.3711 	Validation Prec@1 90.850 	Validation Prec@5 99.590 	
2019-05-03 12:18:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:18:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:18:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:18:34 - INFO - TRAINING - Epoch: [117][0/500]	Time 0.297 (0.297)	Data 0.275 (0.275)	Loss 0.1005 (0.1005)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:18:36 - INFO - TRAINING - Epoch: [117][50/500]	Time 0.065 (0.061)	Data 0.000 (0.006)	Loss 0.0336 (0.0470)	Prec@1 99.000 (98.373)	Prec@5 100.000 (100.000)
2019-05-03 12:18:39 - INFO - TRAINING - Epoch: [117][100/500]	Time 0.055 (0.059)	Data 0.000 (0.003)	Loss 0.0319 (0.0462)	Prec@1 99.000 (98.465)	Prec@5 100.000 (100.000)
2019-05-03 12:18:42 - INFO - TRAINING - Epoch: [117][150/500]	Time 0.051 (0.058)	Data 0.000 (0.003)	Loss 0.0396 (0.0457)	Prec@1 98.000 (98.450)	Prec@5 100.000 (100.000)
2019-05-03 12:18:45 - INFO - TRAINING - Epoch: [117][200/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0572 (0.0455)	Prec@1 98.000 (98.527)	Prec@5 100.000 (100.000)
2019-05-03 12:18:48 - INFO - TRAINING - Epoch: [117][250/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0900 (0.0452)	Prec@1 96.000 (98.526)	Prec@5 100.000 (100.000)
2019-05-03 12:18:51 - INFO - TRAINING - Epoch: [117][300/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0575 (0.0453)	Prec@1 99.000 (98.535)	Prec@5 100.000 (99.997)
2019-05-03 12:18:53 - INFO - TRAINING - Epoch: [117][350/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.0074 (0.0445)	Prec@1 100.000 (98.561)	Prec@5 100.000 (99.997)
2019-05-03 12:18:56 - INFO - TRAINING - Epoch: [117][400/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0052 (0.0447)	Prec@1 100.000 (98.539)	Prec@5 100.000 (99.998)
2019-05-03 12:18:59 - INFO - TRAINING - Epoch: [117][450/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.0305 (0.0443)	Prec@1 99.000 (98.541)	Prec@5 100.000 (99.998)
2019-05-03 12:19:02 - INFO - EVALUATING - Epoch: [117][0/100]	Time 0.357 (0.357)	Data 0.341 (0.341)	Loss 0.3431 (0.3431)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:19:03 - INFO - EVALUATING - Epoch: [117][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.3077 (0.3692)	Prec@1 91.000 (90.784)	Prec@5 100.000 (99.588)
2019-05-03 12:19:04 - INFO - 
 Epoch: 118	Training Loss 0.0445 	Training Prec@1 98.528 	Training Prec@5 99.998 	Validation Loss 0.3711 	Validation Prec@1 90.810 	Validation Prec@5 99.620 	
2019-05-03 12:19:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:19:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:19:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:19:05 - INFO - TRAINING - Epoch: [118][0/500]	Time 0.289 (0.289)	Data 0.257 (0.257)	Loss 0.0447 (0.0447)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:19:07 - INFO - TRAINING - Epoch: [118][50/500]	Time 0.062 (0.058)	Data 0.000 (0.006)	Loss 0.0606 (0.0507)	Prec@1 98.000 (98.412)	Prec@5 100.000 (99.980)
2019-05-03 12:19:10 - INFO - TRAINING - Epoch: [118][100/500]	Time 0.055 (0.056)	Data 0.000 (0.003)	Loss 0.0194 (0.0499)	Prec@1 99.000 (98.366)	Prec@5 100.000 (99.990)
2019-05-03 12:19:13 - INFO - TRAINING - Epoch: [118][150/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0769 (0.0466)	Prec@1 98.000 (98.450)	Prec@5 100.000 (99.987)
2019-05-03 12:19:15 - INFO - TRAINING - Epoch: [118][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.1185 (0.0464)	Prec@1 95.000 (98.413)	Prec@5 100.000 (99.985)
2019-05-03 12:19:18 - INFO - TRAINING - Epoch: [118][250/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.0243 (0.0465)	Prec@1 98.000 (98.410)	Prec@5 100.000 (99.988)
2019-05-03 12:19:21 - INFO - TRAINING - Epoch: [118][300/500]	Time 0.064 (0.056)	Data 0.000 (0.002)	Loss 0.0579 (0.0468)	Prec@1 99.000 (98.429)	Prec@5 100.000 (99.990)
2019-05-03 12:19:24 - INFO - TRAINING - Epoch: [118][350/500]	Time 0.065 (0.056)	Data 0.000 (0.002)	Loss 0.0515 (0.0480)	Prec@1 98.000 (98.402)	Prec@5 100.000 (99.989)
2019-05-03 12:19:27 - INFO - TRAINING - Epoch: [118][400/500]	Time 0.058 (0.056)	Data 0.000 (0.001)	Loss 0.0687 (0.0478)	Prec@1 96.000 (98.387)	Prec@5 100.000 (99.990)
2019-05-03 12:19:30 - INFO - TRAINING - Epoch: [118][450/500]	Time 0.055 (0.056)	Data 0.000 (0.001)	Loss 0.0574 (0.0474)	Prec@1 98.000 (98.395)	Prec@5 100.000 (99.991)
2019-05-03 12:19:33 - INFO - EVALUATING - Epoch: [118][0/100]	Time 0.378 (0.378)	Data 0.364 (0.364)	Loss 0.2970 (0.2970)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:19:34 - INFO - EVALUATING - Epoch: [118][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.3472 (0.3659)	Prec@1 91.000 (90.980)	Prec@5 100.000 (99.647)
2019-05-03 12:19:34 - INFO - 
 Epoch: 119	Training Loss 0.0474 	Training Prec@1 98.380 	Training Prec@5 99.992 	Validation Loss 0.3511 	Validation Prec@1 91.130 	Validation Prec@5 99.710 	
2019-05-03 12:19:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:19:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:19:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:19:35 - INFO - TRAINING - Epoch: [119][0/500]	Time 0.298 (0.298)	Data 0.268 (0.268)	Loss 0.0278 (0.0278)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:19:38 - INFO - TRAINING - Epoch: [119][50/500]	Time 0.058 (0.062)	Data 0.000 (0.006)	Loss 0.0234 (0.0472)	Prec@1 100.000 (98.216)	Prec@5 100.000 (100.000)
2019-05-03 12:19:41 - INFO - TRAINING - Epoch: [119][100/500]	Time 0.062 (0.059)	Data 0.000 (0.003)	Loss 0.0322 (0.0462)	Prec@1 99.000 (98.406)	Prec@5 100.000 (100.000)
2019-05-03 12:19:43 - INFO - TRAINING - Epoch: [119][150/500]	Time 0.051 (0.058)	Data 0.000 (0.003)	Loss 0.0504 (0.0467)	Prec@1 97.000 (98.437)	Prec@5 100.000 (100.000)
2019-05-03 12:19:46 - INFO - TRAINING - Epoch: [119][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1084 (0.0479)	Prec@1 95.000 (98.373)	Prec@5 100.000 (100.000)
2019-05-03 12:19:49 - INFO - TRAINING - Epoch: [119][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0075 (0.0476)	Prec@1 100.000 (98.418)	Prec@5 100.000 (100.000)
2019-05-03 12:19:52 - INFO - TRAINING - Epoch: [119][300/500]	Time 0.046 (0.057)	Data 0.000 (0.002)	Loss 0.0066 (0.0472)	Prec@1 100.000 (98.442)	Prec@5 100.000 (100.000)
2019-05-03 12:19:55 - INFO - TRAINING - Epoch: [119][350/500]	Time 0.047 (0.057)	Data 0.000 (0.002)	Loss 0.0568 (0.0466)	Prec@1 98.000 (98.456)	Prec@5 100.000 (100.000)
2019-05-03 12:19:57 - INFO - TRAINING - Epoch: [119][400/500]	Time 0.055 (0.056)	Data 0.000 (0.002)	Loss 0.1062 (0.0462)	Prec@1 96.000 (98.471)	Prec@5 100.000 (100.000)
2019-05-03 12:20:00 - INFO - TRAINING - Epoch: [119][450/500]	Time 0.044 (0.056)	Data 0.000 (0.001)	Loss 0.0928 (0.0456)	Prec@1 97.000 (98.488)	Prec@5 100.000 (100.000)
2019-05-03 12:20:03 - INFO - EVALUATING - Epoch: [119][0/100]	Time 0.377 (0.377)	Data 0.366 (0.366)	Loss 0.3250 (0.3250)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 12:20:04 - INFO - EVALUATING - Epoch: [119][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.1783 (0.3804)	Prec@1 93.000 (90.765)	Prec@5 100.000 (99.373)
2019-05-03 12:20:05 - INFO - 
 Epoch: 120	Training Loss 0.0450 	Training Prec@1 98.510 	Training Prec@5 100.000 	Validation Loss 0.3593 	Validation Prec@1 90.790 	Validation Prec@5 99.550 	
2019-05-03 12:20:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:20:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:20:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:20:05 - INFO - TRAINING - Epoch: [120][0/500]	Time 0.314 (0.314)	Data 0.290 (0.290)	Loss 0.0496 (0.0496)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:20:08 - INFO - TRAINING - Epoch: [120][50/500]	Time 0.058 (0.059)	Data 0.000 (0.007)	Loss 0.0163 (0.0386)	Prec@1 100.000 (98.608)	Prec@5 100.000 (100.000)
2019-05-03 12:20:11 - INFO - TRAINING - Epoch: [120][100/500]	Time 0.043 (0.056)	Data 0.000 (0.004)	Loss 0.0391 (0.0404)	Prec@1 99.000 (98.584)	Prec@5 100.000 (100.000)
2019-05-03 12:20:13 - INFO - TRAINING - Epoch: [120][150/500]	Time 0.055 (0.055)	Data 0.000 (0.003)	Loss 0.0350 (0.0419)	Prec@1 99.000 (98.563)	Prec@5 100.000 (100.000)
2019-05-03 12:20:16 - INFO - TRAINING - Epoch: [120][200/500]	Time 0.058 (0.055)	Data 0.000 (0.002)	Loss 0.0256 (0.0424)	Prec@1 99.000 (98.567)	Prec@5 100.000 (99.995)
2019-05-03 12:20:19 - INFO - TRAINING - Epoch: [120][250/500]	Time 0.070 (0.054)	Data 0.000 (0.002)	Loss 0.0291 (0.0433)	Prec@1 100.000 (98.530)	Prec@5 100.000 (99.996)
2019-05-03 12:20:21 - INFO - TRAINING - Epoch: [120][300/500]	Time 0.044 (0.054)	Data 0.000 (0.002)	Loss 0.0384 (0.0426)	Prec@1 99.000 (98.561)	Prec@5 100.000 (99.997)
2019-05-03 12:20:24 - INFO - TRAINING - Epoch: [120][350/500]	Time 0.068 (0.054)	Data 0.000 (0.002)	Loss 0.0673 (0.0416)	Prec@1 98.000 (98.598)	Prec@5 100.000 (99.997)
2019-05-03 12:20:27 - INFO - TRAINING - Epoch: [120][400/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.0306 (0.0416)	Prec@1 99.000 (98.564)	Prec@5 100.000 (99.995)
2019-05-03 12:20:29 - INFO - TRAINING - Epoch: [120][450/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.0281 (0.0422)	Prec@1 99.000 (98.534)	Prec@5 100.000 (99.996)
2019-05-03 12:20:32 - INFO - EVALUATING - Epoch: [120][0/100]	Time 0.364 (0.364)	Data 0.352 (0.352)	Loss 0.3159 (0.3159)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:20:33 - INFO - EVALUATING - Epoch: [120][50/100]	Time 0.019 (0.025)	Data 0.000 (0.007)	Loss 0.2408 (0.3771)	Prec@1 92.000 (90.902)	Prec@5 100.000 (99.529)
2019-05-03 12:20:34 - INFO - 
 Epoch: 121	Training Loss 0.0429 	Training Prec@1 98.500 	Training Prec@5 99.996 	Validation Loss 0.3757 	Validation Prec@1 90.580 	Validation Prec@5 99.550 	
2019-05-03 12:20:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:20:34 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:20:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:20:34 - INFO - TRAINING - Epoch: [121][0/500]	Time 0.298 (0.298)	Data 0.274 (0.274)	Loss 0.0267 (0.0267)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:20:37 - INFO - TRAINING - Epoch: [121][50/500]	Time 0.055 (0.062)	Data 0.000 (0.006)	Loss 0.0746 (0.0391)	Prec@1 98.000 (98.667)	Prec@5 100.000 (100.000)
2019-05-03 12:20:40 - INFO - TRAINING - Epoch: [121][100/500]	Time 0.058 (0.059)	Data 0.000 (0.004)	Loss 0.0436 (0.0419)	Prec@1 98.000 (98.554)	Prec@5 100.000 (100.000)
2019-05-03 12:20:43 - INFO - TRAINING - Epoch: [121][150/500]	Time 0.050 (0.059)	Data 0.000 (0.003)	Loss 0.0150 (0.0410)	Prec@1 99.000 (98.583)	Prec@5 100.000 (100.000)
2019-05-03 12:20:46 - INFO - TRAINING - Epoch: [121][200/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0307 (0.0401)	Prec@1 99.000 (98.642)	Prec@5 100.000 (100.000)
2019-05-03 12:20:49 - INFO - TRAINING - Epoch: [121][250/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0213 (0.0409)	Prec@1 99.000 (98.625)	Prec@5 100.000 (100.000)
2019-05-03 12:20:52 - INFO - TRAINING - Epoch: [121][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0895 (0.0412)	Prec@1 97.000 (98.601)	Prec@5 100.000 (100.000)
2019-05-03 12:20:54 - INFO - TRAINING - Epoch: [121][350/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0508 (0.0410)	Prec@1 99.000 (98.593)	Prec@5 100.000 (100.000)
2019-05-03 12:20:57 - INFO - TRAINING - Epoch: [121][400/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0248 (0.0416)	Prec@1 99.000 (98.586)	Prec@5 100.000 (100.000)
2019-05-03 12:21:00 - INFO - TRAINING - Epoch: [121][450/500]	Time 0.059 (0.057)	Data 0.000 (0.001)	Loss 0.0230 (0.0425)	Prec@1 99.000 (98.561)	Prec@5 100.000 (100.000)
2019-05-03 12:21:03 - INFO - EVALUATING - Epoch: [121][0/100]	Time 0.351 (0.351)	Data 0.333 (0.333)	Loss 0.2489 (0.2489)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:21:04 - INFO - EVALUATING - Epoch: [121][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.2904 (0.3701)	Prec@1 94.000 (90.922)	Prec@5 99.000 (99.608)
2019-05-03 12:21:05 - INFO - 
 Epoch: 122	Training Loss 0.0433 	Training Prec@1 98.512 	Training Prec@5 100.000 	Validation Loss 0.3609 	Validation Prec@1 90.760 	Validation Prec@5 99.640 	
2019-05-03 12:21:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:21:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:21:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:21:05 - INFO - TRAINING - Epoch: [122][0/500]	Time 0.296 (0.296)	Data 0.272 (0.272)	Loss 0.0249 (0.0249)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:21:08 - INFO - TRAINING - Epoch: [122][50/500]	Time 0.060 (0.060)	Data 0.000 (0.006)	Loss 0.0192 (0.0433)	Prec@1 99.000 (98.471)	Prec@5 100.000 (100.000)
2019-05-03 12:21:11 - INFO - TRAINING - Epoch: [122][100/500]	Time 0.047 (0.058)	Data 0.000 (0.004)	Loss 0.0969 (0.0391)	Prec@1 96.000 (98.663)	Prec@5 100.000 (100.000)
2019-05-03 12:21:14 - INFO - TRAINING - Epoch: [122][150/500]	Time 0.059 (0.056)	Data 0.000 (0.003)	Loss 0.0248 (0.0392)	Prec@1 100.000 (98.656)	Prec@5 100.000 (100.000)
2019-05-03 12:21:16 - INFO - TRAINING - Epoch: [122][200/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.0720 (0.0414)	Prec@1 97.000 (98.572)	Prec@5 100.000 (100.000)
2019-05-03 12:21:19 - INFO - TRAINING - Epoch: [122][250/500]	Time 0.069 (0.056)	Data 0.000 (0.002)	Loss 0.0134 (0.0416)	Prec@1 100.000 (98.578)	Prec@5 100.000 (100.000)
2019-05-03 12:21:22 - INFO - TRAINING - Epoch: [122][300/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0094 (0.0411)	Prec@1 100.000 (98.605)	Prec@5 100.000 (100.000)
2019-05-03 12:21:24 - INFO - TRAINING - Epoch: [122][350/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.0295 (0.0410)	Prec@1 99.000 (98.635)	Prec@5 100.000 (100.000)
2019-05-03 12:21:27 - INFO - TRAINING - Epoch: [122][400/500]	Time 0.052 (0.055)	Data 0.000 (0.001)	Loss 0.1263 (0.0421)	Prec@1 95.000 (98.571)	Prec@5 100.000 (100.000)
2019-05-03 12:21:30 - INFO - TRAINING - Epoch: [122][450/500]	Time 0.056 (0.055)	Data 0.000 (0.001)	Loss 0.0426 (0.0421)	Prec@1 99.000 (98.588)	Prec@5 100.000 (99.998)
2019-05-03 12:21:33 - INFO - EVALUATING - Epoch: [122][0/100]	Time 0.365 (0.365)	Data 0.359 (0.359)	Loss 0.3165 (0.3165)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 12:21:34 - INFO - EVALUATING - Epoch: [122][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2612 (0.3835)	Prec@1 94.000 (90.706)	Prec@5 99.000 (99.627)
2019-05-03 12:21:35 - INFO - 
 Epoch: 123	Training Loss 0.0427 	Training Prec@1 98.556 	Training Prec@5 99.998 	Validation Loss 0.3728 	Validation Prec@1 90.670 	Validation Prec@5 99.650 	
2019-05-03 12:21:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:21:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:21:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:21:35 - INFO - TRAINING - Epoch: [123][0/500]	Time 0.281 (0.281)	Data 0.258 (0.258)	Loss 0.0292 (0.0292)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:21:38 - INFO - TRAINING - Epoch: [123][50/500]	Time 0.056 (0.060)	Data 0.000 (0.006)	Loss 0.0098 (0.0412)	Prec@1 100.000 (98.706)	Prec@5 100.000 (100.000)
2019-05-03 12:21:41 - INFO - TRAINING - Epoch: [123][100/500]	Time 0.057 (0.057)	Data 0.000 (0.003)	Loss 0.1025 (0.0415)	Prec@1 97.000 (98.644)	Prec@5 100.000 (100.000)
2019-05-03 12:21:43 - INFO - TRAINING - Epoch: [123][150/500]	Time 0.061 (0.056)	Data 0.000 (0.003)	Loss 0.0964 (0.0425)	Prec@1 96.000 (98.570)	Prec@5 100.000 (100.000)
2019-05-03 12:21:46 - INFO - TRAINING - Epoch: [123][200/500]	Time 0.059 (0.056)	Data 0.000 (0.002)	Loss 0.0242 (0.0418)	Prec@1 99.000 (98.587)	Prec@5 100.000 (100.000)
2019-05-03 12:21:49 - INFO - TRAINING - Epoch: [123][250/500]	Time 0.056 (0.056)	Data 0.000 (0.002)	Loss 0.0174 (0.0419)	Prec@1 99.000 (98.574)	Prec@5 100.000 (99.996)
2019-05-03 12:21:52 - INFO - TRAINING - Epoch: [123][300/500]	Time 0.057 (0.056)	Data 0.000 (0.002)	Loss 0.1013 (0.0425)	Prec@1 98.000 (98.538)	Prec@5 100.000 (99.997)
2019-05-03 12:21:54 - INFO - TRAINING - Epoch: [123][350/500]	Time 0.056 (0.056)	Data 0.000 (0.002)	Loss 0.0545 (0.0425)	Prec@1 98.000 (98.558)	Prec@5 100.000 (99.997)
2019-05-03 12:21:57 - INFO - TRAINING - Epoch: [123][400/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.0406 (0.0416)	Prec@1 98.000 (98.601)	Prec@5 100.000 (99.998)
2019-05-03 12:22:00 - INFO - TRAINING - Epoch: [123][450/500]	Time 0.053 (0.056)	Data 0.000 (0.001)	Loss 0.0693 (0.0412)	Prec@1 96.000 (98.603)	Prec@5 100.000 (99.998)
2019-05-03 12:22:03 - INFO - EVALUATING - Epoch: [123][0/100]	Time 0.345 (0.345)	Data 0.336 (0.336)	Loss 0.3311 (0.3311)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 12:22:04 - INFO - EVALUATING - Epoch: [123][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.3363 (0.3847)	Prec@1 90.000 (90.902)	Prec@5 100.000 (99.529)
2019-05-03 12:22:05 - INFO - 
 Epoch: 124	Training Loss 0.0415 	Training Prec@1 98.586 	Training Prec@5 99.998 	Validation Loss 0.3685 	Validation Prec@1 90.960 	Validation Prec@5 99.650 	
2019-05-03 12:22:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:22:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:22:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:22:06 - INFO - TRAINING - Epoch: [124][0/500]	Time 0.322 (0.322)	Data 0.288 (0.288)	Loss 0.0633 (0.0633)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:22:08 - INFO - TRAINING - Epoch: [124][50/500]	Time 0.055 (0.060)	Data 0.000 (0.006)	Loss 0.0183 (0.0454)	Prec@1 100.000 (98.471)	Prec@5 100.000 (100.000)
2019-05-03 12:22:11 - INFO - TRAINING - Epoch: [124][100/500]	Time 0.055 (0.058)	Data 0.000 (0.004)	Loss 0.0224 (0.0404)	Prec@1 99.000 (98.574)	Prec@5 100.000 (100.000)
2019-05-03 12:22:14 - INFO - TRAINING - Epoch: [124][150/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.0237 (0.0414)	Prec@1 99.000 (98.570)	Prec@5 100.000 (100.000)
2019-05-03 12:22:16 - INFO - TRAINING - Epoch: [124][200/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.0482 (0.0413)	Prec@1 99.000 (98.577)	Prec@5 100.000 (100.000)
2019-05-03 12:22:19 - INFO - TRAINING - Epoch: [124][250/500]	Time 0.065 (0.055)	Data 0.000 (0.002)	Loss 0.0151 (0.0422)	Prec@1 100.000 (98.514)	Prec@5 100.000 (100.000)
2019-05-03 12:22:22 - INFO - TRAINING - Epoch: [124][300/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0415 (0.0420)	Prec@1 99.000 (98.512)	Prec@5 100.000 (99.997)
2019-05-03 12:22:24 - INFO - TRAINING - Epoch: [124][350/500]	Time 0.041 (0.055)	Data 0.000 (0.002)	Loss 0.0199 (0.0406)	Prec@1 100.000 (98.584)	Prec@5 100.000 (99.997)
2019-05-03 12:22:27 - INFO - TRAINING - Epoch: [124][400/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0333 (0.0407)	Prec@1 98.000 (98.574)	Prec@5 100.000 (99.998)
2019-05-03 12:22:30 - INFO - TRAINING - Epoch: [124][450/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.0069 (0.0405)	Prec@1 100.000 (98.601)	Prec@5 100.000 (99.998)
2019-05-03 12:22:33 - INFO - EVALUATING - Epoch: [124][0/100]	Time 0.378 (0.378)	Data 0.369 (0.369)	Loss 0.2272 (0.2272)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:22:34 - INFO - EVALUATING - Epoch: [124][50/100]	Time 0.018 (0.024)	Data 0.000 (0.008)	Loss 0.2070 (0.3897)	Prec@1 94.000 (91.000)	Prec@5 99.000 (99.647)
2019-05-03 12:22:35 - INFO - 
 Epoch: 125	Training Loss 0.0409 	Training Prec@1 98.592 	Training Prec@5 99.998 	Validation Loss 0.3750 	Validation Prec@1 90.970 	Validation Prec@5 99.710 	
2019-05-03 12:22:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:22:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:22:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:22:35 - INFO - TRAINING - Epoch: [125][0/500]	Time 0.292 (0.292)	Data 0.256 (0.256)	Loss 0.0050 (0.0050)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:22:38 - INFO - TRAINING - Epoch: [125][50/500]	Time 0.050 (0.061)	Data 0.000 (0.006)	Loss 0.0333 (0.0323)	Prec@1 99.000 (98.784)	Prec@5 100.000 (100.000)
2019-05-03 12:22:41 - INFO - TRAINING - Epoch: [125][100/500]	Time 0.060 (0.059)	Data 0.000 (0.003)	Loss 0.0238 (0.0365)	Prec@1 99.000 (98.733)	Prec@5 100.000 (100.000)
2019-05-03 12:22:43 - INFO - TRAINING - Epoch: [125][150/500]	Time 0.046 (0.058)	Data 0.000 (0.003)	Loss 0.0751 (0.0375)	Prec@1 97.000 (98.715)	Prec@5 100.000 (100.000)
2019-05-03 12:22:46 - INFO - TRAINING - Epoch: [125][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0374 (0.0392)	Prec@1 99.000 (98.627)	Prec@5 100.000 (100.000)
2019-05-03 12:22:49 - INFO - TRAINING - Epoch: [125][250/500]	Time 0.068 (0.058)	Data 0.000 (0.002)	Loss 0.0356 (0.0387)	Prec@1 99.000 (98.673)	Prec@5 100.000 (99.996)
2019-05-03 12:22:52 - INFO - TRAINING - Epoch: [125][300/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0386 (0.0397)	Prec@1 98.000 (98.611)	Prec@5 100.000 (99.997)
2019-05-03 12:22:55 - INFO - TRAINING - Epoch: [125][350/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.0691 (0.0406)	Prec@1 98.000 (98.593)	Prec@5 100.000 (99.997)
2019-05-03 12:22:58 - INFO - TRAINING - Epoch: [125][400/500]	Time 0.070 (0.057)	Data 0.000 (0.002)	Loss 0.0454 (0.0408)	Prec@1 97.000 (98.586)	Prec@5 100.000 (99.998)
2019-05-03 12:23:01 - INFO - TRAINING - Epoch: [125][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0109 (0.0407)	Prec@1 100.000 (98.603)	Prec@5 100.000 (99.998)
2019-05-03 12:23:04 - INFO - EVALUATING - Epoch: [125][0/100]	Time 0.372 (0.372)	Data 0.358 (0.358)	Loss 0.3603 (0.3603)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:23:05 - INFO - EVALUATING - Epoch: [125][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.2313 (0.3953)	Prec@1 94.000 (90.686)	Prec@5 100.000 (99.490)
2019-05-03 12:23:05 - INFO - 
 Epoch: 126	Training Loss 0.0409 	Training Prec@1 98.598 	Training Prec@5 99.998 	Validation Loss 0.3752 	Validation Prec@1 90.910 	Validation Prec@5 99.590 	
2019-05-03 12:23:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:23:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:23:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:23:06 - INFO - TRAINING - Epoch: [126][0/500]	Time 0.303 (0.303)	Data 0.276 (0.276)	Loss 0.0159 (0.0159)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:23:09 - INFO - TRAINING - Epoch: [126][50/500]	Time 0.056 (0.060)	Data 0.000 (0.006)	Loss 0.0235 (0.0428)	Prec@1 100.000 (98.804)	Prec@5 100.000 (100.000)
2019-05-03 12:23:11 - INFO - TRAINING - Epoch: [126][100/500]	Time 0.055 (0.058)	Data 0.000 (0.004)	Loss 0.0691 (0.0406)	Prec@1 98.000 (98.733)	Prec@5 100.000 (100.000)
2019-05-03 12:23:14 - INFO - TRAINING - Epoch: [126][150/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.0195 (0.0402)	Prec@1 99.000 (98.709)	Prec@5 100.000 (100.000)
2019-05-03 12:23:17 - INFO - TRAINING - Epoch: [126][200/500]	Time 0.059 (0.056)	Data 0.000 (0.002)	Loss 0.0108 (0.0393)	Prec@1 100.000 (98.721)	Prec@5 100.000 (100.000)
2019-05-03 12:23:20 - INFO - TRAINING - Epoch: [126][250/500]	Time 0.049 (0.056)	Data 0.000 (0.002)	Loss 0.0099 (0.0399)	Prec@1 100.000 (98.689)	Prec@5 100.000 (100.000)
2019-05-03 12:23:23 - INFO - TRAINING - Epoch: [126][300/500]	Time 0.057 (0.056)	Data 0.000 (0.002)	Loss 0.0187 (0.0404)	Prec@1 100.000 (98.661)	Prec@5 100.000 (100.000)
2019-05-03 12:23:25 - INFO - TRAINING - Epoch: [126][350/500]	Time 0.057 (0.056)	Data 0.000 (0.002)	Loss 0.0491 (0.0404)	Prec@1 98.000 (98.655)	Prec@5 100.000 (100.000)
2019-05-03 12:23:28 - INFO - TRAINING - Epoch: [126][400/500]	Time 0.069 (0.056)	Data 0.000 (0.002)	Loss 0.0226 (0.0406)	Prec@1 100.000 (98.658)	Prec@5 100.000 (100.000)
2019-05-03 12:23:31 - INFO - TRAINING - Epoch: [126][450/500]	Time 0.054 (0.056)	Data 0.000 (0.001)	Loss 0.0381 (0.0406)	Prec@1 98.000 (98.643)	Prec@5 100.000 (100.000)
2019-05-03 12:23:34 - INFO - EVALUATING - Epoch: [126][0/100]	Time 0.379 (0.379)	Data 0.368 (0.368)	Loss 0.2065 (0.2065)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:23:35 - INFO - EVALUATING - Epoch: [126][50/100]	Time 0.015 (0.025)	Data 0.000 (0.008)	Loss 0.1880 (0.3765)	Prec@1 97.000 (91.118)	Prec@5 99.000 (99.549)
2019-05-03 12:23:36 - INFO - 
 Epoch: 127	Training Loss 0.0403 	Training Prec@1 98.648 	Training Prec@5 100.000 	Validation Loss 0.3656 	Validation Prec@1 90.960 	Validation Prec@5 99.600 	
2019-05-03 12:23:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:23:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:23:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:23:36 - INFO - TRAINING - Epoch: [127][0/500]	Time 0.274 (0.274)	Data 0.250 (0.250)	Loss 0.0709 (0.0709)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:23:39 - INFO - TRAINING - Epoch: [127][50/500]	Time 0.063 (0.061)	Data 0.000 (0.006)	Loss 0.0263 (0.0357)	Prec@1 100.000 (98.863)	Prec@5 100.000 (100.000)
2019-05-03 12:23:42 - INFO - TRAINING - Epoch: [127][100/500]	Time 0.053 (0.059)	Data 0.000 (0.003)	Loss 0.0408 (0.0406)	Prec@1 98.000 (98.743)	Prec@5 100.000 (100.000)
2019-05-03 12:23:45 - INFO - TRAINING - Epoch: [127][150/500]	Time 0.051 (0.058)	Data 0.000 (0.003)	Loss 0.0082 (0.0397)	Prec@1 100.000 (98.675)	Prec@5 100.000 (100.000)
2019-05-03 12:23:48 - INFO - TRAINING - Epoch: [127][200/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0235 (0.0418)	Prec@1 100.000 (98.602)	Prec@5 100.000 (100.000)
2019-05-03 12:23:50 - INFO - TRAINING - Epoch: [127][250/500]	Time 0.054 (0.057)	Data 0.000 (0.002)	Loss 0.0331 (0.0394)	Prec@1 99.000 (98.653)	Prec@5 100.000 (100.000)
2019-05-03 12:23:53 - INFO - TRAINING - Epoch: [127][300/500]	Time 0.048 (0.056)	Data 0.000 (0.002)	Loss 0.0660 (0.0400)	Prec@1 97.000 (98.664)	Prec@5 100.000 (100.000)
2019-05-03 12:23:56 - INFO - TRAINING - Epoch: [127][350/500]	Time 0.058 (0.056)	Data 0.000 (0.002)	Loss 0.0211 (0.0403)	Prec@1 100.000 (98.672)	Prec@5 100.000 (100.000)
2019-05-03 12:23:59 - INFO - TRAINING - Epoch: [127][400/500]	Time 0.049 (0.056)	Data 0.000 (0.002)	Loss 0.0219 (0.0393)	Prec@1 100.000 (98.711)	Prec@5 100.000 (100.000)
2019-05-03 12:24:02 - INFO - TRAINING - Epoch: [127][450/500]	Time 0.052 (0.056)	Data 0.000 (0.001)	Loss 0.0537 (0.0400)	Prec@1 98.000 (98.683)	Prec@5 100.000 (100.000)
2019-05-03 12:24:05 - INFO - EVALUATING - Epoch: [127][0/100]	Time 0.369 (0.369)	Data 0.362 (0.362)	Loss 0.2752 (0.2752)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:24:06 - INFO - EVALUATING - Epoch: [127][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.2122 (0.3669)	Prec@1 93.000 (91.333)	Prec@5 99.000 (99.569)
2019-05-03 12:24:06 - INFO - 
 Epoch: 128	Training Loss 0.0403 	Training Prec@1 98.662 	Training Prec@5 99.998 	Validation Loss 0.3624 	Validation Prec@1 90.990 	Validation Prec@5 99.660 	
2019-05-03 12:24:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:24:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:24:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:24:07 - INFO - TRAINING - Epoch: [128][0/500]	Time 0.297 (0.297)	Data 0.264 (0.264)	Loss 0.0150 (0.0150)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:24:10 - INFO - TRAINING - Epoch: [128][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.0229 (0.0363)	Prec@1 99.000 (98.686)	Prec@5 100.000 (100.000)
2019-05-03 12:24:12 - INFO - TRAINING - Epoch: [128][100/500]	Time 0.061 (0.056)	Data 0.000 (0.003)	Loss 0.0314 (0.0386)	Prec@1 99.000 (98.594)	Prec@5 100.000 (100.000)
2019-05-03 12:24:15 - INFO - TRAINING - Epoch: [128][150/500]	Time 0.039 (0.055)	Data 0.000 (0.002)	Loss 0.0064 (0.0369)	Prec@1 100.000 (98.722)	Prec@5 100.000 (100.000)
2019-05-03 12:24:18 - INFO - TRAINING - Epoch: [128][200/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.0170 (0.0379)	Prec@1 99.000 (98.637)	Prec@5 100.000 (100.000)
2019-05-03 12:24:20 - INFO - TRAINING - Epoch: [128][250/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.0317 (0.0398)	Prec@1 99.000 (98.558)	Prec@5 100.000 (100.000)
2019-05-03 12:24:23 - INFO - TRAINING - Epoch: [128][300/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.0235 (0.0394)	Prec@1 99.000 (98.588)	Prec@5 100.000 (100.000)
2019-05-03 12:24:26 - INFO - TRAINING - Epoch: [128][350/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.0793 (0.0393)	Prec@1 97.000 (98.593)	Prec@5 100.000 (100.000)
2019-05-03 12:24:28 - INFO - TRAINING - Epoch: [128][400/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.0615 (0.0389)	Prec@1 98.000 (98.608)	Prec@5 100.000 (100.000)
2019-05-03 12:24:31 - INFO - TRAINING - Epoch: [128][450/500]	Time 0.044 (0.054)	Data 0.000 (0.001)	Loss 0.0154 (0.0388)	Prec@1 99.000 (98.632)	Prec@5 100.000 (100.000)
2019-05-03 12:24:34 - INFO - EVALUATING - Epoch: [128][0/100]	Time 0.368 (0.368)	Data 0.359 (0.359)	Loss 0.1994 (0.1994)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:24:35 - INFO - EVALUATING - Epoch: [128][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.2662 (0.3936)	Prec@1 92.000 (90.471)	Prec@5 100.000 (99.588)
2019-05-03 12:24:36 - INFO - 
 Epoch: 129	Training Loss 0.0388 	Training Prec@1 98.636 	Training Prec@5 100.000 	Validation Loss 0.3842 	Validation Prec@1 90.740 	Validation Prec@5 99.620 	
2019-05-03 12:24:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:24:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:24:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:24:36 - INFO - TRAINING - Epoch: [129][0/500]	Time 0.308 (0.308)	Data 0.279 (0.279)	Loss 0.1095 (0.1095)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:24:39 - INFO - TRAINING - Epoch: [129][50/500]	Time 0.054 (0.060)	Data 0.000 (0.006)	Loss 0.0440 (0.0398)	Prec@1 99.000 (98.686)	Prec@5 100.000 (100.000)
2019-05-03 12:24:42 - INFO - TRAINING - Epoch: [129][100/500]	Time 0.055 (0.057)	Data 0.000 (0.004)	Loss 0.0061 (0.0442)	Prec@1 100.000 (98.465)	Prec@5 100.000 (99.990)
2019-05-03 12:24:44 - INFO - TRAINING - Epoch: [129][150/500]	Time 0.059 (0.057)	Data 0.000 (0.003)	Loss 0.0123 (0.0426)	Prec@1 100.000 (98.517)	Prec@5 100.000 (99.993)
2019-05-03 12:24:47 - INFO - TRAINING - Epoch: [129][200/500]	Time 0.062 (0.057)	Data 0.000 (0.002)	Loss 0.0692 (0.0409)	Prec@1 98.000 (98.617)	Prec@5 100.000 (99.995)
2019-05-03 12:24:50 - INFO - TRAINING - Epoch: [129][250/500]	Time 0.054 (0.056)	Data 0.000 (0.002)	Loss 0.0218 (0.0406)	Prec@1 100.000 (98.610)	Prec@5 100.000 (99.996)
2019-05-03 12:24:53 - INFO - TRAINING - Epoch: [129][300/500]	Time 0.046 (0.056)	Data 0.000 (0.002)	Loss 0.1040 (0.0404)	Prec@1 98.000 (98.635)	Prec@5 100.000 (99.997)
2019-05-03 12:24:55 - INFO - TRAINING - Epoch: [129][350/500]	Time 0.053 (0.056)	Data 0.000 (0.002)	Loss 0.0076 (0.0407)	Prec@1 100.000 (98.613)	Prec@5 100.000 (99.997)
2019-05-03 12:24:58 - INFO - TRAINING - Epoch: [129][400/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0116 (0.0411)	Prec@1 100.000 (98.584)	Prec@5 100.000 (99.998)
2019-05-03 12:25:01 - INFO - TRAINING - Epoch: [129][450/500]	Time 0.038 (0.055)	Data 0.000 (0.001)	Loss 0.0314 (0.0411)	Prec@1 99.000 (98.599)	Prec@5 100.000 (99.998)
2019-05-03 12:25:04 - INFO - EVALUATING - Epoch: [129][0/100]	Time 0.267 (0.267)	Data 0.252 (0.252)	Loss 0.2260 (0.2260)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:25:04 - INFO - EVALUATING - Epoch: [129][50/100]	Time 0.023 (0.023)	Data 0.000 (0.005)	Loss 0.0857 (0.3612)	Prec@1 96.000 (91.451)	Prec@5 100.000 (99.549)
2019-05-03 12:25:05 - INFO - 
 Epoch: 130	Training Loss 0.0408 	Training Prec@1 98.600 	Training Prec@5 99.998 	Validation Loss 0.3541 	Validation Prec@1 91.360 	Validation Prec@5 99.600 	
2019-05-03 12:25:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:25:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:25:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:25:06 - INFO - TRAINING - Epoch: [130][0/500]	Time 0.271 (0.271)	Data 0.249 (0.249)	Loss 0.0210 (0.0210)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:25:09 - INFO - TRAINING - Epoch: [130][50/500]	Time 0.056 (0.060)	Data 0.000 (0.006)	Loss 0.0174 (0.0361)	Prec@1 99.000 (98.725)	Prec@5 100.000 (99.980)
2019-05-03 12:25:11 - INFO - TRAINING - Epoch: [130][100/500]	Time 0.049 (0.057)	Data 0.000 (0.003)	Loss 0.0388 (0.0380)	Prec@1 99.000 (98.713)	Prec@5 100.000 (99.990)
2019-05-03 12:25:14 - INFO - TRAINING - Epoch: [130][150/500]	Time 0.059 (0.056)	Data 0.000 (0.003)	Loss 0.0465 (0.0366)	Prec@1 98.000 (98.748)	Prec@5 100.000 (99.993)
2019-05-03 12:25:17 - INFO - TRAINING - Epoch: [130][200/500]	Time 0.040 (0.055)	Data 0.000 (0.002)	Loss 0.0293 (0.0358)	Prec@1 99.000 (98.791)	Prec@5 100.000 (99.995)
2019-05-03 12:25:19 - INFO - TRAINING - Epoch: [130][250/500]	Time 0.064 (0.055)	Data 0.000 (0.002)	Loss 0.0106 (0.0364)	Prec@1 100.000 (98.761)	Prec@5 100.000 (99.996)
2019-05-03 12:25:22 - INFO - TRAINING - Epoch: [130][300/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.0265 (0.0361)	Prec@1 100.000 (98.804)	Prec@5 100.000 (99.997)
2019-05-03 12:25:25 - INFO - TRAINING - Epoch: [130][350/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0114 (0.0355)	Prec@1 100.000 (98.815)	Prec@5 100.000 (99.997)
2019-05-03 12:25:27 - INFO - TRAINING - Epoch: [130][400/500]	Time 0.059 (0.055)	Data 0.000 (0.001)	Loss 0.0493 (0.0358)	Prec@1 99.000 (98.813)	Prec@5 100.000 (99.998)
2019-05-03 12:25:30 - INFO - TRAINING - Epoch: [130][450/500]	Time 0.063 (0.055)	Data 0.000 (0.001)	Loss 0.0151 (0.0360)	Prec@1 100.000 (98.794)	Prec@5 100.000 (99.998)
2019-05-03 12:25:33 - INFO - EVALUATING - Epoch: [130][0/100]	Time 0.379 (0.379)	Data 0.365 (0.365)	Loss 0.1808 (0.1808)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:25:34 - INFO - EVALUATING - Epoch: [130][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1009 (0.3873)	Prec@1 95.000 (90.490)	Prec@5 100.000 (99.510)
2019-05-03 12:25:35 - INFO - 
 Epoch: 131	Training Loss 0.0367 	Training Prec@1 98.776 	Training Prec@5 99.996 	Validation Loss 0.3725 	Validation Prec@1 90.790 	Validation Prec@5 99.630 	
2019-05-03 12:25:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:25:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:25:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:25:35 - INFO - TRAINING - Epoch: [131][0/500]	Time 0.267 (0.267)	Data 0.244 (0.244)	Loss 0.0087 (0.0087)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:25:38 - INFO - TRAINING - Epoch: [131][50/500]	Time 0.057 (0.061)	Data 0.000 (0.006)	Loss 0.0073 (0.0334)	Prec@1 100.000 (98.882)	Prec@5 100.000 (100.000)
2019-05-03 12:25:41 - INFO - TRAINING - Epoch: [131][100/500]	Time 0.048 (0.059)	Data 0.000 (0.003)	Loss 0.0503 (0.0344)	Prec@1 98.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-03 12:25:44 - INFO - TRAINING - Epoch: [131][150/500]	Time 0.054 (0.058)	Data 0.000 (0.003)	Loss 0.0396 (0.0351)	Prec@1 99.000 (98.841)	Prec@5 100.000 (100.000)
2019-05-03 12:25:47 - INFO - TRAINING - Epoch: [131][200/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0659 (0.0352)	Prec@1 97.000 (98.811)	Prec@5 100.000 (100.000)
2019-05-03 12:25:50 - INFO - TRAINING - Epoch: [131][250/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0073 (0.0362)	Prec@1 100.000 (98.777)	Prec@5 100.000 (100.000)
2019-05-03 12:25:52 - INFO - TRAINING - Epoch: [131][300/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0419 (0.0367)	Prec@1 98.000 (98.757)	Prec@5 100.000 (100.000)
2019-05-03 12:25:55 - INFO - TRAINING - Epoch: [131][350/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0415 (0.0367)	Prec@1 99.000 (98.758)	Prec@5 100.000 (100.000)
2019-05-03 12:25:58 - INFO - TRAINING - Epoch: [131][400/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0337 (0.0377)	Prec@1 99.000 (98.708)	Prec@5 100.000 (100.000)
2019-05-03 12:26:01 - INFO - TRAINING - Epoch: [131][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0545 (0.0380)	Prec@1 98.000 (98.696)	Prec@5 100.000 (100.000)
2019-05-03 12:26:04 - INFO - EVALUATING - Epoch: [131][0/100]	Time 0.378 (0.378)	Data 0.370 (0.370)	Loss 0.4206 (0.4206)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:26:05 - INFO - EVALUATING - Epoch: [131][50/100]	Time 0.022 (0.026)	Data 0.000 (0.008)	Loss 0.1227 (0.3818)	Prec@1 96.000 (91.020)	Prec@5 100.000 (99.490)
2019-05-03 12:26:06 - INFO - 
 Epoch: 132	Training Loss 0.0376 	Training Prec@1 98.704 	Training Prec@5 100.000 	Validation Loss 0.3645 	Validation Prec@1 91.220 	Validation Prec@5 99.580 	
2019-05-03 12:26:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:26:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:26:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:26:06 - INFO - TRAINING - Epoch: [132][0/500]	Time 0.298 (0.298)	Data 0.271 (0.271)	Loss 0.0618 (0.0618)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:26:09 - INFO - TRAINING - Epoch: [132][50/500]	Time 0.056 (0.058)	Data 0.000 (0.006)	Loss 0.0530 (0.0394)	Prec@1 98.000 (98.647)	Prec@5 100.000 (100.000)
2019-05-03 12:26:12 - INFO - TRAINING - Epoch: [132][100/500]	Time 0.059 (0.056)	Data 0.000 (0.003)	Loss 0.0137 (0.0388)	Prec@1 100.000 (98.624)	Prec@5 100.000 (100.000)
2019-05-03 12:26:14 - INFO - TRAINING - Epoch: [132][150/500]	Time 0.047 (0.055)	Data 0.000 (0.003)	Loss 0.0118 (0.0393)	Prec@1 99.000 (98.623)	Prec@5 100.000 (100.000)
2019-05-03 12:26:17 - INFO - TRAINING - Epoch: [132][200/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.0119 (0.0386)	Prec@1 100.000 (98.642)	Prec@5 100.000 (100.000)
2019-05-03 12:26:20 - INFO - TRAINING - Epoch: [132][250/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0082 (0.0376)	Prec@1 100.000 (98.737)	Prec@5 100.000 (100.000)
2019-05-03 12:26:22 - INFO - TRAINING - Epoch: [132][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0089 (0.0372)	Prec@1 100.000 (98.738)	Prec@5 100.000 (100.000)
2019-05-03 12:26:25 - INFO - TRAINING - Epoch: [132][350/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0083 (0.0372)	Prec@1 100.000 (98.738)	Prec@5 100.000 (100.000)
2019-05-03 12:26:28 - INFO - TRAINING - Epoch: [132][400/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0373 (0.0378)	Prec@1 99.000 (98.726)	Prec@5 100.000 (100.000)
2019-05-03 12:26:31 - INFO - TRAINING - Epoch: [132][450/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.0288 (0.0383)	Prec@1 99.000 (98.707)	Prec@5 100.000 (100.000)
2019-05-03 12:26:33 - INFO - EVALUATING - Epoch: [132][0/100]	Time 0.357 (0.357)	Data 0.347 (0.347)	Loss 0.2546 (0.2546)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:26:34 - INFO - EVALUATING - Epoch: [132][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2343 (0.3916)	Prec@1 94.000 (91.275)	Prec@5 99.000 (99.510)
2019-05-03 12:26:35 - INFO - 
 Epoch: 133	Training Loss 0.0379 	Training Prec@1 98.720 	Training Prec@5 100.000 	Validation Loss 0.3688 	Validation Prec@1 91.440 	Validation Prec@5 99.610 	
2019-05-03 12:26:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:26:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:26:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:26:36 - INFO - TRAINING - Epoch: [133][0/500]	Time 0.287 (0.287)	Data 0.263 (0.263)	Loss 0.0111 (0.0111)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:26:39 - INFO - TRAINING - Epoch: [133][50/500]	Time 0.050 (0.061)	Data 0.000 (0.006)	Loss 0.0430 (0.0379)	Prec@1 98.000 (98.686)	Prec@5 100.000 (100.000)
2019-05-03 12:26:41 - INFO - TRAINING - Epoch: [133][100/500]	Time 0.057 (0.059)	Data 0.000 (0.004)	Loss 0.0127 (0.0367)	Prec@1 100.000 (98.772)	Prec@5 100.000 (100.000)
2019-05-03 12:26:44 - INFO - TRAINING - Epoch: [133][150/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.0254 (0.0363)	Prec@1 99.000 (98.781)	Prec@5 100.000 (100.000)
2019-05-03 12:26:47 - INFO - TRAINING - Epoch: [133][200/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.0058 (0.0357)	Prec@1 100.000 (98.821)	Prec@5 100.000 (100.000)
2019-05-03 12:26:50 - INFO - TRAINING - Epoch: [133][250/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0327 (0.0362)	Prec@1 99.000 (98.777)	Prec@5 100.000 (100.000)
2019-05-03 12:26:53 - INFO - TRAINING - Epoch: [133][300/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0345 (0.0360)	Prec@1 98.000 (98.781)	Prec@5 100.000 (100.000)
2019-05-03 12:26:56 - INFO - TRAINING - Epoch: [133][350/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.0238 (0.0350)	Prec@1 99.000 (98.809)	Prec@5 100.000 (100.000)
2019-05-03 12:26:59 - INFO - TRAINING - Epoch: [133][400/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0711 (0.0360)	Prec@1 98.000 (98.773)	Prec@5 100.000 (100.000)
2019-05-03 12:27:01 - INFO - TRAINING - Epoch: [133][450/500]	Time 0.055 (0.058)	Data 0.000 (0.001)	Loss 0.0613 (0.0357)	Prec@1 98.000 (98.785)	Prec@5 100.000 (100.000)
2019-05-03 12:27:05 - INFO - EVALUATING - Epoch: [133][0/100]	Time 0.361 (0.361)	Data 0.352 (0.352)	Loss 0.2674 (0.2674)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:27:05 - INFO - EVALUATING - Epoch: [133][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3108 (0.3907)	Prec@1 93.000 (91.020)	Prec@5 99.000 (99.392)
2019-05-03 12:27:06 - INFO - 
 Epoch: 134	Training Loss 0.0357 	Training Prec@1 98.790 	Training Prec@5 100.000 	Validation Loss 0.3681 	Validation Prec@1 91.120 	Validation Prec@5 99.520 	
2019-05-03 12:27:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:27:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:27:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:27:07 - INFO - TRAINING - Epoch: [134][0/500]	Time 0.285 (0.285)	Data 0.264 (0.264)	Loss 0.0082 (0.0082)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:27:10 - INFO - TRAINING - Epoch: [134][50/500]	Time 0.059 (0.062)	Data 0.000 (0.006)	Loss 0.0105 (0.0296)	Prec@1 100.000 (99.098)	Prec@5 100.000 (100.000)
2019-05-03 12:27:13 - INFO - TRAINING - Epoch: [134][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0344 (0.0335)	Prec@1 99.000 (98.950)	Prec@5 100.000 (100.000)
2019-05-03 12:27:15 - INFO - TRAINING - Epoch: [134][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0351 (0.0353)	Prec@1 99.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-03 12:27:18 - INFO - TRAINING - Epoch: [134][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0097 (0.0347)	Prec@1 100.000 (98.896)	Prec@5 100.000 (100.000)
2019-05-03 12:27:21 - INFO - TRAINING - Epoch: [134][250/500]	Time 0.067 (0.058)	Data 0.000 (0.002)	Loss 0.1397 (0.0346)	Prec@1 95.000 (98.888)	Prec@5 100.000 (100.000)
2019-05-03 12:27:24 - INFO - TRAINING - Epoch: [134][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0293 (0.0357)	Prec@1 99.000 (98.837)	Prec@5 100.000 (100.000)
2019-05-03 12:27:27 - INFO - TRAINING - Epoch: [134][350/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0302 (0.0363)	Prec@1 99.000 (98.812)	Prec@5 100.000 (100.000)
2019-05-03 12:27:29 - INFO - TRAINING - Epoch: [134][400/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0310 (0.0369)	Prec@1 98.000 (98.776)	Prec@5 100.000 (100.000)
2019-05-03 12:27:32 - INFO - TRAINING - Epoch: [134][450/500]	Time 0.068 (0.057)	Data 0.000 (0.001)	Loss 0.0161 (0.0364)	Prec@1 99.000 (98.787)	Prec@5 100.000 (100.000)
2019-05-03 12:27:35 - INFO - EVALUATING - Epoch: [134][0/100]	Time 0.371 (0.371)	Data 0.364 (0.364)	Loss 0.2109 (0.2109)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:27:36 - INFO - EVALUATING - Epoch: [134][50/100]	Time 0.016 (0.024)	Data 0.000 (0.008)	Loss 0.1876 (0.3697)	Prec@1 94.000 (91.078)	Prec@5 100.000 (99.569)
2019-05-03 12:27:37 - INFO - 
 Epoch: 135	Training Loss 0.0365 	Training Prec@1 98.764 	Training Prec@5 100.000 	Validation Loss 0.3611 	Validation Prec@1 91.140 	Validation Prec@5 99.620 	
2019-05-03 12:27:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:27:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:27:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:27:38 - INFO - TRAINING - Epoch: [135][0/500]	Time 0.285 (0.285)	Data 0.260 (0.260)	Loss 0.0109 (0.0109)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:27:40 - INFO - TRAINING - Epoch: [135][50/500]	Time 0.045 (0.057)	Data 0.000 (0.006)	Loss 0.0369 (0.0348)	Prec@1 97.000 (98.784)	Prec@5 100.000 (100.000)
2019-05-03 12:27:43 - INFO - TRAINING - Epoch: [135][100/500]	Time 0.038 (0.055)	Data 0.000 (0.003)	Loss 0.0355 (0.0327)	Prec@1 99.000 (98.762)	Prec@5 100.000 (100.000)
2019-05-03 12:27:46 - INFO - TRAINING - Epoch: [135][150/500]	Time 0.057 (0.055)	Data 0.000 (0.003)	Loss 0.0670 (0.0313)	Prec@1 97.000 (98.841)	Prec@5 100.000 (100.000)
2019-05-03 12:27:48 - INFO - TRAINING - Epoch: [135][200/500]	Time 0.068 (0.054)	Data 0.000 (0.002)	Loss 0.0238 (0.0322)	Prec@1 98.000 (98.831)	Prec@5 100.000 (100.000)
2019-05-03 12:27:51 - INFO - TRAINING - Epoch: [135][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0840 (0.0346)	Prec@1 98.000 (98.749)	Prec@5 100.000 (100.000)
2019-05-03 12:27:54 - INFO - TRAINING - Epoch: [135][300/500]	Time 0.057 (0.054)	Data 0.000 (0.002)	Loss 0.0563 (0.0357)	Prec@1 98.000 (98.704)	Prec@5 100.000 (100.000)
2019-05-03 12:27:56 - INFO - TRAINING - Epoch: [135][350/500]	Time 0.041 (0.054)	Data 0.000 (0.002)	Loss 0.0421 (0.0356)	Prec@1 99.000 (98.715)	Prec@5 100.000 (100.000)
2019-05-03 12:27:59 - INFO - TRAINING - Epoch: [135][400/500]	Time 0.059 (0.054)	Data 0.000 (0.001)	Loss 0.0098 (0.0363)	Prec@1 100.000 (98.681)	Prec@5 100.000 (100.000)
2019-05-03 12:28:02 - INFO - TRAINING - Epoch: [135][450/500]	Time 0.044 (0.054)	Data 0.000 (0.001)	Loss 0.0227 (0.0370)	Prec@1 99.000 (98.665)	Prec@5 100.000 (100.000)
2019-05-03 12:28:05 - INFO - EVALUATING - Epoch: [135][0/100]	Time 0.380 (0.380)	Data 0.367 (0.367)	Loss 0.1929 (0.1929)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:28:05 - INFO - EVALUATING - Epoch: [135][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1345 (0.3792)	Prec@1 94.000 (90.804)	Prec@5 100.000 (99.510)
2019-05-03 12:28:06 - INFO - 
 Epoch: 136	Training Loss 0.0366 	Training Prec@1 98.682 	Training Prec@5 100.000 	Validation Loss 0.3587 	Validation Prec@1 91.310 	Validation Prec@5 99.580 	
2019-05-03 12:28:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:28:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:28:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:28:07 - INFO - TRAINING - Epoch: [136][0/500]	Time 0.290 (0.290)	Data 0.264 (0.264)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:28:10 - INFO - TRAINING - Epoch: [136][50/500]	Time 0.067 (0.061)	Data 0.000 (0.006)	Loss 0.0799 (0.0379)	Prec@1 98.000 (98.725)	Prec@5 100.000 (100.000)
2019-05-03 12:28:12 - INFO - TRAINING - Epoch: [136][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.0090 (0.0393)	Prec@1 100.000 (98.733)	Prec@5 100.000 (100.000)
2019-05-03 12:28:15 - INFO - TRAINING - Epoch: [136][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0104 (0.0371)	Prec@1 100.000 (98.795)	Prec@5 100.000 (100.000)
2019-05-03 12:28:18 - INFO - TRAINING - Epoch: [136][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0050 (0.0359)	Prec@1 100.000 (98.831)	Prec@5 100.000 (99.995)
2019-05-03 12:28:21 - INFO - TRAINING - Epoch: [136][250/500]	Time 0.069 (0.058)	Data 0.000 (0.002)	Loss 0.0157 (0.0354)	Prec@1 100.000 (98.865)	Prec@5 100.000 (99.992)
2019-05-03 12:28:24 - INFO - TRAINING - Epoch: [136][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0673 (0.0361)	Prec@1 97.000 (98.824)	Prec@5 100.000 (99.993)
2019-05-03 12:28:27 - INFO - TRAINING - Epoch: [136][350/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0312 (0.0357)	Prec@1 99.000 (98.840)	Prec@5 100.000 (99.994)
2019-05-03 12:28:30 - INFO - TRAINING - Epoch: [136][400/500]	Time 0.054 (0.057)	Data 0.000 (0.001)	Loss 0.0392 (0.0361)	Prec@1 98.000 (98.823)	Prec@5 100.000 (99.995)
2019-05-03 12:28:32 - INFO - TRAINING - Epoch: [136][450/500]	Time 0.062 (0.057)	Data 0.000 (0.001)	Loss 0.1069 (0.0356)	Prec@1 97.000 (98.834)	Prec@5 100.000 (99.996)
2019-05-03 12:28:36 - INFO - EVALUATING - Epoch: [136][0/100]	Time 0.375 (0.375)	Data 0.363 (0.363)	Loss 0.1924 (0.1924)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:28:36 - INFO - EVALUATING - Epoch: [136][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.2165 (0.3782)	Prec@1 94.000 (90.961)	Prec@5 100.000 (99.510)
2019-05-03 12:28:37 - INFO - 
 Epoch: 137	Training Loss 0.0353 	Training Prec@1 98.840 	Training Prec@5 99.996 	Validation Loss 0.3713 	Validation Prec@1 91.050 	Validation Prec@5 99.600 	
2019-05-03 12:28:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:28:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:28:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:28:38 - INFO - TRAINING - Epoch: [137][0/500]	Time 0.291 (0.291)	Data 0.264 (0.264)	Loss 0.0198 (0.0198)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:28:40 - INFO - TRAINING - Epoch: [137][50/500]	Time 0.061 (0.058)	Data 0.000 (0.006)	Loss 0.0380 (0.0384)	Prec@1 99.000 (98.745)	Prec@5 100.000 (100.000)
2019-05-03 12:28:43 - INFO - TRAINING - Epoch: [137][100/500]	Time 0.062 (0.056)	Data 0.000 (0.003)	Loss 0.0145 (0.0370)	Prec@1 100.000 (98.772)	Prec@5 100.000 (100.000)
2019-05-03 12:28:46 - INFO - TRAINING - Epoch: [137][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0255 (0.0362)	Prec@1 99.000 (98.815)	Prec@5 100.000 (100.000)
2019-05-03 12:28:49 - INFO - TRAINING - Epoch: [137][200/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0129 (0.0348)	Prec@1 100.000 (98.826)	Prec@5 100.000 (100.000)
2019-05-03 12:28:51 - INFO - TRAINING - Epoch: [137][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0525 (0.0344)	Prec@1 99.000 (98.833)	Prec@5 100.000 (100.000)
2019-05-03 12:28:54 - INFO - TRAINING - Epoch: [137][300/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.0471 (0.0344)	Prec@1 98.000 (98.831)	Prec@5 100.000 (100.000)
2019-05-03 12:28:57 - INFO - TRAINING - Epoch: [137][350/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.0320 (0.0346)	Prec@1 98.000 (98.829)	Prec@5 100.000 (100.000)
2019-05-03 12:28:59 - INFO - TRAINING - Epoch: [137][400/500]	Time 0.041 (0.054)	Data 0.000 (0.001)	Loss 0.0514 (0.0343)	Prec@1 99.000 (98.850)	Prec@5 100.000 (100.000)
2019-05-03 12:29:02 - INFO - TRAINING - Epoch: [137][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0115 (0.0348)	Prec@1 100.000 (98.851)	Prec@5 100.000 (99.998)
2019-05-03 12:29:05 - INFO - EVALUATING - Epoch: [137][0/100]	Time 0.383 (0.383)	Data 0.372 (0.372)	Loss 0.1830 (0.1830)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:29:06 - INFO - EVALUATING - Epoch: [137][50/100]	Time 0.011 (0.025)	Data 0.000 (0.008)	Loss 0.3109 (0.3866)	Prec@1 90.000 (91.176)	Prec@5 99.000 (99.451)
2019-05-03 12:29:07 - INFO - 
 Epoch: 138	Training Loss 0.0350 	Training Prec@1 98.848 	Training Prec@5 99.998 	Validation Loss 0.3684 	Validation Prec@1 91.320 	Validation Prec@5 99.600 	
2019-05-03 12:29:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:29:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:29:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:29:07 - INFO - TRAINING - Epoch: [138][0/500]	Time 0.265 (0.265)	Data 0.240 (0.240)	Loss 0.0847 (0.0847)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:29:10 - INFO - TRAINING - Epoch: [138][50/500]	Time 0.070 (0.061)	Data 0.000 (0.005)	Loss 0.0429 (0.0369)	Prec@1 99.000 (98.843)	Prec@5 100.000 (100.000)
2019-05-03 12:29:13 - INFO - TRAINING - Epoch: [138][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0194 (0.0367)	Prec@1 100.000 (98.842)	Prec@5 100.000 (100.000)
2019-05-03 12:29:16 - INFO - TRAINING - Epoch: [138][150/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0642 (0.0357)	Prec@1 98.000 (98.821)	Prec@5 100.000 (100.000)
2019-05-03 12:29:18 - INFO - TRAINING - Epoch: [138][200/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0212 (0.0358)	Prec@1 100.000 (98.806)	Prec@5 100.000 (100.000)
2019-05-03 12:29:21 - INFO - TRAINING - Epoch: [138][250/500]	Time 0.069 (0.058)	Data 0.000 (0.002)	Loss 0.0134 (0.0367)	Prec@1 100.000 (98.733)	Prec@5 100.000 (100.000)
2019-05-03 12:29:24 - INFO - TRAINING - Epoch: [138][300/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0344 (0.0364)	Prec@1 99.000 (98.734)	Prec@5 100.000 (100.000)
2019-05-03 12:29:27 - INFO - TRAINING - Epoch: [138][350/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0083 (0.0361)	Prec@1 100.000 (98.732)	Prec@5 100.000 (100.000)
2019-05-03 12:29:30 - INFO - TRAINING - Epoch: [138][400/500]	Time 0.062 (0.058)	Data 0.000 (0.001)	Loss 0.0096 (0.0361)	Prec@1 100.000 (98.738)	Prec@5 100.000 (99.998)
2019-05-03 12:29:33 - INFO - TRAINING - Epoch: [138][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0161 (0.0360)	Prec@1 100.000 (98.741)	Prec@5 100.000 (99.998)
2019-05-03 12:29:36 - INFO - EVALUATING - Epoch: [138][0/100]	Time 0.380 (0.380)	Data 0.366 (0.366)	Loss 0.2720 (0.2720)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:29:37 - INFO - EVALUATING - Epoch: [138][50/100]	Time 0.014 (0.025)	Data 0.000 (0.008)	Loss 0.1263 (0.3758)	Prec@1 97.000 (90.980)	Prec@5 100.000 (99.529)
2019-05-03 12:29:38 - INFO - 
 Epoch: 139	Training Loss 0.0367 	Training Prec@1 98.720 	Training Prec@5 99.998 	Validation Loss 0.3713 	Validation Prec@1 90.930 	Validation Prec@5 99.590 	
2019-05-03 12:29:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:29:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:29:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:29:38 - INFO - TRAINING - Epoch: [139][0/500]	Time 0.251 (0.251)	Data 0.219 (0.219)	Loss 0.0822 (0.0822)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:29:41 - INFO - TRAINING - Epoch: [139][50/500]	Time 0.063 (0.060)	Data 0.000 (0.005)	Loss 0.0350 (0.0375)	Prec@1 99.000 (98.843)	Prec@5 100.000 (100.000)
2019-05-03 12:29:44 - INFO - TRAINING - Epoch: [139][100/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.0094 (0.0364)	Prec@1 100.000 (98.772)	Prec@5 100.000 (100.000)
2019-05-03 12:29:47 - INFO - TRAINING - Epoch: [139][150/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0927 (0.0357)	Prec@1 98.000 (98.834)	Prec@5 100.000 (100.000)
2019-05-03 12:29:49 - INFO - TRAINING - Epoch: [139][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.1009 (0.0359)	Prec@1 97.000 (98.846)	Prec@5 100.000 (100.000)
2019-05-03 12:29:52 - INFO - TRAINING - Epoch: [139][250/500]	Time 0.053 (0.057)	Data 0.000 (0.002)	Loss 0.0112 (0.0354)	Prec@1 100.000 (98.829)	Prec@5 100.000 (100.000)
2019-05-03 12:29:55 - INFO - TRAINING - Epoch: [139][300/500]	Time 0.054 (0.057)	Data 0.000 (0.002)	Loss 0.0481 (0.0351)	Prec@1 98.000 (98.837)	Prec@5 100.000 (100.000)
2019-05-03 12:29:58 - INFO - TRAINING - Epoch: [139][350/500]	Time 0.053 (0.057)	Data 0.000 (0.001)	Loss 0.0072 (0.0348)	Prec@1 100.000 (98.832)	Prec@5 100.000 (100.000)
2019-05-03 12:30:01 - INFO - TRAINING - Epoch: [139][400/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0740 (0.0358)	Prec@1 97.000 (98.776)	Prec@5 100.000 (100.000)
2019-05-03 12:30:03 - INFO - TRAINING - Epoch: [139][450/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0325 (0.0363)	Prec@1 99.000 (98.741)	Prec@5 100.000 (100.000)
2019-05-03 12:30:07 - INFO - EVALUATING - Epoch: [139][0/100]	Time 0.386 (0.386)	Data 0.373 (0.373)	Loss 0.1871 (0.1871)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:30:07 - INFO - EVALUATING - Epoch: [139][50/100]	Time 0.018 (0.024)	Data 0.000 (0.008)	Loss 0.2552 (0.3704)	Prec@1 91.000 (91.078)	Prec@5 100.000 (99.647)
2019-05-03 12:30:08 - INFO - 
 Epoch: 140	Training Loss 0.0367 	Training Prec@1 98.740 	Training Prec@5 100.000 	Validation Loss 0.3536 	Validation Prec@1 91.080 	Validation Prec@5 99.650 	
2019-05-03 12:30:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:30:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:30:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:30:09 - INFO - TRAINING - Epoch: [140][0/500]	Time 0.304 (0.304)	Data 0.277 (0.277)	Loss 0.0186 (0.0186)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:30:11 - INFO - TRAINING - Epoch: [140][50/500]	Time 0.059 (0.058)	Data 0.000 (0.006)	Loss 0.0741 (0.0406)	Prec@1 97.000 (98.588)	Prec@5 100.000 (99.980)
2019-05-03 12:30:14 - INFO - TRAINING - Epoch: [140][100/500]	Time 0.056 (0.056)	Data 0.000 (0.004)	Loss 0.0186 (0.0367)	Prec@1 99.000 (98.723)	Prec@5 100.000 (99.990)
2019-05-03 12:30:17 - INFO - TRAINING - Epoch: [140][150/500]	Time 0.055 (0.055)	Data 0.000 (0.003)	Loss 0.0536 (0.0350)	Prec@1 98.000 (98.735)	Prec@5 100.000 (99.993)
2019-05-03 12:30:19 - INFO - TRAINING - Epoch: [140][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0237 (0.0348)	Prec@1 100.000 (98.746)	Prec@5 100.000 (99.995)
2019-05-03 12:30:22 - INFO - TRAINING - Epoch: [140][250/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0310 (0.0345)	Prec@1 99.000 (98.753)	Prec@5 100.000 (99.996)
2019-05-03 12:30:25 - INFO - TRAINING - Epoch: [140][300/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.0313 (0.0356)	Prec@1 98.000 (98.718)	Prec@5 100.000 (99.993)
2019-05-03 12:30:28 - INFO - TRAINING - Epoch: [140][350/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0211 (0.0356)	Prec@1 100.000 (98.721)	Prec@5 100.000 (99.994)
2019-05-03 12:30:30 - INFO - TRAINING - Epoch: [140][400/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0817 (0.0352)	Prec@1 95.000 (98.751)	Prec@5 100.000 (99.995)
2019-05-03 12:30:33 - INFO - TRAINING - Epoch: [140][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0579 (0.0347)	Prec@1 98.000 (98.778)	Prec@5 100.000 (99.996)
2019-05-03 12:30:36 - INFO - EVALUATING - Epoch: [140][0/100]	Time 0.363 (0.363)	Data 0.347 (0.347)	Loss 0.2170 (0.2170)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:30:37 - INFO - EVALUATING - Epoch: [140][50/100]	Time 0.022 (0.024)	Data 0.000 (0.007)	Loss 0.2543 (0.3846)	Prec@1 93.000 (91.196)	Prec@5 100.000 (99.569)
2019-05-03 12:30:38 - INFO - 
 Epoch: 141	Training Loss 0.0354 	Training Prec@1 98.760 	Training Prec@5 99.996 	Validation Loss 0.3619 	Validation Prec@1 91.360 	Validation Prec@5 99.640 	
2019-05-03 12:30:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:30:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:30:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:30:38 - INFO - TRAINING - Epoch: [141][0/500]	Time 0.282 (0.282)	Data 0.258 (0.258)	Loss 0.0141 (0.0141)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:30:41 - INFO - TRAINING - Epoch: [141][50/500]	Time 0.055 (0.062)	Data 0.000 (0.006)	Loss 0.0159 (0.0215)	Prec@1 100.000 (99.392)	Prec@5 100.000 (100.000)
2019-05-03 12:30:44 - INFO - TRAINING - Epoch: [141][100/500]	Time 0.055 (0.059)	Data 0.000 (0.003)	Loss 0.0235 (0.0293)	Prec@1 99.000 (99.089)	Prec@5 100.000 (100.000)
2019-05-03 12:30:47 - INFO - TRAINING - Epoch: [141][150/500]	Time 0.052 (0.058)	Data 0.000 (0.003)	Loss 0.0117 (0.0306)	Prec@1 100.000 (99.013)	Prec@5 100.000 (100.000)
2019-05-03 12:30:49 - INFO - TRAINING - Epoch: [141][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0074 (0.0324)	Prec@1 100.000 (98.955)	Prec@5 100.000 (100.000)
2019-05-03 12:30:52 - INFO - TRAINING - Epoch: [141][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0367 (0.0322)	Prec@1 99.000 (98.976)	Prec@5 100.000 (100.000)
2019-05-03 12:30:55 - INFO - TRAINING - Epoch: [141][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0236 (0.0328)	Prec@1 99.000 (98.924)	Prec@5 100.000 (100.000)
2019-05-03 12:30:58 - INFO - TRAINING - Epoch: [141][350/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0380 (0.0322)	Prec@1 99.000 (98.926)	Prec@5 100.000 (100.000)
2019-05-03 12:31:01 - INFO - TRAINING - Epoch: [141][400/500]	Time 0.063 (0.058)	Data 0.000 (0.001)	Loss 0.0637 (0.0331)	Prec@1 98.000 (98.888)	Prec@5 100.000 (100.000)
2019-05-03 12:31:04 - INFO - TRAINING - Epoch: [141][450/500]	Time 0.066 (0.058)	Data 0.000 (0.001)	Loss 0.0758 (0.0335)	Prec@1 97.000 (98.874)	Prec@5 100.000 (100.000)
2019-05-03 12:31:07 - INFO - EVALUATING - Epoch: [141][0/100]	Time 0.258 (0.258)	Data 0.243 (0.243)	Loss 0.2731 (0.2731)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:31:08 - INFO - EVALUATING - Epoch: [141][50/100]	Time 0.019 (0.022)	Data 0.000 (0.005)	Loss 0.3074 (0.4072)	Prec@1 91.000 (91.020)	Prec@5 100.000 (99.569)
2019-05-03 12:31:08 - INFO - 
 Epoch: 142	Training Loss 0.0340 	Training Prec@1 98.864 	Training Prec@5 100.000 	Validation Loss 0.3840 	Validation Prec@1 91.090 	Validation Prec@5 99.630 	
2019-05-03 12:31:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:31:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:31:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:31:09 - INFO - TRAINING - Epoch: [142][0/500]	Time 0.286 (0.286)	Data 0.253 (0.253)	Loss 0.0455 (0.0455)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:31:12 - INFO - TRAINING - Epoch: [142][50/500]	Time 0.049 (0.058)	Data 0.000 (0.006)	Loss 0.0084 (0.0342)	Prec@1 100.000 (98.882)	Prec@5 100.000 (100.000)
2019-05-03 12:31:14 - INFO - TRAINING - Epoch: [142][100/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.0256 (0.0373)	Prec@1 99.000 (98.752)	Prec@5 100.000 (100.000)
2019-05-03 12:31:17 - INFO - TRAINING - Epoch: [142][150/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0032 (0.0354)	Prec@1 100.000 (98.821)	Prec@5 100.000 (100.000)
2019-05-03 12:31:20 - INFO - TRAINING - Epoch: [142][200/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.1094 (0.0360)	Prec@1 95.000 (98.781)	Prec@5 100.000 (100.000)
2019-05-03 12:31:22 - INFO - TRAINING - Epoch: [142][250/500]	Time 0.046 (0.055)	Data 0.000 (0.002)	Loss 0.0068 (0.0357)	Prec@1 100.000 (98.817)	Prec@5 100.000 (100.000)
2019-05-03 12:31:25 - INFO - TRAINING - Epoch: [142][300/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0081 (0.0343)	Prec@1 100.000 (98.870)	Prec@5 100.000 (100.000)
2019-05-03 12:31:28 - INFO - TRAINING - Epoch: [142][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0171 (0.0347)	Prec@1 100.000 (98.872)	Prec@5 100.000 (100.000)
2019-05-03 12:31:30 - INFO - TRAINING - Epoch: [142][400/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.0586 (0.0348)	Prec@1 99.000 (98.848)	Prec@5 100.000 (100.000)
2019-05-03 12:31:33 - INFO - TRAINING - Epoch: [142][450/500]	Time 0.064 (0.054)	Data 0.000 (0.001)	Loss 0.0325 (0.0343)	Prec@1 99.000 (98.851)	Prec@5 100.000 (100.000)
2019-05-03 12:31:36 - INFO - EVALUATING - Epoch: [142][0/100]	Time 0.289 (0.289)	Data 0.279 (0.279)	Loss 0.2465 (0.2465)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:31:37 - INFO - EVALUATING - Epoch: [142][50/100]	Time 0.016 (0.023)	Data 0.000 (0.006)	Loss 0.2610 (0.3889)	Prec@1 92.000 (90.941)	Prec@5 100.000 (99.451)
2019-05-03 12:31:38 - INFO - 
 Epoch: 143	Training Loss 0.0342 	Training Prec@1 98.854 	Training Prec@5 100.000 	Validation Loss 0.3702 	Validation Prec@1 91.000 	Validation Prec@5 99.560 	
2019-05-03 12:31:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:31:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:31:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:31:38 - INFO - TRAINING - Epoch: [143][0/500]	Time 0.279 (0.279)	Data 0.257 (0.257)	Loss 0.0377 (0.0377)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:31:41 - INFO - TRAINING - Epoch: [143][50/500]	Time 0.057 (0.059)	Data 0.000 (0.006)	Loss 0.0102 (0.0334)	Prec@1 100.000 (98.804)	Prec@5 100.000 (100.000)
2019-05-03 12:31:44 - INFO - TRAINING - Epoch: [143][100/500]	Time 0.044 (0.056)	Data 0.000 (0.003)	Loss 0.0282 (0.0345)	Prec@1 99.000 (98.851)	Prec@5 100.000 (100.000)
2019-05-03 12:31:46 - INFO - TRAINING - Epoch: [143][150/500]	Time 0.055 (0.055)	Data 0.000 (0.003)	Loss 0.0085 (0.0333)	Prec@1 100.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-03 12:31:49 - INFO - TRAINING - Epoch: [143][200/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0577 (0.0319)	Prec@1 99.000 (98.930)	Prec@5 100.000 (100.000)
2019-05-03 12:31:52 - INFO - TRAINING - Epoch: [143][250/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.0352 (0.0317)	Prec@1 99.000 (98.936)	Prec@5 100.000 (100.000)
2019-05-03 12:31:54 - INFO - TRAINING - Epoch: [143][300/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.0167 (0.0324)	Prec@1 100.000 (98.907)	Prec@5 100.000 (100.000)
2019-05-03 12:31:57 - INFO - TRAINING - Epoch: [143][350/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0396 (0.0318)	Prec@1 99.000 (98.926)	Prec@5 100.000 (100.000)
2019-05-03 12:32:00 - INFO - TRAINING - Epoch: [143][400/500]	Time 0.042 (0.054)	Data 0.000 (0.002)	Loss 0.0682 (0.0320)	Prec@1 98.000 (98.925)	Prec@5 100.000 (100.000)
2019-05-03 12:32:02 - INFO - TRAINING - Epoch: [143][450/500]	Time 0.061 (0.054)	Data 0.000 (0.001)	Loss 0.0242 (0.0320)	Prec@1 99.000 (98.918)	Prec@5 100.000 (100.000)
2019-05-03 12:32:05 - INFO - EVALUATING - Epoch: [143][0/100]	Time 0.363 (0.363)	Data 0.351 (0.351)	Loss 0.2627 (0.2627)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:32:06 - INFO - EVALUATING - Epoch: [143][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1900 (0.3782)	Prec@1 94.000 (91.294)	Prec@5 100.000 (99.510)
2019-05-03 12:32:07 - INFO - 
 Epoch: 144	Training Loss 0.0324 	Training Prec@1 98.900 	Training Prec@5 100.000 	Validation Loss 0.3638 	Validation Prec@1 91.340 	Validation Prec@5 99.600 	
2019-05-03 12:32:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:32:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:32:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:32:08 - INFO - TRAINING - Epoch: [144][0/500]	Time 0.289 (0.289)	Data 0.263 (0.263)	Loss 0.0232 (0.0232)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:32:11 - INFO - TRAINING - Epoch: [144][50/500]	Time 0.058 (0.061)	Data 0.000 (0.006)	Loss 0.0241 (0.0296)	Prec@1 99.000 (99.020)	Prec@5 100.000 (100.000)
2019-05-03 12:32:13 - INFO - TRAINING - Epoch: [144][100/500]	Time 0.065 (0.059)	Data 0.000 (0.003)	Loss 0.0400 (0.0373)	Prec@1 98.000 (98.752)	Prec@5 100.000 (100.000)
2019-05-03 12:32:16 - INFO - TRAINING - Epoch: [144][150/500]	Time 0.070 (0.059)	Data 0.000 (0.003)	Loss 0.0048 (0.0342)	Prec@1 100.000 (98.854)	Prec@5 100.000 (100.000)
2019-05-03 12:32:19 - INFO - TRAINING - Epoch: [144][200/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.0074 (0.0317)	Prec@1 100.000 (98.930)	Prec@5 100.000 (100.000)
2019-05-03 12:32:22 - INFO - TRAINING - Epoch: [144][250/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.1584 (0.0324)	Prec@1 97.000 (98.876)	Prec@5 100.000 (100.000)
2019-05-03 12:32:25 - INFO - TRAINING - Epoch: [144][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0127 (0.0327)	Prec@1 100.000 (98.877)	Prec@5 100.000 (100.000)
2019-05-03 12:32:28 - INFO - TRAINING - Epoch: [144][350/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0239 (0.0337)	Prec@1 100.000 (98.846)	Prec@5 100.000 (100.000)
2019-05-03 12:32:31 - INFO - TRAINING - Epoch: [144][400/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0053 (0.0343)	Prec@1 100.000 (98.840)	Prec@5 100.000 (100.000)
2019-05-03 12:32:33 - INFO - TRAINING - Epoch: [144][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0171 (0.0341)	Prec@1 100.000 (98.825)	Prec@5 100.000 (100.000)
2019-05-03 12:32:37 - INFO - EVALUATING - Epoch: [144][0/100]	Time 0.371 (0.371)	Data 0.352 (0.352)	Loss 0.2170 (0.2170)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:32:37 - INFO - EVALUATING - Epoch: [144][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1837 (0.3823)	Prec@1 93.000 (91.039)	Prec@5 100.000 (99.490)
2019-05-03 12:32:38 - INFO - 
 Epoch: 145	Training Loss 0.0340 	Training Prec@1 98.828 	Training Prec@5 100.000 	Validation Loss 0.3708 	Validation Prec@1 91.070 	Validation Prec@5 99.620 	
2019-05-03 12:32:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:32:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:32:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:32:39 - INFO - TRAINING - Epoch: [145][0/500]	Time 0.288 (0.288)	Data 0.253 (0.253)	Loss 0.0186 (0.0186)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:32:42 - INFO - TRAINING - Epoch: [145][50/500]	Time 0.044 (0.058)	Data 0.000 (0.006)	Loss 0.0040 (0.0354)	Prec@1 100.000 (98.686)	Prec@5 100.000 (100.000)
2019-05-03 12:32:44 - INFO - TRAINING - Epoch: [145][100/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.0172 (0.0325)	Prec@1 100.000 (98.733)	Prec@5 100.000 (100.000)
2019-05-03 12:32:47 - INFO - TRAINING - Epoch: [145][150/500]	Time 0.056 (0.055)	Data 0.000 (0.002)	Loss 0.0347 (0.0323)	Prec@1 98.000 (98.742)	Prec@5 100.000 (100.000)
2019-05-03 12:32:50 - INFO - TRAINING - Epoch: [145][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0527 (0.0321)	Prec@1 98.000 (98.811)	Prec@5 100.000 (100.000)
2019-05-03 12:32:52 - INFO - TRAINING - Epoch: [145][250/500]	Time 0.066 (0.054)	Data 0.000 (0.002)	Loss 0.0131 (0.0307)	Prec@1 99.000 (98.865)	Prec@5 100.000 (100.000)
2019-05-03 12:32:55 - INFO - TRAINING - Epoch: [145][300/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.0690 (0.0312)	Prec@1 97.000 (98.874)	Prec@5 100.000 (100.000)
2019-05-03 12:32:58 - INFO - TRAINING - Epoch: [145][350/500]	Time 0.057 (0.054)	Data 0.000 (0.002)	Loss 0.0409 (0.0312)	Prec@1 99.000 (98.858)	Prec@5 100.000 (100.000)
2019-05-03 12:33:00 - INFO - TRAINING - Epoch: [145][400/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.0414 (0.0314)	Prec@1 99.000 (98.878)	Prec@5 100.000 (100.000)
2019-05-03 12:33:03 - INFO - TRAINING - Epoch: [145][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0527 (0.0315)	Prec@1 98.000 (98.885)	Prec@5 100.000 (100.000)
2019-05-03 12:33:06 - INFO - EVALUATING - Epoch: [145][0/100]	Time 0.368 (0.368)	Data 0.362 (0.362)	Loss 0.2629 (0.2629)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:33:07 - INFO - EVALUATING - Epoch: [145][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.1817 (0.4035)	Prec@1 96.000 (90.882)	Prec@5 100.000 (99.549)
2019-05-03 12:33:08 - INFO - 
 Epoch: 146	Training Loss 0.0322 	Training Prec@1 98.860 	Training Prec@5 99.998 	Validation Loss 0.3829 	Validation Prec@1 90.880 	Validation Prec@5 99.650 	
2019-05-03 12:33:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:33:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:33:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:33:08 - INFO - TRAINING - Epoch: [146][0/500]	Time 0.284 (0.284)	Data 0.254 (0.254)	Loss 0.0320 (0.0320)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:33:11 - INFO - TRAINING - Epoch: [146][50/500]	Time 0.053 (0.061)	Data 0.000 (0.006)	Loss 0.0275 (0.0251)	Prec@1 99.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:33:14 - INFO - TRAINING - Epoch: [146][100/500]	Time 0.063 (0.059)	Data 0.000 (0.003)	Loss 0.0025 (0.0315)	Prec@1 100.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:33:17 - INFO - TRAINING - Epoch: [146][150/500]	Time 0.058 (0.058)	Data 0.000 (0.003)	Loss 0.0306 (0.0328)	Prec@1 100.000 (98.887)	Prec@5 100.000 (100.000)
2019-05-03 12:33:20 - INFO - TRAINING - Epoch: [146][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0175 (0.0325)	Prec@1 99.000 (98.905)	Prec@5 100.000 (100.000)
2019-05-03 12:33:22 - INFO - TRAINING - Epoch: [146][250/500]	Time 0.042 (0.058)	Data 0.000 (0.002)	Loss 0.0336 (0.0323)	Prec@1 99.000 (98.928)	Prec@5 100.000 (100.000)
2019-05-03 12:33:25 - INFO - TRAINING - Epoch: [146][300/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.0147 (0.0326)	Prec@1 100.000 (98.927)	Prec@5 100.000 (100.000)
2019-05-03 12:33:28 - INFO - TRAINING - Epoch: [146][350/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0047 (0.0326)	Prec@1 100.000 (98.932)	Prec@5 100.000 (100.000)
2019-05-03 12:33:31 - INFO - TRAINING - Epoch: [146][400/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.0113 (0.0329)	Prec@1 100.000 (98.943)	Prec@5 100.000 (100.000)
2019-05-03 12:33:34 - INFO - TRAINING - Epoch: [146][450/500]	Time 0.049 (0.057)	Data 0.000 (0.001)	Loss 0.0416 (0.0327)	Prec@1 98.000 (98.949)	Prec@5 100.000 (100.000)
2019-05-03 12:33:37 - INFO - EVALUATING - Epoch: [146][0/100]	Time 0.367 (0.367)	Data 0.353 (0.353)	Loss 0.2120 (0.2120)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:33:38 - INFO - EVALUATING - Epoch: [146][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.2038 (0.3885)	Prec@1 94.000 (91.157)	Prec@5 100.000 (99.667)
2019-05-03 12:33:39 - INFO - 
 Epoch: 147	Training Loss 0.0329 	Training Prec@1 98.942 	Training Prec@5 100.000 	Validation Loss 0.3734 	Validation Prec@1 91.210 	Validation Prec@5 99.720 	
2019-05-03 12:33:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:33:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:33:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:33:39 - INFO - TRAINING - Epoch: [147][0/500]	Time 0.274 (0.274)	Data 0.244 (0.244)	Loss 0.0117 (0.0117)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:33:42 - INFO - TRAINING - Epoch: [147][50/500]	Time 0.050 (0.060)	Data 0.000 (0.005)	Loss 0.0702 (0.0260)	Prec@1 96.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-03 12:33:45 - INFO - TRAINING - Epoch: [147][100/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0436 (0.0311)	Prec@1 96.000 (98.921)	Prec@5 100.000 (100.000)
2019-05-03 12:33:48 - INFO - TRAINING - Epoch: [147][150/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0116 (0.0305)	Prec@1 100.000 (98.901)	Prec@5 100.000 (100.000)
2019-05-03 12:33:50 - INFO - TRAINING - Epoch: [147][200/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0262 (0.0306)	Prec@1 99.000 (98.935)	Prec@5 100.000 (100.000)
2019-05-03 12:33:53 - INFO - TRAINING - Epoch: [147][250/500]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 0.0343 (0.0316)	Prec@1 99.000 (98.892)	Prec@5 100.000 (100.000)
2019-05-03 12:33:56 - INFO - TRAINING - Epoch: [147][300/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0258 (0.0312)	Prec@1 100.000 (98.940)	Prec@5 100.000 (100.000)
2019-05-03 12:33:59 - INFO - TRAINING - Epoch: [147][350/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0284 (0.0309)	Prec@1 99.000 (98.940)	Prec@5 100.000 (99.997)
2019-05-03 12:34:02 - INFO - TRAINING - Epoch: [147][400/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0237 (0.0308)	Prec@1 100.000 (98.948)	Prec@5 100.000 (99.998)
2019-05-03 12:34:05 - INFO - TRAINING - Epoch: [147][450/500]	Time 0.062 (0.057)	Data 0.000 (0.001)	Loss 0.0191 (0.0313)	Prec@1 99.000 (98.927)	Prec@5 100.000 (99.998)
2019-05-03 12:34:08 - INFO - EVALUATING - Epoch: [147][0/100]	Time 0.374 (0.374)	Data 0.360 (0.360)	Loss 0.2106 (0.2106)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:34:09 - INFO - EVALUATING - Epoch: [147][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.2682 (0.3909)	Prec@1 94.000 (90.922)	Prec@5 100.000 (99.569)
2019-05-03 12:34:09 - INFO - 
 Epoch: 148	Training Loss 0.0317 	Training Prec@1 98.918 	Training Prec@5 99.998 	Validation Loss 0.3771 	Validation Prec@1 90.910 	Validation Prec@5 99.600 	
2019-05-03 12:34:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:34:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:34:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:34:10 - INFO - TRAINING - Epoch: [148][0/500]	Time 0.281 (0.281)	Data 0.244 (0.244)	Loss 0.0081 (0.0081)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:34:13 - INFO - TRAINING - Epoch: [148][50/500]	Time 0.058 (0.060)	Data 0.000 (0.005)	Loss 0.0048 (0.0276)	Prec@1 100.000 (99.020)	Prec@5 100.000 (100.000)
2019-05-03 12:34:15 - INFO - TRAINING - Epoch: [148][100/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.0093 (0.0269)	Prec@1 99.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:34:18 - INFO - TRAINING - Epoch: [148][150/500]	Time 0.038 (0.056)	Data 0.000 (0.002)	Loss 0.0032 (0.0291)	Prec@1 100.000 (99.060)	Prec@5 100.000 (100.000)
2019-05-03 12:34:21 - INFO - TRAINING - Epoch: [148][200/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.0156 (0.0299)	Prec@1 100.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:34:23 - INFO - TRAINING - Epoch: [148][250/500]	Time 0.058 (0.055)	Data 0.000 (0.002)	Loss 0.0265 (0.0297)	Prec@1 99.000 (99.044)	Prec@5 100.000 (100.000)
2019-05-03 12:34:26 - INFO - TRAINING - Epoch: [148][300/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0065 (0.0310)	Prec@1 100.000 (99.010)	Prec@5 100.000 (99.997)
2019-05-03 12:34:29 - INFO - TRAINING - Epoch: [148][350/500]	Time 0.060 (0.055)	Data 0.000 (0.001)	Loss 0.0285 (0.0311)	Prec@1 99.000 (98.986)	Prec@5 100.000 (99.997)
2019-05-03 12:34:31 - INFO - TRAINING - Epoch: [148][400/500]	Time 0.042 (0.055)	Data 0.000 (0.001)	Loss 0.0358 (0.0313)	Prec@1 98.000 (98.963)	Prec@5 100.000 (99.998)
2019-05-03 12:34:34 - INFO - TRAINING - Epoch: [148][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0123 (0.0315)	Prec@1 100.000 (98.967)	Prec@5 100.000 (99.998)
2019-05-03 12:34:37 - INFO - EVALUATING - Epoch: [148][0/100]	Time 0.360 (0.360)	Data 0.350 (0.350)	Loss 0.2581 (0.2581)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:34:38 - INFO - EVALUATING - Epoch: [148][50/100]	Time 0.020 (0.024)	Data 0.000 (0.007)	Loss 0.3122 (0.3916)	Prec@1 92.000 (90.941)	Prec@5 99.000 (99.549)
2019-05-03 12:34:39 - INFO - 
 Epoch: 149	Training Loss 0.0317 	Training Prec@1 98.958 	Training Prec@5 99.998 	Validation Loss 0.3809 	Validation Prec@1 91.060 	Validation Prec@5 99.620 	
2019-05-03 12:34:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:34:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:34:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:34:39 - INFO - TRAINING - Epoch: [149][0/500]	Time 0.293 (0.293)	Data 0.266 (0.266)	Loss 0.0048 (0.0048)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:34:42 - INFO - TRAINING - Epoch: [149][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.0197 (0.0274)	Prec@1 99.000 (99.098)	Prec@5 100.000 (100.000)
2019-05-03 12:34:45 - INFO - TRAINING - Epoch: [149][100/500]	Time 0.055 (0.056)	Data 0.000 (0.003)	Loss 0.0425 (0.0280)	Prec@1 98.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:34:47 - INFO - TRAINING - Epoch: [149][150/500]	Time 0.055 (0.055)	Data 0.000 (0.003)	Loss 0.0066 (0.0296)	Prec@1 100.000 (99.033)	Prec@5 100.000 (100.000)
2019-05-03 12:34:50 - INFO - TRAINING - Epoch: [149][200/500]	Time 0.069 (0.055)	Data 0.000 (0.002)	Loss 0.0172 (0.0301)	Prec@1 100.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:34:53 - INFO - TRAINING - Epoch: [149][250/500]	Time 0.068 (0.055)	Data 0.000 (0.002)	Loss 0.0090 (0.0307)	Prec@1 100.000 (98.956)	Prec@5 100.000 (100.000)
2019-05-03 12:34:55 - INFO - TRAINING - Epoch: [149][300/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.0539 (0.0305)	Prec@1 98.000 (98.987)	Prec@5 100.000 (100.000)
2019-05-03 12:34:58 - INFO - TRAINING - Epoch: [149][350/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0078 (0.0306)	Prec@1 100.000 (99.003)	Prec@5 100.000 (100.000)
2019-05-03 12:35:01 - INFO - TRAINING - Epoch: [149][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.0138 (0.0310)	Prec@1 100.000 (98.978)	Prec@5 100.000 (100.000)
2019-05-03 12:35:03 - INFO - TRAINING - Epoch: [149][450/500]	Time 0.047 (0.054)	Data 0.000 (0.001)	Loss 0.0276 (0.0312)	Prec@1 100.000 (98.978)	Prec@5 100.000 (100.000)
2019-05-03 12:35:06 - INFO - EVALUATING - Epoch: [149][0/100]	Time 0.386 (0.386)	Data 0.373 (0.373)	Loss 0.2288 (0.2288)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:35:07 - INFO - EVALUATING - Epoch: [149][50/100]	Time 0.018 (0.026)	Data 0.000 (0.008)	Loss 0.2293 (0.3975)	Prec@1 95.000 (91.137)	Prec@5 100.000 (99.529)
2019-05-03 12:35:08 - INFO - 
 Epoch: 150	Training Loss 0.0312 	Training Prec@1 98.968 	Training Prec@5 100.000 	Validation Loss 0.3843 	Validation Prec@1 90.940 	Validation Prec@5 99.580 	
2019-05-03 12:35:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:35:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:35:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:35:09 - INFO - TRAINING - Epoch: [150][0/500]	Time 0.311 (0.311)	Data 0.286 (0.286)	Loss 0.0260 (0.0260)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:35:12 - INFO - TRAINING - Epoch: [150][50/500]	Time 0.057 (0.059)	Data 0.000 (0.006)	Loss 0.0705 (0.0358)	Prec@1 98.000 (98.941)	Prec@5 100.000 (100.000)
2019-05-03 12:35:14 - INFO - TRAINING - Epoch: [150][100/500]	Time 0.053 (0.056)	Data 0.000 (0.004)	Loss 0.0093 (0.0339)	Prec@1 100.000 (98.871)	Prec@5 100.000 (100.000)
2019-05-03 12:35:17 - INFO - TRAINING - Epoch: [150][150/500]	Time 0.056 (0.056)	Data 0.000 (0.003)	Loss 0.0252 (0.0356)	Prec@1 99.000 (98.854)	Prec@5 100.000 (100.000)
2019-05-03 12:35:20 - INFO - TRAINING - Epoch: [150][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0335 (0.0336)	Prec@1 99.000 (98.891)	Prec@5 100.000 (99.995)
2019-05-03 12:35:22 - INFO - TRAINING - Epoch: [150][250/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0371 (0.0330)	Prec@1 98.000 (98.892)	Prec@5 100.000 (99.996)
2019-05-03 12:35:25 - INFO - TRAINING - Epoch: [150][300/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0615 (0.0332)	Prec@1 97.000 (98.890)	Prec@5 100.000 (99.997)
2019-05-03 12:35:28 - INFO - TRAINING - Epoch: [150][350/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.0418 (0.0338)	Prec@1 99.000 (98.872)	Prec@5 100.000 (99.997)
2019-05-03 12:35:30 - INFO - TRAINING - Epoch: [150][400/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0904 (0.0332)	Prec@1 97.000 (98.880)	Prec@5 100.000 (99.998)
2019-05-03 12:35:33 - INFO - TRAINING - Epoch: [150][450/500]	Time 0.065 (0.055)	Data 0.000 (0.001)	Loss 0.0809 (0.0329)	Prec@1 96.000 (98.880)	Prec@5 100.000 (99.998)
2019-05-03 12:35:37 - INFO - EVALUATING - Epoch: [150][0/100]	Time 0.446 (0.446)	Data 0.435 (0.435)	Loss 0.2092 (0.2092)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:35:37 - INFO - EVALUATING - Epoch: [150][50/100]	Time 0.014 (0.027)	Data 0.000 (0.009)	Loss 0.1823 (0.3930)	Prec@1 94.000 (91.118)	Prec@5 100.000 (99.608)
2019-05-03 12:35:38 - INFO - 
 Epoch: 151	Training Loss 0.0328 	Training Prec@1 98.876 	Training Prec@5 99.998 	Validation Loss 0.3805 	Validation Prec@1 91.010 	Validation Prec@5 99.640 	
2019-05-03 12:35:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:35:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:35:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:35:39 - INFO - TRAINING - Epoch: [151][0/500]	Time 0.303 (0.303)	Data 0.274 (0.274)	Loss 0.0058 (0.0058)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:35:42 - INFO - TRAINING - Epoch: [151][50/500]	Time 0.045 (0.061)	Data 0.000 (0.006)	Loss 0.0093 (0.0244)	Prec@1 100.000 (99.235)	Prec@5 100.000 (100.000)
2019-05-03 12:35:44 - INFO - TRAINING - Epoch: [151][100/500]	Time 0.056 (0.058)	Data 0.000 (0.004)	Loss 0.0477 (0.0284)	Prec@1 98.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:35:47 - INFO - TRAINING - Epoch: [151][150/500]	Time 0.061 (0.058)	Data 0.000 (0.003)	Loss 0.0083 (0.0287)	Prec@1 100.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:35:50 - INFO - TRAINING - Epoch: [151][200/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0747 (0.0296)	Prec@1 97.000 (98.995)	Prec@5 100.000 (100.000)
2019-05-03 12:35:53 - INFO - TRAINING - Epoch: [151][250/500]	Time 0.049 (0.057)	Data 0.000 (0.002)	Loss 0.0288 (0.0302)	Prec@1 99.000 (98.968)	Prec@5 100.000 (100.000)
2019-05-03 12:35:56 - INFO - TRAINING - Epoch: [151][300/500]	Time 0.071 (0.057)	Data 0.000 (0.002)	Loss 0.0939 (0.0295)	Prec@1 95.000 (98.983)	Prec@5 100.000 (100.000)
2019-05-03 12:35:59 - INFO - TRAINING - Epoch: [151][350/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.0165 (0.0301)	Prec@1 99.000 (98.957)	Prec@5 100.000 (100.000)
2019-05-03 12:36:02 - INFO - TRAINING - Epoch: [151][400/500]	Time 0.051 (0.057)	Data 0.000 (0.002)	Loss 0.0344 (0.0300)	Prec@1 99.000 (98.963)	Prec@5 100.000 (100.000)
2019-05-03 12:36:04 - INFO - TRAINING - Epoch: [151][450/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0495 (0.0308)	Prec@1 98.000 (98.933)	Prec@5 100.000 (100.000)
2019-05-03 12:36:07 - INFO - EVALUATING - Epoch: [151][0/100]	Time 0.360 (0.360)	Data 0.347 (0.347)	Loss 0.2539 (0.2539)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:36:08 - INFO - EVALUATING - Epoch: [151][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3063 (0.3926)	Prec@1 92.000 (90.784)	Prec@5 100.000 (99.490)
2019-05-03 12:36:09 - INFO - 
 Epoch: 152	Training Loss 0.0307 	Training Prec@1 98.936 	Training Prec@5 100.000 	Validation Loss 0.3802 	Validation Prec@1 90.970 	Validation Prec@5 99.650 	
2019-05-03 12:36:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:36:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:36:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:36:10 - INFO - TRAINING - Epoch: [152][0/500]	Time 0.268 (0.268)	Data 0.238 (0.238)	Loss 0.0155 (0.0155)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:36:12 - INFO - TRAINING - Epoch: [152][50/500]	Time 0.049 (0.057)	Data 0.000 (0.005)	Loss 0.0160 (0.0325)	Prec@1 100.000 (98.922)	Prec@5 100.000 (100.000)
2019-05-03 12:36:15 - INFO - TRAINING - Epoch: [152][100/500]	Time 0.050 (0.056)	Data 0.000 (0.003)	Loss 0.0141 (0.0307)	Prec@1 100.000 (98.941)	Prec@5 100.000 (100.000)
2019-05-03 12:36:18 - INFO - TRAINING - Epoch: [152][150/500]	Time 0.061 (0.055)	Data 0.000 (0.002)	Loss 0.0072 (0.0297)	Prec@1 100.000 (98.974)	Prec@5 100.000 (100.000)
2019-05-03 12:36:20 - INFO - TRAINING - Epoch: [152][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0237 (0.0308)	Prec@1 99.000 (98.940)	Prec@5 100.000 (100.000)
2019-05-03 12:36:23 - INFO - TRAINING - Epoch: [152][250/500]	Time 0.044 (0.054)	Data 0.000 (0.002)	Loss 0.0278 (0.0317)	Prec@1 99.000 (98.924)	Prec@5 100.000 (100.000)
2019-05-03 12:36:26 - INFO - TRAINING - Epoch: [152][300/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0351 (0.0328)	Prec@1 99.000 (98.877)	Prec@5 100.000 (100.000)
2019-05-03 12:36:28 - INFO - TRAINING - Epoch: [152][350/500]	Time 0.039 (0.054)	Data 0.000 (0.002)	Loss 0.0702 (0.0329)	Prec@1 98.000 (98.883)	Prec@5 100.000 (100.000)
2019-05-03 12:36:31 - INFO - TRAINING - Epoch: [152][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0021 (0.0319)	Prec@1 100.000 (98.903)	Prec@5 100.000 (100.000)
2019-05-03 12:36:34 - INFO - TRAINING - Epoch: [152][450/500]	Time 0.041 (0.054)	Data 0.000 (0.001)	Loss 0.0170 (0.0313)	Prec@1 100.000 (98.927)	Prec@5 100.000 (100.000)
2019-05-03 12:36:37 - INFO - EVALUATING - Epoch: [152][0/100]	Time 0.383 (0.383)	Data 0.373 (0.373)	Loss 0.4111 (0.4111)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 12:36:38 - INFO - EVALUATING - Epoch: [152][50/100]	Time 0.019 (0.025)	Data 0.000 (0.008)	Loss 0.3250 (0.3940)	Prec@1 92.000 (91.255)	Prec@5 100.000 (99.529)
2019-05-03 12:36:39 - INFO - 
 Epoch: 153	Training Loss 0.0310 	Training Prec@1 98.940 	Training Prec@5 100.000 	Validation Loss 0.3786 	Validation Prec@1 91.260 	Validation Prec@5 99.610 	
2019-05-03 12:36:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:36:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:36:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:36:39 - INFO - TRAINING - Epoch: [153][0/500]	Time 0.291 (0.291)	Data 0.267 (0.267)	Loss 0.0188 (0.0188)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:36:42 - INFO - TRAINING - Epoch: [153][50/500]	Time 0.044 (0.061)	Data 0.000 (0.006)	Loss 0.0156 (0.0307)	Prec@1 100.000 (98.922)	Prec@5 100.000 (100.000)
2019-05-03 12:36:45 - INFO - TRAINING - Epoch: [153][100/500]	Time 0.057 (0.059)	Data 0.000 (0.004)	Loss 0.0311 (0.0283)	Prec@1 99.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:36:48 - INFO - TRAINING - Epoch: [153][150/500]	Time 0.053 (0.058)	Data 0.000 (0.003)	Loss 0.0673 (0.0296)	Prec@1 97.000 (99.033)	Prec@5 100.000 (100.000)
2019-05-03 12:36:50 - INFO - TRAINING - Epoch: [153][200/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0058 (0.0307)	Prec@1 100.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:36:53 - INFO - TRAINING - Epoch: [153][250/500]	Time 0.069 (0.057)	Data 0.000 (0.002)	Loss 0.0117 (0.0304)	Prec@1 99.000 (98.976)	Prec@5 100.000 (100.000)
2019-05-03 12:36:56 - INFO - TRAINING - Epoch: [153][300/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0033 (0.0301)	Prec@1 100.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:36:59 - INFO - TRAINING - Epoch: [153][350/500]	Time 0.062 (0.057)	Data 0.000 (0.002)	Loss 0.0462 (0.0310)	Prec@1 98.000 (98.963)	Prec@5 100.000 (100.000)
2019-05-03 12:37:01 - INFO - TRAINING - Epoch: [153][400/500]	Time 0.052 (0.056)	Data 0.000 (0.002)	Loss 0.0393 (0.0306)	Prec@1 99.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:37:04 - INFO - TRAINING - Epoch: [153][450/500]	Time 0.038 (0.056)	Data 0.000 (0.001)	Loss 0.0107 (0.0304)	Prec@1 100.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:37:07 - INFO - EVALUATING - Epoch: [153][0/100]	Time 0.267 (0.267)	Data 0.259 (0.259)	Loss 0.2387 (0.2387)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:37:08 - INFO - EVALUATING - Epoch: [153][50/100]	Time 0.017 (0.023)	Data 0.000 (0.005)	Loss 0.1767 (0.3778)	Prec@1 93.000 (91.118)	Prec@5 100.000 (99.412)
2019-05-03 12:37:09 - INFO - 
 Epoch: 154	Training Loss 0.0303 	Training Prec@1 98.964 	Training Prec@5 100.000 	Validation Loss 0.3723 	Validation Prec@1 91.200 	Validation Prec@5 99.510 	
2019-05-03 12:37:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:37:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:37:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:37:09 - INFO - TRAINING - Epoch: [154][0/500]	Time 0.282 (0.282)	Data 0.248 (0.248)	Loss 0.0096 (0.0096)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:37:12 - INFO - TRAINING - Epoch: [154][50/500]	Time 0.050 (0.061)	Data 0.000 (0.006)	Loss 0.0628 (0.0325)	Prec@1 98.000 (98.882)	Prec@5 100.000 (100.000)
2019-05-03 12:37:15 - INFO - TRAINING - Epoch: [154][100/500]	Time 0.050 (0.059)	Data 0.000 (0.003)	Loss 0.0461 (0.0324)	Prec@1 98.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-03 12:37:18 - INFO - TRAINING - Epoch: [154][150/500]	Time 0.070 (0.058)	Data 0.000 (0.003)	Loss 0.0700 (0.0350)	Prec@1 97.000 (98.815)	Prec@5 100.000 (100.000)
2019-05-03 12:37:21 - INFO - TRAINING - Epoch: [154][200/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0208 (0.0329)	Prec@1 99.000 (98.925)	Prec@5 100.000 (100.000)
2019-05-03 12:37:23 - INFO - TRAINING - Epoch: [154][250/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0306 (0.0329)	Prec@1 99.000 (98.916)	Prec@5 100.000 (100.000)
2019-05-03 12:37:26 - INFO - TRAINING - Epoch: [154][300/500]	Time 0.054 (0.057)	Data 0.000 (0.002)	Loss 0.0051 (0.0320)	Prec@1 100.000 (98.950)	Prec@5 100.000 (100.000)
2019-05-03 12:37:29 - INFO - TRAINING - Epoch: [154][350/500]	Time 0.043 (0.057)	Data 0.000 (0.002)	Loss 0.0185 (0.0321)	Prec@1 100.000 (98.934)	Prec@5 100.000 (100.000)
2019-05-03 12:37:32 - INFO - TRAINING - Epoch: [154][400/500]	Time 0.044 (0.057)	Data 0.000 (0.002)	Loss 0.0154 (0.0316)	Prec@1 99.000 (98.955)	Prec@5 100.000 (100.000)
2019-05-03 12:37:35 - INFO - TRAINING - Epoch: [154][450/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0344 (0.0311)	Prec@1 99.000 (98.965)	Prec@5 100.000 (100.000)
2019-05-03 12:37:38 - INFO - EVALUATING - Epoch: [154][0/100]	Time 0.342 (0.342)	Data 0.333 (0.333)	Loss 0.2681 (0.2681)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:37:39 - INFO - EVALUATING - Epoch: [154][50/100]	Time 0.017 (0.024)	Data 0.000 (0.007)	Loss 0.1860 (0.3940)	Prec@1 95.000 (90.941)	Prec@5 100.000 (99.569)
2019-05-03 12:37:40 - INFO - 
 Epoch: 155	Training Loss 0.0314 	Training Prec@1 98.946 	Training Prec@5 100.000 	Validation Loss 0.3710 	Validation Prec@1 91.270 	Validation Prec@5 99.650 	
2019-05-03 12:37:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:37:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:37:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:37:40 - INFO - TRAINING - Epoch: [155][0/500]	Time 0.274 (0.274)	Data 0.253 (0.253)	Loss 0.0059 (0.0059)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:37:43 - INFO - TRAINING - Epoch: [155][50/500]	Time 0.068 (0.058)	Data 0.000 (0.006)	Loss 0.0340 (0.0277)	Prec@1 99.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:37:46 - INFO - TRAINING - Epoch: [155][100/500]	Time 0.058 (0.056)	Data 0.000 (0.003)	Loss 0.0143 (0.0279)	Prec@1 100.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:37:48 - INFO - TRAINING - Epoch: [155][150/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0460 (0.0286)	Prec@1 97.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:37:51 - INFO - TRAINING - Epoch: [155][200/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0152 (0.0298)	Prec@1 99.000 (99.030)	Prec@5 100.000 (99.995)
2019-05-03 12:37:54 - INFO - TRAINING - Epoch: [155][250/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0100 (0.0301)	Prec@1 100.000 (99.028)	Prec@5 100.000 (99.996)
2019-05-03 12:37:56 - INFO - TRAINING - Epoch: [155][300/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0218 (0.0318)	Prec@1 99.000 (98.983)	Prec@5 100.000 (99.997)
2019-05-03 12:37:59 - INFO - TRAINING - Epoch: [155][350/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0256 (0.0315)	Prec@1 98.000 (98.977)	Prec@5 100.000 (99.997)
2019-05-03 12:38:02 - INFO - TRAINING - Epoch: [155][400/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.0230 (0.0305)	Prec@1 99.000 (99.005)	Prec@5 100.000 (99.998)
2019-05-03 12:38:04 - INFO - TRAINING - Epoch: [155][450/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.0101 (0.0305)	Prec@1 100.000 (99.011)	Prec@5 100.000 (99.998)
2019-05-03 12:38:07 - INFO - EVALUATING - Epoch: [155][0/100]	Time 0.392 (0.392)	Data 0.383 (0.383)	Loss 0.2677 (0.2677)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:38:08 - INFO - EVALUATING - Epoch: [155][50/100]	Time 0.018 (0.026)	Data 0.000 (0.008)	Loss 0.1753 (0.3982)	Prec@1 93.000 (90.843)	Prec@5 100.000 (99.549)
2019-05-03 12:38:09 - INFO - 
 Epoch: 156	Training Loss 0.0312 	Training Prec@1 98.994 	Training Prec@5 99.998 	Validation Loss 0.3686 	Validation Prec@1 91.170 	Validation Prec@5 99.620 	
2019-05-03 12:38:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:38:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:38:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:38:09 - INFO - TRAINING - Epoch: [156][0/500]	Time 0.284 (0.284)	Data 0.254 (0.254)	Loss 0.0600 (0.0600)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:38:12 - INFO - TRAINING - Epoch: [156][50/500]	Time 0.064 (0.061)	Data 0.000 (0.006)	Loss 0.0073 (0.0261)	Prec@1 100.000 (99.078)	Prec@5 100.000 (100.000)
2019-05-03 12:38:15 - INFO - TRAINING - Epoch: [156][100/500]	Time 0.072 (0.059)	Data 0.000 (0.003)	Loss 0.0351 (0.0284)	Prec@1 99.000 (99.030)	Prec@5 100.000 (100.000)
2019-05-03 12:38:18 - INFO - TRAINING - Epoch: [156][150/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0207 (0.0289)	Prec@1 99.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:38:21 - INFO - TRAINING - Epoch: [156][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0145 (0.0297)	Prec@1 100.000 (98.970)	Prec@5 100.000 (100.000)
2019-05-03 12:38:24 - INFO - TRAINING - Epoch: [156][250/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.0265 (0.0303)	Prec@1 99.000 (98.976)	Prec@5 100.000 (100.000)
2019-05-03 12:38:27 - INFO - TRAINING - Epoch: [156][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0027 (0.0303)	Prec@1 100.000 (98.993)	Prec@5 100.000 (100.000)
2019-05-03 12:38:29 - INFO - TRAINING - Epoch: [156][350/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0152 (0.0304)	Prec@1 100.000 (98.997)	Prec@5 100.000 (100.000)
2019-05-03 12:38:32 - INFO - TRAINING - Epoch: [156][400/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0112 (0.0309)	Prec@1 100.000 (98.975)	Prec@5 100.000 (100.000)
2019-05-03 12:38:35 - INFO - TRAINING - Epoch: [156][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0083 (0.0309)	Prec@1 100.000 (98.953)	Prec@5 100.000 (100.000)
2019-05-03 12:38:38 - INFO - EVALUATING - Epoch: [156][0/100]	Time 0.361 (0.361)	Data 0.345 (0.345)	Loss 0.1465 (0.1465)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:38:39 - INFO - EVALUATING - Epoch: [156][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.2040 (0.4032)	Prec@1 95.000 (90.765)	Prec@5 100.000 (99.490)
2019-05-03 12:38:40 - INFO - 
 Epoch: 157	Training Loss 0.0304 	Training Prec@1 98.980 	Training Prec@5 100.000 	Validation Loss 0.3803 	Validation Prec@1 91.180 	Validation Prec@5 99.540 	
2019-05-03 12:38:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:38:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:38:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:38:41 - INFO - TRAINING - Epoch: [157][0/500]	Time 0.296 (0.296)	Data 0.273 (0.273)	Loss 0.0334 (0.0334)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:38:43 - INFO - TRAINING - Epoch: [157][50/500]	Time 0.047 (0.058)	Data 0.000 (0.006)	Loss 0.0309 (0.0284)	Prec@1 99.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:38:46 - INFO - TRAINING - Epoch: [157][100/500]	Time 0.063 (0.056)	Data 0.000 (0.004)	Loss 0.0118 (0.0288)	Prec@1 99.000 (99.010)	Prec@5 100.000 (100.000)
2019-05-03 12:38:49 - INFO - TRAINING - Epoch: [157][150/500]	Time 0.059 (0.055)	Data 0.000 (0.003)	Loss 0.0222 (0.0299)	Prec@1 99.000 (98.954)	Prec@5 100.000 (100.000)
2019-05-03 12:38:51 - INFO - TRAINING - Epoch: [157][200/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0235 (0.0307)	Prec@1 99.000 (98.935)	Prec@5 100.000 (100.000)
2019-05-03 12:38:54 - INFO - TRAINING - Epoch: [157][250/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0213 (0.0314)	Prec@1 99.000 (98.896)	Prec@5 100.000 (100.000)
2019-05-03 12:38:57 - INFO - TRAINING - Epoch: [157][300/500]	Time 0.065 (0.055)	Data 0.000 (0.002)	Loss 0.0040 (0.0300)	Prec@1 100.000 (98.953)	Prec@5 100.000 (100.000)
2019-05-03 12:39:00 - INFO - TRAINING - Epoch: [157][350/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0230 (0.0301)	Prec@1 99.000 (98.957)	Prec@5 100.000 (100.000)
2019-05-03 12:39:02 - INFO - TRAINING - Epoch: [157][400/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0016 (0.0296)	Prec@1 100.000 (98.990)	Prec@5 100.000 (100.000)
2019-05-03 12:39:05 - INFO - TRAINING - Epoch: [157][450/500]	Time 0.041 (0.055)	Data 0.000 (0.001)	Loss 0.0338 (0.0302)	Prec@1 99.000 (98.989)	Prec@5 100.000 (100.000)
2019-05-03 12:39:08 - INFO - EVALUATING - Epoch: [157][0/100]	Time 0.366 (0.366)	Data 0.356 (0.356)	Loss 0.1744 (0.1744)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:39:09 - INFO - EVALUATING - Epoch: [157][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2229 (0.3970)	Prec@1 94.000 (90.902)	Prec@5 99.000 (99.588)
2019-05-03 12:39:10 - INFO - 
 Epoch: 158	Training Loss 0.0304 	Training Prec@1 98.972 	Training Prec@5 100.000 	Validation Loss 0.3762 	Validation Prec@1 91.200 	Validation Prec@5 99.660 	
2019-05-03 12:39:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:39:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:39:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:39:11 - INFO - TRAINING - Epoch: [158][0/500]	Time 0.283 (0.283)	Data 0.252 (0.252)	Loss 0.0272 (0.0272)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:39:13 - INFO - TRAINING - Epoch: [158][50/500]	Time 0.054 (0.061)	Data 0.000 (0.006)	Loss 0.0453 (0.0279)	Prec@1 98.000 (99.078)	Prec@5 100.000 (100.000)
2019-05-03 12:39:16 - INFO - TRAINING - Epoch: [158][100/500]	Time 0.048 (0.059)	Data 0.000 (0.003)	Loss 0.0336 (0.0284)	Prec@1 98.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:39:19 - INFO - TRAINING - Epoch: [158][150/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0160 (0.0274)	Prec@1 99.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:39:22 - INFO - TRAINING - Epoch: [158][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0689 (0.0289)	Prec@1 99.000 (99.025)	Prec@5 100.000 (100.000)
2019-05-03 12:39:25 - INFO - TRAINING - Epoch: [158][250/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0182 (0.0292)	Prec@1 100.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:39:28 - INFO - TRAINING - Epoch: [158][300/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0208 (0.0295)	Prec@1 99.000 (99.040)	Prec@5 100.000 (100.000)
2019-05-03 12:39:30 - INFO - TRAINING - Epoch: [158][350/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0502 (0.0292)	Prec@1 98.000 (99.031)	Prec@5 100.000 (100.000)
2019-05-03 12:39:33 - INFO - TRAINING - Epoch: [158][400/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0020 (0.0297)	Prec@1 100.000 (99.022)	Prec@5 100.000 (100.000)
2019-05-03 12:39:36 - INFO - TRAINING - Epoch: [158][450/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.0222 (0.0296)	Prec@1 99.000 (99.024)	Prec@5 100.000 (99.998)
2019-05-03 12:39:39 - INFO - EVALUATING - Epoch: [158][0/100]	Time 0.367 (0.367)	Data 0.356 (0.356)	Loss 0.1504 (0.1504)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:39:40 - INFO - EVALUATING - Epoch: [158][50/100]	Time 0.011 (0.024)	Data 0.000 (0.007)	Loss 0.3315 (0.3916)	Prec@1 91.000 (90.765)	Prec@5 100.000 (99.549)
2019-05-03 12:39:41 - INFO - 
 Epoch: 159	Training Loss 0.0299 	Training Prec@1 99.020 	Training Prec@5 99.998 	Validation Loss 0.3772 	Validation Prec@1 90.930 	Validation Prec@5 99.600 	
2019-05-03 12:39:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:39:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:39:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:39:42 - INFO - TRAINING - Epoch: [159][0/500]	Time 0.299 (0.299)	Data 0.265 (0.265)	Loss 0.0272 (0.0272)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:39:44 - INFO - TRAINING - Epoch: [159][50/500]	Time 0.066 (0.058)	Data 0.000 (0.006)	Loss 0.0617 (0.0346)	Prec@1 97.000 (98.804)	Prec@5 100.000 (100.000)
2019-05-03 12:39:47 - INFO - TRAINING - Epoch: [159][100/500]	Time 0.059 (0.056)	Data 0.000 (0.003)	Loss 0.0517 (0.0320)	Prec@1 98.000 (98.881)	Prec@5 100.000 (100.000)
2019-05-03 12:39:50 - INFO - TRAINING - Epoch: [159][150/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.0436 (0.0299)	Prec@1 99.000 (98.967)	Prec@5 100.000 (100.000)
2019-05-03 12:39:52 - INFO - TRAINING - Epoch: [159][200/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.0057 (0.0292)	Prec@1 100.000 (98.995)	Prec@5 100.000 (100.000)
2019-05-03 12:39:55 - INFO - TRAINING - Epoch: [159][250/500]	Time 0.068 (0.054)	Data 0.000 (0.002)	Loss 0.0184 (0.0299)	Prec@1 99.000 (99.004)	Prec@5 100.000 (100.000)
2019-05-03 12:39:57 - INFO - TRAINING - Epoch: [159][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0083 (0.0313)	Prec@1 100.000 (98.953)	Prec@5 100.000 (100.000)
2019-05-03 12:40:00 - INFO - TRAINING - Epoch: [159][350/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0033 (0.0317)	Prec@1 100.000 (98.926)	Prec@5 100.000 (99.997)
2019-05-03 12:40:03 - INFO - TRAINING - Epoch: [159][400/500]	Time 0.056 (0.054)	Data 0.000 (0.001)	Loss 0.0191 (0.0319)	Prec@1 99.000 (98.895)	Prec@5 100.000 (99.998)
2019-05-03 12:40:06 - INFO - TRAINING - Epoch: [159][450/500]	Time 0.048 (0.054)	Data 0.000 (0.001)	Loss 0.0379 (0.0320)	Prec@1 98.000 (98.907)	Prec@5 100.000 (99.998)
2019-05-03 12:40:08 - INFO - EVALUATING - Epoch: [159][0/100]	Time 0.355 (0.355)	Data 0.341 (0.341)	Loss 0.1787 (0.1787)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:40:09 - INFO - EVALUATING - Epoch: [159][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.2717 (0.3856)	Prec@1 94.000 (91.137)	Prec@5 100.000 (99.627)
2019-05-03 12:40:10 - INFO - 
 Epoch: 160	Training Loss 0.0318 	Training Prec@1 98.918 	Training Prec@5 99.998 	Validation Loss 0.3719 	Validation Prec@1 91.100 	Validation Prec@5 99.650 	
2019-05-03 12:40:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:40:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:40:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:40:11 - INFO - TRAINING - Epoch: [160][0/500]	Time 0.273 (0.273)	Data 0.245 (0.245)	Loss 0.0113 (0.0113)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:40:14 - INFO - TRAINING - Epoch: [160][50/500]	Time 0.040 (0.061)	Data 0.000 (0.006)	Loss 0.0096 (0.0306)	Prec@1 100.000 (99.059)	Prec@5 100.000 (100.000)
2019-05-03 12:40:16 - INFO - TRAINING - Epoch: [160][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0401 (0.0279)	Prec@1 98.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:40:19 - INFO - TRAINING - Epoch: [160][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0205 (0.0293)	Prec@1 99.000 (99.060)	Prec@5 100.000 (100.000)
2019-05-03 12:40:22 - INFO - TRAINING - Epoch: [160][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.1249 (0.0282)	Prec@1 98.000 (99.104)	Prec@5 100.000 (100.000)
2019-05-03 12:40:25 - INFO - TRAINING - Epoch: [160][250/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.0049 (0.0282)	Prec@1 100.000 (99.131)	Prec@5 100.000 (100.000)
2019-05-03 12:40:28 - INFO - TRAINING - Epoch: [160][300/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0445 (0.0279)	Prec@1 98.000 (99.123)	Prec@5 100.000 (100.000)
2019-05-03 12:40:31 - INFO - TRAINING - Epoch: [160][350/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0470 (0.0285)	Prec@1 98.000 (99.085)	Prec@5 100.000 (100.000)
2019-05-03 12:40:34 - INFO - TRAINING - Epoch: [160][400/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0381 (0.0294)	Prec@1 98.000 (99.062)	Prec@5 100.000 (100.000)
2019-05-03 12:40:36 - INFO - TRAINING - Epoch: [160][450/500]	Time 0.052 (0.057)	Data 0.000 (0.001)	Loss 0.0574 (0.0294)	Prec@1 99.000 (99.051)	Prec@5 100.000 (100.000)
2019-05-03 12:40:40 - INFO - EVALUATING - Epoch: [160][0/100]	Time 0.379 (0.379)	Data 0.368 (0.368)	Loss 0.3342 (0.3342)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:40:40 - INFO - EVALUATING - Epoch: [160][50/100]	Time 0.023 (0.025)	Data 0.000 (0.008)	Loss 0.2601 (0.3899)	Prec@1 92.000 (91.157)	Prec@5 100.000 (99.647)
2019-05-03 12:40:41 - INFO - 
 Epoch: 161	Training Loss 0.0293 	Training Prec@1 99.048 	Training Prec@5 100.000 	Validation Loss 0.3756 	Validation Prec@1 91.150 	Validation Prec@5 99.620 	
2019-05-03 12:40:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:40:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:40:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:40:42 - INFO - TRAINING - Epoch: [161][0/500]	Time 0.276 (0.276)	Data 0.256 (0.256)	Loss 0.0374 (0.0374)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:40:45 - INFO - TRAINING - Epoch: [161][50/500]	Time 0.068 (0.061)	Data 0.000 (0.006)	Loss 0.1022 (0.0277)	Prec@1 97.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:40:48 - INFO - TRAINING - Epoch: [161][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0315 (0.0278)	Prec@1 100.000 (99.099)	Prec@5 100.000 (100.000)
2019-05-03 12:40:50 - INFO - TRAINING - Epoch: [161][150/500]	Time 0.068 (0.058)	Data 0.000 (0.003)	Loss 0.0138 (0.0262)	Prec@1 99.000 (99.119)	Prec@5 100.000 (100.000)
2019-05-03 12:40:53 - INFO - TRAINING - Epoch: [161][200/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.0196 (0.0274)	Prec@1 99.000 (99.060)	Prec@5 100.000 (100.000)
2019-05-03 12:40:56 - INFO - TRAINING - Epoch: [161][250/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0190 (0.0276)	Prec@1 100.000 (99.044)	Prec@5 100.000 (100.000)
2019-05-03 12:40:59 - INFO - TRAINING - Epoch: [161][300/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0460 (0.0288)	Prec@1 98.000 (99.010)	Prec@5 100.000 (100.000)
2019-05-03 12:41:02 - INFO - TRAINING - Epoch: [161][350/500]	Time 0.048 (0.057)	Data 0.000 (0.002)	Loss 0.0028 (0.0292)	Prec@1 100.000 (99.003)	Prec@5 100.000 (100.000)
2019-05-03 12:41:04 - INFO - TRAINING - Epoch: [161][400/500]	Time 0.064 (0.057)	Data 0.000 (0.001)	Loss 0.0255 (0.0290)	Prec@1 99.000 (99.015)	Prec@5 100.000 (100.000)
2019-05-03 12:41:07 - INFO - TRAINING - Epoch: [161][450/500]	Time 0.070 (0.057)	Data 0.000 (0.001)	Loss 0.0362 (0.0292)	Prec@1 98.000 (99.016)	Prec@5 100.000 (100.000)
2019-05-03 12:41:10 - INFO - EVALUATING - Epoch: [161][0/100]	Time 0.349 (0.349)	Data 0.342 (0.342)	Loss 0.2872 (0.2872)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:41:11 - INFO - EVALUATING - Epoch: [161][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.1799 (0.3901)	Prec@1 94.000 (91.059)	Prec@5 100.000 (99.627)
2019-05-03 12:41:12 - INFO - 
 Epoch: 162	Training Loss 0.0294 	Training Prec@1 98.990 	Training Prec@5 100.000 	Validation Loss 0.3853 	Validation Prec@1 91.030 	Validation Prec@5 99.610 	
2019-05-03 12:41:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:41:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:41:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:41:12 - INFO - TRAINING - Epoch: [162][0/500]	Time 0.275 (0.275)	Data 0.243 (0.243)	Loss 0.0183 (0.0183)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:41:15 - INFO - TRAINING - Epoch: [162][50/500]	Time 0.046 (0.059)	Data 0.000 (0.005)	Loss 0.0226 (0.0352)	Prec@1 99.000 (98.941)	Prec@5 100.000 (99.980)
2019-05-03 12:41:18 - INFO - TRAINING - Epoch: [162][100/500]	Time 0.048 (0.056)	Data 0.000 (0.003)	Loss 0.0286 (0.0338)	Prec@1 99.000 (98.921)	Prec@5 100.000 (99.990)
2019-05-03 12:41:20 - INFO - TRAINING - Epoch: [162][150/500]	Time 0.043 (0.056)	Data 0.000 (0.002)	Loss 0.0016 (0.0324)	Prec@1 100.000 (98.993)	Prec@5 100.000 (99.993)
2019-05-03 12:41:23 - INFO - TRAINING - Epoch: [162][200/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0496 (0.0300)	Prec@1 99.000 (99.060)	Prec@5 100.000 (99.995)
2019-05-03 12:41:26 - INFO - TRAINING - Epoch: [162][250/500]	Time 0.048 (0.055)	Data 0.000 (0.002)	Loss 0.0040 (0.0287)	Prec@1 100.000 (99.088)	Prec@5 100.000 (99.996)
2019-05-03 12:41:28 - INFO - TRAINING - Epoch: [162][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0099 (0.0291)	Prec@1 100.000 (99.076)	Prec@5 100.000 (99.997)
2019-05-03 12:41:31 - INFO - TRAINING - Epoch: [162][350/500]	Time 0.052 (0.054)	Data 0.000 (0.002)	Loss 0.0132 (0.0287)	Prec@1 100.000 (99.091)	Prec@5 100.000 (99.997)
2019-05-03 12:41:34 - INFO - TRAINING - Epoch: [162][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0235 (0.0290)	Prec@1 99.000 (99.082)	Prec@5 100.000 (99.998)
2019-05-03 12:41:36 - INFO - TRAINING - Epoch: [162][450/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.0363 (0.0284)	Prec@1 98.000 (99.086)	Prec@5 100.000 (99.998)
2019-05-03 12:41:39 - INFO - EVALUATING - Epoch: [162][0/100]	Time 0.406 (0.406)	Data 0.390 (0.390)	Loss 0.2444 (0.2444)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:41:40 - INFO - EVALUATING - Epoch: [162][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.1851 (0.4149)	Prec@1 94.000 (90.431)	Prec@5 100.000 (99.549)
2019-05-03 12:41:41 - INFO - 
 Epoch: 163	Training Loss 0.0284 	Training Prec@1 99.076 	Training Prec@5 99.998 	Validation Loss 0.3895 	Validation Prec@1 90.820 	Validation Prec@5 99.610 	
2019-05-03 12:41:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:41:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:41:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:41:42 - INFO - TRAINING - Epoch: [163][0/500]	Time 0.293 (0.293)	Data 0.267 (0.267)	Loss 0.0209 (0.0209)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:41:44 - INFO - TRAINING - Epoch: [163][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.0071 (0.0279)	Prec@1 100.000 (99.235)	Prec@5 100.000 (100.000)
2019-05-03 12:41:47 - INFO - TRAINING - Epoch: [163][100/500]	Time 0.053 (0.056)	Data 0.000 (0.003)	Loss 0.0287 (0.0271)	Prec@1 100.000 (99.228)	Prec@5 100.000 (100.000)
2019-05-03 12:41:50 - INFO - TRAINING - Epoch: [163][150/500]	Time 0.047 (0.055)	Data 0.000 (0.003)	Loss 0.0437 (0.0280)	Prec@1 98.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:41:52 - INFO - TRAINING - Epoch: [163][200/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.0164 (0.0299)	Prec@1 100.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:41:55 - INFO - TRAINING - Epoch: [163][250/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.0387 (0.0295)	Prec@1 98.000 (99.084)	Prec@5 100.000 (100.000)
2019-05-03 12:41:58 - INFO - TRAINING - Epoch: [163][300/500]	Time 0.071 (0.055)	Data 0.000 (0.002)	Loss 0.0503 (0.0298)	Prec@1 98.000 (99.063)	Prec@5 100.000 (100.000)
2019-05-03 12:42:01 - INFO - TRAINING - Epoch: [163][350/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0594 (0.0300)	Prec@1 98.000 (99.074)	Prec@5 100.000 (100.000)
2019-05-03 12:42:03 - INFO - TRAINING - Epoch: [163][400/500]	Time 0.057 (0.055)	Data 0.000 (0.001)	Loss 0.0345 (0.0298)	Prec@1 98.000 (99.070)	Prec@5 100.000 (100.000)
2019-05-03 12:42:06 - INFO - TRAINING - Epoch: [163][450/500]	Time 0.056 (0.055)	Data 0.000 (0.001)	Loss 0.0668 (0.0297)	Prec@1 99.000 (99.069)	Prec@5 100.000 (100.000)
2019-05-03 12:42:09 - INFO - EVALUATING - Epoch: [163][0/100]	Time 0.379 (0.379)	Data 0.369 (0.369)	Loss 0.3288 (0.3288)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:42:10 - INFO - EVALUATING - Epoch: [163][50/100]	Time 0.020 (0.025)	Data 0.000 (0.008)	Loss 0.1337 (0.3972)	Prec@1 96.000 (91.118)	Prec@5 100.000 (99.510)
2019-05-03 12:42:11 - INFO - 
 Epoch: 164	Training Loss 0.0303 	Training Prec@1 99.046 	Training Prec@5 100.000 	Validation Loss 0.3730 	Validation Prec@1 91.190 	Validation Prec@5 99.600 	
2019-05-03 12:42:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:42:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:42:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:42:12 - INFO - TRAINING - Epoch: [164][0/500]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.0074 (0.0074)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:42:14 - INFO - TRAINING - Epoch: [164][50/500]	Time 0.050 (0.060)	Data 0.000 (0.006)	Loss 0.0218 (0.0258)	Prec@1 99.000 (99.098)	Prec@5 100.000 (100.000)
2019-05-03 12:42:17 - INFO - TRAINING - Epoch: [164][100/500]	Time 0.055 (0.058)	Data 0.000 (0.004)	Loss 0.0074 (0.0264)	Prec@1 100.000 (99.119)	Prec@5 100.000 (100.000)
2019-05-03 12:42:20 - INFO - TRAINING - Epoch: [164][150/500]	Time 0.064 (0.057)	Data 0.000 (0.003)	Loss 0.0327 (0.0269)	Prec@1 98.000 (99.053)	Prec@5 100.000 (100.000)
2019-05-03 12:42:23 - INFO - TRAINING - Epoch: [164][200/500]	Time 0.048 (0.057)	Data 0.000 (0.002)	Loss 0.0203 (0.0277)	Prec@1 100.000 (99.070)	Prec@5 100.000 (100.000)
2019-05-03 12:42:26 - INFO - TRAINING - Epoch: [164][250/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0142 (0.0277)	Prec@1 99.000 (99.088)	Prec@5 100.000 (100.000)
2019-05-03 12:42:28 - INFO - TRAINING - Epoch: [164][300/500]	Time 0.062 (0.057)	Data 0.000 (0.002)	Loss 0.0583 (0.0277)	Prec@1 97.000 (99.080)	Prec@5 100.000 (100.000)
2019-05-03 12:42:31 - INFO - TRAINING - Epoch: [164][350/500]	Time 0.049 (0.057)	Data 0.000 (0.002)	Loss 0.0351 (0.0289)	Prec@1 99.000 (99.034)	Prec@5 100.000 (99.997)
2019-05-03 12:42:34 - INFO - TRAINING - Epoch: [164][400/500]	Time 0.064 (0.057)	Data 0.000 (0.002)	Loss 0.0108 (0.0289)	Prec@1 100.000 (99.047)	Prec@5 100.000 (99.998)
2019-05-03 12:42:37 - INFO - TRAINING - Epoch: [164][450/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0225 (0.0292)	Prec@1 100.000 (99.042)	Prec@5 100.000 (99.998)
2019-05-03 12:42:40 - INFO - EVALUATING - Epoch: [164][0/100]	Time 0.374 (0.374)	Data 0.363 (0.363)	Loss 0.2076 (0.2076)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-05-03 12:42:41 - INFO - EVALUATING - Epoch: [164][50/100]	Time 0.017 (0.026)	Data 0.000 (0.007)	Loss 0.1636 (0.3803)	Prec@1 92.000 (91.118)	Prec@5 100.000 (99.510)
2019-05-03 12:42:42 - INFO - 
 Epoch: 165	Training Loss 0.0289 	Training Prec@1 99.060 	Training Prec@5 99.998 	Validation Loss 0.3731 	Validation Prec@1 91.140 	Validation Prec@5 99.580 	
2019-05-03 12:42:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:42:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:42:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:42:42 - INFO - TRAINING - Epoch: [165][0/500]	Time 0.288 (0.288)	Data 0.253 (0.253)	Loss 0.0328 (0.0328)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:42:45 - INFO - TRAINING - Epoch: [165][50/500]	Time 0.058 (0.060)	Data 0.000 (0.006)	Loss 0.0078 (0.0277)	Prec@1 100.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:42:48 - INFO - TRAINING - Epoch: [165][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0259 (0.0286)	Prec@1 99.000 (99.030)	Prec@5 100.000 (100.000)
2019-05-03 12:42:51 - INFO - TRAINING - Epoch: [165][150/500]	Time 0.057 (0.058)	Data 0.000 (0.003)	Loss 0.0065 (0.0271)	Prec@1 100.000 (99.113)	Prec@5 100.000 (100.000)
2019-05-03 12:42:54 - INFO - TRAINING - Epoch: [165][200/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0026 (0.0283)	Prec@1 100.000 (99.045)	Prec@5 100.000 (100.000)
2019-05-03 12:42:57 - INFO - TRAINING - Epoch: [165][250/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0550 (0.0280)	Prec@1 98.000 (99.080)	Prec@5 100.000 (100.000)
2019-05-03 12:42:59 - INFO - TRAINING - Epoch: [165][300/500]	Time 0.060 (0.057)	Data 0.000 (0.002)	Loss 0.0359 (0.0277)	Prec@1 98.000 (99.090)	Prec@5 100.000 (100.000)
2019-05-03 12:43:02 - INFO - TRAINING - Epoch: [165][350/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0074 (0.0275)	Prec@1 100.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:43:05 - INFO - TRAINING - Epoch: [165][400/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0272 (0.0273)	Prec@1 99.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:43:08 - INFO - TRAINING - Epoch: [165][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0203 (0.0279)	Prec@1 99.000 (99.073)	Prec@5 100.000 (100.000)
2019-05-03 12:43:11 - INFO - EVALUATING - Epoch: [165][0/100]	Time 0.351 (0.351)	Data 0.342 (0.342)	Loss 0.3046 (0.3046)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:43:12 - INFO - EVALUATING - Epoch: [165][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.2172 (0.3827)	Prec@1 93.000 (91.118)	Prec@5 100.000 (99.686)
2019-05-03 12:43:13 - INFO - 
 Epoch: 166	Training Loss 0.0283 	Training Prec@1 99.058 	Training Prec@5 100.000 	Validation Loss 0.3755 	Validation Prec@1 91.150 	Validation Prec@5 99.690 	
2019-05-03 12:43:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:43:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:43:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:43:13 - INFO - TRAINING - Epoch: [166][0/500]	Time 0.253 (0.253)	Data 0.224 (0.224)	Loss 0.0054 (0.0054)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:43:16 - INFO - TRAINING - Epoch: [166][50/500]	Time 0.041 (0.060)	Data 0.000 (0.005)	Loss 0.0109 (0.0312)	Prec@1 99.000 (99.020)	Prec@5 100.000 (99.980)
2019-05-03 12:43:19 - INFO - TRAINING - Epoch: [166][100/500]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 0.0087 (0.0312)	Prec@1 100.000 (98.990)	Prec@5 100.000 (99.990)
2019-05-03 12:43:22 - INFO - TRAINING - Epoch: [166][150/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0196 (0.0307)	Prec@1 100.000 (98.947)	Prec@5 100.000 (99.993)
2019-05-03 12:43:25 - INFO - TRAINING - Epoch: [166][200/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0473 (0.0301)	Prec@1 97.000 (98.990)	Prec@5 100.000 (99.995)
2019-05-03 12:43:28 - INFO - TRAINING - Epoch: [166][250/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.0314 (0.0293)	Prec@1 99.000 (99.012)	Prec@5 100.000 (99.996)
2019-05-03 12:43:30 - INFO - TRAINING - Epoch: [166][300/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0162 (0.0284)	Prec@1 99.000 (99.047)	Prec@5 100.000 (99.997)
2019-05-03 12:43:33 - INFO - TRAINING - Epoch: [166][350/500]	Time 0.046 (0.057)	Data 0.000 (0.002)	Loss 0.0125 (0.0279)	Prec@1 100.000 (99.085)	Prec@5 100.000 (99.994)
2019-05-03 12:43:36 - INFO - TRAINING - Epoch: [166][400/500]	Time 0.062 (0.057)	Data 0.000 (0.001)	Loss 0.0537 (0.0282)	Prec@1 98.000 (99.080)	Prec@5 100.000 (99.995)
2019-05-03 12:43:39 - INFO - TRAINING - Epoch: [166][450/500]	Time 0.061 (0.057)	Data 0.000 (0.001)	Loss 0.0116 (0.0284)	Prec@1 100.000 (99.051)	Prec@5 100.000 (99.996)
2019-05-03 12:43:42 - INFO - EVALUATING - Epoch: [166][0/100]	Time 0.358 (0.358)	Data 0.344 (0.344)	Loss 0.3471 (0.3471)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:43:43 - INFO - EVALUATING - Epoch: [166][50/100]	Time 0.023 (0.024)	Data 0.000 (0.007)	Loss 0.1474 (0.3974)	Prec@1 97.000 (91.216)	Prec@5 100.000 (99.549)
2019-05-03 12:43:44 - INFO - 
 Epoch: 167	Training Loss 0.0283 	Training Prec@1 99.058 	Training Prec@5 99.996 	Validation Loss 0.3814 	Validation Prec@1 91.260 	Validation Prec@5 99.660 	
2019-05-03 12:43:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:43:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:43:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:43:44 - INFO - TRAINING - Epoch: [167][0/500]	Time 0.286 (0.286)	Data 0.257 (0.257)	Loss 0.0295 (0.0295)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:43:47 - INFO - TRAINING - Epoch: [167][50/500]	Time 0.054 (0.058)	Data 0.000 (0.006)	Loss 0.0222 (0.0280)	Prec@1 99.000 (99.098)	Prec@5 100.000 (100.000)
2019-05-03 12:43:49 - INFO - TRAINING - Epoch: [167][100/500]	Time 0.063 (0.056)	Data 0.000 (0.003)	Loss 0.0643 (0.0281)	Prec@1 97.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:43:52 - INFO - TRAINING - Epoch: [167][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0434 (0.0284)	Prec@1 98.000 (98.987)	Prec@5 100.000 (100.000)
2019-05-03 12:43:55 - INFO - TRAINING - Epoch: [167][200/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.0088 (0.0269)	Prec@1 100.000 (99.055)	Prec@5 100.000 (100.000)
2019-05-03 12:43:57 - INFO - TRAINING - Epoch: [167][250/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0068 (0.0269)	Prec@1 100.000 (99.072)	Prec@5 100.000 (100.000)
2019-05-03 12:44:00 - INFO - TRAINING - Epoch: [167][300/500]	Time 0.043 (0.054)	Data 0.000 (0.002)	Loss 0.0145 (0.0270)	Prec@1 99.000 (99.073)	Prec@5 100.000 (99.997)
2019-05-03 12:44:03 - INFO - TRAINING - Epoch: [167][350/500]	Time 0.046 (0.054)	Data 0.000 (0.002)	Loss 0.0275 (0.0268)	Prec@1 98.000 (99.085)	Prec@5 100.000 (99.997)
2019-05-03 12:44:05 - INFO - TRAINING - Epoch: [167][400/500]	Time 0.049 (0.054)	Data 0.000 (0.001)	Loss 0.0066 (0.0271)	Prec@1 100.000 (99.087)	Prec@5 100.000 (99.998)
2019-05-03 12:44:08 - INFO - TRAINING - Epoch: [167][450/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0038 (0.0272)	Prec@1 100.000 (99.098)	Prec@5 100.000 (99.998)
2019-05-03 12:44:11 - INFO - EVALUATING - Epoch: [167][0/100]	Time 0.377 (0.377)	Data 0.368 (0.368)	Loss 0.3907 (0.3907)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:44:12 - INFO - EVALUATING - Epoch: [167][50/100]	Time 0.019 (0.025)	Data 0.000 (0.008)	Loss 0.2785 (0.3804)	Prec@1 95.000 (91.216)	Prec@5 99.000 (99.569)
2019-05-03 12:44:13 - INFO - 
 Epoch: 168	Training Loss 0.0267 	Training Prec@1 99.110 	Training Prec@5 99.998 	Validation Loss 0.3734 	Validation Prec@1 91.180 	Validation Prec@5 99.600 	
2019-05-03 12:44:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:44:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:44:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:44:13 - INFO - TRAINING - Epoch: [168][0/500]	Time 0.262 (0.262)	Data 0.234 (0.234)	Loss 0.0211 (0.0211)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:44:16 - INFO - TRAINING - Epoch: [168][50/500]	Time 0.063 (0.058)	Data 0.000 (0.005)	Loss 0.0127 (0.0252)	Prec@1 100.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-03 12:44:19 - INFO - TRAINING - Epoch: [168][100/500]	Time 0.060 (0.056)	Data 0.000 (0.003)	Loss 0.0270 (0.0265)	Prec@1 99.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:44:21 - INFO - TRAINING - Epoch: [168][150/500]	Time 0.064 (0.055)	Data 0.000 (0.002)	Loss 0.0196 (0.0270)	Prec@1 98.000 (99.086)	Prec@5 100.000 (100.000)
2019-05-03 12:44:24 - INFO - TRAINING - Epoch: [168][200/500]	Time 0.051 (0.055)	Data 0.000 (0.002)	Loss 0.0817 (0.0267)	Prec@1 98.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:44:27 - INFO - TRAINING - Epoch: [168][250/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0135 (0.0264)	Prec@1 99.000 (99.120)	Prec@5 100.000 (100.000)
2019-05-03 12:44:30 - INFO - TRAINING - Epoch: [168][300/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0334 (0.0262)	Prec@1 99.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-03 12:44:32 - INFO - TRAINING - Epoch: [168][350/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0335 (0.0264)	Prec@1 99.000 (99.145)	Prec@5 100.000 (100.000)
2019-05-03 12:44:35 - INFO - TRAINING - Epoch: [168][400/500]	Time 0.050 (0.054)	Data 0.000 (0.001)	Loss 0.0500 (0.0267)	Prec@1 98.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:44:38 - INFO - TRAINING - Epoch: [168][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0320 (0.0268)	Prec@1 99.000 (99.135)	Prec@5 100.000 (100.000)
2019-05-03 12:44:41 - INFO - EVALUATING - Epoch: [168][0/100]	Time 0.367 (0.367)	Data 0.360 (0.360)	Loss 0.3080 (0.3080)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:44:42 - INFO - EVALUATING - Epoch: [168][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.3590 (0.4008)	Prec@1 93.000 (90.922)	Prec@5 99.000 (99.471)
2019-05-03 12:44:43 - INFO - 
 Epoch: 169	Training Loss 0.0273 	Training Prec@1 99.114 	Training Prec@5 100.000 	Validation Loss 0.3753 	Validation Prec@1 91.170 	Validation Prec@5 99.560 	
2019-05-03 12:44:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:44:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:44:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:44:43 - INFO - TRAINING - Epoch: [169][0/500]	Time 0.294 (0.294)	Data 0.270 (0.270)	Loss 0.0304 (0.0304)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:44:46 - INFO - TRAINING - Epoch: [169][50/500]	Time 0.056 (0.062)	Data 0.000 (0.006)	Loss 0.0562 (0.0247)	Prec@1 99.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-03 12:44:49 - INFO - TRAINING - Epoch: [169][100/500]	Time 0.052 (0.059)	Data 0.000 (0.004)	Loss 0.0187 (0.0240)	Prec@1 100.000 (99.238)	Prec@5 100.000 (100.000)
2019-05-03 12:44:52 - INFO - TRAINING - Epoch: [169][150/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0324 (0.0278)	Prec@1 99.000 (99.073)	Prec@5 100.000 (100.000)
2019-05-03 12:44:54 - INFO - TRAINING - Epoch: [169][200/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0370 (0.0278)	Prec@1 98.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:44:57 - INFO - TRAINING - Epoch: [169][250/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0152 (0.0288)	Prec@1 100.000 (99.016)	Prec@5 100.000 (99.996)
2019-05-03 12:45:00 - INFO - TRAINING - Epoch: [169][300/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0323 (0.0286)	Prec@1 99.000 (99.037)	Prec@5 100.000 (99.997)
2019-05-03 12:45:03 - INFO - TRAINING - Epoch: [169][350/500]	Time 0.040 (0.058)	Data 0.000 (0.002)	Loss 0.0104 (0.0277)	Prec@1 100.000 (99.051)	Prec@5 100.000 (99.997)
2019-05-03 12:45:06 - INFO - TRAINING - Epoch: [169][400/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0385 (0.0272)	Prec@1 99.000 (99.060)	Prec@5 100.000 (99.998)
2019-05-03 12:45:09 - INFO - TRAINING - Epoch: [169][450/500]	Time 0.066 (0.058)	Data 0.000 (0.001)	Loss 0.0410 (0.0277)	Prec@1 98.000 (99.058)	Prec@5 100.000 (99.998)
2019-05-03 12:45:12 - INFO - EVALUATING - Epoch: [169][0/100]	Time 0.366 (0.366)	Data 0.350 (0.350)	Loss 0.2303 (0.2303)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:45:13 - INFO - EVALUATING - Epoch: [169][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2803 (0.3873)	Prec@1 94.000 (90.843)	Prec@5 100.000 (99.608)
2019-05-03 12:45:14 - INFO - 
 Epoch: 170	Training Loss 0.0281 	Training Prec@1 99.050 	Training Prec@5 99.998 	Validation Loss 0.3774 	Validation Prec@1 90.960 	Validation Prec@5 99.660 	
2019-05-03 12:45:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:45:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:45:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:45:14 - INFO - TRAINING - Epoch: [170][0/500]	Time 0.283 (0.283)	Data 0.255 (0.255)	Loss 0.0300 (0.0300)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:45:17 - INFO - TRAINING - Epoch: [170][50/500]	Time 0.051 (0.061)	Data 0.000 (0.006)	Loss 0.0111 (0.0312)	Prec@1 100.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:45:20 - INFO - TRAINING - Epoch: [170][100/500]	Time 0.062 (0.059)	Data 0.000 (0.003)	Loss 0.0671 (0.0341)	Prec@1 97.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:45:23 - INFO - TRAINING - Epoch: [170][150/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0040 (0.0332)	Prec@1 100.000 (98.947)	Prec@5 100.000 (100.000)
2019-05-03 12:45:26 - INFO - TRAINING - Epoch: [170][200/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0489 (0.0324)	Prec@1 99.000 (98.960)	Prec@5 100.000 (100.000)
2019-05-03 12:45:28 - INFO - TRAINING - Epoch: [170][250/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0050 (0.0313)	Prec@1 100.000 (98.988)	Prec@5 100.000 (100.000)
2019-05-03 12:45:31 - INFO - TRAINING - Epoch: [170][300/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.0352 (0.0302)	Prec@1 99.000 (99.037)	Prec@5 100.000 (100.000)
2019-05-03 12:45:34 - INFO - TRAINING - Epoch: [170][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0207 (0.0294)	Prec@1 99.000 (99.057)	Prec@5 100.000 (100.000)
2019-05-03 12:45:37 - INFO - TRAINING - Epoch: [170][400/500]	Time 0.047 (0.058)	Data 0.000 (0.001)	Loss 0.0160 (0.0292)	Prec@1 99.000 (99.062)	Prec@5 100.000 (100.000)
2019-05-03 12:45:40 - INFO - TRAINING - Epoch: [170][450/500]	Time 0.057 (0.058)	Data 0.000 (0.001)	Loss 0.0683 (0.0290)	Prec@1 97.000 (99.069)	Prec@5 100.000 (100.000)
2019-05-03 12:45:43 - INFO - EVALUATING - Epoch: [170][0/100]	Time 0.376 (0.376)	Data 0.366 (0.366)	Loss 0.2463 (0.2463)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:45:44 - INFO - EVALUATING - Epoch: [170][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.2872 (0.3837)	Prec@1 94.000 (91.098)	Prec@5 100.000 (99.608)
2019-05-03 12:45:45 - INFO - 
 Epoch: 171	Training Loss 0.0296 	Training Prec@1 99.054 	Training Prec@5 100.000 	Validation Loss 0.3744 	Validation Prec@1 91.250 	Validation Prec@5 99.660 	
2019-05-03 12:45:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:45:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:45:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:45:45 - INFO - TRAINING - Epoch: [171][0/500]	Time 0.272 (0.272)	Data 0.244 (0.244)	Loss 0.0252 (0.0252)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:45:48 - INFO - TRAINING - Epoch: [171][50/500]	Time 0.057 (0.058)	Data 0.000 (0.005)	Loss 0.0108 (0.0318)	Prec@1 100.000 (98.961)	Prec@5 100.000 (100.000)
2019-05-03 12:45:51 - INFO - TRAINING - Epoch: [171][100/500]	Time 0.056 (0.056)	Data 0.000 (0.003)	Loss 0.0078 (0.0313)	Prec@1 100.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:45:53 - INFO - TRAINING - Epoch: [171][150/500]	Time 0.058 (0.055)	Data 0.000 (0.002)	Loss 0.0080 (0.0312)	Prec@1 100.000 (98.954)	Prec@5 100.000 (100.000)
2019-05-03 12:45:56 - INFO - TRAINING - Epoch: [171][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0280 (0.0290)	Prec@1 99.000 (99.010)	Prec@5 100.000 (100.000)
2019-05-03 12:45:59 - INFO - TRAINING - Epoch: [171][250/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.0056 (0.0286)	Prec@1 100.000 (99.016)	Prec@5 100.000 (100.000)
2019-05-03 12:46:01 - INFO - TRAINING - Epoch: [171][300/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0184 (0.0284)	Prec@1 100.000 (99.027)	Prec@5 100.000 (100.000)
2019-05-03 12:46:04 - INFO - TRAINING - Epoch: [171][350/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0049 (0.0284)	Prec@1 100.000 (99.009)	Prec@5 100.000 (100.000)
2019-05-03 12:46:07 - INFO - TRAINING - Epoch: [171][400/500]	Time 0.055 (0.054)	Data 0.000 (0.001)	Loss 0.0605 (0.0280)	Prec@1 97.000 (99.022)	Prec@5 100.000 (100.000)
2019-05-03 12:46:09 - INFO - TRAINING - Epoch: [171][450/500]	Time 0.052 (0.054)	Data 0.000 (0.001)	Loss 0.0398 (0.0280)	Prec@1 98.000 (99.029)	Prec@5 100.000 (100.000)
2019-05-03 12:46:12 - INFO - EVALUATING - Epoch: [171][0/100]	Time 0.376 (0.376)	Data 0.363 (0.363)	Loss 0.2094 (0.2094)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:46:13 - INFO - EVALUATING - Epoch: [171][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.3249 (0.4007)	Prec@1 93.000 (91.176)	Prec@5 100.000 (99.686)
2019-05-03 12:46:14 - INFO - 
 Epoch: 172	Training Loss 0.0279 	Training Prec@1 99.034 	Training Prec@5 100.000 	Validation Loss 0.3903 	Validation Prec@1 91.200 	Validation Prec@5 99.660 	
2019-05-03 12:46:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:46:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:46:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:46:15 - INFO - TRAINING - Epoch: [172][0/500]	Time 0.270 (0.270)	Data 0.242 (0.242)	Loss 0.0197 (0.0197)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:46:17 - INFO - TRAINING - Epoch: [172][50/500]	Time 0.060 (0.060)	Data 0.000 (0.005)	Loss 0.0262 (0.0232)	Prec@1 99.000 (99.235)	Prec@5 100.000 (100.000)
2019-05-03 12:46:20 - INFO - TRAINING - Epoch: [172][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0053 (0.0260)	Prec@1 100.000 (99.119)	Prec@5 100.000 (100.000)
2019-05-03 12:46:23 - INFO - TRAINING - Epoch: [172][150/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0019 (0.0273)	Prec@1 100.000 (99.060)	Prec@5 100.000 (100.000)
2019-05-03 12:46:26 - INFO - TRAINING - Epoch: [172][200/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0606 (0.0267)	Prec@1 99.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:46:29 - INFO - TRAINING - Epoch: [172][250/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0099 (0.0265)	Prec@1 100.000 (99.131)	Prec@5 100.000 (100.000)
2019-05-03 12:46:32 - INFO - TRAINING - Epoch: [172][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0618 (0.0265)	Prec@1 98.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-03 12:46:34 - INFO - TRAINING - Epoch: [172][350/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.0070 (0.0261)	Prec@1 100.000 (99.154)	Prec@5 100.000 (100.000)
2019-05-03 12:46:37 - INFO - TRAINING - Epoch: [172][400/500]	Time 0.063 (0.057)	Data 0.000 (0.002)	Loss 0.0091 (0.0257)	Prec@1 100.000 (99.175)	Prec@5 100.000 (100.000)
2019-05-03 12:46:40 - INFO - TRAINING - Epoch: [172][450/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.1250 (0.0262)	Prec@1 97.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-03 12:46:43 - INFO - EVALUATING - Epoch: [172][0/100]	Time 0.346 (0.346)	Data 0.339 (0.339)	Loss 0.2201 (0.2201)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:46:44 - INFO - EVALUATING - Epoch: [172][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.1959 (0.3974)	Prec@1 94.000 (90.863)	Prec@5 100.000 (99.549)
2019-05-03 12:46:45 - INFO - 
 Epoch: 173	Training Loss 0.0264 	Training Prec@1 99.144 	Training Prec@5 100.000 	Validation Loss 0.3839 	Validation Prec@1 90.940 	Validation Prec@5 99.570 	
2019-05-03 12:46:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:46:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:46:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:46:46 - INFO - TRAINING - Epoch: [173][0/500]	Time 0.291 (0.291)	Data 0.261 (0.261)	Loss 0.0352 (0.0352)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:46:48 - INFO - TRAINING - Epoch: [173][50/500]	Time 0.058 (0.062)	Data 0.000 (0.006)	Loss 0.0360 (0.0277)	Prec@1 98.000 (99.176)	Prec@5 100.000 (100.000)
2019-05-03 12:46:51 - INFO - TRAINING - Epoch: [173][100/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.0261 (0.0278)	Prec@1 99.000 (99.069)	Prec@5 100.000 (100.000)
2019-05-03 12:46:54 - INFO - TRAINING - Epoch: [173][150/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.0523 (0.0272)	Prec@1 98.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:46:57 - INFO - TRAINING - Epoch: [173][200/500]	Time 0.064 (0.058)	Data 0.000 (0.002)	Loss 0.0051 (0.0273)	Prec@1 100.000 (99.129)	Prec@5 100.000 (100.000)
2019-05-03 12:47:00 - INFO - TRAINING - Epoch: [173][250/500]	Time 0.044 (0.058)	Data 0.000 (0.002)	Loss 0.0173 (0.0273)	Prec@1 99.000 (99.124)	Prec@5 100.000 (100.000)
2019-05-03 12:47:03 - INFO - TRAINING - Epoch: [173][300/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0384 (0.0283)	Prec@1 99.000 (99.116)	Prec@5 100.000 (100.000)
2019-05-03 12:47:06 - INFO - TRAINING - Epoch: [173][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0119 (0.0292)	Prec@1 100.000 (99.066)	Prec@5 100.000 (100.000)
2019-05-03 12:47:08 - INFO - TRAINING - Epoch: [173][400/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0082 (0.0287)	Prec@1 100.000 (99.092)	Prec@5 100.000 (100.000)
2019-05-03 12:47:11 - INFO - TRAINING - Epoch: [173][450/500]	Time 0.057 (0.057)	Data 0.000 (0.001)	Loss 0.0082 (0.0283)	Prec@1 100.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:47:14 - INFO - EVALUATING - Epoch: [173][0/100]	Time 0.367 (0.367)	Data 0.359 (0.359)	Loss 0.2417 (0.2417)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:47:15 - INFO - EVALUATING - Epoch: [173][50/100]	Time 0.019 (0.025)	Data 0.000 (0.007)	Loss 0.2499 (0.4038)	Prec@1 95.000 (90.686)	Prec@5 100.000 (99.510)
2019-05-03 12:47:16 - INFO - 
 Epoch: 174	Training Loss 0.0284 	Training Prec@1 99.096 	Training Prec@5 100.000 	Validation Loss 0.3874 	Validation Prec@1 90.820 	Validation Prec@5 99.590 	
2019-05-03 12:47:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:47:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:47:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:47:17 - INFO - TRAINING - Epoch: [174][0/500]	Time 0.268 (0.268)	Data 0.237 (0.237)	Loss 0.0277 (0.0277)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:47:19 - INFO - TRAINING - Epoch: [174][50/500]	Time 0.047 (0.057)	Data 0.000 (0.005)	Loss 0.0215 (0.0200)	Prec@1 99.000 (99.353)	Prec@5 100.000 (100.000)
2019-05-03 12:47:22 - INFO - TRAINING - Epoch: [174][100/500]	Time 0.058 (0.056)	Data 0.000 (0.003)	Loss 0.0186 (0.0260)	Prec@1 100.000 (99.178)	Prec@5 100.000 (100.000)
2019-05-03 12:47:25 - INFO - TRAINING - Epoch: [174][150/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.0244 (0.0280)	Prec@1 98.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:47:27 - INFO - TRAINING - Epoch: [174][200/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0137 (0.0267)	Prec@1 99.000 (99.154)	Prec@5 100.000 (100.000)
2019-05-03 12:47:30 - INFO - TRAINING - Epoch: [174][250/500]	Time 0.047 (0.054)	Data 0.000 (0.002)	Loss 0.0020 (0.0266)	Prec@1 100.000 (99.151)	Prec@5 100.000 (99.996)
2019-05-03 12:47:33 - INFO - TRAINING - Epoch: [174][300/500]	Time 0.039 (0.054)	Data 0.000 (0.002)	Loss 0.0080 (0.0279)	Prec@1 100.000 (99.116)	Prec@5 100.000 (99.997)
2019-05-03 12:47:35 - INFO - TRAINING - Epoch: [174][350/500]	Time 0.044 (0.054)	Data 0.000 (0.002)	Loss 0.0530 (0.0280)	Prec@1 97.000 (99.097)	Prec@5 100.000 (99.997)
2019-05-03 12:47:38 - INFO - TRAINING - Epoch: [174][400/500]	Time 0.059 (0.054)	Data 0.000 (0.001)	Loss 0.0306 (0.0278)	Prec@1 98.000 (99.107)	Prec@5 100.000 (99.998)
2019-05-03 12:47:41 - INFO - TRAINING - Epoch: [174][450/500]	Time 0.057 (0.054)	Data 0.000 (0.001)	Loss 0.0373 (0.0273)	Prec@1 99.000 (99.122)	Prec@5 100.000 (99.998)
2019-05-03 12:47:44 - INFO - EVALUATING - Epoch: [174][0/100]	Time 0.364 (0.364)	Data 0.356 (0.356)	Loss 0.2620 (0.2620)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:47:45 - INFO - EVALUATING - Epoch: [174][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.1731 (0.3885)	Prec@1 95.000 (90.980)	Prec@5 99.000 (99.549)
2019-05-03 12:47:46 - INFO - 
 Epoch: 175	Training Loss 0.0269 	Training Prec@1 99.142 	Training Prec@5 99.998 	Validation Loss 0.3798 	Validation Prec@1 91.090 	Validation Prec@5 99.590 	
2019-05-03 12:47:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:47:46 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:47:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:47:46 - INFO - TRAINING - Epoch: [175][0/500]	Time 0.277 (0.277)	Data 0.244 (0.244)	Loss 0.0147 (0.0147)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:47:49 - INFO - TRAINING - Epoch: [175][50/500]	Time 0.054 (0.059)	Data 0.000 (0.005)	Loss 0.0282 (0.0279)	Prec@1 98.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:47:51 - INFO - TRAINING - Epoch: [175][100/500]	Time 0.054 (0.056)	Data 0.000 (0.003)	Loss 0.0145 (0.0268)	Prec@1 99.000 (99.178)	Prec@5 100.000 (100.000)
2019-05-03 12:47:54 - INFO - TRAINING - Epoch: [175][150/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0680 (0.0267)	Prec@1 98.000 (99.179)	Prec@5 100.000 (100.000)
2019-05-03 12:47:57 - INFO - TRAINING - Epoch: [175][200/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0292 (0.0273)	Prec@1 99.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:47:59 - INFO - TRAINING - Epoch: [175][250/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.0260 (0.0273)	Prec@1 99.000 (99.135)	Prec@5 100.000 (100.000)
2019-05-03 12:48:02 - INFO - TRAINING - Epoch: [175][300/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.0101 (0.0286)	Prec@1 100.000 (99.096)	Prec@5 100.000 (100.000)
2019-05-03 12:48:05 - INFO - TRAINING - Epoch: [175][350/500]	Time 0.061 (0.055)	Data 0.000 (0.001)	Loss 0.0433 (0.0282)	Prec@1 99.000 (99.108)	Prec@5 100.000 (100.000)
2019-05-03 12:48:08 - INFO - TRAINING - Epoch: [175][400/500]	Time 0.051 (0.055)	Data 0.000 (0.001)	Loss 0.0549 (0.0277)	Prec@1 99.000 (99.117)	Prec@5 100.000 (100.000)
2019-05-03 12:48:10 - INFO - TRAINING - Epoch: [175][450/500]	Time 0.054 (0.055)	Data 0.000 (0.001)	Loss 0.0092 (0.0274)	Prec@1 100.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:48:14 - INFO - EVALUATING - Epoch: [175][0/100]	Time 0.386 (0.386)	Data 0.376 (0.376)	Loss 0.2856 (0.2856)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:14 - INFO - EVALUATING - Epoch: [175][50/100]	Time 0.014 (0.026)	Data 0.000 (0.008)	Loss 0.3116 (0.3905)	Prec@1 92.000 (90.902)	Prec@5 100.000 (99.529)
2019-05-03 12:48:15 - INFO - 
 Epoch: 176	Training Loss 0.0266 	Training Prec@1 99.140 	Training Prec@5 100.000 	Validation Loss 0.3774 	Validation Prec@1 91.100 	Validation Prec@5 99.600 	
2019-05-03 12:48:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:48:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:48:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:48:16 - INFO - TRAINING - Epoch: [176][0/500]	Time 0.283 (0.283)	Data 0.256 (0.256)	Loss 0.0417 (0.0417)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:19 - INFO - TRAINING - Epoch: [176][50/500]	Time 0.058 (0.061)	Data 0.000 (0.006)	Loss 0.0520 (0.0253)	Prec@1 97.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-03 12:48:22 - INFO - TRAINING - Epoch: [176][100/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.0517 (0.0290)	Prec@1 99.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:48:24 - INFO - TRAINING - Epoch: [176][150/500]	Time 0.054 (0.058)	Data 0.000 (0.003)	Loss 0.0616 (0.0290)	Prec@1 98.000 (99.013)	Prec@5 100.000 (100.000)
2019-05-03 12:48:27 - INFO - TRAINING - Epoch: [176][200/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0450 (0.0285)	Prec@1 99.000 (99.010)	Prec@5 100.000 (100.000)
2019-05-03 12:48:30 - INFO - TRAINING - Epoch: [176][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0166 (0.0302)	Prec@1 100.000 (98.948)	Prec@5 100.000 (100.000)
2019-05-03 12:48:33 - INFO - TRAINING - Epoch: [176][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0217 (0.0296)	Prec@1 99.000 (98.963)	Prec@5 100.000 (100.000)
2019-05-03 12:48:36 - INFO - TRAINING - Epoch: [176][350/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.0162 (0.0283)	Prec@1 100.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:39 - INFO - TRAINING - Epoch: [176][400/500]	Time 0.061 (0.057)	Data 0.000 (0.002)	Loss 0.0563 (0.0283)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:41 - INFO - TRAINING - Epoch: [176][450/500]	Time 0.065 (0.057)	Data 0.000 (0.001)	Loss 0.0048 (0.0275)	Prec@1 100.000 (99.033)	Prec@5 100.000 (100.000)
2019-05-03 12:48:45 - INFO - EVALUATING - Epoch: [176][0/100]	Time 0.356 (0.356)	Data 0.349 (0.349)	Loss 0.2314 (0.2314)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:46 - INFO - EVALUATING - Epoch: [176][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2393 (0.3841)	Prec@1 96.000 (90.941)	Prec@5 100.000 (99.647)
2019-05-03 12:48:46 - INFO - 
 Epoch: 177	Training Loss 0.0277 	Training Prec@1 99.040 	Training Prec@5 100.000 	Validation Loss 0.3798 	Validation Prec@1 91.140 	Validation Prec@5 99.650 	
2019-05-03 12:48:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:48:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:48:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:48:47 - INFO - TRAINING - Epoch: [177][0/500]	Time 0.287 (0.287)	Data 0.257 (0.257)	Loss 0.0316 (0.0316)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:48:50 - INFO - TRAINING - Epoch: [177][50/500]	Time 0.059 (0.061)	Data 0.000 (0.006)	Loss 0.0363 (0.0276)	Prec@1 99.000 (99.118)	Prec@5 100.000 (99.980)
2019-05-03 12:48:53 - INFO - TRAINING - Epoch: [177][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.0044 (0.0281)	Prec@1 100.000 (99.069)	Prec@5 100.000 (99.990)
2019-05-03 12:48:55 - INFO - TRAINING - Epoch: [177][150/500]	Time 0.059 (0.058)	Data 0.000 (0.003)	Loss 0.0066 (0.0265)	Prec@1 100.000 (99.126)	Prec@5 100.000 (99.993)
2019-05-03 12:48:58 - INFO - TRAINING - Epoch: [177][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0388 (0.0274)	Prec@1 99.000 (99.090)	Prec@5 100.000 (99.995)
2019-05-03 12:49:01 - INFO - TRAINING - Epoch: [177][250/500]	Time 0.049 (0.058)	Data 0.000 (0.002)	Loss 0.0036 (0.0276)	Prec@1 100.000 (99.100)	Prec@5 100.000 (99.996)
2019-05-03 12:49:04 - INFO - TRAINING - Epoch: [177][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0405 (0.0276)	Prec@1 98.000 (99.110)	Prec@5 100.000 (99.997)
2019-05-03 12:49:07 - INFO - TRAINING - Epoch: [177][350/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0252 (0.0272)	Prec@1 100.000 (99.131)	Prec@5 100.000 (99.994)
2019-05-03 12:49:10 - INFO - TRAINING - Epoch: [177][400/500]	Time 0.067 (0.057)	Data 0.000 (0.002)	Loss 0.0128 (0.0267)	Prec@1 99.000 (99.165)	Prec@5 100.000 (99.995)
2019-05-03 12:49:12 - INFO - TRAINING - Epoch: [177][450/500]	Time 0.053 (0.057)	Data 0.000 (0.001)	Loss 0.0114 (0.0272)	Prec@1 100.000 (99.151)	Prec@5 100.000 (99.996)
2019-05-03 12:49:16 - INFO - EVALUATING - Epoch: [177][0/100]	Time 0.379 (0.379)	Data 0.370 (0.370)	Loss 0.2746 (0.2746)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:49:17 - INFO - EVALUATING - Epoch: [177][50/100]	Time 0.019 (0.025)	Data 0.000 (0.008)	Loss 0.2682 (0.3986)	Prec@1 93.000 (91.020)	Prec@5 100.000 (99.549)
2019-05-03 12:49:18 - INFO - 
 Epoch: 178	Training Loss 0.0272 	Training Prec@1 99.140 	Training Prec@5 99.996 	Validation Loss 0.3818 	Validation Prec@1 91.130 	Validation Prec@5 99.650 	
2019-05-03 12:49:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:49:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:49:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:49:18 - INFO - TRAINING - Epoch: [178][0/500]	Time 0.276 (0.276)	Data 0.252 (0.252)	Loss 0.0140 (0.0140)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:49:21 - INFO - TRAINING - Epoch: [178][50/500]	Time 0.053 (0.058)	Data 0.000 (0.006)	Loss 0.0085 (0.0197)	Prec@1 100.000 (99.294)	Prec@5 100.000 (100.000)
2019-05-03 12:49:23 - INFO - TRAINING - Epoch: [178][100/500]	Time 0.061 (0.055)	Data 0.000 (0.003)	Loss 0.0143 (0.0214)	Prec@1 99.000 (99.277)	Prec@5 100.000 (100.000)
2019-05-03 12:49:26 - INFO - TRAINING - Epoch: [178][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0298 (0.0235)	Prec@1 99.000 (99.232)	Prec@5 100.000 (100.000)
2019-05-03 12:49:29 - INFO - TRAINING - Epoch: [178][200/500]	Time 0.060 (0.054)	Data 0.000 (0.002)	Loss 0.0103 (0.0259)	Prec@1 100.000 (99.149)	Prec@5 100.000 (100.000)
2019-05-03 12:49:31 - INFO - TRAINING - Epoch: [178][250/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0163 (0.0262)	Prec@1 100.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:49:34 - INFO - TRAINING - Epoch: [178][300/500]	Time 0.048 (0.054)	Data 0.000 (0.002)	Loss 0.0035 (0.0266)	Prec@1 100.000 (99.123)	Prec@5 100.000 (100.000)
2019-05-03 12:49:37 - INFO - TRAINING - Epoch: [178][350/500]	Time 0.058 (0.054)	Data 0.000 (0.002)	Loss 0.0538 (0.0261)	Prec@1 97.000 (99.134)	Prec@5 100.000 (100.000)
2019-05-03 12:49:39 - INFO - TRAINING - Epoch: [178][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0210 (0.0259)	Prec@1 99.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-03 12:49:42 - INFO - TRAINING - Epoch: [178][450/500]	Time 0.046 (0.054)	Data 0.000 (0.001)	Loss 0.0087 (0.0257)	Prec@1 100.000 (99.146)	Prec@5 100.000 (100.000)
2019-05-03 12:49:45 - INFO - EVALUATING - Epoch: [178][0/100]	Time 0.369 (0.369)	Data 0.356 (0.356)	Loss 0.1343 (0.1343)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:49:46 - INFO - EVALUATING - Epoch: [178][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.3260 (0.3854)	Prec@1 94.000 (91.196)	Prec@5 99.000 (99.549)
2019-05-03 12:49:47 - INFO - 
 Epoch: 179	Training Loss 0.0260 	Training Prec@1 99.128 	Training Prec@5 100.000 	Validation Loss 0.3777 	Validation Prec@1 91.260 	Validation Prec@5 99.630 	
2019-05-03 12:49:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:49:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:49:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:49:47 - INFO - TRAINING - Epoch: [179][0/500]	Time 0.292 (0.292)	Data 0.270 (0.270)	Loss 0.0237 (0.0237)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:49:50 - INFO - TRAINING - Epoch: [179][50/500]	Time 0.061 (0.061)	Data 0.000 (0.006)	Loss 0.0229 (0.0272)	Prec@1 99.000 (99.294)	Prec@5 100.000 (100.000)
2019-05-03 12:49:53 - INFO - TRAINING - Epoch: [179][100/500]	Time 0.056 (0.059)	Data 0.000 (0.004)	Loss 0.0470 (0.0287)	Prec@1 97.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:49:56 - INFO - TRAINING - Epoch: [179][150/500]	Time 0.059 (0.058)	Data 0.000 (0.003)	Loss 0.0241 (0.0287)	Prec@1 99.000 (99.106)	Prec@5 100.000 (100.000)
2019-05-03 12:49:59 - INFO - TRAINING - Epoch: [179][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0402 (0.0278)	Prec@1 99.000 (99.095)	Prec@5 100.000 (100.000)
2019-05-03 12:50:02 - INFO - TRAINING - Epoch: [179][250/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0058 (0.0271)	Prec@1 100.000 (99.116)	Prec@5 100.000 (100.000)
2019-05-03 12:50:04 - INFO - TRAINING - Epoch: [179][300/500]	Time 0.054 (0.058)	Data 0.000 (0.002)	Loss 0.0126 (0.0274)	Prec@1 100.000 (99.106)	Prec@5 100.000 (100.000)
2019-05-03 12:50:07 - INFO - TRAINING - Epoch: [179][350/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0531 (0.0275)	Prec@1 99.000 (99.091)	Prec@5 100.000 (100.000)
2019-05-03 12:50:10 - INFO - TRAINING - Epoch: [179][400/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.0508 (0.0278)	Prec@1 99.000 (99.072)	Prec@5 100.000 (100.000)
2019-05-03 12:50:13 - INFO - TRAINING - Epoch: [179][450/500]	Time 0.055 (0.058)	Data 0.000 (0.001)	Loss 0.0250 (0.0282)	Prec@1 99.000 (99.053)	Prec@5 100.000 (100.000)
2019-05-03 12:50:16 - INFO - EVALUATING - Epoch: [179][0/100]	Time 0.341 (0.341)	Data 0.331 (0.331)	Loss 0.1739 (0.1739)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:50:17 - INFO - EVALUATING - Epoch: [179][50/100]	Time 0.016 (0.024)	Data 0.000 (0.007)	Loss 0.2948 (0.3826)	Prec@1 94.000 (91.098)	Prec@5 99.000 (99.588)
2019-05-03 12:50:18 - INFO - 
 Epoch: 180	Training Loss 0.0283 	Training Prec@1 99.058 	Training Prec@5 100.000 	Validation Loss 0.3710 	Validation Prec@1 91.270 	Validation Prec@5 99.660 	
2019-05-03 12:50:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:50:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:50:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:50:18 - INFO - TRAINING - Epoch: [180][0/500]	Time 0.300 (0.300)	Data 0.270 (0.270)	Loss 0.0314 (0.0314)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:50:21 - INFO - TRAINING - Epoch: [180][50/500]	Time 0.043 (0.059)	Data 0.000 (0.006)	Loss 0.0430 (0.0298)	Prec@1 99.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:50:24 - INFO - TRAINING - Epoch: [180][100/500]	Time 0.059 (0.057)	Data 0.000 (0.003)	Loss 0.0149 (0.0279)	Prec@1 99.000 (98.980)	Prec@5 100.000 (100.000)
2019-05-03 12:50:26 - INFO - TRAINING - Epoch: [180][150/500]	Time 0.060 (0.056)	Data 0.000 (0.002)	Loss 0.0198 (0.0274)	Prec@1 99.000 (99.020)	Prec@5 100.000 (100.000)
2019-05-03 12:50:29 - INFO - TRAINING - Epoch: [180][200/500]	Time 0.054 (0.055)	Data 0.000 (0.002)	Loss 0.0231 (0.0271)	Prec@1 100.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:50:32 - INFO - TRAINING - Epoch: [180][250/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0164 (0.0259)	Prec@1 100.000 (99.143)	Prec@5 100.000 (100.000)
2019-05-03 12:50:35 - INFO - TRAINING - Epoch: [180][300/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0093 (0.0261)	Prec@1 100.000 (99.143)	Prec@5 100.000 (100.000)
2019-05-03 12:50:37 - INFO - TRAINING - Epoch: [180][350/500]	Time 0.045 (0.055)	Data 0.000 (0.002)	Loss 0.0069 (0.0264)	Prec@1 100.000 (99.131)	Prec@5 100.000 (100.000)
2019-05-03 12:50:40 - INFO - TRAINING - Epoch: [180][400/500]	Time 0.055 (0.055)	Data 0.000 (0.001)	Loss 0.0626 (0.0271)	Prec@1 98.000 (99.107)	Prec@5 100.000 (100.000)
2019-05-03 12:50:43 - INFO - TRAINING - Epoch: [180][450/500]	Time 0.063 (0.055)	Data 0.000 (0.001)	Loss 0.0438 (0.0270)	Prec@1 99.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:50:46 - INFO - EVALUATING - Epoch: [180][0/100]	Time 0.358 (0.358)	Data 0.344 (0.344)	Loss 0.2100 (0.2100)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:50:46 - INFO - EVALUATING - Epoch: [180][50/100]	Time 0.021 (0.024)	Data 0.000 (0.007)	Loss 0.2662 (0.3771)	Prec@1 94.000 (91.137)	Prec@5 99.000 (99.647)
2019-05-03 12:50:47 - INFO - 
 Epoch: 181	Training Loss 0.0265 	Training Prec@1 99.112 	Training Prec@5 100.000 	Validation Loss 0.3785 	Validation Prec@1 91.310 	Validation Prec@5 99.620 	
2019-05-03 12:50:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:50:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:50:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:50:48 - INFO - TRAINING - Epoch: [181][0/500]	Time 0.280 (0.280)	Data 0.247 (0.247)	Loss 0.0019 (0.0019)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:50:51 - INFO - TRAINING - Epoch: [181][50/500]	Time 0.057 (0.061)	Data 0.000 (0.005)	Loss 0.0173 (0.0292)	Prec@1 100.000 (99.118)	Prec@5 100.000 (100.000)
2019-05-03 12:50:54 - INFO - TRAINING - Epoch: [181][100/500]	Time 0.056 (0.059)	Data 0.000 (0.003)	Loss 0.0176 (0.0262)	Prec@1 100.000 (99.248)	Prec@5 100.000 (100.000)
2019-05-03 12:50:56 - INFO - TRAINING - Epoch: [181][150/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.0303 (0.0274)	Prec@1 99.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:50:59 - INFO - TRAINING - Epoch: [181][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0090 (0.0285)	Prec@1 100.000 (99.119)	Prec@5 100.000 (100.000)
2019-05-03 12:51:02 - INFO - TRAINING - Epoch: [181][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0180 (0.0291)	Prec@1 99.000 (99.104)	Prec@5 100.000 (100.000)
2019-05-03 12:51:05 - INFO - TRAINING - Epoch: [181][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0433 (0.0292)	Prec@1 97.000 (99.086)	Prec@5 100.000 (100.000)
2019-05-03 12:51:08 - INFO - TRAINING - Epoch: [181][350/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0058 (0.0286)	Prec@1 100.000 (99.114)	Prec@5 100.000 (100.000)
2019-05-03 12:51:11 - INFO - TRAINING - Epoch: [181][400/500]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 0.0618 (0.0291)	Prec@1 99.000 (99.095)	Prec@5 100.000 (100.000)
2019-05-03 12:51:13 - INFO - TRAINING - Epoch: [181][450/500]	Time 0.056 (0.057)	Data 0.000 (0.001)	Loss 0.0025 (0.0283)	Prec@1 100.000 (99.118)	Prec@5 100.000 (100.000)
2019-05-03 12:51:17 - INFO - EVALUATING - Epoch: [181][0/100]	Time 0.371 (0.371)	Data 0.358 (0.358)	Loss 0.2729 (0.2729)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:51:18 - INFO - EVALUATING - Epoch: [181][50/100]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.2459 (0.3771)	Prec@1 94.000 (91.275)	Prec@5 100.000 (99.490)
2019-05-03 12:51:18 - INFO - 
 Epoch: 182	Training Loss 0.0281 	Training Prec@1 99.116 	Training Prec@5 100.000 	Validation Loss 0.3653 	Validation Prec@1 91.340 	Validation Prec@5 99.540 	
2019-05-03 12:51:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:51:19 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:51:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:51:19 - INFO - TRAINING - Epoch: [182][0/500]	Time 0.278 (0.278)	Data 0.252 (0.252)	Loss 0.0133 (0.0133)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:51:22 - INFO - TRAINING - Epoch: [182][50/500]	Time 0.056 (0.061)	Data 0.000 (0.006)	Loss 0.0179 (0.0231)	Prec@1 100.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-03 12:51:25 - INFO - TRAINING - Epoch: [182][100/500]	Time 0.058 (0.059)	Data 0.000 (0.003)	Loss 0.0296 (0.0269)	Prec@1 99.000 (99.119)	Prec@5 100.000 (99.980)
2019-05-03 12:51:27 - INFO - TRAINING - Epoch: [182][150/500]	Time 0.058 (0.058)	Data 0.000 (0.003)	Loss 0.0032 (0.0270)	Prec@1 100.000 (99.119)	Prec@5 100.000 (99.987)
2019-05-03 12:51:30 - INFO - TRAINING - Epoch: [182][200/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0262 (0.0268)	Prec@1 99.000 (99.085)	Prec@5 100.000 (99.990)
2019-05-03 12:51:33 - INFO - TRAINING - Epoch: [182][250/500]	Time 0.053 (0.058)	Data 0.000 (0.002)	Loss 0.0223 (0.0271)	Prec@1 100.000 (99.084)	Prec@5 100.000 (99.992)
2019-05-03 12:51:36 - INFO - TRAINING - Epoch: [182][300/500]	Time 0.066 (0.058)	Data 0.000 (0.002)	Loss 0.0742 (0.0267)	Prec@1 98.000 (99.110)	Prec@5 100.000 (99.993)
2019-05-03 12:51:39 - INFO - TRAINING - Epoch: [182][350/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0932 (0.0274)	Prec@1 99.000 (99.083)	Prec@5 100.000 (99.994)
2019-05-03 12:51:42 - INFO - TRAINING - Epoch: [182][400/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0112 (0.0276)	Prec@1 100.000 (99.072)	Prec@5 100.000 (99.995)
2019-05-03 12:51:45 - INFO - TRAINING - Epoch: [182][450/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0262 (0.0274)	Prec@1 99.000 (99.075)	Prec@5 100.000 (99.996)
2019-05-03 12:51:48 - INFO - EVALUATING - Epoch: [182][0/100]	Time 0.401 (0.401)	Data 0.388 (0.388)	Loss 0.2900 (0.2900)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:51:49 - INFO - EVALUATING - Epoch: [182][50/100]	Time 0.017 (0.025)	Data 0.000 (0.008)	Loss 0.1759 (0.4045)	Prec@1 96.000 (91.059)	Prec@5 99.000 (99.627)
2019-05-03 12:51:49 - INFO - 
 Epoch: 183	Training Loss 0.0272 	Training Prec@1 99.086 	Training Prec@5 99.996 	Validation Loss 0.3807 	Validation Prec@1 91.060 	Validation Prec@5 99.640 	
2019-05-03 12:51:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:51:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:51:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:51:50 - INFO - TRAINING - Epoch: [183][0/500]	Time 0.276 (0.276)	Data 0.249 (0.249)	Loss 0.0825 (0.0825)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-05-03 12:51:53 - INFO - TRAINING - Epoch: [183][50/500]	Time 0.067 (0.058)	Data 0.000 (0.006)	Loss 0.0368 (0.0265)	Prec@1 98.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:51:55 - INFO - TRAINING - Epoch: [183][100/500]	Time 0.043 (0.056)	Data 0.000 (0.003)	Loss 0.0163 (0.0260)	Prec@1 99.000 (99.129)	Prec@5 100.000 (100.000)
2019-05-03 12:51:58 - INFO - TRAINING - Epoch: [183][150/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0740 (0.0258)	Prec@1 99.000 (99.126)	Prec@5 100.000 (100.000)
2019-05-03 12:52:01 - INFO - TRAINING - Epoch: [183][200/500]	Time 0.062 (0.055)	Data 0.000 (0.002)	Loss 0.0124 (0.0259)	Prec@1 100.000 (99.164)	Prec@5 100.000 (100.000)
2019-05-03 12:52:03 - INFO - TRAINING - Epoch: [183][250/500]	Time 0.059 (0.054)	Data 0.000 (0.002)	Loss 0.0050 (0.0253)	Prec@1 100.000 (99.187)	Prec@5 100.000 (100.000)
2019-05-03 12:52:06 - INFO - TRAINING - Epoch: [183][300/500]	Time 0.054 (0.054)	Data 0.000 (0.002)	Loss 0.0242 (0.0256)	Prec@1 99.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:52:09 - INFO - TRAINING - Epoch: [183][350/500]	Time 0.044 (0.054)	Data 0.000 (0.001)	Loss 0.0336 (0.0257)	Prec@1 99.000 (99.168)	Prec@5 100.000 (100.000)
2019-05-03 12:52:11 - INFO - TRAINING - Epoch: [183][400/500]	Time 0.063 (0.054)	Data 0.000 (0.001)	Loss 0.0347 (0.0261)	Prec@1 98.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-03 12:52:14 - INFO - TRAINING - Epoch: [183][450/500]	Time 0.050 (0.054)	Data 0.000 (0.001)	Loss 0.0219 (0.0264)	Prec@1 99.000 (99.115)	Prec@5 100.000 (100.000)
2019-05-03 12:52:17 - INFO - EVALUATING - Epoch: [183][0/100]	Time 0.363 (0.363)	Data 0.352 (0.352)	Loss 0.2865 (0.2865)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:52:18 - INFO - EVALUATING - Epoch: [183][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.1666 (0.4070)	Prec@1 97.000 (91.118)	Prec@5 100.000 (99.529)
2019-05-03 12:52:19 - INFO - 
 Epoch: 184	Training Loss 0.0272 	Training Prec@1 99.092 	Training Prec@5 100.000 	Validation Loss 0.3855 	Validation Prec@1 91.290 	Validation Prec@5 99.640 	
2019-05-03 12:52:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:52:19 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:52:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:52:19 - INFO - TRAINING - Epoch: [184][0/500]	Time 0.271 (0.271)	Data 0.243 (0.243)	Loss 0.0464 (0.0464)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:52:22 - INFO - TRAINING - Epoch: [184][50/500]	Time 0.044 (0.061)	Data 0.000 (0.005)	Loss 0.0061 (0.0257)	Prec@1 100.000 (99.235)	Prec@5 100.000 (100.000)
2019-05-03 12:52:25 - INFO - TRAINING - Epoch: [184][100/500]	Time 0.049 (0.059)	Data 0.000 (0.003)	Loss 0.0296 (0.0266)	Prec@1 99.000 (99.129)	Prec@5 100.000 (100.000)
2019-05-03 12:52:28 - INFO - TRAINING - Epoch: [184][150/500]	Time 0.059 (0.058)	Data 0.000 (0.002)	Loss 0.0103 (0.0257)	Prec@1 100.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:52:31 - INFO - TRAINING - Epoch: [184][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0366 (0.0255)	Prec@1 99.000 (99.164)	Prec@5 100.000 (100.000)
2019-05-03 12:52:34 - INFO - TRAINING - Epoch: [184][250/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0073 (0.0267)	Prec@1 100.000 (99.143)	Prec@5 100.000 (100.000)
2019-05-03 12:52:36 - INFO - TRAINING - Epoch: [184][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0081 (0.0260)	Prec@1 100.000 (99.153)	Prec@5 100.000 (100.000)
2019-05-03 12:52:39 - INFO - TRAINING - Epoch: [184][350/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0454 (0.0257)	Prec@1 97.000 (99.151)	Prec@5 100.000 (100.000)
2019-05-03 12:52:42 - INFO - TRAINING - Epoch: [184][400/500]	Time 0.062 (0.058)	Data 0.000 (0.001)	Loss 0.0223 (0.0254)	Prec@1 99.000 (99.160)	Prec@5 100.000 (100.000)
2019-05-03 12:52:45 - INFO - TRAINING - Epoch: [184][450/500]	Time 0.066 (0.057)	Data 0.000 (0.001)	Loss 0.0140 (0.0256)	Prec@1 100.000 (99.155)	Prec@5 100.000 (100.000)
2019-05-03 12:52:48 - INFO - EVALUATING - Epoch: [184][0/100]	Time 0.370 (0.370)	Data 0.360 (0.360)	Loss 0.3154 (0.3154)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 12:52:49 - INFO - EVALUATING - Epoch: [184][50/100]	Time 0.026 (0.026)	Data 0.000 (0.007)	Loss 0.2866 (0.3944)	Prec@1 95.000 (91.196)	Prec@5 99.000 (99.549)
2019-05-03 12:52:50 - INFO - 
 Epoch: 185	Training Loss 0.0259 	Training Prec@1 99.140 	Training Prec@5 100.000 	Validation Loss 0.3778 	Validation Prec@1 91.260 	Validation Prec@5 99.610 	
2019-05-03 12:52:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:52:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:52:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:52:50 - INFO - TRAINING - Epoch: [185][0/500]	Time 0.273 (0.273)	Data 0.250 (0.250)	Loss 0.0187 (0.0187)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:52:53 - INFO - TRAINING - Epoch: [185][50/500]	Time 0.051 (0.060)	Data 0.000 (0.006)	Loss 0.0149 (0.0272)	Prec@1 100.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:52:56 - INFO - TRAINING - Epoch: [185][100/500]	Time 0.059 (0.058)	Data 0.000 (0.003)	Loss 0.0222 (0.0278)	Prec@1 99.000 (99.050)	Prec@5 100.000 (100.000)
2019-05-03 12:52:59 - INFO - TRAINING - Epoch: [185][150/500]	Time 0.056 (0.057)	Data 0.000 (0.003)	Loss 0.0397 (0.0292)	Prec@1 98.000 (99.020)	Prec@5 100.000 (100.000)
2019-05-03 12:53:02 - INFO - TRAINING - Epoch: [185][200/500]	Time 0.057 (0.057)	Data 0.000 (0.002)	Loss 0.0280 (0.0283)	Prec@1 99.000 (99.065)	Prec@5 100.000 (100.000)
2019-05-03 12:53:05 - INFO - TRAINING - Epoch: [185][250/500]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 0.0082 (0.0268)	Prec@1 100.000 (99.084)	Prec@5 100.000 (100.000)
2019-05-03 12:53:07 - INFO - TRAINING - Epoch: [185][300/500]	Time 0.047 (0.057)	Data 0.000 (0.002)	Loss 0.0087 (0.0269)	Prec@1 100.000 (99.100)	Prec@5 100.000 (100.000)
2019-05-03 12:53:10 - INFO - TRAINING - Epoch: [185][350/500]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 0.0057 (0.0265)	Prec@1 100.000 (99.120)	Prec@5 100.000 (100.000)
2019-05-03 12:53:13 - INFO - TRAINING - Epoch: [185][400/500]	Time 0.040 (0.057)	Data 0.000 (0.002)	Loss 0.0081 (0.0263)	Prec@1 100.000 (99.125)	Prec@5 100.000 (100.000)
2019-05-03 12:53:16 - INFO - TRAINING - Epoch: [185][450/500]	Time 0.054 (0.057)	Data 0.000 (0.001)	Loss 0.0220 (0.0262)	Prec@1 99.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:53:19 - INFO - EVALUATING - Epoch: [185][0/100]	Time 0.361 (0.361)	Data 0.354 (0.354)	Loss 0.2775 (0.2775)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:53:20 - INFO - EVALUATING - Epoch: [185][50/100]	Time 0.020 (0.025)	Data 0.000 (0.007)	Loss 0.1675 (0.3817)	Prec@1 95.000 (91.176)	Prec@5 100.000 (99.529)
2019-05-03 12:53:21 - INFO - 
 Epoch: 186	Training Loss 0.0263 	Training Prec@1 99.122 	Training Prec@5 100.000 	Validation Loss 0.3723 	Validation Prec@1 91.180 	Validation Prec@5 99.620 	
2019-05-03 12:53:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:53:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:53:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:53:21 - INFO - TRAINING - Epoch: [186][0/500]	Time 0.302 (0.302)	Data 0.274 (0.274)	Loss 0.0083 (0.0083)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:53:24 - INFO - TRAINING - Epoch: [186][50/500]	Time 0.056 (0.059)	Data 0.000 (0.006)	Loss 0.0053 (0.0258)	Prec@1 100.000 (99.039)	Prec@5 100.000 (100.000)
2019-05-03 12:53:27 - INFO - TRAINING - Epoch: [186][100/500]	Time 0.048 (0.056)	Data 0.000 (0.003)	Loss 0.0154 (0.0277)	Prec@1 100.000 (98.990)	Prec@5 100.000 (100.000)
2019-05-03 12:53:29 - INFO - TRAINING - Epoch: [186][150/500]	Time 0.067 (0.055)	Data 0.000 (0.003)	Loss 0.0188 (0.0262)	Prec@1 100.000 (99.066)	Prec@5 100.000 (100.000)
2019-05-03 12:53:32 - INFO - TRAINING - Epoch: [186][200/500]	Time 0.052 (0.055)	Data 0.000 (0.002)	Loss 0.0148 (0.0251)	Prec@1 99.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:53:35 - INFO - TRAINING - Epoch: [186][250/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0511 (0.0257)	Prec@1 97.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:53:37 - INFO - TRAINING - Epoch: [186][300/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0457 (0.0256)	Prec@1 99.000 (99.153)	Prec@5 100.000 (100.000)
2019-05-03 12:53:40 - INFO - TRAINING - Epoch: [186][350/500]	Time 0.063 (0.055)	Data 0.000 (0.002)	Loss 0.0344 (0.0258)	Prec@1 99.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-03 12:53:43 - INFO - TRAINING - Epoch: [186][400/500]	Time 0.041 (0.054)	Data 0.000 (0.001)	Loss 0.0114 (0.0253)	Prec@1 100.000 (99.172)	Prec@5 100.000 (100.000)
2019-05-03 12:53:46 - INFO - TRAINING - Epoch: [186][450/500]	Time 0.061 (0.054)	Data 0.000 (0.001)	Loss 0.0284 (0.0264)	Prec@1 98.000 (99.129)	Prec@5 100.000 (100.000)
2019-05-03 12:53:49 - INFO - EVALUATING - Epoch: [186][0/100]	Time 0.379 (0.379)	Data 0.367 (0.367)	Loss 0.2211 (0.2211)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:53:49 - INFO - EVALUATING - Epoch: [186][50/100]	Time 0.016 (0.025)	Data 0.000 (0.008)	Loss 0.1292 (0.3756)	Prec@1 96.000 (91.510)	Prec@5 100.000 (99.490)
2019-05-03 12:53:50 - INFO - 
 Epoch: 187	Training Loss 0.0263 	Training Prec@1 99.122 	Training Prec@5 100.000 	Validation Loss 0.3628 	Validation Prec@1 91.460 	Validation Prec@5 99.570 	
2019-05-03 12:53:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:53:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:53:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:53:51 - INFO - TRAINING - Epoch: [187][0/500]	Time 0.293 (0.293)	Data 0.255 (0.255)	Loss 0.0733 (0.0733)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:53:54 - INFO - TRAINING - Epoch: [187][50/500]	Time 0.060 (0.061)	Data 0.000 (0.006)	Loss 0.0069 (0.0283)	Prec@1 100.000 (99.020)	Prec@5 100.000 (100.000)
2019-05-03 12:53:57 - INFO - TRAINING - Epoch: [187][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0308 (0.0286)	Prec@1 98.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:53:59 - INFO - TRAINING - Epoch: [187][150/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0396 (0.0299)	Prec@1 98.000 (98.993)	Prec@5 100.000 (100.000)
2019-05-03 12:54:02 - INFO - TRAINING - Epoch: [187][200/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0056 (0.0286)	Prec@1 100.000 (99.055)	Prec@5 100.000 (100.000)
2019-05-03 12:54:05 - INFO - TRAINING - Epoch: [187][250/500]	Time 0.069 (0.058)	Data 0.000 (0.002)	Loss 0.0025 (0.0274)	Prec@1 100.000 (99.080)	Prec@5 100.000 (100.000)
2019-05-03 12:54:08 - INFO - TRAINING - Epoch: [187][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0168 (0.0265)	Prec@1 99.000 (99.123)	Prec@5 100.000 (100.000)
2019-05-03 12:54:11 - INFO - TRAINING - Epoch: [187][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0302 (0.0266)	Prec@1 99.000 (99.105)	Prec@5 100.000 (100.000)
2019-05-03 12:54:14 - INFO - TRAINING - Epoch: [187][400/500]	Time 0.064 (0.057)	Data 0.000 (0.001)	Loss 0.0180 (0.0264)	Prec@1 100.000 (99.107)	Prec@5 100.000 (100.000)
2019-05-03 12:54:17 - INFO - TRAINING - Epoch: [187][450/500]	Time 0.058 (0.057)	Data 0.000 (0.001)	Loss 0.0199 (0.0267)	Prec@1 99.000 (99.089)	Prec@5 100.000 (100.000)
2019-05-03 12:54:20 - INFO - EVALUATING - Epoch: [187][0/100]	Time 0.368 (0.368)	Data 0.355 (0.355)	Loss 0.2837 (0.2837)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:54:21 - INFO - EVALUATING - Epoch: [187][50/100]	Time 0.015 (0.025)	Data 0.000 (0.007)	Loss 0.2011 (0.3928)	Prec@1 93.000 (91.020)	Prec@5 100.000 (99.608)
2019-05-03 12:54:21 - INFO - 
 Epoch: 188	Training Loss 0.0265 	Training Prec@1 99.114 	Training Prec@5 100.000 	Validation Loss 0.3845 	Validation Prec@1 91.160 	Validation Prec@5 99.620 	
2019-05-03 12:54:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:54:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:54:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:54:22 - INFO - TRAINING - Epoch: [188][0/500]	Time 0.288 (0.288)	Data 0.263 (0.263)	Loss 0.0194 (0.0194)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:54:25 - INFO - TRAINING - Epoch: [188][50/500]	Time 0.070 (0.062)	Data 0.000 (0.006)	Loss 0.0101 (0.0244)	Prec@1 100.000 (99.176)	Prec@5 100.000 (100.000)
2019-05-03 12:54:28 - INFO - TRAINING - Epoch: [188][100/500]	Time 0.059 (0.059)	Data 0.000 (0.003)	Loss 0.0197 (0.0233)	Prec@1 99.000 (99.168)	Prec@5 100.000 (100.000)
2019-05-03 12:54:30 - INFO - TRAINING - Epoch: [188][150/500]	Time 0.065 (0.058)	Data 0.000 (0.003)	Loss 0.0096 (0.0254)	Prec@1 100.000 (99.086)	Prec@5 100.000 (100.000)
2019-05-03 12:54:33 - INFO - TRAINING - Epoch: [188][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0597 (0.0250)	Prec@1 96.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:54:36 - INFO - TRAINING - Epoch: [188][250/500]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 0.0201 (0.0258)	Prec@1 99.000 (99.092)	Prec@5 100.000 (100.000)
2019-05-03 12:54:39 - INFO - TRAINING - Epoch: [188][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0219 (0.0255)	Prec@1 99.000 (99.110)	Prec@5 100.000 (100.000)
2019-05-03 12:54:42 - INFO - TRAINING - Epoch: [188][350/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0044 (0.0256)	Prec@1 100.000 (99.111)	Prec@5 100.000 (100.000)
2019-05-03 12:54:45 - INFO - TRAINING - Epoch: [188][400/500]	Time 0.064 (0.058)	Data 0.000 (0.001)	Loss 0.0233 (0.0249)	Prec@1 99.000 (99.130)	Prec@5 100.000 (100.000)
2019-05-03 12:54:48 - INFO - TRAINING - Epoch: [188][450/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0203 (0.0251)	Prec@1 99.000 (99.137)	Prec@5 100.000 (99.998)
2019-05-03 12:54:51 - INFO - EVALUATING - Epoch: [188][0/100]	Time 0.252 (0.252)	Data 0.244 (0.244)	Loss 0.2510 (0.2510)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:54:52 - INFO - EVALUATING - Epoch: [188][50/100]	Time 0.023 (0.023)	Data 0.000 (0.005)	Loss 0.2645 (0.3898)	Prec@1 94.000 (91.196)	Prec@5 99.000 (99.490)
2019-05-03 12:54:52 - INFO - 
 Epoch: 189	Training Loss 0.0251 	Training Prec@1 99.156 	Training Prec@5 99.998 	Validation Loss 0.3898 	Validation Prec@1 91.080 	Validation Prec@5 99.570 	
2019-05-03 12:54:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:54:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:54:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:54:53 - INFO - TRAINING - Epoch: [189][0/500]	Time 0.272 (0.272)	Data 0.248 (0.248)	Loss 0.0331 (0.0331)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:54:56 - INFO - TRAINING - Epoch: [189][50/500]	Time 0.059 (0.059)	Data 0.000 (0.006)	Loss 0.0234 (0.0223)	Prec@1 99.000 (99.255)	Prec@5 100.000 (100.000)
2019-05-03 12:54:58 - INFO - TRAINING - Epoch: [189][100/500]	Time 0.056 (0.057)	Data 0.000 (0.003)	Loss 0.0180 (0.0256)	Prec@1 100.000 (99.178)	Prec@5 100.000 (100.000)
2019-05-03 12:55:01 - INFO - TRAINING - Epoch: [189][150/500]	Time 0.050 (0.056)	Data 0.000 (0.003)	Loss 0.0347 (0.0264)	Prec@1 99.000 (99.146)	Prec@5 100.000 (100.000)
2019-05-03 12:55:04 - INFO - TRAINING - Epoch: [189][200/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0417 (0.0262)	Prec@1 99.000 (99.124)	Prec@5 100.000 (100.000)
2019-05-03 12:55:06 - INFO - TRAINING - Epoch: [189][250/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0227 (0.0259)	Prec@1 100.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:55:09 - INFO - TRAINING - Epoch: [189][300/500]	Time 0.055 (0.055)	Data 0.000 (0.002)	Loss 0.0045 (0.0256)	Prec@1 100.000 (99.140)	Prec@5 100.000 (100.000)
2019-05-03 12:55:12 - INFO - TRAINING - Epoch: [189][350/500]	Time 0.044 (0.055)	Data 0.000 (0.002)	Loss 0.0468 (0.0255)	Prec@1 98.000 (99.148)	Prec@5 100.000 (100.000)
2019-05-03 12:55:15 - INFO - TRAINING - Epoch: [189][400/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0134 (0.0261)	Prec@1 100.000 (99.137)	Prec@5 100.000 (100.000)
2019-05-03 12:55:17 - INFO - TRAINING - Epoch: [189][450/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.0098 (0.0263)	Prec@1 100.000 (99.126)	Prec@5 100.000 (100.000)
2019-05-03 12:55:20 - INFO - EVALUATING - Epoch: [189][0/100]	Time 0.374 (0.374)	Data 0.362 (0.362)	Loss 0.2108 (0.2108)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:55:21 - INFO - EVALUATING - Epoch: [189][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2982 (0.3772)	Prec@1 93.000 (91.235)	Prec@5 100.000 (99.627)
2019-05-03 12:55:22 - INFO - 
 Epoch: 190	Training Loss 0.0263 	Training Prec@1 99.122 	Training Prec@5 100.000 	Validation Loss 0.3694 	Validation Prec@1 91.320 	Validation Prec@5 99.630 	
2019-05-03 12:55:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:55:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:55:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:55:23 - INFO - TRAINING - Epoch: [190][0/500]	Time 0.324 (0.324)	Data 0.291 (0.291)	Loss 0.0068 (0.0068)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:55:25 - INFO - TRAINING - Epoch: [190][50/500]	Time 0.060 (0.062)	Data 0.000 (0.006)	Loss 0.0104 (0.0274)	Prec@1 100.000 (99.078)	Prec@5 100.000 (100.000)
2019-05-03 12:55:28 - INFO - TRAINING - Epoch: [190][100/500]	Time 0.047 (0.059)	Data 0.000 (0.004)	Loss 0.0108 (0.0256)	Prec@1 100.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:55:31 - INFO - TRAINING - Epoch: [190][150/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0041 (0.0259)	Prec@1 100.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:55:34 - INFO - TRAINING - Epoch: [190][200/500]	Time 0.052 (0.058)	Data 0.000 (0.002)	Loss 0.0068 (0.0255)	Prec@1 100.000 (99.174)	Prec@5 100.000 (100.000)
2019-05-03 12:55:37 - INFO - TRAINING - Epoch: [190][250/500]	Time 0.067 (0.058)	Data 0.000 (0.002)	Loss 0.0255 (0.0250)	Prec@1 99.000 (99.175)	Prec@5 100.000 (100.000)
2019-05-03 12:55:40 - INFO - TRAINING - Epoch: [190][300/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0165 (0.0247)	Prec@1 99.000 (99.199)	Prec@5 100.000 (100.000)
2019-05-03 12:55:43 - INFO - TRAINING - Epoch: [190][350/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0783 (0.0248)	Prec@1 99.000 (99.205)	Prec@5 100.000 (100.000)
2019-05-03 12:55:45 - INFO - TRAINING - Epoch: [190][400/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0100 (0.0250)	Prec@1 100.000 (99.195)	Prec@5 100.000 (100.000)
2019-05-03 12:55:48 - INFO - TRAINING - Epoch: [190][450/500]	Time 0.071 (0.058)	Data 0.000 (0.002)	Loss 0.0311 (0.0249)	Prec@1 98.000 (99.188)	Prec@5 100.000 (100.000)
2019-05-03 12:55:51 - INFO - EVALUATING - Epoch: [190][0/100]	Time 0.371 (0.371)	Data 0.360 (0.360)	Loss 0.2620 (0.2620)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:55:52 - INFO - EVALUATING - Epoch: [190][50/100]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.1917 (0.3866)	Prec@1 94.000 (91.235)	Prec@5 100.000 (99.569)
2019-05-03 12:55:53 - INFO - 
 Epoch: 191	Training Loss 0.0251 	Training Prec@1 99.180 	Training Prec@5 100.000 	Validation Loss 0.3812 	Validation Prec@1 91.180 	Validation Prec@5 99.600 	
2019-05-03 12:55:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:55:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:55:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:55:54 - INFO - TRAINING - Epoch: [191][0/500]	Time 0.296 (0.296)	Data 0.272 (0.272)	Loss 0.0301 (0.0301)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:55:56 - INFO - TRAINING - Epoch: [191][50/500]	Time 0.048 (0.058)	Data 0.000 (0.006)	Loss 0.0957 (0.0271)	Prec@1 97.000 (99.196)	Prec@5 100.000 (100.000)
2019-05-03 12:55:59 - INFO - TRAINING - Epoch: [191][100/500]	Time 0.054 (0.056)	Data 0.000 (0.004)	Loss 0.0266 (0.0282)	Prec@1 99.000 (99.089)	Prec@5 100.000 (100.000)
2019-05-03 12:56:02 - INFO - TRAINING - Epoch: [191][150/500]	Time 0.058 (0.055)	Data 0.000 (0.003)	Loss 0.0316 (0.0272)	Prec@1 99.000 (99.139)	Prec@5 100.000 (100.000)
2019-05-03 12:56:04 - INFO - TRAINING - Epoch: [191][200/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.0051 (0.0268)	Prec@1 100.000 (99.124)	Prec@5 100.000 (100.000)
2019-05-03 12:56:07 - INFO - TRAINING - Epoch: [191][250/500]	Time 0.050 (0.054)	Data 0.000 (0.002)	Loss 0.0665 (0.0275)	Prec@1 98.000 (99.104)	Prec@5 100.000 (100.000)
2019-05-03 12:56:10 - INFO - TRAINING - Epoch: [191][300/500]	Time 0.049 (0.054)	Data 0.000 (0.002)	Loss 0.0287 (0.0270)	Prec@1 99.000 (99.136)	Prec@5 100.000 (100.000)
2019-05-03 12:56:12 - INFO - TRAINING - Epoch: [191][350/500]	Time 0.053 (0.054)	Data 0.000 (0.002)	Loss 0.0717 (0.0261)	Prec@1 98.000 (99.185)	Prec@5 100.000 (100.000)
2019-05-03 12:56:15 - INFO - TRAINING - Epoch: [191][400/500]	Time 0.055 (0.054)	Data 0.000 (0.002)	Loss 0.0167 (0.0255)	Prec@1 100.000 (99.209)	Prec@5 100.000 (100.000)
2019-05-03 12:56:18 - INFO - TRAINING - Epoch: [191][450/500]	Time 0.054 (0.054)	Data 0.000 (0.001)	Loss 0.0122 (0.0259)	Prec@1 100.000 (99.177)	Prec@5 100.000 (100.000)
2019-05-03 12:56:21 - INFO - EVALUATING - Epoch: [191][0/100]	Time 0.285 (0.285)	Data 0.278 (0.278)	Loss 0.3282 (0.3282)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:56:22 - INFO - EVALUATING - Epoch: [191][50/100]	Time 0.014 (0.023)	Data 0.000 (0.006)	Loss 0.2805 (0.3844)	Prec@1 94.000 (91.627)	Prec@5 100.000 (99.529)
2019-05-03 12:56:23 - INFO - 
 Epoch: 192	Training Loss 0.0261 	Training Prec@1 99.172 	Training Prec@5 100.000 	Validation Loss 0.3851 	Validation Prec@1 91.350 	Validation Prec@5 99.570 	
2019-05-03 12:56:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:56:23 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:56:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:56:23 - INFO - TRAINING - Epoch: [192][0/500]	Time 0.291 (0.291)	Data 0.262 (0.262)	Loss 0.0527 (0.0527)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:56:26 - INFO - TRAINING - Epoch: [192][50/500]	Time 0.045 (0.059)	Data 0.000 (0.006)	Loss 0.0397 (0.0262)	Prec@1 99.000 (99.059)	Prec@5 100.000 (100.000)
2019-05-03 12:56:29 - INFO - TRAINING - Epoch: [192][100/500]	Time 0.055 (0.057)	Data 0.000 (0.003)	Loss 0.0452 (0.0263)	Prec@1 99.000 (99.079)	Prec@5 100.000 (100.000)
2019-05-03 12:56:31 - INFO - TRAINING - Epoch: [192][150/500]	Time 0.062 (0.056)	Data 0.000 (0.003)	Loss 0.0166 (0.0262)	Prec@1 99.000 (99.106)	Prec@5 100.000 (100.000)
2019-05-03 12:56:34 - INFO - TRAINING - Epoch: [192][200/500]	Time 0.061 (0.056)	Data 0.000 (0.002)	Loss 0.0233 (0.0261)	Prec@1 99.000 (99.095)	Prec@5 100.000 (100.000)
2019-05-03 12:56:37 - INFO - TRAINING - Epoch: [192][250/500]	Time 0.048 (0.056)	Data 0.000 (0.002)	Loss 0.0480 (0.0253)	Prec@1 98.000 (99.155)	Prec@5 100.000 (99.996)
2019-05-03 12:56:40 - INFO - TRAINING - Epoch: [192][300/500]	Time 0.060 (0.056)	Data 0.000 (0.002)	Loss 0.0704 (0.0248)	Prec@1 98.000 (99.163)	Prec@5 100.000 (99.997)
2019-05-03 12:56:42 - INFO - TRAINING - Epoch: [192][350/500]	Time 0.054 (0.056)	Data 0.000 (0.002)	Loss 0.0089 (0.0244)	Prec@1 100.000 (99.191)	Prec@5 100.000 (99.997)
2019-05-03 12:56:45 - INFO - TRAINING - Epoch: [192][400/500]	Time 0.071 (0.056)	Data 0.000 (0.002)	Loss 0.0282 (0.0244)	Prec@1 99.000 (99.187)	Prec@5 100.000 (99.998)
2019-05-03 12:56:48 - INFO - TRAINING - Epoch: [192][450/500]	Time 0.053 (0.056)	Data 0.000 (0.001)	Loss 0.0293 (0.0248)	Prec@1 98.000 (99.180)	Prec@5 100.000 (99.998)
2019-05-03 12:56:51 - INFO - EVALUATING - Epoch: [192][0/100]	Time 0.372 (0.372)	Data 0.362 (0.362)	Loss 0.2627 (0.2627)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-05-03 12:56:52 - INFO - EVALUATING - Epoch: [192][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.1905 (0.3655)	Prec@1 95.000 (91.373)	Prec@5 100.000 (99.667)
2019-05-03 12:56:53 - INFO - 
 Epoch: 193	Training Loss 0.0255 	Training Prec@1 99.166 	Training Prec@5 99.998 	Validation Loss 0.3613 	Validation Prec@1 91.380 	Validation Prec@5 99.710 	
2019-05-03 12:56:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:56:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:56:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:56:53 - INFO - TRAINING - Epoch: [193][0/500]	Time 0.265 (0.265)	Data 0.233 (0.233)	Loss 0.0395 (0.0395)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:56:56 - INFO - TRAINING - Epoch: [193][50/500]	Time 0.058 (0.061)	Data 0.000 (0.005)	Loss 0.0424 (0.0261)	Prec@1 99.000 (99.098)	Prec@5 100.000 (100.000)
2019-05-03 12:56:59 - INFO - TRAINING - Epoch: [193][100/500]	Time 0.064 (0.059)	Data 0.000 (0.003)	Loss 0.0147 (0.0236)	Prec@1 99.000 (99.218)	Prec@5 100.000 (100.000)
2019-05-03 12:57:02 - INFO - TRAINING - Epoch: [193][150/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0353 (0.0242)	Prec@1 97.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:57:05 - INFO - TRAINING - Epoch: [193][200/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0372 (0.0248)	Prec@1 99.000 (99.174)	Prec@5 100.000 (100.000)
2019-05-03 12:57:07 - INFO - TRAINING - Epoch: [193][250/500]	Time 0.062 (0.058)	Data 0.000 (0.002)	Loss 0.0446 (0.0250)	Prec@1 99.000 (99.167)	Prec@5 100.000 (100.000)
2019-05-03 12:57:10 - INFO - TRAINING - Epoch: [193][300/500]	Time 0.065 (0.057)	Data 0.000 (0.002)	Loss 0.0197 (0.0249)	Prec@1 99.000 (99.179)	Prec@5 100.000 (100.000)
2019-05-03 12:57:13 - INFO - TRAINING - Epoch: [193][350/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0191 (0.0238)	Prec@1 99.000 (99.214)	Prec@5 100.000 (100.000)
2019-05-03 12:57:16 - INFO - TRAINING - Epoch: [193][400/500]	Time 0.055 (0.057)	Data 0.000 (0.001)	Loss 0.0056 (0.0239)	Prec@1 100.000 (99.224)	Prec@5 100.000 (100.000)
2019-05-03 12:57:19 - INFO - TRAINING - Epoch: [193][450/500]	Time 0.061 (0.057)	Data 0.000 (0.001)	Loss 0.0420 (0.0237)	Prec@1 98.000 (99.220)	Prec@5 100.000 (99.998)
2019-05-03 12:57:22 - INFO - EVALUATING - Epoch: [193][0/100]	Time 0.349 (0.349)	Data 0.341 (0.341)	Loss 0.2975 (0.2975)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-05-03 12:57:23 - INFO - EVALUATING - Epoch: [193][50/100]	Time 0.018 (0.024)	Data 0.000 (0.007)	Loss 0.2004 (0.3850)	Prec@1 94.000 (90.980)	Prec@5 100.000 (99.608)
2019-05-03 12:57:24 - INFO - 
 Epoch: 194	Training Loss 0.0240 	Training Prec@1 99.204 	Training Prec@5 99.998 	Validation Loss 0.3769 	Validation Prec@1 91.230 	Validation Prec@5 99.600 	
2019-05-03 12:57:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:57:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:57:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:57:24 - INFO - TRAINING - Epoch: [194][0/500]	Time 0.287 (0.287)	Data 0.265 (0.265)	Loss 0.0468 (0.0468)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-05-03 12:57:27 - INFO - TRAINING - Epoch: [194][50/500]	Time 0.062 (0.060)	Data 0.000 (0.006)	Loss 0.0131 (0.0285)	Prec@1 100.000 (99.059)	Prec@5 100.000 (100.000)
2019-05-03 12:57:29 - INFO - TRAINING - Epoch: [194][100/500]	Time 0.054 (0.057)	Data 0.000 (0.003)	Loss 0.0517 (0.0251)	Prec@1 99.000 (99.198)	Prec@5 100.000 (100.000)
2019-05-03 12:57:32 - INFO - TRAINING - Epoch: [194][150/500]	Time 0.059 (0.056)	Data 0.000 (0.003)	Loss 0.0544 (0.0258)	Prec@1 98.000 (99.166)	Prec@5 100.000 (100.000)
2019-05-03 12:57:35 - INFO - TRAINING - Epoch: [194][200/500]	Time 0.049 (0.055)	Data 0.000 (0.002)	Loss 0.0213 (0.0262)	Prec@1 100.000 (99.154)	Prec@5 100.000 (100.000)
2019-05-03 12:57:38 - INFO - TRAINING - Epoch: [194][250/500]	Time 0.050 (0.055)	Data 0.000 (0.002)	Loss 0.0051 (0.0262)	Prec@1 100.000 (99.147)	Prec@5 100.000 (100.000)
2019-05-03 12:57:40 - INFO - TRAINING - Epoch: [194][300/500]	Time 0.059 (0.055)	Data 0.000 (0.002)	Loss 0.0409 (0.0260)	Prec@1 98.000 (99.110)	Prec@5 100.000 (100.000)
2019-05-03 12:57:43 - INFO - TRAINING - Epoch: [194][350/500]	Time 0.057 (0.055)	Data 0.000 (0.002)	Loss 0.0120 (0.0253)	Prec@1 100.000 (99.148)	Prec@5 100.000 (100.000)
2019-05-03 12:57:46 - INFO - TRAINING - Epoch: [194][400/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0171 (0.0256)	Prec@1 100.000 (99.150)	Prec@5 100.000 (100.000)
2019-05-03 12:57:49 - INFO - TRAINING - Epoch: [194][450/500]	Time 0.059 (0.055)	Data 0.000 (0.001)	Loss 0.0602 (0.0253)	Prec@1 97.000 (99.155)	Prec@5 100.000 (100.000)
2019-05-03 12:57:52 - INFO - EVALUATING - Epoch: [194][0/100]	Time 0.374 (0.374)	Data 0.364 (0.364)	Loss 0.1788 (0.1788)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:57:53 - INFO - EVALUATING - Epoch: [194][50/100]	Time 0.026 (0.025)	Data 0.000 (0.007)	Loss 0.2771 (0.3999)	Prec@1 94.000 (90.980)	Prec@5 100.000 (99.549)
2019-05-03 12:57:54 - INFO - 
 Epoch: 195	Training Loss 0.0250 	Training Prec@1 99.170 	Training Prec@5 100.000 	Validation Loss 0.3878 	Validation Prec@1 90.950 	Validation Prec@5 99.550 	
2019-05-03 12:57:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:57:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:57:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:57:54 - INFO - TRAINING - Epoch: [195][0/500]	Time 0.309 (0.309)	Data 0.277 (0.277)	Loss 0.0332 (0.0332)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:57:57 - INFO - TRAINING - Epoch: [195][50/500]	Time 0.054 (0.062)	Data 0.000 (0.006)	Loss 0.0277 (0.0204)	Prec@1 99.000 (99.353)	Prec@5 100.000 (100.000)
2019-05-03 12:58:00 - INFO - TRAINING - Epoch: [195][100/500]	Time 0.066 (0.060)	Data 0.000 (0.004)	Loss 0.0124 (0.0224)	Prec@1 100.000 (99.267)	Prec@5 100.000 (100.000)
2019-05-03 12:58:03 - INFO - TRAINING - Epoch: [195][150/500]	Time 0.067 (0.059)	Data 0.000 (0.003)	Loss 0.0078 (0.0247)	Prec@1 100.000 (99.212)	Prec@5 100.000 (100.000)
2019-05-03 12:58:05 - INFO - TRAINING - Epoch: [195][200/500]	Time 0.055 (0.058)	Data 0.000 (0.002)	Loss 0.0261 (0.0252)	Prec@1 99.000 (99.179)	Prec@5 100.000 (100.000)
2019-05-03 12:58:08 - INFO - TRAINING - Epoch: [195][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0089 (0.0252)	Prec@1 100.000 (99.183)	Prec@5 100.000 (100.000)
2019-05-03 12:58:11 - INFO - TRAINING - Epoch: [195][300/500]	Time 0.065 (0.057)	Data 0.000 (0.002)	Loss 0.0239 (0.0251)	Prec@1 99.000 (99.173)	Prec@5 100.000 (100.000)
2019-05-03 12:58:14 - INFO - TRAINING - Epoch: [195][350/500]	Time 0.053 (0.057)	Data 0.000 (0.002)	Loss 0.0065 (0.0252)	Prec@1 100.000 (99.177)	Prec@5 100.000 (100.000)
2019-05-03 12:58:17 - INFO - TRAINING - Epoch: [195][400/500]	Time 0.055 (0.057)	Data 0.000 (0.002)	Loss 0.0816 (0.0254)	Prec@1 98.000 (99.157)	Prec@5 100.000 (100.000)
2019-05-03 12:58:19 - INFO - TRAINING - Epoch: [195][450/500]	Time 0.062 (0.057)	Data 0.000 (0.001)	Loss 0.0042 (0.0252)	Prec@1 100.000 (99.177)	Prec@5 100.000 (100.000)
2019-05-03 12:58:23 - INFO - EVALUATING - Epoch: [195][0/100]	Time 0.363 (0.363)	Data 0.356 (0.356)	Loss 0.1563 (0.1563)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:58:23 - INFO - EVALUATING - Epoch: [195][50/100]	Time 0.020 (0.025)	Data 0.000 (0.007)	Loss 0.2677 (0.3844)	Prec@1 94.000 (91.353)	Prec@5 99.000 (99.588)
2019-05-03 12:58:24 - INFO - 
 Epoch: 196	Training Loss 0.0252 	Training Prec@1 99.164 	Training Prec@5 100.000 	Validation Loss 0.3818 	Validation Prec@1 91.290 	Validation Prec@5 99.600 	
2019-05-03 12:58:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:58:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:58:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:58:25 - INFO - TRAINING - Epoch: [196][0/500]	Time 0.279 (0.279)	Data 0.251 (0.251)	Loss 0.0055 (0.0055)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:58:28 - INFO - TRAINING - Epoch: [196][50/500]	Time 0.058 (0.061)	Data 0.000 (0.006)	Loss 0.0132 (0.0250)	Prec@1 99.000 (99.255)	Prec@5 100.000 (100.000)
2019-05-03 12:58:31 - INFO - TRAINING - Epoch: [196][100/500]	Time 0.051 (0.059)	Data 0.000 (0.003)	Loss 0.0391 (0.0275)	Prec@1 99.000 (99.109)	Prec@5 100.000 (100.000)
2019-05-03 12:58:33 - INFO - TRAINING - Epoch: [196][150/500]	Time 0.050 (0.058)	Data 0.000 (0.002)	Loss 0.0112 (0.0263)	Prec@1 100.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:58:36 - INFO - TRAINING - Epoch: [196][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0618 (0.0262)	Prec@1 98.000 (99.124)	Prec@5 100.000 (100.000)
2019-05-03 12:58:39 - INFO - TRAINING - Epoch: [196][250/500]	Time 0.069 (0.058)	Data 0.000 (0.002)	Loss 0.0292 (0.0249)	Prec@1 99.000 (99.159)	Prec@5 100.000 (100.000)
2019-05-03 12:58:42 - INFO - TRAINING - Epoch: [196][300/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0056 (0.0252)	Prec@1 100.000 (99.153)	Prec@5 100.000 (100.000)
2019-05-03 12:58:45 - INFO - TRAINING - Epoch: [196][350/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0184 (0.0248)	Prec@1 99.000 (99.165)	Prec@5 100.000 (100.000)
2019-05-03 12:58:48 - INFO - TRAINING - Epoch: [196][400/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.0047 (0.0258)	Prec@1 100.000 (99.150)	Prec@5 100.000 (100.000)
2019-05-03 12:58:50 - INFO - TRAINING - Epoch: [196][450/500]	Time 0.060 (0.057)	Data 0.000 (0.001)	Loss 0.0472 (0.0259)	Prec@1 97.000 (99.146)	Prec@5 100.000 (100.000)
2019-05-03 12:58:53 - INFO - EVALUATING - Epoch: [196][0/100]	Time 0.356 (0.356)	Data 0.339 (0.339)	Loss 0.2965 (0.2965)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 12:58:54 - INFO - EVALUATING - Epoch: [196][50/100]	Time 0.024 (0.024)	Data 0.000 (0.007)	Loss 0.2218 (0.4158)	Prec@1 95.000 (90.608)	Prec@5 100.000 (99.451)
2019-05-03 12:58:55 - INFO - 
 Epoch: 197	Training Loss 0.0260 	Training Prec@1 99.132 	Training Prec@5 100.000 	Validation Loss 0.3903 	Validation Prec@1 91.230 	Validation Prec@5 99.530 	
2019-05-03 12:58:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:58:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:58:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:58:55 - INFO - TRAINING - Epoch: [197][0/500]	Time 0.292 (0.292)	Data 0.268 (0.268)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-05-03 12:58:58 - INFO - TRAINING - Epoch: [197][50/500]	Time 0.057 (0.062)	Data 0.000 (0.006)	Loss 0.0047 (0.0249)	Prec@1 100.000 (99.255)	Prec@5 100.000 (100.000)
2019-05-03 12:59:01 - INFO - TRAINING - Epoch: [197][100/500]	Time 0.064 (0.059)	Data 0.000 (0.003)	Loss 0.0752 (0.0259)	Prec@1 98.000 (99.178)	Prec@5 100.000 (99.990)
2019-05-03 12:59:04 - INFO - TRAINING - Epoch: [197][150/500]	Time 0.060 (0.059)	Data 0.000 (0.003)	Loss 0.0145 (0.0254)	Prec@1 100.000 (99.159)	Prec@5 100.000 (99.993)
2019-05-03 12:59:07 - INFO - TRAINING - Epoch: [197][200/500]	Time 0.048 (0.058)	Data 0.000 (0.002)	Loss 0.0428 (0.0258)	Prec@1 99.000 (99.139)	Prec@5 100.000 (99.995)
2019-05-03 12:59:10 - INFO - TRAINING - Epoch: [197][250/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0851 (0.0249)	Prec@1 98.000 (99.163)	Prec@5 100.000 (99.996)
2019-05-03 12:59:13 - INFO - TRAINING - Epoch: [197][300/500]	Time 0.058 (0.058)	Data 0.000 (0.002)	Loss 0.0302 (0.0250)	Prec@1 99.000 (99.169)	Prec@5 100.000 (99.993)
2019-05-03 12:59:15 - INFO - TRAINING - Epoch: [197][350/500]	Time 0.051 (0.058)	Data 0.000 (0.002)	Loss 0.0308 (0.0258)	Prec@1 98.000 (99.148)	Prec@5 100.000 (99.994)
2019-05-03 12:59:18 - INFO - TRAINING - Epoch: [197][400/500]	Time 0.056 (0.058)	Data 0.000 (0.002)	Loss 0.0517 (0.0264)	Prec@1 98.000 (99.135)	Prec@5 100.000 (99.995)
2019-05-03 12:59:21 - INFO - TRAINING - Epoch: [197][450/500]	Time 0.057 (0.058)	Data 0.000 (0.001)	Loss 0.0322 (0.0264)	Prec@1 99.000 (99.135)	Prec@5 100.000 (99.996)
2019-05-03 12:59:24 - INFO - EVALUATING - Epoch: [197][0/100]	Time 0.288 (0.288)	Data 0.273 (0.273)	Loss 0.1732 (0.1732)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:59:25 - INFO - EVALUATING - Epoch: [197][50/100]	Time 0.017 (0.023)	Data 0.000 (0.006)	Loss 0.2640 (0.3929)	Prec@1 93.000 (91.039)	Prec@5 100.000 (99.510)
2019-05-03 12:59:26 - INFO - 
 Epoch: 198	Training Loss 0.0264 	Training Prec@1 99.130 	Training Prec@5 99.996 	Validation Loss 0.3786 	Validation Prec@1 91.330 	Validation Prec@5 99.580 	
2019-05-03 12:59:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:59:26 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:59:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:59:26 - INFO - TRAINING - Epoch: [198][0/500]	Time 0.279 (0.279)	Data 0.252 (0.252)	Loss 0.0153 (0.0153)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:59:29 - INFO - TRAINING - Epoch: [198][50/500]	Time 0.062 (0.058)	Data 0.000 (0.006)	Loss 0.0123 (0.0226)	Prec@1 100.000 (99.235)	Prec@5 100.000 (100.000)
2019-05-03 12:59:32 - INFO - TRAINING - Epoch: [198][100/500]	Time 0.062 (0.056)	Data 0.000 (0.003)	Loss 0.0292 (0.0238)	Prec@1 98.000 (99.198)	Prec@5 100.000 (100.000)
2019-05-03 12:59:34 - INFO - TRAINING - Epoch: [198][150/500]	Time 0.047 (0.055)	Data 0.000 (0.002)	Loss 0.0982 (0.0237)	Prec@1 97.000 (99.232)	Prec@5 100.000 (100.000)
2019-05-03 12:59:37 - INFO - TRAINING - Epoch: [198][200/500]	Time 0.060 (0.055)	Data 0.000 (0.002)	Loss 0.0235 (0.0247)	Prec@1 99.000 (99.224)	Prec@5 100.000 (99.995)
2019-05-03 12:59:40 - INFO - TRAINING - Epoch: [198][250/500]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 0.0289 (0.0255)	Prec@1 98.000 (99.227)	Prec@5 100.000 (99.996)
2019-05-03 12:59:42 - INFO - TRAINING - Epoch: [198][300/500]	Time 0.065 (0.054)	Data 0.000 (0.002)	Loss 0.0052 (0.0250)	Prec@1 100.000 (99.246)	Prec@5 100.000 (99.997)
2019-05-03 12:59:45 - INFO - TRAINING - Epoch: [198][350/500]	Time 0.053 (0.054)	Data 0.000 (0.001)	Loss 0.0039 (0.0248)	Prec@1 100.000 (99.245)	Prec@5 100.000 (99.997)
2019-05-03 12:59:48 - INFO - TRAINING - Epoch: [198][400/500]	Time 0.046 (0.054)	Data 0.000 (0.001)	Loss 0.0343 (0.0252)	Prec@1 98.000 (99.209)	Prec@5 100.000 (99.998)
2019-05-03 12:59:51 - INFO - TRAINING - Epoch: [198][450/500]	Time 0.062 (0.054)	Data 0.000 (0.001)	Loss 0.0126 (0.0256)	Prec@1 100.000 (99.186)	Prec@5 100.000 (99.998)
2019-05-03 12:59:54 - INFO - EVALUATING - Epoch: [198][0/100]	Time 0.344 (0.344)	Data 0.337 (0.337)	Loss 0.2285 (0.2285)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 12:59:55 - INFO - EVALUATING - Epoch: [198][50/100]	Time 0.022 (0.025)	Data 0.000 (0.007)	Loss 0.2600 (0.3985)	Prec@1 93.000 (91.078)	Prec@5 99.000 (99.608)
2019-05-03 12:59:55 - INFO - 
 Epoch: 199	Training Loss 0.0256 	Training Prec@1 99.182 	Training Prec@5 99.998 	Validation Loss 0.3798 	Validation Prec@1 91.290 	Validation Prec@5 99.610 	
2019-05-03 12:59:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 12:59:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 12:59:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 12:59:56 - INFO - TRAINING - Epoch: [199][0/500]	Time 0.270 (0.270)	Data 0.239 (0.239)	Loss 0.0328 (0.0328)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-05-03 12:59:59 - INFO - TRAINING - Epoch: [199][50/500]	Time 0.062 (0.061)	Data 0.000 (0.005)	Loss 0.0735 (0.0224)	Prec@1 99.000 (99.294)	Prec@5 100.000 (100.000)
2019-05-03 13:00:02 - INFO - TRAINING - Epoch: [199][100/500]	Time 0.057 (0.059)	Data 0.000 (0.003)	Loss 0.0035 (0.0232)	Prec@1 100.000 (99.228)	Prec@5 100.000 (100.000)
2019-05-03 13:00:04 - INFO - TRAINING - Epoch: [199][150/500]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 0.0062 (0.0236)	Prec@1 100.000 (99.212)	Prec@5 100.000 (100.000)
2019-05-03 13:00:07 - INFO - TRAINING - Epoch: [199][200/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0029 (0.0254)	Prec@1 100.000 (99.134)	Prec@5 100.000 (100.000)
2019-05-03 13:00:10 - INFO - TRAINING - Epoch: [199][250/500]	Time 0.060 (0.058)	Data 0.000 (0.002)	Loss 0.0145 (0.0254)	Prec@1 100.000 (99.112)	Prec@5 100.000 (100.000)
2019-05-03 13:00:13 - INFO - TRAINING - Epoch: [199][300/500]	Time 0.063 (0.058)	Data 0.000 (0.002)	Loss 0.0438 (0.0264)	Prec@1 97.000 (99.103)	Prec@5 100.000 (100.000)
2019-05-03 13:00:16 - INFO - TRAINING - Epoch: [199][350/500]	Time 0.057 (0.058)	Data 0.000 (0.002)	Loss 0.0214 (0.0270)	Prec@1 99.000 (99.097)	Prec@5 100.000 (100.000)
2019-05-03 13:00:19 - INFO - TRAINING - Epoch: [199][400/500]	Time 0.051 (0.057)	Data 0.000 (0.001)	Loss 0.0955 (0.0269)	Prec@1 98.000 (99.082)	Prec@5 100.000 (100.000)
2019-05-03 13:00:22 - INFO - TRAINING - Epoch: [199][450/500]	Time 0.050 (0.057)	Data 0.000 (0.001)	Loss 0.0133 (0.0265)	Prec@1 100.000 (99.089)	Prec@5 100.000 (100.000)
2019-05-03 13:00:25 - INFO - EVALUATING - Epoch: [199][0/100]	Time 0.350 (0.350)	Data 0.342 (0.342)	Loss 0.3237 (0.3237)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-05-03 13:00:26 - INFO - EVALUATING - Epoch: [199][50/100]	Time 0.018 (0.025)	Data 0.000 (0.007)	Loss 0.2746 (0.3963)	Prec@1 92.000 (90.824)	Prec@5 99.000 (99.608)
2019-05-03 13:00:27 - INFO - 
 Epoch: 200	Training Loss 0.0263 	Training Prec@1 99.092 	Training Prec@5 100.000 	Validation Loss 0.3772 	Validation Prec@1 91.080 	Validation Prec@5 99.590 	
2019-05-03 13:00:27 - DEBUG - update_title_pos
2019-05-03 13:00:27 - DEBUG - findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/pami/anaconda3/envs/spacex/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2019-05-03 13:00:27 - DEBUG - update_title_pos
2019-05-03 13:00:27 - DEBUG - update_title_pos
2019-05-03 13:00:27 - DEBUG - update_title_pos
