2019-04-10 16:41:33 - INFO - saving to ./results/train_tmp/2019-04-10_16-41-33
2019-04-10 16:41:33 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', epochs=200, evaluate=None, gpus='0', inflate=4, input_size=None, lr=0.03, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/train_tmp/', resume='', save='2019-04-10_16-41-33', start_epoch=0, type='torch.cuda.FloatTensor', val_ratio=0.1, weight_decay=0, workers=0)
2019-04-10 16:41:33 - INFO - creating model resnet_preact_quan_test
2019-04-10 16:41:33 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 4}
2019-04-10 16:41:33 - INFO - number of parameters: 4300398
2019-04-10 16:41:37 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.03}}
2019-04-10 16:41:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:41:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:41:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:41:37 - INFO - TRAINING - Epoch: [0][0/450]	Time 0.447 (0.447)	Data 0.016 (0.016)	Loss 2.4855 (2.4855)	Prec@1 7.000 (7.000)	Prec@5 53.000 (53.000)
2019-04-10 16:41:40 - INFO - TRAINING - Epoch: [0][50/450]	Time 0.051 (0.059)	Data 0.012 (0.014)	Loss 2.1711 (2.1759)	Prec@1 21.000 (19.412)	Prec@5 69.000 (71.020)
2019-04-10 16:41:42 - INFO - TRAINING - Epoch: [0][100/450]	Time 0.051 (0.056)	Data 0.012 (0.014)	Loss 1.9590 (2.1053)	Prec@1 24.000 (21.941)	Prec@5 83.000 (75.465)
2019-04-10 16:41:45 - INFO - TRAINING - Epoch: [0][150/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 1.9426 (2.0608)	Prec@1 30.000 (23.113)	Prec@5 83.000 (77.914)
2019-04-10 16:41:47 - INFO - TRAINING - Epoch: [0][200/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 1.7999 (2.0239)	Prec@1 33.000 (24.836)	Prec@5 92.000 (79.552)
2019-04-10 16:41:50 - INFO - TRAINING - Epoch: [0][250/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 1.8315 (1.9936)	Prec@1 30.000 (26.008)	Prec@5 87.000 (80.745)
2019-04-10 16:41:53 - INFO - TRAINING - Epoch: [0][300/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 1.7698 (1.9628)	Prec@1 37.000 (27.498)	Prec@5 90.000 (81.738)
2019-04-10 16:41:55 - INFO - TRAINING - Epoch: [0][350/450]	Time 0.050 (0.053)	Data 0.012 (0.014)	Loss 1.6180 (1.9348)	Prec@1 47.000 (28.732)	Prec@5 90.000 (82.584)
2019-04-10 16:41:58 - INFO - TRAINING - Epoch: [0][400/450]	Time 0.052 (0.053)	Data 0.014 (0.014)	Loss 1.7971 (1.9104)	Prec@1 35.000 (29.885)	Prec@5 85.000 (83.344)
2019-04-10 16:42:01 - INFO - EVALUATING - Epoch: [0][0/50]	Time 0.040 (0.040)	Data 0.012 (0.012)	Loss 1.6916 (1.6916)	Prec@1 38.000 (38.000)	Prec@5 93.000 (93.000)
2019-04-10 16:42:01 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.016 (0.016)	Data 0.010 (0.010)	Loss 1.5744 (1.5744)	Prec@1 50.000 (50.000)	Prec@5 91.000 (91.000)
2019-04-10 16:42:02 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.6149 (1.6501)	Prec@1 45.000 (40.039)	Prec@5 87.000 (90.961)
2019-04-10 16:42:03 - INFO - 
 Epoch: 1	Training Loss 1.8895 	Training Prec@1 30.629 	Training Prec@5 83.927 	Validation Loss 1.6636 	Validation Prec@1 39.840 	Validation Prec@5 90.440 	Test Loss 1.6576 	Test Prec@1  39.950 	Test Prec@5  90.340 

2019-04-10 16:42:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:42:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:42:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:42:03 - INFO - TRAINING - Epoch: [1][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 1.6944 (1.6944)	Prec@1 36.000 (36.000)	Prec@5 91.000 (91.000)
2019-04-10 16:42:06 - INFO - TRAINING - Epoch: [1][50/450]	Time 0.052 (0.052)	Data 0.012 (0.014)	Loss 1.6813 (1.7212)	Prec@1 34.000 (37.902)	Prec@5 92.000 (88.235)
2019-04-10 16:42:08 - INFO - TRAINING - Epoch: [1][100/450]	Time 0.052 (0.052)	Data 0.012 (0.014)	Loss 1.6860 (1.6887)	Prec@1 40.000 (38.891)	Prec@5 84.000 (88.772)
2019-04-10 16:42:11 - INFO - TRAINING - Epoch: [1][150/450]	Time 0.054 (0.052)	Data 0.012 (0.014)	Loss 1.5594 (1.6666)	Prec@1 47.000 (39.563)	Prec@5 90.000 (89.219)
2019-04-10 16:42:14 - INFO - TRAINING - Epoch: [1][200/450]	Time 0.054 (0.052)	Data 0.014 (0.014)	Loss 1.5700 (1.6487)	Prec@1 42.000 (40.050)	Prec@5 94.000 (89.507)
2019-04-10 16:42:16 - INFO - TRAINING - Epoch: [1][250/450]	Time 0.056 (0.052)	Data 0.012 (0.014)	Loss 1.4381 (1.6338)	Prec@1 46.000 (40.781)	Prec@5 95.000 (89.733)
2019-04-10 16:42:19 - INFO - TRAINING - Epoch: [1][300/450]	Time 0.052 (0.052)	Data 0.013 (0.014)	Loss 1.4869 (1.6182)	Prec@1 50.000 (41.508)	Prec@5 90.000 (89.887)
2019-04-10 16:42:22 - INFO - TRAINING - Epoch: [1][350/450]	Time 0.052 (0.052)	Data 0.013 (0.014)	Loss 1.4502 (1.5997)	Prec@1 42.000 (42.117)	Prec@5 93.000 (90.174)
2019-04-10 16:42:24 - INFO - TRAINING - Epoch: [1][400/450]	Time 0.051 (0.052)	Data 0.015 (0.014)	Loss 1.4583 (1.5845)	Prec@1 46.000 (42.761)	Prec@5 91.000 (90.397)
2019-04-10 16:42:27 - INFO - EVALUATING - Epoch: [1][0/50]	Time 0.044 (0.044)	Data 0.010 (0.010)	Loss 1.2478 (1.2478)	Prec@1 54.000 (54.000)	Prec@5 91.000 (91.000)
2019-04-10 16:42:28 - INFO - EVALUATING - Epoch: [1][0/100]	Time 0.016 (0.016)	Data 0.009 (0.009)	Loss 1.2680 (1.2680)	Prec@1 53.000 (53.000)	Prec@5 96.000 (96.000)
2019-04-10 16:42:28 - INFO - EVALUATING - Epoch: [1][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.4035 (1.4316)	Prec@1 49.000 (48.569)	Prec@5 93.000 (92.647)
2019-04-10 16:42:29 - INFO - 
 Epoch: 2	Training Loss 1.5728 	Training Prec@1 43.258 	Training Prec@5 90.500 	Validation Loss 1.4628 	Validation Prec@1 47.560 	Validation Prec@5 92.040 	Test Loss 1.4434 	Test Prec@1  48.080 	Test Prec@5  92.350 

2019-04-10 16:42:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:42:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:42:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:42:29 - INFO - TRAINING - Epoch: [2][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 1.4425 (1.4425)	Prec@1 47.000 (47.000)	Prec@5 94.000 (94.000)
2019-04-10 16:42:32 - INFO - TRAINING - Epoch: [2][50/450]	Time 0.052 (0.052)	Data 0.012 (0.013)	Loss 1.4179 (1.4746)	Prec@1 45.000 (46.647)	Prec@5 97.000 (92.059)
2019-04-10 16:42:35 - INFO - TRAINING - Epoch: [2][100/450]	Time 0.052 (0.052)	Data 0.012 (0.013)	Loss 1.2574 (1.4437)	Prec@1 55.000 (47.644)	Prec@5 92.000 (92.594)
2019-04-10 16:42:37 - INFO - TRAINING - Epoch: [2][150/450]	Time 0.052 (0.052)	Data 0.012 (0.013)	Loss 1.3073 (1.4374)	Prec@1 56.000 (48.020)	Prec@5 94.000 (92.623)
2019-04-10 16:42:40 - INFO - TRAINING - Epoch: [2][200/450]	Time 0.052 (0.052)	Data 0.012 (0.013)	Loss 1.4050 (1.4291)	Prec@1 48.000 (48.507)	Prec@5 91.000 (92.741)
2019-04-10 16:42:42 - INFO - TRAINING - Epoch: [2][250/450]	Time 0.052 (0.052)	Data 0.012 (0.013)	Loss 1.4207 (1.4117)	Prec@1 49.000 (49.402)	Prec@5 94.000 (92.904)
2019-04-10 16:42:45 - INFO - TRAINING - Epoch: [2][300/450]	Time 0.057 (0.052)	Data 0.012 (0.013)	Loss 1.5606 (1.4004)	Prec@1 49.000 (49.827)	Prec@5 84.000 (93.073)
2019-04-10 16:42:48 - INFO - TRAINING - Epoch: [2][350/450]	Time 0.052 (0.053)	Data 0.012 (0.013)	Loss 1.5282 (1.3904)	Prec@1 47.000 (50.311)	Prec@5 94.000 (93.182)
2019-04-10 16:42:50 - INFO - TRAINING - Epoch: [2][400/450]	Time 0.053 (0.053)	Data 0.014 (0.013)	Loss 1.3412 (1.3741)	Prec@1 52.000 (51.000)	Prec@5 93.000 (93.362)
2019-04-10 16:42:53 - INFO - EVALUATING - Epoch: [2][0/50]	Time 0.039 (0.039)	Data 0.011 (0.011)	Loss 1.2779 (1.2779)	Prec@1 54.000 (54.000)	Prec@5 95.000 (95.000)
2019-04-10 16:42:54 - INFO - EVALUATING - Epoch: [2][0/100]	Time 0.016 (0.016)	Data 0.010 (0.010)	Loss 1.2152 (1.2152)	Prec@1 52.000 (52.000)	Prec@5 94.000 (94.000)
2019-04-10 16:42:55 - INFO - EVALUATING - Epoch: [2][50/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 1.1533 (1.3093)	Prec@1 59.000 (51.392)	Prec@5 96.000 (94.588)
2019-04-10 16:42:56 - INFO - 
 Epoch: 3	Training Loss 1.3661 	Training Prec@1 51.276 	Training Prec@5 93.438 	Validation Loss 1.3213 	Validation Prec@1 51.800 	Validation Prec@5 94.840 	Test Loss 1.3061 	Test Prec@1  51.820 	Test Prec@5  94.690 

2019-04-10 16:42:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:42:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:42:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:42:56 - INFO - TRAINING - Epoch: [3][0/450]	Time 0.036 (0.036)	Data 0.019 (0.019)	Loss 1.2389 (1.2389)	Prec@1 56.000 (56.000)	Prec@5 92.000 (92.000)
2019-04-10 16:42:58 - INFO - TRAINING - Epoch: [3][50/450]	Time 0.053 (0.052)	Data 0.014 (0.014)	Loss 1.5349 (1.3354)	Prec@1 46.000 (52.000)	Prec@5 94.000 (93.804)
2019-04-10 16:43:01 - INFO - TRAINING - Epoch: [3][100/450]	Time 0.052 (0.052)	Data 0.012 (0.014)	Loss 1.2626 (1.2983)	Prec@1 56.000 (53.891)	Prec@5 93.000 (93.891)
2019-04-10 16:43:03 - INFO - TRAINING - Epoch: [3][150/450]	Time 0.052 (0.052)	Data 0.013 (0.014)	Loss 1.4950 (1.2916)	Prec@1 52.000 (54.338)	Prec@5 93.000 (93.887)
2019-04-10 16:43:06 - INFO - TRAINING - Epoch: [3][200/450]	Time 0.051 (0.053)	Data 0.014 (0.014)	Loss 1.2956 (1.2744)	Prec@1 55.000 (54.866)	Prec@5 95.000 (94.194)
2019-04-10 16:43:09 - INFO - TRAINING - Epoch: [3][250/450]	Time 0.051 (0.053)	Data 0.013 (0.014)	Loss 1.2102 (1.2596)	Prec@1 59.000 (55.430)	Prec@5 90.000 (94.426)
2019-04-10 16:43:11 - INFO - TRAINING - Epoch: [3][300/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 1.0490 (1.2493)	Prec@1 61.000 (55.734)	Prec@5 96.000 (94.575)
2019-04-10 16:43:14 - INFO - TRAINING - Epoch: [3][350/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 1.0786 (1.2458)	Prec@1 59.000 (55.843)	Prec@5 97.000 (94.550)
2019-04-10 16:43:17 - INFO - TRAINING - Epoch: [3][400/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 1.1941 (1.2367)	Prec@1 59.000 (56.172)	Prec@5 94.000 (94.663)
2019-04-10 16:43:19 - INFO - EVALUATING - Epoch: [3][0/50]	Time 0.039 (0.039)	Data 0.011 (0.011)	Loss 1.1701 (1.1701)	Prec@1 56.000 (56.000)	Prec@5 99.000 (99.000)
2019-04-10 16:43:20 - INFO - EVALUATING - Epoch: [3][0/100]	Time 0.016 (0.016)	Data 0.009 (0.009)	Loss 1.0369 (1.0369)	Prec@1 65.000 (65.000)	Prec@5 97.000 (97.000)
2019-04-10 16:43:21 - INFO - EVALUATING - Epoch: [3][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.0143 (1.1193)	Prec@1 66.000 (60.118)	Prec@5 99.000 (96.333)
2019-04-10 16:43:22 - INFO - 
 Epoch: 4	Training Loss 1.2271 	Training Prec@1 56.489 	Training Prec@5 94.729 	Validation Loss 1.1418 	Validation Prec@1 59.360 	Validation Prec@5 96.240 	Test Loss 1.1279 	Test Prec@1  59.810 	Test Prec@5  96.360 

2019-04-10 16:43:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:43:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:43:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:43:22 - INFO - TRAINING - Epoch: [4][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 1.1012 (1.1012)	Prec@1 59.000 (59.000)	Prec@5 98.000 (98.000)
2019-04-10 16:43:24 - INFO - TRAINING - Epoch: [4][50/450]	Time 0.052 (0.052)	Data 0.013 (0.014)	Loss 1.2143 (1.2057)	Prec@1 55.000 (57.020)	Prec@5 96.000 (95.294)
2019-04-10 16:43:27 - INFO - TRAINING - Epoch: [4][100/450]	Time 0.052 (0.052)	Data 0.012 (0.014)	Loss 0.8487 (1.1680)	Prec@1 71.000 (58.307)	Prec@5 99.000 (95.653)
2019-04-10 16:43:30 - INFO - TRAINING - Epoch: [4][150/450]	Time 0.052 (0.052)	Data 0.012 (0.014)	Loss 1.1413 (1.1490)	Prec@1 58.000 (59.007)	Prec@5 98.000 (95.781)
2019-04-10 16:43:32 - INFO - TRAINING - Epoch: [4][200/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 1.2345 (1.1387)	Prec@1 58.000 (59.483)	Prec@5 94.000 (95.801)
2019-04-10 16:43:35 - INFO - TRAINING - Epoch: [4][250/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 1.0825 (1.1349)	Prec@1 65.000 (59.665)	Prec@5 96.000 (95.725)
2019-04-10 16:43:38 - INFO - TRAINING - Epoch: [4][300/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 1.0948 (1.1323)	Prec@1 60.000 (59.844)	Prec@5 94.000 (95.744)
2019-04-10 16:43:40 - INFO - TRAINING - Epoch: [4][350/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 1.0528 (1.1218)	Prec@1 62.000 (60.319)	Prec@5 97.000 (95.764)
2019-04-10 16:43:43 - INFO - TRAINING - Epoch: [4][400/450]	Time 0.051 (0.053)	Data 0.013 (0.014)	Loss 1.1980 (1.1139)	Prec@1 59.000 (60.641)	Prec@5 95.000 (95.875)
2019-04-10 16:43:46 - INFO - EVALUATING - Epoch: [4][0/50]	Time 0.040 (0.040)	Data 0.010 (0.010)	Loss 1.3005 (1.3005)	Prec@1 61.000 (61.000)	Prec@5 97.000 (97.000)
2019-04-10 16:43:46 - INFO - EVALUATING - Epoch: [4][0/100]	Time 0.016 (0.016)	Data 0.009 (0.009)	Loss 1.3257 (1.3257)	Prec@1 53.000 (53.000)	Prec@5 96.000 (96.000)
2019-04-10 16:43:47 - INFO - EVALUATING - Epoch: [4][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.4271 (1.3874)	Prec@1 47.000 (51.902)	Prec@5 89.000 (93.333)
2019-04-10 16:43:48 - INFO - 
 Epoch: 5	Training Loss 1.1060 	Training Prec@1 60.849 	Training Prec@5 95.929 	Validation Loss 1.4166 	Validation Prec@1 51.380 	Validation Prec@5 93.420 	Test Loss 1.3893 	Test Prec@1  51.370 	Test Prec@5  93.620 

2019-04-10 16:43:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:43:48 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:43:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:43:48 - INFO - TRAINING - Epoch: [5][0/450]	Time 0.035 (0.035)	Data 0.017 (0.017)	Loss 0.9277 (0.9277)	Prec@1 66.000 (66.000)	Prec@5 97.000 (97.000)
2019-04-10 16:43:51 - INFO - TRAINING - Epoch: [5][50/450]	Time 0.053 (0.052)	Data 0.014 (0.014)	Loss 1.1643 (1.0926)	Prec@1 54.000 (61.745)	Prec@5 95.000 (95.745)
2019-04-10 16:43:53 - INFO - TRAINING - Epoch: [5][100/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 1.1786 (1.0895)	Prec@1 56.000 (61.762)	Prec@5 93.000 (96.020)
2019-04-10 16:43:56 - INFO - TRAINING - Epoch: [5][150/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.9814 (1.0766)	Prec@1 63.000 (61.914)	Prec@5 92.000 (96.139)
2019-04-10 16:43:59 - INFO - TRAINING - Epoch: [5][200/450]	Time 0.052 (0.053)	Data 0.014 (0.014)	Loss 0.9075 (1.0673)	Prec@1 68.000 (62.174)	Prec@5 98.000 (96.209)
2019-04-10 16:44:01 - INFO - TRAINING - Epoch: [5][250/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 1.0487 (1.0548)	Prec@1 62.000 (62.614)	Prec@5 100.000 (96.339)
2019-04-10 16:44:04 - INFO - TRAINING - Epoch: [5][300/450]	Time 0.051 (0.053)	Data 0.013 (0.014)	Loss 0.9914 (1.0481)	Prec@1 67.000 (62.847)	Prec@5 98.000 (96.419)
2019-04-10 16:44:07 - INFO - TRAINING - Epoch: [5][350/450]	Time 0.052 (0.053)	Data 0.014 (0.014)	Loss 1.0580 (1.0416)	Prec@1 61.000 (63.077)	Prec@5 99.000 (96.524)
2019-04-10 16:44:09 - INFO - TRAINING - Epoch: [5][400/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 1.0444 (1.0352)	Prec@1 65.000 (63.324)	Prec@5 95.000 (96.584)
2019-04-10 16:44:12 - INFO - EVALUATING - Epoch: [5][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 1.0236 (1.0236)	Prec@1 66.000 (66.000)	Prec@5 96.000 (96.000)
2019-04-10 16:44:13 - INFO - EVALUATING - Epoch: [5][0/100]	Time 0.016 (0.016)	Data 0.010 (0.010)	Loss 1.0573 (1.0573)	Prec@1 59.000 (59.000)	Prec@5 96.000 (96.000)
2019-04-10 16:44:14 - INFO - EVALUATING - Epoch: [5][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.8987 (1.0183)	Prec@1 71.000 (63.529)	Prec@5 98.000 (97.157)
2019-04-10 16:44:14 - INFO - 
 Epoch: 6	Training Loss 1.0288 	Training Prec@1 63.578 	Training Prec@5 96.624 	Validation Loss 1.0430 	Validation Prec@1 63.220 	Validation Prec@5 96.700 	Test Loss 1.0169 	Test Prec@1  63.850 	Test Prec@5  97.040 

2019-04-10 16:44:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:44:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:44:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:44:15 - INFO - TRAINING - Epoch: [6][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 1.0714 (1.0714)	Prec@1 61.000 (61.000)	Prec@5 95.000 (95.000)
2019-04-10 16:44:17 - INFO - TRAINING - Epoch: [6][50/450]	Time 0.054 (0.052)	Data 0.014 (0.014)	Loss 1.1556 (1.0187)	Prec@1 59.000 (64.196)	Prec@5 96.000 (97.059)
2019-04-10 16:44:20 - INFO - TRAINING - Epoch: [6][100/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 0.9440 (0.9930)	Prec@1 66.000 (65.040)	Prec@5 98.000 (97.158)
2019-04-10 16:44:22 - INFO - TRAINING - Epoch: [6][150/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.8842 (0.9867)	Prec@1 69.000 (65.238)	Prec@5 99.000 (97.146)
2019-04-10 16:44:25 - INFO - TRAINING - Epoch: [6][200/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 1.0025 (0.9866)	Prec@1 61.000 (65.433)	Prec@5 100.000 (97.045)
2019-04-10 16:44:28 - INFO - TRAINING - Epoch: [6][250/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 1.0055 (0.9815)	Prec@1 65.000 (65.526)	Prec@5 96.000 (97.028)
2019-04-10 16:44:30 - INFO - TRAINING - Epoch: [6][300/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 1.1236 (0.9728)	Prec@1 58.000 (65.738)	Prec@5 94.000 (97.113)
2019-04-10 16:44:33 - INFO - TRAINING - Epoch: [6][350/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 1.0131 (0.9752)	Prec@1 62.000 (65.764)	Prec@5 99.000 (97.054)
2019-04-10 16:44:36 - INFO - TRAINING - Epoch: [6][400/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.7964 (0.9672)	Prec@1 72.000 (65.985)	Prec@5 100.000 (97.115)
2019-04-10 16:44:38 - INFO - EVALUATING - Epoch: [6][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 1.3200 (1.3200)	Prec@1 56.000 (56.000)	Prec@5 92.000 (92.000)
2019-04-10 16:44:39 - INFO - EVALUATING - Epoch: [6][0/100]	Time 0.016 (0.016)	Data 0.009 (0.009)	Loss 1.0775 (1.0775)	Prec@1 59.000 (59.000)	Prec@5 96.000 (96.000)
2019-04-10 16:44:40 - INFO - EVALUATING - Epoch: [6][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.1246 (1.2561)	Prec@1 61.000 (57.784)	Prec@5 94.000 (93.588)
2019-04-10 16:44:41 - INFO - 
 Epoch: 7	Training Loss 0.9635 	Training Prec@1 66.149 	Training Prec@5 97.169 	Validation Loss 1.2926 	Validation Prec@1 57.680 	Validation Prec@5 93.120 	Test Loss 1.2611 	Test Prec@1  57.720 	Test Prec@5  93.840 

2019-04-10 16:44:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:44:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:44:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:44:41 - INFO - TRAINING - Epoch: [7][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.9144 (0.9144)	Prec@1 69.000 (69.000)	Prec@5 100.000 (100.000)
2019-04-10 16:44:44 - INFO - TRAINING - Epoch: [7][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 1.1389 (0.9357)	Prec@1 59.000 (66.824)	Prec@5 96.000 (97.176)
2019-04-10 16:44:46 - INFO - TRAINING - Epoch: [7][100/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.9412 (0.9405)	Prec@1 67.000 (66.624)	Prec@5 97.000 (97.277)
2019-04-10 16:44:49 - INFO - TRAINING - Epoch: [7][150/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.8877 (0.9293)	Prec@1 68.000 (67.159)	Prec@5 98.000 (97.397)
2019-04-10 16:44:52 - INFO - TRAINING - Epoch: [7][200/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.7926 (0.9316)	Prec@1 72.000 (67.030)	Prec@5 97.000 (97.458)
2019-04-10 16:44:54 - INFO - TRAINING - Epoch: [7][250/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.9203 (0.9217)	Prec@1 67.000 (67.347)	Prec@5 98.000 (97.530)
2019-04-10 16:44:57 - INFO - TRAINING - Epoch: [7][300/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.7753 (0.9165)	Prec@1 71.000 (67.635)	Prec@5 100.000 (97.468)
2019-04-10 16:45:00 - INFO - TRAINING - Epoch: [7][350/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 1.0812 (0.9135)	Prec@1 58.000 (67.783)	Prec@5 98.000 (97.450)
2019-04-10 16:45:02 - INFO - TRAINING - Epoch: [7][400/450]	Time 0.056 (0.053)	Data 0.014 (0.014)	Loss 1.0805 (0.9095)	Prec@1 61.000 (67.963)	Prec@5 95.000 (97.476)
2019-04-10 16:45:05 - INFO - EVALUATING - Epoch: [7][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.8580 (0.8580)	Prec@1 64.000 (64.000)	Prec@5 99.000 (99.000)
2019-04-10 16:45:06 - INFO - EVALUATING - Epoch: [7][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.8649 (0.8649)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-04-10 16:45:07 - INFO - EVALUATING - Epoch: [7][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.8531 (0.9353)	Prec@1 72.000 (68.353)	Prec@5 96.000 (96.627)
2019-04-10 16:45:08 - INFO - 
 Epoch: 8	Training Loss 0.9061 	Training Prec@1 68.127 	Training Prec@5 97.482 	Validation Loss 0.9569 	Validation Prec@1 67.040 	Validation Prec@5 96.420 	Test Loss 0.9473 	Test Prec@1  67.960 	Test Prec@5  96.680 

2019-04-10 16:45:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:45:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:45:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:45:08 - INFO - TRAINING - Epoch: [8][0/450]	Time 0.031 (0.031)	Data 0.015 (0.015)	Loss 0.6331 (0.6331)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-04-10 16:45:10 - INFO - TRAINING - Epoch: [8][50/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.8400 (0.8964)	Prec@1 69.000 (67.608)	Prec@5 99.000 (97.549)
2019-04-10 16:45:13 - INFO - TRAINING - Epoch: [8][100/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.8781 (0.8876)	Prec@1 70.000 (68.109)	Prec@5 99.000 (97.446)
2019-04-10 16:45:16 - INFO - TRAINING - Epoch: [8][150/450]	Time 0.059 (0.055)	Data 0.012 (0.014)	Loss 0.8304 (0.8693)	Prec@1 74.000 (69.119)	Prec@5 96.000 (97.543)
2019-04-10 16:45:19 - INFO - TRAINING - Epoch: [8][200/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.9589 (0.8679)	Prec@1 66.000 (69.299)	Prec@5 95.000 (97.552)
2019-04-10 16:45:21 - INFO - TRAINING - Epoch: [8][250/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 1.0778 (0.8685)	Prec@1 61.000 (69.382)	Prec@5 98.000 (97.570)
2019-04-10 16:45:24 - INFO - TRAINING - Epoch: [8][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.6902 (0.8654)	Prec@1 75.000 (69.482)	Prec@5 100.000 (97.605)
2019-04-10 16:45:27 - INFO - TRAINING - Epoch: [8][350/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.8187 (0.8610)	Prec@1 72.000 (69.704)	Prec@5 99.000 (97.661)
2019-04-10 16:45:29 - INFO - TRAINING - Epoch: [8][400/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.7285 (0.8552)	Prec@1 75.000 (69.903)	Prec@5 98.000 (97.726)
2019-04-10 16:45:32 - INFO - EVALUATING - Epoch: [8][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.8163 (0.8163)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-04-10 16:45:33 - INFO - EVALUATING - Epoch: [8][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.8438 (0.8438)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-04-10 16:45:34 - INFO - EVALUATING - Epoch: [8][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.9153 (0.9444)	Prec@1 75.000 (68.275)	Prec@5 97.000 (96.824)
2019-04-10 16:45:34 - INFO - 
 Epoch: 9	Training Loss 0.8562 	Training Prec@1 69.889 	Training Prec@5 97.733 	Validation Loss 0.9470 	Validation Prec@1 67.920 	Validation Prec@5 96.600 	Test Loss 0.9577 	Test Prec@1  67.650 	Test Prec@5  96.780 

2019-04-10 16:45:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:45:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:45:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:45:34 - INFO - TRAINING - Epoch: [9][0/450]	Time 0.032 (0.032)	Data 0.015 (0.015)	Loss 0.6054 (0.6054)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-04-10 16:45:37 - INFO - TRAINING - Epoch: [9][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.6596 (0.8320)	Prec@1 81.000 (70.863)	Prec@5 99.000 (98.000)
2019-04-10 16:45:40 - INFO - TRAINING - Epoch: [9][100/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.7631 (0.8434)	Prec@1 67.000 (70.475)	Prec@5 98.000 (97.861)
2019-04-10 16:45:43 - INFO - TRAINING - Epoch: [9][150/450]	Time 0.053 (0.053)	Data 0.011 (0.014)	Loss 0.7344 (0.8421)	Prec@1 72.000 (70.656)	Prec@5 98.000 (97.821)
2019-04-10 16:45:45 - INFO - TRAINING - Epoch: [9][200/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.7860 (0.8321)	Prec@1 70.000 (70.935)	Prec@5 100.000 (97.816)
2019-04-10 16:45:48 - INFO - TRAINING - Epoch: [9][250/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.8526 (0.8289)	Prec@1 71.000 (70.916)	Prec@5 98.000 (97.869)
2019-04-10 16:45:51 - INFO - TRAINING - Epoch: [9][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.7821 (0.8288)	Prec@1 68.000 (70.950)	Prec@5 98.000 (97.841)
2019-04-10 16:45:53 - INFO - TRAINING - Epoch: [9][350/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.8277 (0.8255)	Prec@1 74.000 (71.068)	Prec@5 95.000 (97.821)
2019-04-10 16:45:56 - INFO - TRAINING - Epoch: [9][400/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.7271 (0.8217)	Prec@1 75.000 (71.389)	Prec@5 98.000 (97.818)
2019-04-10 16:45:59 - INFO - EVALUATING - Epoch: [9][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.9374 (0.9374)	Prec@1 69.000 (69.000)	Prec@5 97.000 (97.000)
2019-04-10 16:45:59 - INFO - EVALUATING - Epoch: [9][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9617 (0.9617)	Prec@1 65.000 (65.000)	Prec@5 96.000 (96.000)
2019-04-10 16:46:00 - INFO - EVALUATING - Epoch: [9][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.8007 (0.9401)	Prec@1 70.000 (68.000)	Prec@5 100.000 (97.196)
2019-04-10 16:46:01 - INFO - 
 Epoch: 10	Training Loss 0.8157 	Training Prec@1 71.613 	Training Prec@5 97.871 	Validation Loss 0.9333 	Validation Prec@1 68.400 	Validation Prec@5 97.460 	Test Loss 0.9531 	Test Prec@1  67.300 	Test Prec@5  97.280 

2019-04-10 16:46:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:46:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:46:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:46:01 - INFO - TRAINING - Epoch: [10][0/450]	Time 0.031 (0.031)	Data 0.014 (0.014)	Loss 0.5886 (0.5886)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-04-10 16:46:04 - INFO - TRAINING - Epoch: [10][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.5936 (0.7977)	Prec@1 78.000 (71.922)	Prec@5 100.000 (98.020)
2019-04-10 16:46:07 - INFO - TRAINING - Epoch: [10][100/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.6669 (0.8046)	Prec@1 74.000 (71.832)	Prec@5 100.000 (98.099)
2019-04-10 16:46:09 - INFO - TRAINING - Epoch: [10][150/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.6097 (0.7902)	Prec@1 79.000 (72.291)	Prec@5 99.000 (98.265)
2019-04-10 16:46:12 - INFO - TRAINING - Epoch: [10][200/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.8564 (0.7874)	Prec@1 74.000 (72.498)	Prec@5 95.000 (98.169)
2019-04-10 16:46:15 - INFO - TRAINING - Epoch: [10][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.6625 (0.7883)	Prec@1 79.000 (72.582)	Prec@5 99.000 (98.112)
2019-04-10 16:46:18 - INFO - TRAINING - Epoch: [10][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.5567 (0.7838)	Prec@1 84.000 (72.654)	Prec@5 99.000 (98.149)
2019-04-10 16:46:20 - INFO - TRAINING - Epoch: [10][350/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.7547 (0.7774)	Prec@1 71.000 (72.835)	Prec@5 98.000 (98.197)
2019-04-10 16:46:23 - INFO - TRAINING - Epoch: [10][400/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.6803 (0.7745)	Prec@1 77.000 (72.908)	Prec@5 98.000 (98.239)
2019-04-10 16:46:25 - INFO - EVALUATING - Epoch: [10][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.7911 (0.7911)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-04-10 16:46:26 - INFO - EVALUATING - Epoch: [10][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 1.0459 (1.0459)	Prec@1 65.000 (65.000)	Prec@5 94.000 (94.000)
2019-04-10 16:46:27 - INFO - EVALUATING - Epoch: [10][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.9785 (0.9881)	Prec@1 72.000 (65.902)	Prec@5 97.000 (97.196)
2019-04-10 16:46:28 - INFO - 
 Epoch: 11	Training Loss 0.7717 	Training Prec@1 73.013 	Training Prec@5 98.258 	Validation Loss 0.9907 	Validation Prec@1 65.300 	Validation Prec@5 96.940 	Test Loss 0.9917 	Test Prec@1  65.570 	Test Prec@5  97.250 

2019-04-10 16:46:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:46:28 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:46:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:46:28 - INFO - TRAINING - Epoch: [11][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.8575 (0.8575)	Prec@1 73.000 (73.000)	Prec@5 98.000 (98.000)
2019-04-10 16:46:31 - INFO - TRAINING - Epoch: [11][50/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.6252 (0.7822)	Prec@1 77.000 (72.588)	Prec@5 100.000 (98.373)
2019-04-10 16:46:34 - INFO - TRAINING - Epoch: [11][100/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.8592 (0.7847)	Prec@1 75.000 (72.693)	Prec@5 97.000 (98.218)
2019-04-10 16:46:36 - INFO - TRAINING - Epoch: [11][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6044 (0.7896)	Prec@1 83.000 (72.576)	Prec@5 100.000 (98.225)
2019-04-10 16:46:39 - INFO - TRAINING - Epoch: [11][200/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.7230 (0.7744)	Prec@1 72.000 (73.149)	Prec@5 100.000 (98.279)
2019-04-10 16:46:42 - INFO - TRAINING - Epoch: [11][250/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.9022 (0.7665)	Prec@1 64.000 (73.550)	Prec@5 98.000 (98.271)
2019-04-10 16:46:44 - INFO - TRAINING - Epoch: [11][300/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.6839 (0.7614)	Prec@1 77.000 (73.797)	Prec@5 99.000 (98.272)
2019-04-10 16:46:47 - INFO - TRAINING - Epoch: [11][350/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.6428 (0.7581)	Prec@1 75.000 (73.795)	Prec@5 98.000 (98.271)
2019-04-10 16:46:50 - INFO - TRAINING - Epoch: [11][400/450]	Time 0.052 (0.053)	Data 0.012 (0.014)	Loss 0.7179 (0.7573)	Prec@1 75.000 (73.818)	Prec@5 99.000 (98.287)
2019-04-10 16:46:52 - INFO - EVALUATING - Epoch: [11][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 1.1824 (1.1824)	Prec@1 59.000 (59.000)	Prec@5 95.000 (95.000)
2019-04-10 16:46:53 - INFO - EVALUATING - Epoch: [11][0/100]	Time 0.016 (0.016)	Data 0.009 (0.009)	Loss 1.1889 (1.1889)	Prec@1 53.000 (53.000)	Prec@5 100.000 (100.000)
2019-04-10 16:46:54 - INFO - EVALUATING - Epoch: [11][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.1194 (1.2011)	Prec@1 63.000 (58.882)	Prec@5 97.000 (97.020)
2019-04-10 16:46:55 - INFO - 
 Epoch: 12	Training Loss 0.7551 	Training Prec@1 73.878 	Training Prec@5 98.296 	Validation Loss 1.2108 	Validation Prec@1 58.660 	Validation Prec@5 96.920 	Test Loss 1.2080 	Test Prec@1  58.530 	Test Prec@5  96.980 

2019-04-10 16:46:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:46:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:46:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:46:55 - INFO - TRAINING - Epoch: [12][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.6737 (0.6737)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-04-10 16:46:58 - INFO - TRAINING - Epoch: [12][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.6604 (0.7399)	Prec@1 81.000 (73.804)	Prec@5 99.000 (98.529)
2019-04-10 16:47:00 - INFO - TRAINING - Epoch: [12][100/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.6870 (0.7264)	Prec@1 76.000 (74.396)	Prec@5 98.000 (98.465)
2019-04-10 16:47:03 - INFO - TRAINING - Epoch: [12][150/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.6158 (0.7135)	Prec@1 80.000 (75.000)	Prec@5 97.000 (98.563)
2019-04-10 16:47:06 - INFO - TRAINING - Epoch: [12][200/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.6742 (0.7209)	Prec@1 78.000 (74.781)	Prec@5 100.000 (98.597)
2019-04-10 16:47:08 - INFO - TRAINING - Epoch: [12][250/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.7043 (0.7245)	Prec@1 76.000 (74.757)	Prec@5 98.000 (98.570)
2019-04-10 16:47:11 - INFO - TRAINING - Epoch: [12][300/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.8807 (0.7199)	Prec@1 69.000 (75.003)	Prec@5 95.000 (98.522)
2019-04-10 16:47:14 - INFO - TRAINING - Epoch: [12][350/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.5735 (0.7179)	Prec@1 85.000 (75.160)	Prec@5 99.000 (98.530)
2019-04-10 16:47:16 - INFO - TRAINING - Epoch: [12][400/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.6601 (0.7188)	Prec@1 80.000 (75.100)	Prec@5 99.000 (98.511)
2019-04-10 16:47:19 - INFO - EVALUATING - Epoch: [12][0/50]	Time 0.039 (0.039)	Data 0.011 (0.011)	Loss 1.1120 (1.1120)	Prec@1 62.000 (62.000)	Prec@5 97.000 (97.000)
2019-04-10 16:47:20 - INFO - EVALUATING - Epoch: [12][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.8741 (0.8741)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-04-10 16:47:21 - INFO - EVALUATING - Epoch: [12][50/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.9229 (0.9343)	Prec@1 69.000 (68.667)	Prec@5 98.000 (96.961)
2019-04-10 16:47:22 - INFO - 
 Epoch: 13	Training Loss 0.7184 	Training Prec@1 75.162 	Training Prec@5 98.493 	Validation Loss 0.9466 	Validation Prec@1 66.960 	Validation Prec@5 97.260 	Test Loss 0.9435 	Test Prec@1  67.790 	Test Prec@5  97.090 

2019-04-10 16:47:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:47:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:47:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:47:22 - INFO - TRAINING - Epoch: [13][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.6905 (0.6905)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-04-10 16:47:24 - INFO - TRAINING - Epoch: [13][50/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.6912 (0.7219)	Prec@1 76.000 (74.765)	Prec@5 98.000 (98.235)
2019-04-10 16:47:27 - INFO - TRAINING - Epoch: [13][100/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.7226 (0.7149)	Prec@1 77.000 (75.366)	Prec@5 98.000 (98.307)
2019-04-10 16:47:30 - INFO - TRAINING - Epoch: [13][150/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.7172 (0.7123)	Prec@1 76.000 (75.457)	Prec@5 100.000 (98.404)
2019-04-10 16:47:32 - INFO - TRAINING - Epoch: [13][200/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.6564 (0.7132)	Prec@1 78.000 (75.408)	Prec@5 98.000 (98.453)
2019-04-10 16:47:35 - INFO - TRAINING - Epoch: [13][250/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.6275 (0.7169)	Prec@1 79.000 (75.311)	Prec@5 98.000 (98.454)
2019-04-10 16:47:38 - INFO - TRAINING - Epoch: [13][300/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.9164 (0.7147)	Prec@1 73.000 (75.352)	Prec@5 99.000 (98.452)
2019-04-10 16:47:40 - INFO - TRAINING - Epoch: [13][350/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.6900 (0.7142)	Prec@1 77.000 (75.365)	Prec@5 98.000 (98.422)
2019-04-10 16:47:43 - INFO - TRAINING - Epoch: [13][400/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.8325 (0.7107)	Prec@1 70.000 (75.501)	Prec@5 95.000 (98.446)
2019-04-10 16:47:46 - INFO - EVALUATING - Epoch: [13][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.6857 (0.6857)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-04-10 16:47:47 - INFO - EVALUATING - Epoch: [13][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.7004 (0.7004)	Prec@1 71.000 (71.000)	Prec@5 100.000 (100.000)
2019-04-10 16:47:47 - INFO - EVALUATING - Epoch: [13][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.7009 (0.7301)	Prec@1 76.000 (74.490)	Prec@5 100.000 (98.314)
2019-04-10 16:47:48 - INFO - 
 Epoch: 14	Training Loss 0.7106 	Training Prec@1 75.453 	Training Prec@5 98.424 	Validation Loss 0.7369 	Validation Prec@1 74.560 	Validation Prec@5 98.500 	Test Loss 0.7303 	Test Prec@1  74.270 	Test Prec@5  98.480 

2019-04-10 16:47:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:47:48 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:47:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:47:48 - INFO - TRAINING - Epoch: [14][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.7301 (0.7301)	Prec@1 74.000 (74.000)	Prec@5 97.000 (97.000)
2019-04-10 16:47:51 - INFO - TRAINING - Epoch: [14][50/450]	Time 0.054 (0.054)	Data 0.011 (0.013)	Loss 0.6734 (0.7096)	Prec@1 75.000 (75.667)	Prec@5 100.000 (98.627)
2019-04-10 16:47:54 - INFO - TRAINING - Epoch: [14][100/450]	Time 0.053 (0.054)	Data 0.013 (0.012)	Loss 0.5251 (0.7232)	Prec@1 79.000 (75.040)	Prec@5 100.000 (98.406)
2019-04-10 16:47:56 - INFO - TRAINING - Epoch: [14][150/450]	Time 0.053 (0.054)	Data 0.011 (0.012)	Loss 0.6758 (0.7199)	Prec@1 73.000 (75.252)	Prec@5 99.000 (98.444)
2019-04-10 16:47:59 - INFO - TRAINING - Epoch: [14][200/450]	Time 0.054 (0.054)	Data 0.012 (0.012)	Loss 0.7526 (0.7182)	Prec@1 76.000 (75.398)	Prec@5 99.000 (98.418)
2019-04-10 16:48:02 - INFO - TRAINING - Epoch: [14][250/450]	Time 0.053 (0.054)	Data 0.012 (0.012)	Loss 0.6061 (0.7108)	Prec@1 80.000 (75.653)	Prec@5 99.000 (98.478)
2019-04-10 16:48:05 - INFO - TRAINING - Epoch: [14][300/450]	Time 0.054 (0.054)	Data 0.012 (0.012)	Loss 0.5966 (0.7111)	Prec@1 82.000 (75.508)	Prec@5 97.000 (98.462)
2019-04-10 16:48:07 - INFO - TRAINING - Epoch: [14][350/450]	Time 0.054 (0.054)	Data 0.011 (0.012)	Loss 0.7058 (0.7057)	Prec@1 81.000 (75.781)	Prec@5 97.000 (98.501)
2019-04-10 16:48:10 - INFO - TRAINING - Epoch: [14][400/450]	Time 0.054 (0.054)	Data 0.011 (0.012)	Loss 0.5988 (0.7029)	Prec@1 76.000 (75.833)	Prec@5 98.000 (98.534)
2019-04-10 16:48:13 - INFO - EVALUATING - Epoch: [14][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 1.1059 (1.1059)	Prec@1 62.000 (62.000)	Prec@5 95.000 (95.000)
2019-04-10 16:48:14 - INFO - EVALUATING - Epoch: [14][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9672 (0.9672)	Prec@1 68.000 (68.000)	Prec@5 96.000 (96.000)
2019-04-10 16:48:14 - INFO - EVALUATING - Epoch: [14][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.0009 (0.9857)	Prec@1 64.000 (65.922)	Prec@5 95.000 (96.529)
2019-04-10 16:48:15 - INFO - 
 Epoch: 15	Training Loss 0.7022 	Training Prec@1 75.836 	Training Prec@5 98.558 	Validation Loss 0.9684 	Validation Prec@1 66.440 	Validation Prec@5 97.020 	Test Loss 0.9793 	Test Prec@1  66.260 	Test Prec@5  96.710 

2019-04-10 16:48:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:48:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:48:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:48:15 - INFO - TRAINING - Epoch: [15][0/450]	Time 0.031 (0.031)	Data 0.014 (0.014)	Loss 0.7423 (0.7423)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-04-10 16:48:18 - INFO - TRAINING - Epoch: [15][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.6015 (0.7435)	Prec@1 80.000 (74.765)	Prec@5 98.000 (98.490)
2019-04-10 16:48:21 - INFO - TRAINING - Epoch: [15][100/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.7293 (0.7211)	Prec@1 76.000 (75.366)	Prec@5 98.000 (98.475)
2019-04-10 16:48:24 - INFO - TRAINING - Epoch: [15][150/450]	Time 0.053 (0.055)	Data 0.014 (0.014)	Loss 0.6628 (0.7138)	Prec@1 78.000 (75.536)	Prec@5 100.000 (98.477)
2019-04-10 16:48:26 - INFO - TRAINING - Epoch: [15][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6297 (0.7028)	Prec@1 80.000 (76.005)	Prec@5 97.000 (98.498)
2019-04-10 16:48:29 - INFO - TRAINING - Epoch: [15][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4671 (0.6957)	Prec@1 82.000 (76.311)	Prec@5 100.000 (98.490)
2019-04-10 16:48:32 - INFO - TRAINING - Epoch: [15][300/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.4640 (0.6937)	Prec@1 86.000 (76.409)	Prec@5 100.000 (98.482)
2019-04-10 16:48:34 - INFO - TRAINING - Epoch: [15][350/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.5442 (0.6919)	Prec@1 82.000 (76.410)	Prec@5 100.000 (98.516)
2019-04-10 16:48:37 - INFO - TRAINING - Epoch: [15][400/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.6466 (0.6921)	Prec@1 80.000 (76.431)	Prec@5 99.000 (98.481)
2019-04-10 16:48:40 - INFO - EVALUATING - Epoch: [15][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 1.0756 (1.0756)	Prec@1 63.000 (63.000)	Prec@5 96.000 (96.000)
2019-04-10 16:48:41 - INFO - EVALUATING - Epoch: [15][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 1.0222 (1.0222)	Prec@1 69.000 (69.000)	Prec@5 93.000 (93.000)
2019-04-10 16:48:41 - INFO - EVALUATING - Epoch: [15][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.0822 (1.0386)	Prec@1 66.000 (66.706)	Prec@5 90.000 (94.314)
2019-04-10 16:48:42 - INFO - 
 Epoch: 16	Training Loss 0.6900 	Training Prec@1 76.524 	Training Prec@5 98.502 	Validation Loss 1.0250 	Validation Prec@1 67.700 	Validation Prec@5 94.820 	Test Loss 1.0409 	Test Prec@1  67.060 	Test Prec@5  94.420 

2019-04-10 16:48:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:48:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:48:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:48:42 - INFO - TRAINING - Epoch: [16][0/450]	Time 0.032 (0.032)	Data 0.014 (0.014)	Loss 0.7006 (0.7006)	Prec@1 79.000 (79.000)	Prec@5 97.000 (97.000)
2019-04-10 16:48:45 - INFO - TRAINING - Epoch: [16][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.7373 (0.7410)	Prec@1 75.000 (74.431)	Prec@5 99.000 (98.412)
2019-04-10 16:48:48 - INFO - TRAINING - Epoch: [16][100/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.9324 (0.7079)	Prec@1 70.000 (75.941)	Prec@5 97.000 (98.495)
2019-04-10 16:48:50 - INFO - TRAINING - Epoch: [16][150/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.7849 (0.7081)	Prec@1 74.000 (75.914)	Prec@5 99.000 (98.563)
2019-04-10 16:48:53 - INFO - TRAINING - Epoch: [16][200/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.7549 (0.7073)	Prec@1 72.000 (75.821)	Prec@5 99.000 (98.493)
2019-04-10 16:48:56 - INFO - TRAINING - Epoch: [16][250/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.8371 (0.7072)	Prec@1 72.000 (75.900)	Prec@5 98.000 (98.486)
2019-04-10 16:48:58 - INFO - TRAINING - Epoch: [16][300/450]	Time 0.053 (0.054)	Data 0.011 (0.013)	Loss 0.5847 (0.7061)	Prec@1 81.000 (75.874)	Prec@5 100.000 (98.545)
2019-04-10 16:49:01 - INFO - TRAINING - Epoch: [16][350/450]	Time 0.054 (0.054)	Data 0.011 (0.013)	Loss 0.5302 (0.7030)	Prec@1 83.000 (75.952)	Prec@5 98.000 (98.524)
2019-04-10 16:49:04 - INFO - TRAINING - Epoch: [16][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.6612 (0.7026)	Prec@1 79.000 (75.928)	Prec@5 100.000 (98.524)
2019-04-10 16:49:07 - INFO - EVALUATING - Epoch: [16][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 1.2561 (1.2561)	Prec@1 55.000 (55.000)	Prec@5 97.000 (97.000)
2019-04-10 16:49:07 - INFO - EVALUATING - Epoch: [16][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.8920 (0.8920)	Prec@1 64.000 (64.000)	Prec@5 100.000 (100.000)
2019-04-10 16:49:08 - INFO - EVALUATING - Epoch: [16][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.0617 (1.0666)	Prec@1 66.000 (64.392)	Prec@5 98.000 (97.059)
2019-04-10 16:49:09 - INFO - 
 Epoch: 17	Training Loss 0.7005 	Training Prec@1 75.984 	Training Prec@5 98.500 	Validation Loss 1.0653 	Validation Prec@1 64.060 	Validation Prec@5 97.360 	Test Loss 1.0704 	Test Prec@1  64.010 	Test Prec@5  96.980 

2019-04-10 16:49:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:49:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:49:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:49:09 - INFO - TRAINING - Epoch: [17][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.6315 (0.6315)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-04-10 16:49:12 - INFO - TRAINING - Epoch: [17][50/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.7074 (0.7552)	Prec@1 76.000 (74.235)	Prec@5 99.000 (98.353)
2019-04-10 16:49:15 - INFO - TRAINING - Epoch: [17][100/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.4950 (0.7215)	Prec@1 86.000 (75.267)	Prec@5 99.000 (98.406)
2019-04-10 16:49:18 - INFO - TRAINING - Epoch: [17][150/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.7098 (0.7131)	Prec@1 76.000 (75.609)	Prec@5 99.000 (98.411)
2019-04-10 16:49:21 - INFO - TRAINING - Epoch: [17][200/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.6751 (0.7060)	Prec@1 76.000 (75.945)	Prec@5 98.000 (98.413)
2019-04-10 16:49:24 - INFO - TRAINING - Epoch: [17][250/450]	Time 0.057 (0.057)	Data 0.011 (0.013)	Loss 0.5998 (0.7085)	Prec@1 76.000 (75.880)	Prec@5 98.000 (98.422)
2019-04-10 16:49:26 - INFO - TRAINING - Epoch: [17][300/450]	Time 0.056 (0.057)	Data 0.012 (0.013)	Loss 0.8278 (0.7081)	Prec@1 68.000 (75.857)	Prec@5 98.000 (98.375)
2019-04-10 16:49:29 - INFO - TRAINING - Epoch: [17][350/450]	Time 0.056 (0.057)	Data 0.012 (0.013)	Loss 0.7719 (0.7098)	Prec@1 75.000 (75.721)	Prec@5 98.000 (98.402)
2019-04-10 16:49:32 - INFO - TRAINING - Epoch: [17][400/450]	Time 0.054 (0.056)	Data 0.012 (0.013)	Loss 0.6854 (0.7074)	Prec@1 78.000 (75.855)	Prec@5 99.000 (98.424)
2019-04-10 16:49:35 - INFO - EVALUATING - Epoch: [17][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 1.4999 (1.4999)	Prec@1 50.000 (50.000)	Prec@5 90.000 (90.000)
2019-04-10 16:49:35 - INFO - EVALUATING - Epoch: [17][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 1.2795 (1.2795)	Prec@1 60.000 (60.000)	Prec@5 97.000 (97.000)
2019-04-10 16:49:36 - INFO - EVALUATING - Epoch: [17][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.4005 (1.3593)	Prec@1 54.000 (55.667)	Prec@5 95.000 (95.235)
2019-04-10 16:49:37 - INFO - 
 Epoch: 18	Training Loss 0.7079 	Training Prec@1 75.760 	Training Prec@5 98.416 	Validation Loss 1.3988 	Validation Prec@1 54.420 	Validation Prec@5 94.700 	Test Loss 1.3689 	Test Prec@1  55.220 	Test Prec@5  95.090 

2019-04-10 16:49:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:49:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:49:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:49:37 - INFO - TRAINING - Epoch: [18][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.5729 (0.5729)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-04-10 16:49:40 - INFO - TRAINING - Epoch: [18][50/450]	Time 0.053 (0.053)	Data 0.012 (0.012)	Loss 0.6093 (0.7382)	Prec@1 77.000 (74.529)	Prec@5 99.000 (98.255)
2019-04-10 16:49:43 - INFO - TRAINING - Epoch: [18][100/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.7393 (0.7346)	Prec@1 76.000 (74.723)	Prec@5 99.000 (98.356)
2019-04-10 16:49:45 - INFO - TRAINING - Epoch: [18][150/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.9944 (0.7292)	Prec@1 65.000 (74.834)	Prec@5 96.000 (98.384)
2019-04-10 16:49:48 - INFO - TRAINING - Epoch: [18][200/450]	Time 0.054 (0.053)	Data 0.012 (0.012)	Loss 0.7336 (0.7247)	Prec@1 79.000 (75.095)	Prec@5 97.000 (98.313)
2019-04-10 16:49:51 - INFO - TRAINING - Epoch: [18][250/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.6198 (0.7242)	Prec@1 79.000 (75.159)	Prec@5 97.000 (98.295)
2019-04-10 16:49:53 - INFO - TRAINING - Epoch: [18][300/450]	Time 0.053 (0.053)	Data 0.012 (0.012)	Loss 0.7724 (0.7224)	Prec@1 72.000 (75.279)	Prec@5 100.000 (98.316)
2019-04-10 16:49:56 - INFO - TRAINING - Epoch: [18][350/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.9612 (0.7259)	Prec@1 66.000 (75.194)	Prec@5 96.000 (98.288)
2019-04-10 16:49:59 - INFO - TRAINING - Epoch: [18][400/450]	Time 0.054 (0.053)	Data 0.012 (0.012)	Loss 0.7434 (0.7208)	Prec@1 72.000 (75.242)	Prec@5 100.000 (98.339)
2019-04-10 16:50:01 - INFO - EVALUATING - Epoch: [18][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 1.3140 (1.3140)	Prec@1 53.000 (53.000)	Prec@5 97.000 (97.000)
2019-04-10 16:50:02 - INFO - EVALUATING - Epoch: [18][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 1.0433 (1.0433)	Prec@1 63.000 (63.000)	Prec@5 97.000 (97.000)
2019-04-10 16:50:03 - INFO - EVALUATING - Epoch: [18][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 1.1261 (1.0537)	Prec@1 59.000 (64.569)	Prec@5 97.000 (96.902)
2019-04-10 16:50:04 - INFO - 
 Epoch: 19	Training Loss 0.7165 	Training Prec@1 75.393 	Training Prec@5 98.367 	Validation Loss 1.0520 	Validation Prec@1 64.860 	Validation Prec@5 97.020 	Test Loss 1.0417 	Test Prec@1  64.660 	Test Prec@5  97.080 

2019-04-10 16:50:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:50:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:50:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:50:04 - INFO - TRAINING - Epoch: [19][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.7337 (0.7337)	Prec@1 76.000 (76.000)	Prec@5 95.000 (95.000)
2019-04-10 16:50:07 - INFO - TRAINING - Epoch: [19][50/450]	Time 0.053 (0.053)	Data 0.012 (0.012)	Loss 0.6735 (0.7445)	Prec@1 75.000 (74.157)	Prec@5 100.000 (98.431)
2019-04-10 16:50:09 - INFO - TRAINING - Epoch: [19][100/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.6660 (0.7395)	Prec@1 78.000 (74.475)	Prec@5 99.000 (98.505)
2019-04-10 16:50:12 - INFO - TRAINING - Epoch: [19][150/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.8440 (0.7345)	Prec@1 75.000 (74.854)	Prec@5 95.000 (98.404)
2019-04-10 16:50:15 - INFO - TRAINING - Epoch: [19][200/450]	Time 0.053 (0.053)	Data 0.012 (0.012)	Loss 0.7516 (0.7357)	Prec@1 76.000 (74.861)	Prec@5 100.000 (98.338)
2019-04-10 16:50:17 - INFO - TRAINING - Epoch: [19][250/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.7194 (0.7304)	Prec@1 77.000 (74.940)	Prec@5 98.000 (98.394)
2019-04-10 16:50:20 - INFO - TRAINING - Epoch: [19][300/450]	Time 0.053 (0.053)	Data 0.011 (0.012)	Loss 0.6530 (0.7363)	Prec@1 77.000 (74.827)	Prec@5 100.000 (98.319)
2019-04-10 16:50:23 - INFO - TRAINING - Epoch: [19][350/450]	Time 0.053 (0.053)	Data 0.013 (0.013)	Loss 0.8769 (0.7379)	Prec@1 75.000 (74.903)	Prec@5 98.000 (98.248)
2019-04-10 16:50:25 - INFO - TRAINING - Epoch: [19][400/450]	Time 0.054 (0.054)	Data 0.013 (0.013)	Loss 0.8120 (0.7376)	Prec@1 74.000 (74.923)	Prec@5 97.000 (98.239)
2019-04-10 16:50:28 - INFO - EVALUATING - Epoch: [19][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.9076 (0.9076)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-04-10 16:50:29 - INFO - EVALUATING - Epoch: [19][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9999 (0.9999)	Prec@1 65.000 (65.000)	Prec@5 98.000 (98.000)
2019-04-10 16:50:30 - INFO - EVALUATING - Epoch: [19][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.9968 (1.0325)	Prec@1 63.000 (64.980)	Prec@5 95.000 (97.059)
2019-04-10 16:50:31 - INFO - 
 Epoch: 20	Training Loss 0.7354 	Training Prec@1 74.998 	Training Prec@5 98.244 	Validation Loss 1.0162 	Validation Prec@1 65.320 	Validation Prec@5 97.640 	Test Loss 1.0318 	Test Prec@1  64.480 	Test Prec@5  97.340 

2019-04-10 16:50:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:50:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:50:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:50:31 - INFO - TRAINING - Epoch: [20][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.7112 (0.7112)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-04-10 16:50:33 - INFO - TRAINING - Epoch: [20][50/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.6755 (0.7449)	Prec@1 76.000 (74.314)	Prec@5 99.000 (98.490)
2019-04-10 16:50:36 - INFO - TRAINING - Epoch: [20][100/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.6451 (0.7333)	Prec@1 76.000 (74.792)	Prec@5 98.000 (98.426)
2019-04-10 16:50:39 - INFO - TRAINING - Epoch: [20][150/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.8357 (0.7343)	Prec@1 73.000 (74.675)	Prec@5 100.000 (98.377)
2019-04-10 16:50:42 - INFO - TRAINING - Epoch: [20][200/450]	Time 0.053 (0.053)	Data 0.011 (0.014)	Loss 0.7922 (0.7395)	Prec@1 73.000 (74.617)	Prec@5 95.000 (98.284)
2019-04-10 16:50:44 - INFO - TRAINING - Epoch: [20][250/450]	Time 0.053 (0.053)	Data 0.013 (0.013)	Loss 0.5217 (0.7366)	Prec@1 82.000 (74.657)	Prec@5 100.000 (98.335)
2019-04-10 16:50:47 - INFO - TRAINING - Epoch: [20][300/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.8075 (0.7398)	Prec@1 72.000 (74.522)	Prec@5 98.000 (98.319)
2019-04-10 16:50:50 - INFO - TRAINING - Epoch: [20][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.8050 (0.7421)	Prec@1 72.000 (74.453)	Prec@5 99.000 (98.350)
2019-04-10 16:50:52 - INFO - TRAINING - Epoch: [20][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5958 (0.7438)	Prec@1 80.000 (74.382)	Prec@5 100.000 (98.319)
2019-04-10 16:50:55 - INFO - EVALUATING - Epoch: [20][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 1.0815 (1.0815)	Prec@1 64.000 (64.000)	Prec@5 98.000 (98.000)
2019-04-10 16:50:56 - INFO - EVALUATING - Epoch: [20][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9321 (0.9321)	Prec@1 71.000 (71.000)	Prec@5 96.000 (96.000)
2019-04-10 16:50:57 - INFO - EVALUATING - Epoch: [20][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.9121 (0.9485)	Prec@1 66.000 (67.353)	Prec@5 96.000 (97.157)
2019-04-10 16:50:58 - INFO - 
 Epoch: 21	Training Loss 0.7438 	Training Prec@1 74.402 	Training Prec@5 98.293 	Validation Loss 0.9717 	Validation Prec@1 66.440 	Validation Prec@5 96.840 	Test Loss 0.9632 	Test Prec@1  66.560 	Test Prec@5  97.340 

2019-04-10 16:50:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:50:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:50:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:50:58 - INFO - TRAINING - Epoch: [21][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.8676 (0.8676)	Prec@1 73.000 (73.000)	Prec@5 96.000 (96.000)
2019-04-10 16:51:00 - INFO - TRAINING - Epoch: [21][50/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.5964 (0.7573)	Prec@1 78.000 (73.922)	Prec@5 99.000 (98.314)
2019-04-10 16:51:03 - INFO - TRAINING - Epoch: [21][100/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.7465 (0.7371)	Prec@1 76.000 (75.040)	Prec@5 100.000 (98.178)
2019-04-10 16:51:06 - INFO - TRAINING - Epoch: [21][150/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.8825 (0.7248)	Prec@1 70.000 (75.424)	Prec@5 95.000 (98.285)
2019-04-10 16:51:08 - INFO - TRAINING - Epoch: [21][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.7375 (0.7183)	Prec@1 75.000 (75.667)	Prec@5 96.000 (98.338)
2019-04-10 16:51:11 - INFO - TRAINING - Epoch: [21][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.7597 (0.7187)	Prec@1 73.000 (75.677)	Prec@5 98.000 (98.371)
2019-04-10 16:51:14 - INFO - TRAINING - Epoch: [21][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.9542 (0.7179)	Prec@1 67.000 (75.618)	Prec@5 96.000 (98.385)
2019-04-10 16:51:17 - INFO - TRAINING - Epoch: [21][350/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.6304 (0.7226)	Prec@1 76.000 (75.402)	Prec@5 100.000 (98.322)
2019-04-10 16:51:19 - INFO - TRAINING - Epoch: [21][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.6000 (0.7239)	Prec@1 82.000 (75.322)	Prec@5 98.000 (98.317)
2019-04-10 16:51:22 - INFO - EVALUATING - Epoch: [21][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 1.0773 (1.0773)	Prec@1 63.000 (63.000)	Prec@5 95.000 (95.000)
2019-04-10 16:51:23 - INFO - EVALUATING - Epoch: [21][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 1.1015 (1.1015)	Prec@1 60.000 (60.000)	Prec@5 96.000 (96.000)
2019-04-10 16:51:24 - INFO - EVALUATING - Epoch: [21][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.1668 (1.1083)	Prec@1 61.000 (61.706)	Prec@5 91.000 (95.824)
2019-04-10 16:51:25 - INFO - 
 Epoch: 22	Training Loss 0.7261 	Training Prec@1 75.249 	Training Prec@5 98.284 	Validation Loss 1.1225 	Validation Prec@1 61.580 	Validation Prec@5 95.500 	Test Loss 1.1058 	Test Prec@1  61.650 	Test Prec@5  95.820 

2019-04-10 16:51:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:51:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:51:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:51:25 - INFO - TRAINING - Epoch: [22][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.7598 (0.7598)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-04-10 16:51:27 - INFO - TRAINING - Epoch: [22][50/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.7239 (0.7489)	Prec@1 72.000 (73.804)	Prec@5 99.000 (98.333)
2019-04-10 16:51:30 - INFO - TRAINING - Epoch: [22][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.7339 (0.7175)	Prec@1 75.000 (75.198)	Prec@5 97.000 (98.436)
2019-04-10 16:51:33 - INFO - TRAINING - Epoch: [22][150/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.5065 (0.7176)	Prec@1 82.000 (75.358)	Prec@5 99.000 (98.464)
2019-04-10 16:51:36 - INFO - TRAINING - Epoch: [22][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.7959 (0.7183)	Prec@1 71.000 (75.249)	Prec@5 100.000 (98.453)
2019-04-10 16:51:39 - INFO - TRAINING - Epoch: [22][250/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.6943 (0.7176)	Prec@1 72.000 (75.271)	Prec@5 99.000 (98.466)
2019-04-10 16:51:41 - INFO - TRAINING - Epoch: [22][300/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.7407 (0.7145)	Prec@1 71.000 (75.279)	Prec@5 98.000 (98.505)
2019-04-10 16:51:44 - INFO - TRAINING - Epoch: [22][350/450]	Time 0.058 (0.056)	Data 0.013 (0.014)	Loss 0.7403 (0.7164)	Prec@1 73.000 (75.191)	Prec@5 99.000 (98.544)
2019-04-10 16:51:47 - INFO - TRAINING - Epoch: [22][400/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.8222 (0.7178)	Prec@1 77.000 (75.242)	Prec@5 98.000 (98.479)
2019-04-10 16:51:50 - INFO - EVALUATING - Epoch: [22][0/50]	Time 0.044 (0.044)	Data 0.012 (0.012)	Loss 0.9963 (0.9963)	Prec@1 66.000 (66.000)	Prec@5 93.000 (93.000)
2019-04-10 16:51:51 - INFO - EVALUATING - Epoch: [22][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.9415 (0.9415)	Prec@1 66.000 (66.000)	Prec@5 98.000 (98.000)
2019-04-10 16:51:52 - INFO - EVALUATING - Epoch: [22][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.9702 (0.9927)	Prec@1 65.000 (65.510)	Prec@5 98.000 (97.294)
2019-04-10 16:51:53 - INFO - 
 Epoch: 23	Training Loss 0.7210 	Training Prec@1 75.142 	Training Prec@5 98.458 	Validation Loss 1.0158 	Validation Prec@1 64.120 	Validation Prec@5 96.940 	Test Loss 1.0131 	Test Prec@1  64.520 	Test Prec@5  97.150 

2019-04-10 16:51:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:51:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:51:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:51:53 - INFO - TRAINING - Epoch: [23][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.5347 (0.5347)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 16:51:55 - INFO - TRAINING - Epoch: [23][50/450]	Time 0.056 (0.055)	Data 0.012 (0.014)	Loss 0.7063 (0.7131)	Prec@1 76.000 (75.784)	Prec@5 99.000 (98.667)
2019-04-10 16:51:58 - INFO - TRAINING - Epoch: [23][100/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.7913 (0.7181)	Prec@1 73.000 (75.545)	Prec@5 99.000 (98.495)
2019-04-10 16:52:01 - INFO - TRAINING - Epoch: [23][150/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.5859 (0.7137)	Prec@1 80.000 (75.728)	Prec@5 96.000 (98.444)
2019-04-10 16:52:04 - INFO - TRAINING - Epoch: [23][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.7406 (0.7109)	Prec@1 75.000 (75.736)	Prec@5 96.000 (98.438)
2019-04-10 16:52:07 - INFO - TRAINING - Epoch: [23][250/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.6740 (0.7126)	Prec@1 77.000 (75.645)	Prec@5 99.000 (98.462)
2019-04-10 16:52:10 - INFO - TRAINING - Epoch: [23][300/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.5925 (0.7143)	Prec@1 79.000 (75.522)	Prec@5 100.000 (98.435)
2019-04-10 16:52:12 - INFO - TRAINING - Epoch: [23][350/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.7626 (0.7140)	Prec@1 71.000 (75.595)	Prec@5 99.000 (98.436)
2019-04-10 16:52:15 - INFO - TRAINING - Epoch: [23][400/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.6087 (0.7126)	Prec@1 75.000 (75.571)	Prec@5 100.000 (98.459)
2019-04-10 16:52:18 - INFO - EVALUATING - Epoch: [23][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 1.0948 (1.0948)	Prec@1 65.000 (65.000)	Prec@5 94.000 (94.000)
2019-04-10 16:52:19 - INFO - EVALUATING - Epoch: [23][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 1.3474 (1.3474)	Prec@1 60.000 (60.000)	Prec@5 91.000 (91.000)
2019-04-10 16:52:20 - INFO - EVALUATING - Epoch: [23][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.3049 (1.2988)	Prec@1 61.000 (58.922)	Prec@5 92.000 (92.039)
2019-04-10 16:52:21 - INFO - 
 Epoch: 24	Training Loss 0.7089 	Training Prec@1 75.702 	Training Prec@5 98.460 	Validation Loss 1.2970 	Validation Prec@1 59.000 	Validation Prec@5 92.400 	Test Loss 1.3149 	Test Prec@1  58.480 	Test Prec@5  92.050 

2019-04-10 16:52:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:52:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:52:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:52:21 - INFO - TRAINING - Epoch: [24][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.7082 (0.7082)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-04-10 16:52:24 - INFO - TRAINING - Epoch: [24][50/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.8337 (0.7157)	Prec@1 72.000 (75.196)	Prec@5 97.000 (98.176)
2019-04-10 16:52:26 - INFO - TRAINING - Epoch: [24][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.7420 (0.6877)	Prec@1 76.000 (76.149)	Prec@5 100.000 (98.525)
2019-04-10 16:52:29 - INFO - TRAINING - Epoch: [24][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.5108 (0.6823)	Prec@1 83.000 (76.556)	Prec@5 100.000 (98.589)
2019-04-10 16:52:32 - INFO - TRAINING - Epoch: [24][200/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.6187 (0.6886)	Prec@1 77.000 (76.204)	Prec@5 100.000 (98.577)
2019-04-10 16:52:34 - INFO - TRAINING - Epoch: [24][250/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.7198 (0.6909)	Prec@1 78.000 (76.163)	Prec@5 97.000 (98.582)
2019-04-10 16:52:37 - INFO - TRAINING - Epoch: [24][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6342 (0.6855)	Prec@1 76.000 (76.365)	Prec@5 100.000 (98.608)
2019-04-10 16:52:40 - INFO - TRAINING - Epoch: [24][350/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.7246 (0.6872)	Prec@1 73.000 (76.385)	Prec@5 99.000 (98.558)
2019-04-10 16:52:42 - INFO - TRAINING - Epoch: [24][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.8079 (0.6907)	Prec@1 75.000 (76.284)	Prec@5 99.000 (98.541)
2019-04-10 16:52:45 - INFO - EVALUATING - Epoch: [24][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 1.3496 (1.3496)	Prec@1 55.000 (55.000)	Prec@5 87.000 (87.000)
2019-04-10 16:52:46 - INFO - EVALUATING - Epoch: [24][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 1.1422 (1.1422)	Prec@1 63.000 (63.000)	Prec@5 94.000 (94.000)
2019-04-10 16:52:47 - INFO - EVALUATING - Epoch: [24][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 1.0499 (1.0698)	Prec@1 68.000 (64.882)	Prec@5 89.000 (94.510)
2019-04-10 16:52:48 - INFO - 
 Epoch: 25	Training Loss 0.6902 	Training Prec@1 76.298 	Training Prec@5 98.560 	Validation Loss 1.0487 	Validation Prec@1 65.920 	Validation Prec@5 94.560 	Test Loss 1.0646 	Test Prec@1  65.490 	Test Prec@5  94.880 

2019-04-10 16:52:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:52:48 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:52:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:52:48 - INFO - TRAINING - Epoch: [25][0/450]	Time 0.032 (0.032)	Data 0.013 (0.013)	Loss 0.6508 (0.6508)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-04-10 16:52:50 - INFO - TRAINING - Epoch: [25][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.7400 (0.7117)	Prec@1 74.000 (75.020)	Prec@5 99.000 (98.765)
2019-04-10 16:52:53 - INFO - TRAINING - Epoch: [25][100/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.6271 (0.7045)	Prec@1 86.000 (75.723)	Prec@5 98.000 (98.693)
2019-04-10 16:52:56 - INFO - TRAINING - Epoch: [25][150/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.7800 (0.6961)	Prec@1 66.000 (75.967)	Prec@5 99.000 (98.603)
2019-04-10 16:52:58 - INFO - TRAINING - Epoch: [25][200/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.7371 (0.6902)	Prec@1 73.000 (76.040)	Prec@5 99.000 (98.662)
2019-04-10 16:53:01 - INFO - TRAINING - Epoch: [25][250/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.6951 (0.6850)	Prec@1 71.000 (76.255)	Prec@5 98.000 (98.677)
2019-04-10 16:53:04 - INFO - TRAINING - Epoch: [25][300/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.5777 (0.6854)	Prec@1 79.000 (76.262)	Prec@5 99.000 (98.648)
2019-04-10 16:53:06 - INFO - TRAINING - Epoch: [25][350/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.5236 (0.6841)	Prec@1 82.000 (76.393)	Prec@5 99.000 (98.624)
2019-04-10 16:53:09 - INFO - TRAINING - Epoch: [25][400/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.8972 (0.6844)	Prec@1 69.000 (76.362)	Prec@5 96.000 (98.608)
2019-04-10 16:53:12 - INFO - EVALUATING - Epoch: [25][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.9556 (0.9556)	Prec@1 67.000 (67.000)	Prec@5 97.000 (97.000)
2019-04-10 16:53:12 - INFO - EVALUATING - Epoch: [25][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9053 (0.9053)	Prec@1 67.000 (67.000)	Prec@5 99.000 (99.000)
2019-04-10 16:53:13 - INFO - EVALUATING - Epoch: [25][50/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.7695 (0.8855)	Prec@1 76.000 (70.157)	Prec@5 99.000 (97.078)
2019-04-10 16:53:14 - INFO - 
 Epoch: 26	Training Loss 0.6844 	Training Prec@1 76.396 	Training Prec@5 98.616 	Validation Loss 0.8928 	Validation Prec@1 70.180 	Validation Prec@5 97.100 	Test Loss 0.8778 	Test Prec@1  70.290 	Test Prec@5  97.280 

2019-04-10 16:53:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:53:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:53:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:53:14 - INFO - TRAINING - Epoch: [26][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.7175 (0.7175)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-04-10 16:53:17 - INFO - TRAINING - Epoch: [26][50/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.7461 (0.6877)	Prec@1 72.000 (76.078)	Prec@5 100.000 (98.529)
2019-04-10 16:53:20 - INFO - TRAINING - Epoch: [26][100/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.5850 (0.6826)	Prec@1 79.000 (76.584)	Prec@5 98.000 (98.525)
2019-04-10 16:53:22 - INFO - TRAINING - Epoch: [26][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5933 (0.6716)	Prec@1 80.000 (77.139)	Prec@5 100.000 (98.609)
2019-04-10 16:53:25 - INFO - TRAINING - Epoch: [26][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.6550 (0.6749)	Prec@1 75.000 (77.100)	Prec@5 99.000 (98.622)
2019-04-10 16:53:28 - INFO - TRAINING - Epoch: [26][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.6287 (0.6727)	Prec@1 79.000 (77.155)	Prec@5 98.000 (98.629)
2019-04-10 16:53:30 - INFO - TRAINING - Epoch: [26][300/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.7047 (0.6714)	Prec@1 72.000 (77.130)	Prec@5 100.000 (98.608)
2019-04-10 16:53:33 - INFO - TRAINING - Epoch: [26][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.7391 (0.6693)	Prec@1 77.000 (77.191)	Prec@5 98.000 (98.587)
2019-04-10 16:53:36 - INFO - TRAINING - Epoch: [26][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6152 (0.6689)	Prec@1 79.000 (77.145)	Prec@5 100.000 (98.601)
2019-04-10 16:53:39 - INFO - EVALUATING - Epoch: [26][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.8497 (0.8497)	Prec@1 68.000 (68.000)	Prec@5 100.000 (100.000)
2019-04-10 16:53:39 - INFO - EVALUATING - Epoch: [26][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 1.1797 (1.1797)	Prec@1 61.000 (61.000)	Prec@5 95.000 (95.000)
2019-04-10 16:53:40 - INFO - EVALUATING - Epoch: [26][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 1.1410 (1.0620)	Prec@1 64.000 (63.608)	Prec@5 97.000 (97.569)
2019-04-10 16:53:41 - INFO - 
 Epoch: 27	Training Loss 0.6698 	Training Prec@1 77.060 	Training Prec@5 98.576 	Validation Loss 1.0387 	Validation Prec@1 63.380 	Validation Prec@5 97.780 	Test Loss 1.0715 	Test Prec@1  62.860 	Test Prec@5  97.680 

2019-04-10 16:53:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:53:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:53:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:53:41 - INFO - TRAINING - Epoch: [27][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.5031 (0.5031)	Prec@1 85.000 (85.000)	Prec@5 98.000 (98.000)
2019-04-10 16:53:44 - INFO - TRAINING - Epoch: [27][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.6654 (0.6809)	Prec@1 74.000 (77.196)	Prec@5 99.000 (98.549)
2019-04-10 16:53:47 - INFO - TRAINING - Epoch: [27][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.5602 (0.6875)	Prec@1 81.000 (76.851)	Prec@5 100.000 (98.446)
2019-04-10 16:53:50 - INFO - TRAINING - Epoch: [27][150/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.4841 (0.6693)	Prec@1 80.000 (77.450)	Prec@5 100.000 (98.490)
2019-04-10 16:53:53 - INFO - TRAINING - Epoch: [27][200/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.5632 (0.6685)	Prec@1 88.000 (77.647)	Prec@5 99.000 (98.493)
2019-04-10 16:53:55 - INFO - TRAINING - Epoch: [27][250/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.7425 (0.6664)	Prec@1 76.000 (77.645)	Prec@5 99.000 (98.550)
2019-04-10 16:53:58 - INFO - TRAINING - Epoch: [27][300/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.5768 (0.6632)	Prec@1 81.000 (77.728)	Prec@5 99.000 (98.548)
2019-04-10 16:54:01 - INFO - TRAINING - Epoch: [27][350/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.7423 (0.6611)	Prec@1 77.000 (77.647)	Prec@5 97.000 (98.587)
2019-04-10 16:54:04 - INFO - TRAINING - Epoch: [27][400/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.6232 (0.6607)	Prec@1 77.000 (77.681)	Prec@5 100.000 (98.589)
2019-04-10 16:54:06 - INFO - EVALUATING - Epoch: [27][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.6864 (0.6864)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-04-10 16:54:07 - INFO - EVALUATING - Epoch: [27][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.6942 (0.6942)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-04-10 16:54:08 - INFO - EVALUATING - Epoch: [27][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.6862 (0.7382)	Prec@1 77.000 (74.686)	Prec@5 98.000 (98.137)
2019-04-10 16:54:09 - INFO - 
 Epoch: 28	Training Loss 0.6592 	Training Prec@1 77.716 	Training Prec@5 98.624 	Validation Loss 0.7378 	Validation Prec@1 75.440 	Validation Prec@5 98.000 	Test Loss 0.7312 	Test Prec@1  75.020 	Test Prec@5  98.260 

2019-04-10 16:54:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:54:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:54:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:54:09 - INFO - TRAINING - Epoch: [28][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.7604 (0.7604)	Prec@1 69.000 (69.000)	Prec@5 99.000 (99.000)
2019-04-10 16:54:12 - INFO - TRAINING - Epoch: [28][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.5903 (0.6643)	Prec@1 76.000 (77.255)	Prec@5 99.000 (98.647)
2019-04-10 16:54:14 - INFO - TRAINING - Epoch: [28][100/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.6592 (0.6575)	Prec@1 72.000 (77.604)	Prec@5 99.000 (98.693)
2019-04-10 16:54:17 - INFO - TRAINING - Epoch: [28][150/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.5016 (0.6461)	Prec@1 85.000 (77.921)	Prec@5 100.000 (98.815)
2019-04-10 16:54:20 - INFO - TRAINING - Epoch: [28][200/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.6487 (0.6449)	Prec@1 80.000 (78.025)	Prec@5 98.000 (98.766)
2019-04-10 16:54:22 - INFO - TRAINING - Epoch: [28][250/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.7674 (0.6452)	Prec@1 71.000 (77.932)	Prec@5 99.000 (98.741)
2019-04-10 16:54:25 - INFO - TRAINING - Epoch: [28][300/450]	Time 0.053 (0.053)	Data 0.011 (0.014)	Loss 0.5782 (0.6473)	Prec@1 81.000 (77.910)	Prec@5 100.000 (98.721)
2019-04-10 16:54:28 - INFO - TRAINING - Epoch: [28][350/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.6667 (0.6477)	Prec@1 77.000 (77.872)	Prec@5 98.000 (98.712)
2019-04-10 16:54:30 - INFO - TRAINING - Epoch: [28][400/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.5177 (0.6457)	Prec@1 80.000 (77.958)	Prec@5 99.000 (98.698)
2019-04-10 16:54:33 - INFO - EVALUATING - Epoch: [28][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.9128 (0.9128)	Prec@1 69.000 (69.000)	Prec@5 97.000 (97.000)
2019-04-10 16:54:34 - INFO - EVALUATING - Epoch: [28][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.8617 (0.8617)	Prec@1 71.000 (71.000)	Prec@5 95.000 (95.000)
2019-04-10 16:54:35 - INFO - EVALUATING - Epoch: [28][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.9896 (0.9054)	Prec@1 69.000 (69.392)	Prec@5 94.000 (96.667)
2019-04-10 16:54:36 - INFO - 
 Epoch: 29	Training Loss 0.6456 	Training Prec@1 77.969 	Training Prec@5 98.669 	Validation Loss 0.8736 	Validation Prec@1 70.660 	Validation Prec@5 97.100 	Test Loss 0.8954 	Test Prec@1  69.260 	Test Prec@5  96.850 

2019-04-10 16:54:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:54:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:54:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:54:36 - INFO - TRAINING - Epoch: [29][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.6388 (0.6388)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 16:54:38 - INFO - TRAINING - Epoch: [29][50/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.5002 (0.6368)	Prec@1 83.000 (78.451)	Prec@5 100.000 (98.725)
2019-04-10 16:54:41 - INFO - TRAINING - Epoch: [29][100/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.6046 (0.6293)	Prec@1 78.000 (78.673)	Prec@5 98.000 (98.634)
2019-04-10 16:54:44 - INFO - TRAINING - Epoch: [29][150/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.6097 (0.6313)	Prec@1 78.000 (78.503)	Prec@5 99.000 (98.682)
2019-04-10 16:54:46 - INFO - TRAINING - Epoch: [29][200/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.5103 (0.6267)	Prec@1 83.000 (78.582)	Prec@5 99.000 (98.766)
2019-04-10 16:54:49 - INFO - TRAINING - Epoch: [29][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.4420 (0.6272)	Prec@1 88.000 (78.450)	Prec@5 100.000 (98.757)
2019-04-10 16:54:52 - INFO - TRAINING - Epoch: [29][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.5504 (0.6260)	Prec@1 80.000 (78.492)	Prec@5 98.000 (98.777)
2019-04-10 16:54:55 - INFO - TRAINING - Epoch: [29][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.6003 (0.6285)	Prec@1 76.000 (78.393)	Prec@5 100.000 (98.781)
2019-04-10 16:54:57 - INFO - TRAINING - Epoch: [29][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6202 (0.6298)	Prec@1 76.000 (78.287)	Prec@5 100.000 (98.768)
2019-04-10 16:55:00 - INFO - EVALUATING - Epoch: [29][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.9141 (0.9141)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-04-10 16:55:01 - INFO - EVALUATING - Epoch: [29][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.9473 (0.9473)	Prec@1 66.000 (66.000)	Prec@5 97.000 (97.000)
2019-04-10 16:55:02 - INFO - EVALUATING - Epoch: [29][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.9602 (1.0054)	Prec@1 72.000 (66.686)	Prec@5 95.000 (96.588)
2019-04-10 16:55:03 - INFO - 
 Epoch: 30	Training Loss 0.6319 	Training Prec@1 78.260 	Training Prec@5 98.764 	Validation Loss 0.9806 	Validation Prec@1 67.940 	Validation Prec@5 96.020 	Test Loss 0.9970 	Test Prec@1  67.170 	Test Prec@5  96.610 

2019-04-10 16:55:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:55:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:55:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:55:03 - INFO - TRAINING - Epoch: [30][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.6136 (0.6136)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-04-10 16:55:05 - INFO - TRAINING - Epoch: [30][50/450]	Time 0.055 (0.053)	Data 0.013 (0.014)	Loss 0.6232 (0.6587)	Prec@1 80.000 (77.275)	Prec@5 98.000 (98.706)
2019-04-10 16:55:08 - INFO - TRAINING - Epoch: [30][100/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.5136 (0.6314)	Prec@1 83.000 (78.218)	Prec@5 99.000 (98.802)
2019-04-10 16:55:11 - INFO - TRAINING - Epoch: [30][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6815 (0.6250)	Prec@1 73.000 (78.550)	Prec@5 100.000 (98.901)
2019-04-10 16:55:13 - INFO - TRAINING - Epoch: [30][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4957 (0.6289)	Prec@1 84.000 (78.468)	Prec@5 98.000 (98.871)
2019-04-10 16:55:16 - INFO - TRAINING - Epoch: [30][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.6514 (0.6256)	Prec@1 78.000 (78.693)	Prec@5 98.000 (98.845)
2019-04-10 16:55:19 - INFO - TRAINING - Epoch: [30][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.7317 (0.6275)	Prec@1 78.000 (78.711)	Prec@5 98.000 (98.824)
2019-04-10 16:55:22 - INFO - TRAINING - Epoch: [30][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.7364 (0.6244)	Prec@1 76.000 (78.809)	Prec@5 100.000 (98.877)
2019-04-10 16:55:24 - INFO - TRAINING - Epoch: [30][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.6070 (0.6258)	Prec@1 78.000 (78.748)	Prec@5 99.000 (98.860)
2019-04-10 16:55:27 - INFO - EVALUATING - Epoch: [30][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.7390 (0.7390)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-04-10 16:55:28 - INFO - EVALUATING - Epoch: [30][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.6289 (0.6289)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 16:55:29 - INFO - EVALUATING - Epoch: [30][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.7489 (0.7719)	Prec@1 78.000 (72.569)	Prec@5 96.000 (98.294)
2019-04-10 16:55:30 - INFO - 
 Epoch: 31	Training Loss 0.6291 	Training Prec@1 78.584 	Training Prec@5 98.849 	Validation Loss 0.7779 	Validation Prec@1 72.220 	Validation Prec@5 98.320 	Test Loss 0.7684 	Test Prec@1  72.750 	Test Prec@5  98.510 

2019-04-10 16:55:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:55:30 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:55:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:55:30 - INFO - TRAINING - Epoch: [31][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.5451 (0.5451)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-04-10 16:55:32 - INFO - TRAINING - Epoch: [31][50/450]	Time 0.054 (0.053)	Data 0.012 (0.015)	Loss 0.6537 (0.6096)	Prec@1 75.000 (78.843)	Prec@5 100.000 (98.765)
2019-04-10 16:55:35 - INFO - TRAINING - Epoch: [31][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6307 (0.5986)	Prec@1 79.000 (79.287)	Prec@5 99.000 (98.861)
2019-04-10 16:55:38 - INFO - TRAINING - Epoch: [31][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4713 (0.5982)	Prec@1 84.000 (79.351)	Prec@5 100.000 (98.901)
2019-04-10 16:55:41 - INFO - TRAINING - Epoch: [31][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.6287 (0.5989)	Prec@1 76.000 (79.328)	Prec@5 99.000 (98.841)
2019-04-10 16:55:43 - INFO - TRAINING - Epoch: [31][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.5651 (0.5992)	Prec@1 83.000 (79.271)	Prec@5 99.000 (98.849)
2019-04-10 16:55:46 - INFO - TRAINING - Epoch: [31][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5995 (0.5983)	Prec@1 77.000 (79.322)	Prec@5 98.000 (98.870)
2019-04-10 16:55:49 - INFO - TRAINING - Epoch: [31][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.6337 (0.5994)	Prec@1 82.000 (79.245)	Prec@5 99.000 (98.886)
2019-04-10 16:55:51 - INFO - TRAINING - Epoch: [31][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.5585 (0.6043)	Prec@1 81.000 (79.135)	Prec@5 98.000 (98.850)
2019-04-10 16:55:54 - INFO - EVALUATING - Epoch: [31][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.6966 (0.6966)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-04-10 16:55:55 - INFO - EVALUATING - Epoch: [31][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.7067 (0.7067)	Prec@1 74.000 (74.000)	Prec@5 100.000 (100.000)
2019-04-10 16:55:56 - INFO - EVALUATING - Epoch: [31][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.7191 (0.7682)	Prec@1 75.000 (74.431)	Prec@5 98.000 (97.863)
2019-04-10 16:55:57 - INFO - 
 Epoch: 32	Training Loss 0.6065 	Training Prec@1 79.107 	Training Prec@5 98.840 	Validation Loss 0.7609 	Validation Prec@1 74.100 	Validation Prec@5 97.740 	Test Loss 0.7718 	Test Prec@1  74.130 	Test Prec@5  97.920 

2019-04-10 16:55:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:55:57 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:55:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:55:57 - INFO - TRAINING - Epoch: [32][0/450]	Time 0.029 (0.029)	Data 0.012 (0.012)	Loss 0.7537 (0.7537)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-04-10 16:56:00 - INFO - TRAINING - Epoch: [32][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.5123 (0.5967)	Prec@1 79.000 (79.137)	Prec@5 100.000 (98.843)
2019-04-10 16:56:02 - INFO - TRAINING - Epoch: [32][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.4279 (0.5930)	Prec@1 85.000 (79.574)	Prec@5 100.000 (98.950)
2019-04-10 16:56:05 - INFO - TRAINING - Epoch: [32][150/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.7505 (0.5960)	Prec@1 73.000 (79.603)	Prec@5 98.000 (98.947)
2019-04-10 16:56:08 - INFO - TRAINING - Epoch: [32][200/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.4937 (0.5940)	Prec@1 82.000 (79.552)	Prec@5 99.000 (98.985)
2019-04-10 16:56:10 - INFO - TRAINING - Epoch: [32][250/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.6462 (0.5956)	Prec@1 83.000 (79.470)	Prec@5 97.000 (98.992)
2019-04-10 16:56:13 - INFO - TRAINING - Epoch: [32][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5610 (0.5927)	Prec@1 80.000 (79.728)	Prec@5 100.000 (98.970)
2019-04-10 16:56:16 - INFO - TRAINING - Epoch: [32][350/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.5749 (0.5899)	Prec@1 80.000 (79.829)	Prec@5 99.000 (98.952)
2019-04-10 16:56:18 - INFO - TRAINING - Epoch: [32][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5259 (0.5925)	Prec@1 82.000 (79.726)	Prec@5 100.000 (98.960)
2019-04-10 16:56:21 - INFO - EVALUATING - Epoch: [32][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.7933 (0.7933)	Prec@1 72.000 (72.000)	Prec@5 99.000 (99.000)
2019-04-10 16:56:22 - INFO - EVALUATING - Epoch: [32][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.7893 (0.7893)	Prec@1 72.000 (72.000)	Prec@5 99.000 (99.000)
2019-04-10 16:56:23 - INFO - EVALUATING - Epoch: [32][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.8710 (0.8918)	Prec@1 69.000 (69.608)	Prec@5 94.000 (97.196)
2019-04-10 16:56:24 - INFO - 
 Epoch: 33	Training Loss 0.5925 	Training Prec@1 79.818 	Training Prec@5 98.940 	Validation Loss 0.8914 	Validation Prec@1 69.840 	Validation Prec@5 97.540 	Test Loss 0.9060 	Test Prec@1  68.990 	Test Prec@5  97.530 

2019-04-10 16:56:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:56:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:56:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:56:24 - INFO - TRAINING - Epoch: [33][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.6111 (0.6111)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-04-10 16:56:27 - INFO - TRAINING - Epoch: [33][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.4895 (0.5889)	Prec@1 85.000 (79.882)	Prec@5 98.000 (98.725)
2019-04-10 16:56:29 - INFO - TRAINING - Epoch: [33][100/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.6630 (0.5731)	Prec@1 79.000 (80.416)	Prec@5 99.000 (98.921)
2019-04-10 16:56:32 - INFO - TRAINING - Epoch: [33][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4617 (0.5758)	Prec@1 88.000 (80.351)	Prec@5 99.000 (98.974)
2019-04-10 16:56:35 - INFO - TRAINING - Epoch: [33][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.5606 (0.5757)	Prec@1 80.000 (80.284)	Prec@5 99.000 (99.020)
2019-04-10 16:56:37 - INFO - TRAINING - Epoch: [33][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.5878 (0.5744)	Prec@1 79.000 (80.295)	Prec@5 100.000 (99.080)
2019-04-10 16:56:40 - INFO - TRAINING - Epoch: [33][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.6658 (0.5764)	Prec@1 77.000 (80.243)	Prec@5 97.000 (99.043)
2019-04-10 16:56:43 - INFO - TRAINING - Epoch: [33][350/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.3321 (0.5747)	Prec@1 89.000 (80.293)	Prec@5 100.000 (99.034)
2019-04-10 16:56:46 - INFO - TRAINING - Epoch: [33][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.7108 (0.5788)	Prec@1 80.000 (80.200)	Prec@5 99.000 (99.020)
2019-04-10 16:56:48 - INFO - EVALUATING - Epoch: [33][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.7857 (0.7857)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-04-10 16:56:49 - INFO - EVALUATING - Epoch: [33][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.7906 (0.7906)	Prec@1 74.000 (74.000)	Prec@5 96.000 (96.000)
2019-04-10 16:56:50 - INFO - EVALUATING - Epoch: [33][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.7179 (0.8153)	Prec@1 75.000 (72.608)	Prec@5 97.000 (97.137)
2019-04-10 16:56:51 - INFO - 
 Epoch: 34	Training Loss 0.5794 	Training Prec@1 80.136 	Training Prec@5 99.016 	Validation Loss 0.8167 	Validation Prec@1 73.100 	Validation Prec@5 96.860 	Test Loss 0.8260 	Test Prec@1  72.560 	Test Prec@5  96.980 

2019-04-10 16:56:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:56:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:56:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:56:51 - INFO - TRAINING - Epoch: [34][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.6431 (0.6431)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-04-10 16:56:54 - INFO - TRAINING - Epoch: [34][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.6292 (0.5763)	Prec@1 81.000 (80.686)	Prec@5 98.000 (98.902)
2019-04-10 16:56:56 - INFO - TRAINING - Epoch: [34][100/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.5319 (0.5689)	Prec@1 80.000 (80.891)	Prec@5 100.000 (98.842)
2019-04-10 16:56:59 - INFO - TRAINING - Epoch: [34][150/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.4795 (0.5630)	Prec@1 86.000 (80.887)	Prec@5 100.000 (98.947)
2019-04-10 16:57:02 - INFO - TRAINING - Epoch: [34][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.5152 (0.5646)	Prec@1 82.000 (80.781)	Prec@5 98.000 (98.980)
2019-04-10 16:57:04 - INFO - TRAINING - Epoch: [34][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5491 (0.5690)	Prec@1 84.000 (80.550)	Prec@5 98.000 (98.964)
2019-04-10 16:57:07 - INFO - TRAINING - Epoch: [34][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.5523 (0.5723)	Prec@1 77.000 (80.445)	Prec@5 100.000 (98.950)
2019-04-10 16:57:10 - INFO - TRAINING - Epoch: [34][350/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.6854 (0.5722)	Prec@1 78.000 (80.444)	Prec@5 98.000 (98.966)
2019-04-10 16:57:13 - INFO - TRAINING - Epoch: [34][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.6287 (0.5700)	Prec@1 75.000 (80.524)	Prec@5 100.000 (98.975)
2019-04-10 16:57:15 - INFO - EVALUATING - Epoch: [34][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.6670 (0.6670)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 16:57:16 - INFO - EVALUATING - Epoch: [34][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.7145 (0.7145)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-04-10 16:57:17 - INFO - EVALUATING - Epoch: [34][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.6389 (0.6714)	Prec@1 81.000 (77.392)	Prec@5 99.000 (98.176)
2019-04-10 16:57:18 - INFO - 
 Epoch: 35	Training Loss 0.5691 	Training Prec@1 80.569 	Training Prec@5 98.991 	Validation Loss 0.6747 	Validation Prec@1 76.920 	Validation Prec@5 98.260 	Test Loss 0.6705 	Test Prec@1  77.280 	Test Prec@5  98.330 

2019-04-10 16:57:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:57:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:57:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:57:18 - INFO - TRAINING - Epoch: [35][0/450]	Time 0.029 (0.029)	Data 0.012 (0.012)	Loss 0.4571 (0.4571)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 16:57:21 - INFO - TRAINING - Epoch: [35][50/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.5249 (0.5596)	Prec@1 85.000 (80.902)	Prec@5 99.000 (99.078)
2019-04-10 16:57:23 - INFO - TRAINING - Epoch: [35][100/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.5384 (0.5503)	Prec@1 81.000 (81.119)	Prec@5 99.000 (99.178)
2019-04-10 16:57:26 - INFO - TRAINING - Epoch: [35][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.6299 (0.5537)	Prec@1 81.000 (80.940)	Prec@5 98.000 (99.146)
2019-04-10 16:57:29 - INFO - TRAINING - Epoch: [35][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.4445 (0.5544)	Prec@1 87.000 (80.861)	Prec@5 98.000 (99.090)
2019-04-10 16:57:32 - INFO - TRAINING - Epoch: [35][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.3414 (0.5551)	Prec@1 89.000 (80.869)	Prec@5 100.000 (99.084)
2019-04-10 16:57:34 - INFO - TRAINING - Epoch: [35][300/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.5194 (0.5554)	Prec@1 84.000 (80.870)	Prec@5 97.000 (99.040)
2019-04-10 16:57:37 - INFO - TRAINING - Epoch: [35][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4924 (0.5581)	Prec@1 83.000 (80.752)	Prec@5 100.000 (99.031)
2019-04-10 16:57:40 - INFO - TRAINING - Epoch: [35][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.4767 (0.5586)	Prec@1 81.000 (80.746)	Prec@5 100.000 (99.045)
2019-04-10 16:57:42 - INFO - EVALUATING - Epoch: [35][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.7272 (0.7272)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-04-10 16:57:43 - INFO - EVALUATING - Epoch: [35][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.7348 (0.7348)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-04-10 16:57:44 - INFO - EVALUATING - Epoch: [35][50/100]	Time 0.018 (0.018)	Data 0.012 (0.010)	Loss 0.6351 (0.7661)	Prec@1 77.000 (73.373)	Prec@5 97.000 (98.196)
2019-04-10 16:57:45 - INFO - 
 Epoch: 36	Training Loss 0.5605 	Training Prec@1 80.711 	Training Prec@5 99.007 	Validation Loss 0.7765 	Validation Prec@1 72.840 	Validation Prec@5 98.420 	Test Loss 0.7638 	Test Prec@1  73.200 	Test Prec@5  98.420 

2019-04-10 16:57:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:57:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:57:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:57:45 - INFO - TRAINING - Epoch: [36][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.5221 (0.5221)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-04-10 16:57:48 - INFO - TRAINING - Epoch: [36][50/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.5235 (0.5566)	Prec@1 79.000 (81.608)	Prec@5 100.000 (99.137)
2019-04-10 16:57:51 - INFO - TRAINING - Epoch: [36][100/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.4612 (0.5477)	Prec@1 83.000 (81.485)	Prec@5 99.000 (99.149)
2019-04-10 16:57:54 - INFO - TRAINING - Epoch: [36][150/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.4914 (0.5481)	Prec@1 86.000 (81.404)	Prec@5 99.000 (99.132)
2019-04-10 16:57:56 - INFO - TRAINING - Epoch: [36][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.7244 (0.5430)	Prec@1 77.000 (81.652)	Prec@5 99.000 (99.104)
2019-04-10 16:57:59 - INFO - TRAINING - Epoch: [36][250/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.5067 (0.5452)	Prec@1 81.000 (81.514)	Prec@5 100.000 (99.088)
2019-04-10 16:58:02 - INFO - TRAINING - Epoch: [36][300/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.6892 (0.5484)	Prec@1 77.000 (81.286)	Prec@5 98.000 (99.120)
2019-04-10 16:58:05 - INFO - TRAINING - Epoch: [36][350/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.4262 (0.5479)	Prec@1 86.000 (81.345)	Prec@5 100.000 (99.100)
2019-04-10 16:58:08 - INFO - TRAINING - Epoch: [36][400/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.6931 (0.5496)	Prec@1 78.000 (81.299)	Prec@5 98.000 (99.100)
2019-04-10 16:58:10 - INFO - EVALUATING - Epoch: [36][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.7438 (0.7438)	Prec@1 77.000 (77.000)	Prec@5 96.000 (96.000)
2019-04-10 16:58:11 - INFO - EVALUATING - Epoch: [36][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.9629 (0.9629)	Prec@1 68.000 (68.000)	Prec@5 95.000 (95.000)
2019-04-10 16:58:12 - INFO - EVALUATING - Epoch: [36][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.9760 (1.0007)	Prec@1 69.000 (68.510)	Prec@5 95.000 (94.980)
2019-04-10 16:58:13 - INFO - 
 Epoch: 37	Training Loss 0.5487 	Training Prec@1 81.336 	Training Prec@5 99.098 	Validation Loss 0.9826 	Validation Prec@1 69.000 	Validation Prec@5 95.620 	Test Loss 0.9954 	Test Prec@1  68.460 	Test Prec@5  95.180 

2019-04-10 16:58:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:58:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:58:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:58:13 - INFO - TRAINING - Epoch: [37][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.4520 (0.4520)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 16:58:16 - INFO - TRAINING - Epoch: [37][50/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.6373 (0.5505)	Prec@1 78.000 (81.627)	Prec@5 99.000 (98.765)
2019-04-10 16:58:19 - INFO - TRAINING - Epoch: [37][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.4716 (0.5419)	Prec@1 82.000 (81.683)	Prec@5 99.000 (98.941)
2019-04-10 16:58:21 - INFO - TRAINING - Epoch: [37][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.6233 (0.5393)	Prec@1 79.000 (81.861)	Prec@5 99.000 (99.046)
2019-04-10 16:58:24 - INFO - TRAINING - Epoch: [37][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4563 (0.5341)	Prec@1 86.000 (81.950)	Prec@5 100.000 (99.010)
2019-04-10 16:58:27 - INFO - TRAINING - Epoch: [37][250/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.4379 (0.5309)	Prec@1 80.000 (82.008)	Prec@5 99.000 (99.036)
2019-04-10 16:58:29 - INFO - TRAINING - Epoch: [37][300/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.5274 (0.5317)	Prec@1 84.000 (82.073)	Prec@5 98.000 (99.027)
2019-04-10 16:58:32 - INFO - TRAINING - Epoch: [37][350/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.6280 (0.5308)	Prec@1 82.000 (82.077)	Prec@5 100.000 (99.051)
2019-04-10 16:58:35 - INFO - TRAINING - Epoch: [37][400/450]	Time 0.052 (0.054)	Data 0.012 (0.013)	Loss 0.5078 (0.5304)	Prec@1 83.000 (82.027)	Prec@5 100.000 (99.037)
2019-04-10 16:58:37 - INFO - EVALUATING - Epoch: [37][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.6143 (0.6143)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-04-10 16:58:38 - INFO - EVALUATING - Epoch: [37][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.5363 (0.5363)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-04-10 16:58:39 - INFO - EVALUATING - Epoch: [37][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5024 (0.5955)	Prec@1 84.000 (79.216)	Prec@5 98.000 (98.784)
2019-04-10 16:58:40 - INFO - 
 Epoch: 38	Training Loss 0.5313 	Training Prec@1 81.949 	Training Prec@5 99.051 	Validation Loss 0.5987 	Validation Prec@1 79.580 	Validation Prec@5 99.000 	Test Loss 0.5954 	Test Prec@1  79.430 	Test Prec@5  99.020 

2019-04-10 16:58:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:58:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:58:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:58:40 - INFO - TRAINING - Epoch: [38][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.3960 (0.3960)	Prec@1 91.000 (91.000)	Prec@5 98.000 (98.000)
2019-04-10 16:58:43 - INFO - TRAINING - Epoch: [38][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.4721 (0.5583)	Prec@1 83.000 (81.196)	Prec@5 99.000 (99.157)
2019-04-10 16:58:46 - INFO - TRAINING - Epoch: [38][100/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.4307 (0.5258)	Prec@1 82.000 (82.139)	Prec@5 100.000 (99.188)
2019-04-10 16:58:48 - INFO - TRAINING - Epoch: [38][150/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.3943 (0.5208)	Prec@1 88.000 (82.172)	Prec@5 100.000 (99.252)
2019-04-10 16:58:51 - INFO - TRAINING - Epoch: [38][200/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.5050 (0.5163)	Prec@1 87.000 (82.403)	Prec@5 100.000 (99.234)
2019-04-10 16:58:54 - INFO - TRAINING - Epoch: [38][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5101 (0.5167)	Prec@1 83.000 (82.367)	Prec@5 100.000 (99.235)
2019-04-10 16:58:56 - INFO - TRAINING - Epoch: [38][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5205 (0.5186)	Prec@1 83.000 (82.272)	Prec@5 100.000 (99.219)
2019-04-10 16:58:59 - INFO - TRAINING - Epoch: [38][350/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.7370 (0.5157)	Prec@1 76.000 (82.419)	Prec@5 99.000 (99.214)
2019-04-10 16:59:02 - INFO - TRAINING - Epoch: [38][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4944 (0.5132)	Prec@1 87.000 (82.549)	Prec@5 100.000 (99.214)
2019-04-10 16:59:04 - INFO - EVALUATING - Epoch: [38][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.6723 (0.6723)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-04-10 16:59:05 - INFO - EVALUATING - Epoch: [38][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.5474 (0.5474)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-04-10 16:59:06 - INFO - EVALUATING - Epoch: [38][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5169 (0.6039)	Prec@1 84.000 (79.667)	Prec@5 99.000 (98.706)
2019-04-10 16:59:07 - INFO - 
 Epoch: 39	Training Loss 0.5176 	Training Prec@1 82.449 	Training Prec@5 99.209 	Validation Loss 0.6058 	Validation Prec@1 78.960 	Validation Prec@5 98.940 	Test Loss 0.6004 	Test Prec@1  79.550 	Test Prec@5  98.940 

2019-04-10 16:59:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:59:07 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:59:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:59:07 - INFO - TRAINING - Epoch: [39][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.5933 (0.5933)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-04-10 16:59:10 - INFO - TRAINING - Epoch: [39][50/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4307 (0.5286)	Prec@1 86.000 (82.039)	Prec@5 100.000 (99.157)
2019-04-10 16:59:13 - INFO - TRAINING - Epoch: [39][100/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.3684 (0.5084)	Prec@1 88.000 (82.584)	Prec@5 100.000 (99.248)
2019-04-10 16:59:15 - INFO - TRAINING - Epoch: [39][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.6016 (0.5068)	Prec@1 79.000 (82.808)	Prec@5 100.000 (99.219)
2019-04-10 16:59:18 - INFO - TRAINING - Epoch: [39][200/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.5211 (0.5051)	Prec@1 83.000 (82.920)	Prec@5 99.000 (99.219)
2019-04-10 16:59:21 - INFO - TRAINING - Epoch: [39][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4439 (0.5052)	Prec@1 83.000 (82.865)	Prec@5 99.000 (99.243)
2019-04-10 16:59:24 - INFO - TRAINING - Epoch: [39][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.6209 (0.5075)	Prec@1 81.000 (82.784)	Prec@5 99.000 (99.216)
2019-04-10 16:59:26 - INFO - TRAINING - Epoch: [39][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5810 (0.5035)	Prec@1 81.000 (82.863)	Prec@5 98.000 (99.225)
2019-04-10 16:59:29 - INFO - TRAINING - Epoch: [39][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.7332 (0.5076)	Prec@1 82.000 (82.751)	Prec@5 97.000 (99.209)
2019-04-10 16:59:32 - INFO - EVALUATING - Epoch: [39][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.6992 (0.6992)	Prec@1 77.000 (77.000)	Prec@5 97.000 (97.000)
2019-04-10 16:59:32 - INFO - EVALUATING - Epoch: [39][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.5803 (0.5803)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 16:59:33 - INFO - EVALUATING - Epoch: [39][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.6641 (0.6609)	Prec@1 78.000 (77.471)	Prec@5 96.000 (98.255)
2019-04-10 16:59:34 - INFO - 
 Epoch: 40	Training Loss 0.5058 	Training Prec@1 82.771 	Training Prec@5 99.227 	Validation Loss 0.6615 	Validation Prec@1 77.280 	Validation Prec@5 98.040 	Test Loss 0.6625 	Test Prec@1  77.450 	Test Prec@5  98.330 

2019-04-10 16:59:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 16:59:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 16:59:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 16:59:34 - INFO - TRAINING - Epoch: [40][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.6539 (0.6539)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-04-10 16:59:37 - INFO - TRAINING - Epoch: [40][50/450]	Time 0.054 (0.055)	Data 0.012 (0.013)	Loss 0.6633 (0.5137)	Prec@1 78.000 (82.255)	Prec@5 99.000 (99.333)
2019-04-10 16:59:40 - INFO - TRAINING - Epoch: [40][100/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5440 (0.4890)	Prec@1 83.000 (82.842)	Prec@5 99.000 (99.396)
2019-04-10 16:59:43 - INFO - TRAINING - Epoch: [40][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.6482 (0.4860)	Prec@1 79.000 (83.126)	Prec@5 99.000 (99.377)
2019-04-10 16:59:45 - INFO - TRAINING - Epoch: [40][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4785 (0.4848)	Prec@1 85.000 (83.249)	Prec@5 99.000 (99.373)
2019-04-10 16:59:48 - INFO - TRAINING - Epoch: [40][250/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.5682 (0.4899)	Prec@1 81.000 (83.088)	Prec@5 99.000 (99.331)
2019-04-10 16:59:51 - INFO - TRAINING - Epoch: [40][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5782 (0.4906)	Prec@1 84.000 (83.153)	Prec@5 100.000 (99.322)
2019-04-10 16:59:53 - INFO - TRAINING - Epoch: [40][350/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.4018 (0.4944)	Prec@1 88.000 (83.068)	Prec@5 99.000 (99.291)
2019-04-10 16:59:56 - INFO - TRAINING - Epoch: [40][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4123 (0.4945)	Prec@1 89.000 (83.085)	Prec@5 99.000 (99.287)
2019-04-10 16:59:59 - INFO - EVALUATING - Epoch: [40][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.6672 (0.6672)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-04-10 17:00:00 - INFO - EVALUATING - Epoch: [40][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.5338 (0.5338)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:00:01 - INFO - EVALUATING - Epoch: [40][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.6677 (0.5923)	Prec@1 75.000 (79.804)	Prec@5 99.000 (98.725)
2019-04-10 17:00:01 - INFO - 
 Epoch: 41	Training Loss 0.4951 	Training Prec@1 83.067 	Training Prec@5 99.271 	Validation Loss 0.6079 	Validation Prec@1 79.820 	Validation Prec@5 98.640 	Test Loss 0.5964 	Test Prec@1  79.720 	Test Prec@5  98.660 

2019-04-10 17:00:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:00:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:00:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:00:02 - INFO - TRAINING - Epoch: [41][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.3465 (0.3465)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:00:04 - INFO - TRAINING - Epoch: [41][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.3133 (0.4748)	Prec@1 89.000 (84.000)	Prec@5 100.000 (99.490)
2019-04-10 17:00:07 - INFO - TRAINING - Epoch: [41][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.4748 (0.4806)	Prec@1 84.000 (83.693)	Prec@5 99.000 (99.337)
2019-04-10 17:00:10 - INFO - TRAINING - Epoch: [41][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.5309 (0.4877)	Prec@1 82.000 (83.199)	Prec@5 100.000 (99.325)
2019-04-10 17:00:12 - INFO - TRAINING - Epoch: [41][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.3358 (0.4870)	Prec@1 90.000 (83.313)	Prec@5 100.000 (99.353)
2019-04-10 17:00:15 - INFO - TRAINING - Epoch: [41][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.4740 (0.4822)	Prec@1 85.000 (83.498)	Prec@5 99.000 (99.331)
2019-04-10 17:00:18 - INFO - TRAINING - Epoch: [41][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.4587 (0.4820)	Prec@1 85.000 (83.468)	Prec@5 99.000 (99.332)
2019-04-10 17:00:21 - INFO - TRAINING - Epoch: [41][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5589 (0.4852)	Prec@1 81.000 (83.356)	Prec@5 99.000 (99.305)
2019-04-10 17:00:23 - INFO - TRAINING - Epoch: [41][400/450]	Time 0.057 (0.054)	Data 0.014 (0.014)	Loss 0.3825 (0.4877)	Prec@1 86.000 (83.289)	Prec@5 100.000 (99.312)
2019-04-10 17:00:26 - INFO - EVALUATING - Epoch: [41][0/50]	Time 0.044 (0.044)	Data 0.010 (0.010)	Loss 0.6733 (0.6733)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-04-10 17:00:27 - INFO - EVALUATING - Epoch: [41][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.6732 (0.6732)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-04-10 17:00:28 - INFO - EVALUATING - Epoch: [41][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.5053 (0.7637)	Prec@1 80.000 (73.725)	Prec@5 99.000 (98.078)
2019-04-10 17:00:29 - INFO - 
 Epoch: 42	Training Loss 0.4853 	Training Prec@1 83.391 	Training Prec@5 99.318 	Validation Loss 0.7622 	Validation Prec@1 74.460 	Validation Prec@5 98.160 	Test Loss 0.7530 	Test Prec@1  74.290 	Test Prec@5  98.280 

2019-04-10 17:00:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:00:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:00:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:00:29 - INFO - TRAINING - Epoch: [42][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.5443 (0.5443)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:00:32 - INFO - TRAINING - Epoch: [42][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.5007 (0.4868)	Prec@1 81.000 (82.980)	Prec@5 99.000 (99.392)
2019-04-10 17:00:35 - INFO - TRAINING - Epoch: [42][100/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.3611 (0.4698)	Prec@1 88.000 (83.812)	Prec@5 100.000 (99.337)
2019-04-10 17:00:37 - INFO - TRAINING - Epoch: [42][150/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.5233 (0.4679)	Prec@1 79.000 (83.861)	Prec@5 99.000 (99.364)
2019-04-10 17:00:40 - INFO - TRAINING - Epoch: [42][200/450]	Time 0.052 (0.056)	Data 0.012 (0.014)	Loss 0.4436 (0.4680)	Prec@1 84.000 (83.831)	Prec@5 99.000 (99.373)
2019-04-10 17:00:43 - INFO - TRAINING - Epoch: [42][250/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.7805 (0.4674)	Prec@1 77.000 (83.900)	Prec@5 98.000 (99.371)
2019-04-10 17:00:45 - INFO - TRAINING - Epoch: [42][300/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.5429 (0.4663)	Prec@1 82.000 (83.950)	Prec@5 99.000 (99.355)
2019-04-10 17:00:48 - INFO - TRAINING - Epoch: [42][350/450]	Time 0.061 (0.055)	Data 0.014 (0.014)	Loss 0.4982 (0.4694)	Prec@1 83.000 (83.929)	Prec@5 99.000 (99.362)
2019-04-10 17:00:51 - INFO - TRAINING - Epoch: [42][400/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.2834 (0.4700)	Prec@1 91.000 (83.933)	Prec@5 99.000 (99.364)
2019-04-10 17:00:54 - INFO - EVALUATING - Epoch: [42][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.6250 (0.6250)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 17:00:54 - INFO - EVALUATING - Epoch: [42][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.5436 (0.5436)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-04-10 17:00:55 - INFO - EVALUATING - Epoch: [42][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.5694 (0.7078)	Prec@1 80.000 (75.059)	Prec@5 99.000 (98.843)
2019-04-10 17:00:56 - INFO - 
 Epoch: 43	Training Loss 0.4699 	Training Prec@1 83.947 	Training Prec@5 99.351 	Validation Loss 0.7013 	Validation Prec@1 75.960 	Validation Prec@5 98.760 	Test Loss 0.7013 	Test Prec@1  75.560 	Test Prec@5  98.860 

2019-04-10 17:00:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:00:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:00:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:00:56 - INFO - TRAINING - Epoch: [43][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.3391 (0.3391)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:00:59 - INFO - TRAINING - Epoch: [43][50/450]	Time 0.056 (0.055)	Data 0.013 (0.014)	Loss 0.3207 (0.4558)	Prec@1 89.000 (84.353)	Prec@5 100.000 (99.412)
2019-04-10 17:01:02 - INFO - TRAINING - Epoch: [43][100/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.4277 (0.4560)	Prec@1 86.000 (84.337)	Prec@5 100.000 (99.386)
2019-04-10 17:01:05 - INFO - TRAINING - Epoch: [43][150/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.4633 (0.4666)	Prec@1 82.000 (83.974)	Prec@5 98.000 (99.358)
2019-04-10 17:01:07 - INFO - TRAINING - Epoch: [43][200/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.5645 (0.4643)	Prec@1 79.000 (84.080)	Prec@5 100.000 (99.393)
2019-04-10 17:01:10 - INFO - TRAINING - Epoch: [43][250/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.5504 (0.4616)	Prec@1 81.000 (84.275)	Prec@5 98.000 (99.367)
2019-04-10 17:01:13 - INFO - TRAINING - Epoch: [43][300/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.3809 (0.4629)	Prec@1 88.000 (84.319)	Prec@5 100.000 (99.346)
2019-04-10 17:01:15 - INFO - TRAINING - Epoch: [43][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4358 (0.4635)	Prec@1 87.000 (84.234)	Prec@5 100.000 (99.370)
2019-04-10 17:01:18 - INFO - TRAINING - Epoch: [43][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.5136 (0.4633)	Prec@1 78.000 (84.249)	Prec@5 100.000 (99.357)
2019-04-10 17:01:21 - INFO - EVALUATING - Epoch: [43][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.6014 (0.6014)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-04-10 17:01:22 - INFO - EVALUATING - Epoch: [43][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.5424 (0.5424)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-04-10 17:01:22 - INFO - EVALUATING - Epoch: [43][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.4061 (0.5752)	Prec@1 88.000 (81.255)	Prec@5 100.000 (98.863)
2019-04-10 17:01:23 - INFO - 
 Epoch: 44	Training Loss 0.4621 	Training Prec@1 84.271 	Training Prec@5 99.369 	Validation Loss 0.5731 	Validation Prec@1 80.920 	Validation Prec@5 98.880 	Test Loss 0.5701 	Test Prec@1  81.390 	Test Prec@5  98.990 

2019-04-10 17:01:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:01:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:01:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:01:23 - INFO - TRAINING - Epoch: [44][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.5974 (0.5974)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 17:01:26 - INFO - TRAINING - Epoch: [44][50/450]	Time 0.052 (0.053)	Data 0.013 (0.015)	Loss 0.3409 (0.4547)	Prec@1 87.000 (84.314)	Prec@5 100.000 (99.216)
2019-04-10 17:01:29 - INFO - TRAINING - Epoch: [44][100/450]	Time 0.053 (0.054)	Data 0.013 (0.015)	Loss 0.5634 (0.4483)	Prec@1 81.000 (84.683)	Prec@5 98.000 (99.297)
2019-04-10 17:01:32 - INFO - TRAINING - Epoch: [44][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.5127 (0.4522)	Prec@1 81.000 (84.609)	Prec@5 99.000 (99.278)
2019-04-10 17:01:34 - INFO - TRAINING - Epoch: [44][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.5246 (0.4450)	Prec@1 81.000 (84.856)	Prec@5 100.000 (99.318)
2019-04-10 17:01:37 - INFO - TRAINING - Epoch: [44][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.3241 (0.4418)	Prec@1 90.000 (84.928)	Prec@5 100.000 (99.351)
2019-04-10 17:01:40 - INFO - TRAINING - Epoch: [44][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.5981 (0.4443)	Prec@1 81.000 (84.887)	Prec@5 99.000 (99.355)
2019-04-10 17:01:42 - INFO - TRAINING - Epoch: [44][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.4157 (0.4467)	Prec@1 84.000 (84.823)	Prec@5 99.000 (99.359)
2019-04-10 17:01:45 - INFO - TRAINING - Epoch: [44][400/450]	Time 0.059 (0.054)	Data 0.012 (0.014)	Loss 0.4670 (0.4499)	Prec@1 86.000 (84.708)	Prec@5 100.000 (99.357)
2019-04-10 17:01:48 - INFO - EVALUATING - Epoch: [44][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.6038 (0.6038)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-04-10 17:01:49 - INFO - EVALUATING - Epoch: [44][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.5763 (0.5763)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-04-10 17:01:50 - INFO - EVALUATING - Epoch: [44][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5430 (0.6117)	Prec@1 80.000 (79.255)	Prec@5 99.000 (98.961)
2019-04-10 17:01:50 - INFO - 
 Epoch: 45	Training Loss 0.4514 	Training Prec@1 84.629 	Training Prec@5 99.376 	Validation Loss 0.6123 	Validation Prec@1 79.040 	Validation Prec@5 99.140 	Test Loss 0.6160 	Test Prec@1  78.880 	Test Prec@5  99.150 

2019-04-10 17:01:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:01:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:01:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:01:51 - INFO - TRAINING - Epoch: [45][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.3906 (0.3906)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 17:01:53 - INFO - TRAINING - Epoch: [45][50/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.7129 (0.4446)	Prec@1 74.000 (84.706)	Prec@5 100.000 (99.333)
2019-04-10 17:01:56 - INFO - TRAINING - Epoch: [45][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3938 (0.4303)	Prec@1 86.000 (85.347)	Prec@5 99.000 (99.376)
2019-04-10 17:01:59 - INFO - TRAINING - Epoch: [45][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.4100 (0.4251)	Prec@1 85.000 (85.530)	Prec@5 100.000 (99.444)
2019-04-10 17:02:01 - INFO - TRAINING - Epoch: [45][200/450]	Time 0.052 (0.054)	Data 0.014 (0.014)	Loss 0.5303 (0.4303)	Prec@1 82.000 (85.453)	Prec@5 100.000 (99.413)
2019-04-10 17:02:04 - INFO - TRAINING - Epoch: [45][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.4102 (0.4366)	Prec@1 86.000 (85.283)	Prec@5 99.000 (99.410)
2019-04-10 17:02:07 - INFO - TRAINING - Epoch: [45][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.4266 (0.4396)	Prec@1 84.000 (85.133)	Prec@5 99.000 (99.405)
2019-04-10 17:02:10 - INFO - TRAINING - Epoch: [45][350/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.3971 (0.4357)	Prec@1 84.000 (85.211)	Prec@5 100.000 (99.399)
2019-04-10 17:02:12 - INFO - TRAINING - Epoch: [45][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.4753 (0.4371)	Prec@1 86.000 (85.155)	Prec@5 100.000 (99.404)
2019-04-10 17:02:15 - INFO - EVALUATING - Epoch: [45][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.5941 (0.5941)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 17:02:16 - INFO - EVALUATING - Epoch: [45][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.6248 (0.6248)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-04-10 17:02:17 - INFO - EVALUATING - Epoch: [45][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5531 (0.5386)	Prec@1 82.000 (81.784)	Prec@5 99.000 (99.137)
2019-04-10 17:02:18 - INFO - 
 Epoch: 46	Training Loss 0.4385 	Training Prec@1 85.076 	Training Prec@5 99.393 	Validation Loss 0.5441 	Validation Prec@1 81.340 	Validation Prec@5 99.020 	Test Loss 0.5382 	Test Prec@1  81.540 	Test Prec@5  99.220 

2019-04-10 17:02:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:02:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:02:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:02:18 - INFO - TRAINING - Epoch: [46][0/450]	Time 0.031 (0.031)	Data 0.014 (0.014)	Loss 0.3578 (0.3578)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-04-10 17:02:21 - INFO - TRAINING - Epoch: [46][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.3628 (0.4163)	Prec@1 88.000 (85.745)	Prec@5 100.000 (99.412)
2019-04-10 17:02:24 - INFO - TRAINING - Epoch: [46][100/450]	Time 0.058 (0.057)	Data 0.014 (0.014)	Loss 0.4725 (0.4190)	Prec@1 83.000 (85.653)	Prec@5 100.000 (99.406)
2019-04-10 17:02:26 - INFO - TRAINING - Epoch: [46][150/450]	Time 0.057 (0.057)	Data 0.014 (0.015)	Loss 0.4975 (0.4210)	Prec@1 83.000 (85.603)	Prec@5 99.000 (99.464)
2019-04-10 17:02:29 - INFO - TRAINING - Epoch: [46][200/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.3662 (0.4200)	Prec@1 87.000 (85.637)	Prec@5 100.000 (99.458)
2019-04-10 17:02:32 - INFO - TRAINING - Epoch: [46][250/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.4620 (0.4228)	Prec@1 86.000 (85.494)	Prec@5 100.000 (99.430)
2019-04-10 17:02:35 - INFO - TRAINING - Epoch: [46][300/450]	Time 0.053 (0.056)	Data 0.014 (0.014)	Loss 0.4515 (0.4218)	Prec@1 83.000 (85.561)	Prec@5 99.000 (99.435)
2019-04-10 17:02:37 - INFO - TRAINING - Epoch: [46][350/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.4452 (0.4220)	Prec@1 85.000 (85.615)	Prec@5 100.000 (99.453)
2019-04-10 17:02:40 - INFO - TRAINING - Epoch: [46][400/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.4518 (0.4226)	Prec@1 83.000 (85.606)	Prec@5 100.000 (99.444)
2019-04-10 17:02:43 - INFO - EVALUATING - Epoch: [46][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.6434 (0.6434)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-04-10 17:02:44 - INFO - EVALUATING - Epoch: [46][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.5337 (0.5337)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 17:02:45 - INFO - EVALUATING - Epoch: [46][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.6759 (0.7404)	Prec@1 74.000 (75.667)	Prec@5 99.000 (98.314)
2019-04-10 17:02:45 - INFO - 
 Epoch: 47	Training Loss 0.4235 	Training Prec@1 85.573 	Training Prec@5 99.442 	Validation Loss 0.7280 	Validation Prec@1 75.660 	Validation Prec@5 98.340 	Test Loss 0.7411 	Test Prec@1  75.510 	Test Prec@5  98.480 

2019-04-10 17:02:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:02:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:02:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:02:45 - INFO - TRAINING - Epoch: [47][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.4555 (0.4555)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:02:48 - INFO - TRAINING - Epoch: [47][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.5063 (0.4491)	Prec@1 81.000 (84.961)	Prec@5 98.000 (99.176)
2019-04-10 17:02:51 - INFO - TRAINING - Epoch: [47][100/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.4416 (0.4331)	Prec@1 83.000 (85.733)	Prec@5 100.000 (99.356)
2019-04-10 17:02:54 - INFO - TRAINING - Epoch: [47][150/450]	Time 0.055 (0.053)	Data 0.013 (0.014)	Loss 0.3744 (0.4216)	Prec@1 87.000 (85.960)	Prec@5 99.000 (99.391)
2019-04-10 17:02:56 - INFO - TRAINING - Epoch: [47][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2997 (0.4249)	Prec@1 91.000 (85.871)	Prec@5 100.000 (99.378)
2019-04-10 17:02:59 - INFO - TRAINING - Epoch: [47][250/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.2846 (0.4238)	Prec@1 89.000 (85.900)	Prec@5 100.000 (99.386)
2019-04-10 17:03:02 - INFO - TRAINING - Epoch: [47][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.4154 (0.4298)	Prec@1 82.000 (85.625)	Prec@5 100.000 (99.382)
2019-04-10 17:03:04 - INFO - TRAINING - Epoch: [47][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3682 (0.4301)	Prec@1 89.000 (85.621)	Prec@5 100.000 (99.376)
2019-04-10 17:03:07 - INFO - TRAINING - Epoch: [47][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.6792 (0.4279)	Prec@1 76.000 (85.636)	Prec@5 99.000 (99.411)
2019-04-10 17:03:10 - INFO - EVALUATING - Epoch: [47][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4928 (0.4928)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-04-10 17:03:11 - INFO - EVALUATING - Epoch: [47][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.5810 (0.5810)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-04-10 17:03:12 - INFO - EVALUATING - Epoch: [47][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.4779 (0.5464)	Prec@1 86.000 (82.020)	Prec@5 99.000 (98.863)
2019-04-10 17:03:12 - INFO - 
 Epoch: 48	Training Loss 0.4273 	Training Prec@1 85.664 	Training Prec@5 99.418 	Validation Loss 0.5413 	Validation Prec@1 82.220 	Validation Prec@5 99.060 	Test Loss 0.5458 	Test Prec@1  81.840 	Test Prec@5  99.040 

2019-04-10 17:03:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:03:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:03:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:03:13 - INFO - TRAINING - Epoch: [48][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.5384 (0.5384)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 17:03:15 - INFO - TRAINING - Epoch: [48][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.3711 (0.4033)	Prec@1 85.000 (86.294)	Prec@5 100.000 (99.490)
2019-04-10 17:03:18 - INFO - TRAINING - Epoch: [48][100/450]	Time 0.059 (0.054)	Data 0.012 (0.014)	Loss 0.4195 (0.4135)	Prec@1 86.000 (85.752)	Prec@5 100.000 (99.475)
2019-04-10 17:03:21 - INFO - TRAINING - Epoch: [48][150/450]	Time 0.062 (0.054)	Data 0.014 (0.014)	Loss 0.3699 (0.4205)	Prec@1 87.000 (85.450)	Prec@5 100.000 (99.490)
2019-04-10 17:03:23 - INFO - TRAINING - Epoch: [48][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.3491 (0.4171)	Prec@1 88.000 (85.577)	Prec@5 100.000 (99.498)
2019-04-10 17:03:26 - INFO - TRAINING - Epoch: [48][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.3040 (0.4130)	Prec@1 91.000 (85.793)	Prec@5 99.000 (99.490)
2019-04-10 17:03:29 - INFO - TRAINING - Epoch: [48][300/450]	Time 0.057 (0.054)	Data 0.014 (0.014)	Loss 0.4600 (0.4120)	Prec@1 85.000 (85.927)	Prec@5 100.000 (99.502)
2019-04-10 17:03:32 - INFO - TRAINING - Epoch: [48][350/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.4588 (0.4139)	Prec@1 85.000 (85.886)	Prec@5 100.000 (99.513)
2019-04-10 17:03:34 - INFO - TRAINING - Epoch: [48][400/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.3694 (0.4120)	Prec@1 89.000 (85.945)	Prec@5 100.000 (99.516)
2019-04-10 17:03:37 - INFO - EVALUATING - Epoch: [48][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4459 (0.4459)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-04-10 17:03:38 - INFO - EVALUATING - Epoch: [48][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.6075 (0.6075)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-04-10 17:03:39 - INFO - EVALUATING - Epoch: [48][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.4570 (0.5758)	Prec@1 85.000 (81.157)	Prec@5 99.000 (98.647)
2019-04-10 17:03:40 - INFO - 
 Epoch: 49	Training Loss 0.4090 	Training Prec@1 86.022 	Training Prec@5 99.524 	Validation Loss 0.5659 	Validation Prec@1 80.740 	Validation Prec@5 99.000 	Test Loss 0.5686 	Test Prec@1  81.350 	Test Prec@5  98.730 

2019-04-10 17:03:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:03:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:03:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:03:40 - INFO - TRAINING - Epoch: [49][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.3761 (0.3761)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:03:43 - INFO - TRAINING - Epoch: [49][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.3347 (0.3924)	Prec@1 89.000 (86.078)	Prec@5 100.000 (99.510)
2019-04-10 17:03:46 - INFO - TRAINING - Epoch: [49][100/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.3881 (0.4002)	Prec@1 86.000 (86.297)	Prec@5 100.000 (99.515)
2019-04-10 17:03:48 - INFO - TRAINING - Epoch: [49][150/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.4137 (0.3922)	Prec@1 84.000 (86.623)	Prec@5 100.000 (99.550)
2019-04-10 17:03:51 - INFO - TRAINING - Epoch: [49][200/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.3152 (0.3928)	Prec@1 90.000 (86.567)	Prec@5 100.000 (99.552)
2019-04-10 17:03:54 - INFO - TRAINING - Epoch: [49][250/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.4361 (0.3952)	Prec@1 85.000 (86.566)	Prec@5 99.000 (99.554)
2019-04-10 17:03:57 - INFO - TRAINING - Epoch: [49][300/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.4330 (0.3950)	Prec@1 82.000 (86.578)	Prec@5 100.000 (99.538)
2019-04-10 17:04:00 - INFO - TRAINING - Epoch: [49][350/450]	Time 0.058 (0.057)	Data 0.012 (0.014)	Loss 0.5716 (0.3969)	Prec@1 81.000 (86.550)	Prec@5 98.000 (99.516)
2019-04-10 17:04:03 - INFO - TRAINING - Epoch: [49][400/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.4649 (0.3984)	Prec@1 83.000 (86.464)	Prec@5 100.000 (99.514)
2019-04-10 17:04:05 - INFO - EVALUATING - Epoch: [49][0/50]	Time 0.048 (0.048)	Data 0.010 (0.010)	Loss 0.5264 (0.5264)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-04-10 17:04:06 - INFO - EVALUATING - Epoch: [49][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.5173 (0.5173)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-04-10 17:04:07 - INFO - EVALUATING - Epoch: [49][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5530 (0.5794)	Prec@1 85.000 (80.314)	Prec@5 99.000 (98.784)
2019-04-10 17:04:08 - INFO - 
 Epoch: 50	Training Loss 0.3983 	Training Prec@1 86.456 	Training Prec@5 99.522 	Validation Loss 0.5799 	Validation Prec@1 80.400 	Validation Prec@5 98.800 	Test Loss 0.5745 	Test Prec@1  80.690 	Test Prec@5  98.860 

2019-04-10 17:04:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:04:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:04:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:04:08 - INFO - TRAINING - Epoch: [50][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.4856 (0.4856)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:04:11 - INFO - TRAINING - Epoch: [50][50/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.4218 (0.3989)	Prec@1 88.000 (86.980)	Prec@5 99.000 (99.549)
2019-04-10 17:04:14 - INFO - TRAINING - Epoch: [50][100/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.4465 (0.3898)	Prec@1 84.000 (86.713)	Prec@5 100.000 (99.634)
2019-04-10 17:04:16 - INFO - TRAINING - Epoch: [50][150/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.4337 (0.3869)	Prec@1 84.000 (86.894)	Prec@5 100.000 (99.583)
2019-04-10 17:04:19 - INFO - TRAINING - Epoch: [50][200/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.3202 (0.3855)	Prec@1 91.000 (86.980)	Prec@5 100.000 (99.597)
2019-04-10 17:04:22 - INFO - TRAINING - Epoch: [50][250/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.3002 (0.3805)	Prec@1 88.000 (87.012)	Prec@5 100.000 (99.614)
2019-04-10 17:04:24 - INFO - TRAINING - Epoch: [50][300/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.3298 (0.3796)	Prec@1 89.000 (87.013)	Prec@5 99.000 (99.588)
2019-04-10 17:04:27 - INFO - TRAINING - Epoch: [50][350/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.2934 (0.3803)	Prec@1 91.000 (86.977)	Prec@5 99.000 (99.576)
2019-04-10 17:04:30 - INFO - TRAINING - Epoch: [50][400/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.4673 (0.3826)	Prec@1 84.000 (86.835)	Prec@5 100.000 (99.579)
2019-04-10 17:04:32 - INFO - EVALUATING - Epoch: [50][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.5779 (0.5779)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-04-10 17:04:33 - INFO - EVALUATING - Epoch: [50][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4193 (0.4193)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:04:34 - INFO - EVALUATING - Epoch: [50][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5160 (0.5737)	Prec@1 82.000 (81.235)	Prec@5 99.000 (98.902)
2019-04-10 17:04:35 - INFO - 
 Epoch: 51	Training Loss 0.3842 	Training Prec@1 86.816 	Training Prec@5 99.571 	Validation Loss 0.5703 	Validation Prec@1 81.340 	Validation Prec@5 98.960 	Test Loss 0.5826 	Test Prec@1  80.680 	Test Prec@5  98.990 

2019-04-10 17:04:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:04:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:04:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:04:35 - INFO - TRAINING - Epoch: [51][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.3821 (0.3821)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:04:38 - INFO - TRAINING - Epoch: [51][50/450]	Time 0.053 (0.053)	Data 0.012 (0.013)	Loss 0.3820 (0.3651)	Prec@1 87.000 (87.980)	Prec@5 99.000 (99.588)
2019-04-10 17:04:40 - INFO - TRAINING - Epoch: [51][100/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.3271 (0.3701)	Prec@1 89.000 (87.584)	Prec@5 100.000 (99.653)
2019-04-10 17:04:43 - INFO - TRAINING - Epoch: [51][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4601 (0.3728)	Prec@1 85.000 (87.523)	Prec@5 99.000 (99.570)
2019-04-10 17:04:46 - INFO - TRAINING - Epoch: [51][200/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.4560 (0.3773)	Prec@1 80.000 (87.199)	Prec@5 100.000 (99.567)
2019-04-10 17:04:48 - INFO - TRAINING - Epoch: [51][250/450]	Time 0.053 (0.054)	Data 0.011 (0.013)	Loss 0.3762 (0.3743)	Prec@1 86.000 (87.151)	Prec@5 100.000 (99.590)
2019-04-10 17:04:51 - INFO - TRAINING - Epoch: [51][300/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.2443 (0.3759)	Prec@1 91.000 (87.100)	Prec@5 100.000 (99.581)
2019-04-10 17:04:54 - INFO - TRAINING - Epoch: [51][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.3755 (0.3757)	Prec@1 90.000 (87.085)	Prec@5 100.000 (99.593)
2019-04-10 17:04:57 - INFO - TRAINING - Epoch: [51][400/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.2283 (0.3759)	Prec@1 92.000 (87.105)	Prec@5 100.000 (99.599)
2019-04-10 17:04:59 - INFO - EVALUATING - Epoch: [51][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.6292 (0.6292)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-04-10 17:05:00 - INFO - EVALUATING - Epoch: [51][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4706 (0.4706)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-04-10 17:05:01 - INFO - EVALUATING - Epoch: [51][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.4441 (0.5320)	Prec@1 90.000 (82.569)	Prec@5 97.000 (98.667)
2019-04-10 17:05:02 - INFO - 
 Epoch: 52	Training Loss 0.3776 	Training Prec@1 87.098 	Training Prec@5 99.591 	Validation Loss 0.5523 	Validation Prec@1 81.500 	Validation Prec@5 98.740 	Test Loss 0.5395 	Test Prec@1  82.070 	Test Prec@5  98.800 

2019-04-10 17:05:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:05:02 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:05:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:05:02 - INFO - TRAINING - Epoch: [52][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.2537 (0.2537)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:05:05 - INFO - TRAINING - Epoch: [52][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.2574 (0.3828)	Prec@1 90.000 (86.784)	Prec@5 100.000 (99.588)
2019-04-10 17:05:07 - INFO - TRAINING - Epoch: [52][100/450]	Time 0.055 (0.053)	Data 0.012 (0.013)	Loss 0.3302 (0.3799)	Prec@1 89.000 (86.851)	Prec@5 99.000 (99.634)
2019-04-10 17:05:10 - INFO - TRAINING - Epoch: [52][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.5834 (0.3726)	Prec@1 79.000 (87.146)	Prec@5 100.000 (99.649)
2019-04-10 17:05:13 - INFO - TRAINING - Epoch: [52][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4572 (0.3712)	Prec@1 82.000 (87.229)	Prec@5 99.000 (99.642)
2019-04-10 17:05:16 - INFO - TRAINING - Epoch: [52][250/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.2959 (0.3687)	Prec@1 91.000 (87.271)	Prec@5 100.000 (99.629)
2019-04-10 17:05:18 - INFO - TRAINING - Epoch: [52][300/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.3307 (0.3748)	Prec@1 91.000 (87.179)	Prec@5 99.000 (99.635)
2019-04-10 17:05:21 - INFO - TRAINING - Epoch: [52][350/450]	Time 0.056 (0.054)	Data 0.012 (0.013)	Loss 0.2626 (0.3768)	Prec@1 91.000 (87.100)	Prec@5 100.000 (99.632)
2019-04-10 17:05:24 - INFO - TRAINING - Epoch: [52][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.4269 (0.3722)	Prec@1 87.000 (87.257)	Prec@5 100.000 (99.656)
2019-04-10 17:05:27 - INFO - EVALUATING - Epoch: [52][0/50]	Time 0.048 (0.048)	Data 0.010 (0.010)	Loss 0.7500 (0.7500)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-04-10 17:05:27 - INFO - EVALUATING - Epoch: [52][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.4356 (0.4356)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:05:28 - INFO - EVALUATING - Epoch: [52][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.3946 (0.5283)	Prec@1 90.000 (82.412)	Prec@5 98.000 (99.059)
2019-04-10 17:05:29 - INFO - 
 Epoch: 53	Training Loss 0.3728 	Training Prec@1 87.236 	Training Prec@5 99.638 	Validation Loss 0.5339 	Validation Prec@1 81.860 	Validation Prec@5 99.140 	Test Loss 0.5293 	Test Prec@1  82.290 	Test Prec@5  99.110 

2019-04-10 17:05:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:05:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:05:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:05:29 - INFO - TRAINING - Epoch: [53][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.3819 (0.3819)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:05:32 - INFO - TRAINING - Epoch: [53][50/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.2235 (0.3683)	Prec@1 92.000 (87.294)	Prec@5 100.000 (99.686)
2019-04-10 17:05:35 - INFO - TRAINING - Epoch: [53][100/450]	Time 0.056 (0.056)	Data 0.012 (0.013)	Loss 0.3142 (0.3643)	Prec@1 92.000 (87.356)	Prec@5 100.000 (99.693)
2019-04-10 17:05:38 - INFO - TRAINING - Epoch: [53][150/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.3311 (0.3598)	Prec@1 87.000 (87.444)	Prec@5 100.000 (99.722)
2019-04-10 17:05:41 - INFO - TRAINING - Epoch: [53][200/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.4317 (0.3582)	Prec@1 85.000 (87.522)	Prec@5 99.000 (99.711)
2019-04-10 17:05:44 - INFO - TRAINING - Epoch: [53][250/450]	Time 0.056 (0.057)	Data 0.012 (0.013)	Loss 0.3138 (0.3556)	Prec@1 90.000 (87.661)	Prec@5 100.000 (99.709)
2019-04-10 17:05:46 - INFO - TRAINING - Epoch: [53][300/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.4031 (0.3578)	Prec@1 83.000 (87.645)	Prec@5 100.000 (99.684)
2019-04-10 17:05:49 - INFO - TRAINING - Epoch: [53][350/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.3414 (0.3588)	Prec@1 91.000 (87.652)	Prec@5 100.000 (99.678)
2019-04-10 17:05:52 - INFO - TRAINING - Epoch: [53][400/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.2585 (0.3594)	Prec@1 89.000 (87.618)	Prec@5 100.000 (99.681)
2019-04-10 17:05:55 - INFO - EVALUATING - Epoch: [53][0/50]	Time 0.049 (0.049)	Data 0.010 (0.010)	Loss 0.4077 (0.4077)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:05:56 - INFO - EVALUATING - Epoch: [53][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.3085 (0.3085)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:05:57 - INFO - EVALUATING - Epoch: [53][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.4258 (0.4564)	Prec@1 87.000 (85.118)	Prec@5 99.000 (99.373)
2019-04-10 17:05:58 - INFO - 
 Epoch: 54	Training Loss 0.3607 	Training Prec@1 87.602 	Training Prec@5 99.667 	Validation Loss 0.4499 	Validation Prec@1 84.880 	Validation Prec@5 99.500 	Test Loss 0.4572 	Test Prec@1  84.590 	Test Prec@5  99.440 

2019-04-10 17:05:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:05:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:05:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:05:58 - INFO - TRAINING - Epoch: [54][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.2694 (0.2694)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:01 - INFO - TRAINING - Epoch: [54][50/450]	Time 0.053 (0.053)	Data 0.011 (0.013)	Loss 0.3245 (0.3425)	Prec@1 87.000 (88.745)	Prec@5 100.000 (99.510)
2019-04-10 17:06:03 - INFO - TRAINING - Epoch: [54][100/450]	Time 0.054 (0.053)	Data 0.013 (0.013)	Loss 0.2063 (0.3585)	Prec@1 91.000 (88.030)	Prec@5 100.000 (99.634)
2019-04-10 17:06:06 - INFO - TRAINING - Epoch: [54][150/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.2967 (0.3543)	Prec@1 92.000 (88.007)	Prec@5 100.000 (99.629)
2019-04-10 17:06:09 - INFO - TRAINING - Epoch: [54][200/450]	Time 0.053 (0.053)	Data 0.013 (0.013)	Loss 0.2705 (0.3545)	Prec@1 90.000 (88.040)	Prec@5 100.000 (99.652)
2019-04-10 17:06:11 - INFO - TRAINING - Epoch: [54][250/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.1581 (0.3514)	Prec@1 97.000 (88.116)	Prec@5 100.000 (99.669)
2019-04-10 17:06:14 - INFO - TRAINING - Epoch: [54][300/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.3205 (0.3509)	Prec@1 87.000 (88.086)	Prec@5 100.000 (99.681)
2019-04-10 17:06:17 - INFO - TRAINING - Epoch: [54][350/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.2983 (0.3539)	Prec@1 90.000 (87.952)	Prec@5 99.000 (99.661)
2019-04-10 17:06:19 - INFO - TRAINING - Epoch: [54][400/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.3751 (0.3535)	Prec@1 90.000 (88.022)	Prec@5 100.000 (99.656)
2019-04-10 17:06:22 - INFO - EVALUATING - Epoch: [54][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.5916 (0.5916)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:23 - INFO - EVALUATING - Epoch: [54][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3560 (0.3560)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:24 - INFO - EVALUATING - Epoch: [54][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2516 (0.4334)	Prec@1 93.000 (85.392)	Prec@5 100.000 (99.373)
2019-04-10 17:06:25 - INFO - 
 Epoch: 55	Training Loss 0.3535 	Training Prec@1 88.033 	Training Prec@5 99.644 	Validation Loss 0.4207 	Validation Prec@1 86.060 	Validation Prec@5 99.620 	Test Loss 0.4258 	Test Prec@1  85.420 	Test Prec@5  99.480 

2019-04-10 17:06:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:06:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:06:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:06:25 - INFO - TRAINING - Epoch: [55][0/450]	Time 0.032 (0.032)	Data 0.013 (0.013)	Loss 0.3132 (0.3132)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:27 - INFO - TRAINING - Epoch: [55][50/450]	Time 0.055 (0.053)	Data 0.013 (0.014)	Loss 0.2801 (0.3375)	Prec@1 91.000 (88.157)	Prec@5 100.000 (99.745)
2019-04-10 17:06:30 - INFO - TRAINING - Epoch: [55][100/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.3722 (0.3295)	Prec@1 86.000 (88.545)	Prec@5 100.000 (99.743)
2019-04-10 17:06:33 - INFO - TRAINING - Epoch: [55][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2539 (0.3318)	Prec@1 91.000 (88.497)	Prec@5 100.000 (99.742)
2019-04-10 17:06:35 - INFO - TRAINING - Epoch: [55][200/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.3198 (0.3380)	Prec@1 88.000 (88.318)	Prec@5 100.000 (99.711)
2019-04-10 17:06:38 - INFO - TRAINING - Epoch: [55][250/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.3290 (0.3402)	Prec@1 91.000 (88.195)	Prec@5 99.000 (99.685)
2019-04-10 17:06:41 - INFO - TRAINING - Epoch: [55][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2190 (0.3424)	Prec@1 92.000 (88.123)	Prec@5 100.000 (99.678)
2019-04-10 17:06:44 - INFO - TRAINING - Epoch: [55][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.4201 (0.3431)	Prec@1 82.000 (88.123)	Prec@5 100.000 (99.658)
2019-04-10 17:06:46 - INFO - TRAINING - Epoch: [55][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1612 (0.3450)	Prec@1 97.000 (88.110)	Prec@5 100.000 (99.651)
2019-04-10 17:06:49 - INFO - EVALUATING - Epoch: [55][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.4060 (0.4060)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:50 - INFO - EVALUATING - Epoch: [55][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4397 (0.4397)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:06:51 - INFO - EVALUATING - Epoch: [55][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.4098 (0.4674)	Prec@1 88.000 (84.569)	Prec@5 98.000 (98.961)
2019-04-10 17:06:52 - INFO - 
 Epoch: 56	Training Loss 0.3440 	Training Prec@1 88.118 	Training Prec@5 99.660 	Validation Loss 0.4686 	Validation Prec@1 84.540 	Validation Prec@5 99.160 	Test Loss 0.4701 	Test Prec@1  84.630 	Test Prec@5  98.960 

2019-04-10 17:06:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:06:52 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:06:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:06:52 - INFO - TRAINING - Epoch: [56][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.3100 (0.3100)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:06:55 - INFO - TRAINING - Epoch: [56][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.3486 (0.3447)	Prec@1 89.000 (88.471)	Prec@5 100.000 (99.804)
2019-04-10 17:06:57 - INFO - TRAINING - Epoch: [56][100/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.3094 (0.3304)	Prec@1 92.000 (88.782)	Prec@5 100.000 (99.752)
2019-04-10 17:07:00 - INFO - TRAINING - Epoch: [56][150/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.3465 (0.3291)	Prec@1 89.000 (88.775)	Prec@5 100.000 (99.735)
2019-04-10 17:07:03 - INFO - TRAINING - Epoch: [56][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.2395 (0.3267)	Prec@1 95.000 (88.836)	Prec@5 100.000 (99.736)
2019-04-10 17:07:06 - INFO - TRAINING - Epoch: [56][250/450]	Time 0.054 (0.057)	Data 0.013 (0.014)	Loss 0.3533 (0.3266)	Prec@1 91.000 (88.821)	Prec@5 99.000 (99.733)
2019-04-10 17:07:09 - INFO - TRAINING - Epoch: [56][300/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.4699 (0.3309)	Prec@1 83.000 (88.691)	Prec@5 100.000 (99.748)
2019-04-10 17:07:11 - INFO - TRAINING - Epoch: [56][350/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.4052 (0.3307)	Prec@1 86.000 (88.678)	Prec@5 99.000 (99.721)
2019-04-10 17:07:14 - INFO - TRAINING - Epoch: [56][400/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.2871 (0.3354)	Prec@1 91.000 (88.544)	Prec@5 99.000 (99.711)
2019-04-10 17:07:17 - INFO - EVALUATING - Epoch: [56][0/50]	Time 0.040 (0.040)	Data 0.010 (0.010)	Loss 0.5903 (0.5903)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 17:07:18 - INFO - EVALUATING - Epoch: [56][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4236 (0.4236)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:07:19 - INFO - EVALUATING - Epoch: [56][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.4143 (0.4833)	Prec@1 85.000 (84.176)	Prec@5 99.000 (99.059)
2019-04-10 17:07:19 - INFO - 
 Epoch: 57	Training Loss 0.3371 	Training Prec@1 88.511 	Training Prec@5 99.698 	Validation Loss 0.4637 	Validation Prec@1 84.220 	Validation Prec@5 99.360 	Test Loss 0.4778 	Test Prec@1  84.420 	Test Prec@5  99.130 

2019-04-10 17:07:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:07:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:07:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:07:20 - INFO - TRAINING - Epoch: [57][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.2497 (0.2497)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:07:22 - INFO - TRAINING - Epoch: [57][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.2016 (0.3102)	Prec@1 93.000 (89.882)	Prec@5 100.000 (99.588)
2019-04-10 17:07:25 - INFO - TRAINING - Epoch: [57][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.2638 (0.3181)	Prec@1 90.000 (89.347)	Prec@5 99.000 (99.634)
2019-04-10 17:07:28 - INFO - TRAINING - Epoch: [57][150/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.2900 (0.3190)	Prec@1 88.000 (89.205)	Prec@5 100.000 (99.695)
2019-04-10 17:07:30 - INFO - TRAINING - Epoch: [57][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3649 (0.3221)	Prec@1 89.000 (89.204)	Prec@5 100.000 (99.726)
2019-04-10 17:07:33 - INFO - TRAINING - Epoch: [57][250/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.4097 (0.3227)	Prec@1 89.000 (89.143)	Prec@5 100.000 (99.737)
2019-04-10 17:07:36 - INFO - TRAINING - Epoch: [57][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.3393 (0.3246)	Prec@1 91.000 (89.086)	Prec@5 99.000 (99.738)
2019-04-10 17:07:38 - INFO - TRAINING - Epoch: [57][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3984 (0.3269)	Prec@1 85.000 (88.969)	Prec@5 99.000 (99.721)
2019-04-10 17:07:41 - INFO - TRAINING - Epoch: [57][400/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.4077 (0.3264)	Prec@1 87.000 (88.950)	Prec@5 100.000 (99.728)
2019-04-10 17:07:44 - INFO - EVALUATING - Epoch: [57][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.4886 (0.4886)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-04-10 17:07:45 - INFO - EVALUATING - Epoch: [57][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.5418 (0.5418)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-04-10 17:07:46 - INFO - EVALUATING - Epoch: [57][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.5605 (0.5326)	Prec@1 83.000 (82.039)	Prec@5 98.000 (99.275)
2019-04-10 17:07:46 - INFO - 
 Epoch: 58	Training Loss 0.3253 	Training Prec@1 88.953 	Training Prec@5 99.733 	Validation Loss 0.5217 	Validation Prec@1 82.840 	Validation Prec@5 99.260 	Test Loss 0.5253 	Test Prec@1  82.490 	Test Prec@5  99.330 

2019-04-10 17:07:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:07:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:07:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:07:47 - INFO - TRAINING - Epoch: [58][0/450]	Time 0.032 (0.032)	Data 0.014 (0.014)	Loss 0.1373 (0.1373)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:07:49 - INFO - TRAINING - Epoch: [58][50/450]	Time 0.054 (0.053)	Data 0.013 (0.015)	Loss 0.2646 (0.3144)	Prec@1 90.000 (89.078)	Prec@5 100.000 (99.804)
2019-04-10 17:07:52 - INFO - TRAINING - Epoch: [58][100/450]	Time 0.055 (0.053)	Data 0.014 (0.015)	Loss 0.4505 (0.3085)	Prec@1 85.000 (89.436)	Prec@5 100.000 (99.822)
2019-04-10 17:07:55 - INFO - TRAINING - Epoch: [58][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.3089 (0.3110)	Prec@1 88.000 (89.325)	Prec@5 100.000 (99.768)
2019-04-10 17:07:57 - INFO - TRAINING - Epoch: [58][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2566 (0.3119)	Prec@1 90.000 (89.284)	Prec@5 100.000 (99.776)
2019-04-10 17:08:00 - INFO - TRAINING - Epoch: [58][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.3395 (0.3137)	Prec@1 89.000 (89.291)	Prec@5 100.000 (99.757)
2019-04-10 17:08:03 - INFO - TRAINING - Epoch: [58][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3671 (0.3189)	Prec@1 90.000 (89.093)	Prec@5 98.000 (99.714)
2019-04-10 17:08:06 - INFO - TRAINING - Epoch: [58][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1854 (0.3171)	Prec@1 96.000 (89.151)	Prec@5 100.000 (99.701)
2019-04-10 17:08:08 - INFO - TRAINING - Epoch: [58][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2638 (0.3168)	Prec@1 92.000 (89.197)	Prec@5 100.000 (99.701)
2019-04-10 17:08:11 - INFO - EVALUATING - Epoch: [58][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.4080 (0.4080)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:08:12 - INFO - EVALUATING - Epoch: [58][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3985 (0.3985)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:08:13 - INFO - EVALUATING - Epoch: [58][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3145 (0.4440)	Prec@1 89.000 (85.137)	Prec@5 100.000 (99.176)
2019-04-10 17:08:14 - INFO - 
 Epoch: 59	Training Loss 0.3180 	Training Prec@1 89.184 	Training Prec@5 99.707 	Validation Loss 0.4379 	Validation Prec@1 85.500 	Validation Prec@5 99.340 	Test Loss 0.4432 	Test Prec@1  85.070 	Test Prec@5  99.320 

2019-04-10 17:08:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:08:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:08:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:08:14 - INFO - TRAINING - Epoch: [59][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.3135 (0.3135)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:08:16 - INFO - TRAINING - Epoch: [59][50/450]	Time 0.049 (0.054)	Data 0.022 (0.014)	Loss 0.4111 (0.3055)	Prec@1 85.000 (89.667)	Prec@5 100.000 (99.863)
2019-04-10 17:08:19 - INFO - TRAINING - Epoch: [59][100/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2298 (0.3025)	Prec@1 93.000 (89.614)	Prec@5 100.000 (99.822)
2019-04-10 17:08:22 - INFO - TRAINING - Epoch: [59][150/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.1662 (0.3006)	Prec@1 95.000 (89.675)	Prec@5 100.000 (99.795)
2019-04-10 17:08:25 - INFO - TRAINING - Epoch: [59][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2688 (0.3020)	Prec@1 89.000 (89.597)	Prec@5 100.000 (99.756)
2019-04-10 17:08:27 - INFO - TRAINING - Epoch: [59][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3105 (0.3041)	Prec@1 92.000 (89.582)	Prec@5 100.000 (99.753)
2019-04-10 17:08:30 - INFO - TRAINING - Epoch: [59][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.3556 (0.3039)	Prec@1 89.000 (89.565)	Prec@5 99.000 (99.767)
2019-04-10 17:08:33 - INFO - TRAINING - Epoch: [59][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2168 (0.3044)	Prec@1 92.000 (89.567)	Prec@5 100.000 (99.758)
2019-04-10 17:08:36 - INFO - TRAINING - Epoch: [59][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1999 (0.3082)	Prec@1 89.000 (89.446)	Prec@5 100.000 (99.746)
2019-04-10 17:08:38 - INFO - EVALUATING - Epoch: [59][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.4396 (0.4396)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:08:39 - INFO - EVALUATING - Epoch: [59][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3934 (0.3934)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:08:40 - INFO - EVALUATING - Epoch: [59][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3302 (0.4483)	Prec@1 88.000 (85.137)	Prec@5 100.000 (99.275)
2019-04-10 17:08:41 - INFO - 
 Epoch: 60	Training Loss 0.3102 	Training Prec@1 89.413 	Training Prec@5 99.740 	Validation Loss 0.4107 	Validation Prec@1 86.220 	Validation Prec@5 99.460 	Test Loss 0.4397 	Test Prec@1  85.200 	Test Prec@5  99.460 

2019-04-10 17:08:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:08:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:08:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:08:41 - INFO - TRAINING - Epoch: [60][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.4403 (0.4403)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 17:08:44 - INFO - TRAINING - Epoch: [60][50/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.3026 (0.3077)	Prec@1 89.000 (89.471)	Prec@5 100.000 (99.608)
2019-04-10 17:08:47 - INFO - TRAINING - Epoch: [60][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.4670 (0.3029)	Prec@1 89.000 (89.693)	Prec@5 98.000 (99.693)
2019-04-10 17:08:49 - INFO - TRAINING - Epoch: [60][150/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2008 (0.2964)	Prec@1 91.000 (89.808)	Prec@5 100.000 (99.722)
2019-04-10 17:08:52 - INFO - TRAINING - Epoch: [60][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3863 (0.2997)	Prec@1 89.000 (89.687)	Prec@5 99.000 (99.736)
2019-04-10 17:08:55 - INFO - TRAINING - Epoch: [60][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3332 (0.3008)	Prec@1 91.000 (89.669)	Prec@5 100.000 (99.749)
2019-04-10 17:08:57 - INFO - TRAINING - Epoch: [60][300/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.2312 (0.2987)	Prec@1 90.000 (89.811)	Prec@5 100.000 (99.751)
2019-04-10 17:09:00 - INFO - TRAINING - Epoch: [60][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.3613 (0.3028)	Prec@1 88.000 (89.687)	Prec@5 100.000 (99.761)
2019-04-10 17:09:03 - INFO - TRAINING - Epoch: [60][400/450]	Time 0.056 (0.055)	Data 0.012 (0.014)	Loss 0.3266 (0.3023)	Prec@1 90.000 (89.718)	Prec@5 100.000 (99.751)
2019-04-10 17:09:06 - INFO - EVALUATING - Epoch: [60][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.3839 (0.3839)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:09:07 - INFO - EVALUATING - Epoch: [60][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2525 (0.2525)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:09:07 - INFO - EVALUATING - Epoch: [60][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3251 (0.4195)	Prec@1 88.000 (86.098)	Prec@5 99.000 (99.471)
2019-04-10 17:09:08 - INFO - 
 Epoch: 61	Training Loss 0.3029 	Training Prec@1 89.656 	Training Prec@5 99.749 	Validation Loss 0.4048 	Validation Prec@1 85.860 	Validation Prec@5 99.640 	Test Loss 0.4091 	Test Prec@1  86.060 	Test Prec@5  99.570 

2019-04-10 17:09:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:09:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:09:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:09:08 - INFO - TRAINING - Epoch: [61][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1777 (0.1777)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:09:11 - INFO - TRAINING - Epoch: [61][50/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.3226 (0.2889)	Prec@1 90.000 (90.098)	Prec@5 100.000 (99.863)
2019-04-10 17:09:14 - INFO - TRAINING - Epoch: [61][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2231 (0.2903)	Prec@1 93.000 (90.158)	Prec@5 100.000 (99.832)
2019-04-10 17:09:17 - INFO - TRAINING - Epoch: [61][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2403 (0.2900)	Prec@1 92.000 (90.238)	Prec@5 99.000 (99.801)
2019-04-10 17:09:19 - INFO - TRAINING - Epoch: [61][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2621 (0.2844)	Prec@1 90.000 (90.323)	Prec@5 100.000 (99.826)
2019-04-10 17:09:22 - INFO - TRAINING - Epoch: [61][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.3394 (0.2863)	Prec@1 92.000 (90.263)	Prec@5 99.000 (99.825)
2019-04-10 17:09:25 - INFO - TRAINING - Epoch: [61][300/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.3041 (0.2896)	Prec@1 89.000 (90.219)	Prec@5 100.000 (99.801)
2019-04-10 17:09:27 - INFO - TRAINING - Epoch: [61][350/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.2819 (0.2927)	Prec@1 92.000 (90.028)	Prec@5 100.000 (99.769)
2019-04-10 17:09:30 - INFO - TRAINING - Epoch: [61][400/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.2947 (0.2923)	Prec@1 90.000 (90.017)	Prec@5 100.000 (99.753)
2019-04-10 17:09:33 - INFO - EVALUATING - Epoch: [61][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.3369 (0.3369)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:09:34 - INFO - EVALUATING - Epoch: [61][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3487 (0.3487)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:09:35 - INFO - EVALUATING - Epoch: [61][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.3339 (0.3986)	Prec@1 87.000 (86.412)	Prec@5 98.000 (99.333)
2019-04-10 17:09:36 - INFO - 
 Epoch: 62	Training Loss 0.2943 	Training Prec@1 89.942 	Training Prec@5 99.760 	Validation Loss 0.3966 	Validation Prec@1 86.520 	Validation Prec@5 99.540 	Test Loss 0.3926 	Test Prec@1  86.540 	Test Prec@5  99.410 

2019-04-10 17:09:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:09:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:09:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:09:36 - INFO - TRAINING - Epoch: [62][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1772 (0.1772)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:09:39 - INFO - TRAINING - Epoch: [62][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.4197 (0.2812)	Prec@1 88.000 (90.667)	Prec@5 100.000 (99.843)
2019-04-10 17:09:41 - INFO - TRAINING - Epoch: [62][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1863 (0.2876)	Prec@1 93.000 (90.406)	Prec@5 100.000 (99.762)
2019-04-10 17:09:44 - INFO - TRAINING - Epoch: [62][150/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.2053 (0.2827)	Prec@1 92.000 (90.589)	Prec@5 100.000 (99.755)
2019-04-10 17:09:47 - INFO - TRAINING - Epoch: [62][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3330 (0.2856)	Prec@1 90.000 (90.413)	Prec@5 99.000 (99.746)
2019-04-10 17:09:49 - INFO - TRAINING - Epoch: [62][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3375 (0.2852)	Prec@1 89.000 (90.394)	Prec@5 100.000 (99.753)
2019-04-10 17:09:52 - INFO - TRAINING - Epoch: [62][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2470 (0.2859)	Prec@1 90.000 (90.342)	Prec@5 100.000 (99.764)
2019-04-10 17:09:55 - INFO - TRAINING - Epoch: [62][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.4869 (0.2857)	Prec@1 86.000 (90.330)	Prec@5 99.000 (99.772)
2019-04-10 17:09:58 - INFO - TRAINING - Epoch: [62][400/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.3205 (0.2866)	Prec@1 89.000 (90.274)	Prec@5 100.000 (99.761)
2019-04-10 17:10:00 - INFO - EVALUATING - Epoch: [62][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3854 (0.3854)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:01 - INFO - EVALUATING - Epoch: [62][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4194 (0.4194)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 17:10:02 - INFO - EVALUATING - Epoch: [62][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2847 (0.4887)	Prec@1 91.000 (83.804)	Prec@5 100.000 (99.137)
2019-04-10 17:10:03 - INFO - 
 Epoch: 63	Training Loss 0.2887 	Training Prec@1 90.209 	Training Prec@5 99.753 	Validation Loss 0.4763 	Validation Prec@1 83.980 	Validation Prec@5 99.240 	Test Loss 0.4888 	Test Prec@1  84.020 	Test Prec@5  99.240 

2019-04-10 17:10:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:10:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:10:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:10:03 - INFO - TRAINING - Epoch: [63][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2892 (0.2892)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:06 - INFO - TRAINING - Epoch: [63][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.2049 (0.2616)	Prec@1 92.000 (91.020)	Prec@5 99.000 (99.843)
2019-04-10 17:10:09 - INFO - TRAINING - Epoch: [63][100/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.3298 (0.2701)	Prec@1 86.000 (90.693)	Prec@5 100.000 (99.762)
2019-04-10 17:10:12 - INFO - TRAINING - Epoch: [63][150/450]	Time 0.056 (0.057)	Data 0.012 (0.014)	Loss 0.2793 (0.2675)	Prec@1 91.000 (90.801)	Prec@5 99.000 (99.815)
2019-04-10 17:10:14 - INFO - TRAINING - Epoch: [63][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.3546 (0.2708)	Prec@1 89.000 (90.632)	Prec@5 99.000 (99.811)
2019-04-10 17:10:17 - INFO - TRAINING - Epoch: [63][250/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.2650 (0.2766)	Prec@1 91.000 (90.442)	Prec@5 99.000 (99.797)
2019-04-10 17:10:20 - INFO - TRAINING - Epoch: [63][300/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.3472 (0.2801)	Prec@1 86.000 (90.332)	Prec@5 100.000 (99.791)
2019-04-10 17:10:22 - INFO - TRAINING - Epoch: [63][350/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.2205 (0.2798)	Prec@1 92.000 (90.336)	Prec@5 100.000 (99.792)
2019-04-10 17:10:25 - INFO - TRAINING - Epoch: [63][400/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.3363 (0.2800)	Prec@1 89.000 (90.332)	Prec@5 100.000 (99.793)
2019-04-10 17:10:28 - INFO - EVALUATING - Epoch: [63][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.5804 (0.5804)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:29 - INFO - EVALUATING - Epoch: [63][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3147 (0.3147)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:30 - INFO - EVALUATING - Epoch: [63][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2977 (0.4428)	Prec@1 86.000 (85.588)	Prec@5 100.000 (99.431)
2019-04-10 17:10:30 - INFO - 
 Epoch: 64	Training Loss 0.2802 	Training Prec@1 90.333 	Training Prec@5 99.800 	Validation Loss 0.4198 	Validation Prec@1 86.580 	Validation Prec@5 99.520 	Test Loss 0.4300 	Test Prec@1  85.890 	Test Prec@5  99.450 

2019-04-10 17:10:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:10:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:10:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:10:31 - INFO - TRAINING - Epoch: [64][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2455 (0.2455)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:33 - INFO - TRAINING - Epoch: [64][50/450]	Time 0.054 (0.053)	Data 0.014 (0.015)	Loss 0.2249 (0.2487)	Prec@1 91.000 (91.294)	Prec@5 100.000 (99.765)
2019-04-10 17:10:36 - INFO - TRAINING - Epoch: [64][100/450]	Time 0.053 (0.054)	Data 0.013 (0.015)	Loss 0.2979 (0.2513)	Prec@1 87.000 (91.228)	Prec@5 100.000 (99.802)
2019-04-10 17:10:39 - INFO - TRAINING - Epoch: [64][150/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1903 (0.2546)	Prec@1 93.000 (91.199)	Prec@5 100.000 (99.815)
2019-04-10 17:10:41 - INFO - TRAINING - Epoch: [64][200/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1418 (0.2565)	Prec@1 97.000 (91.144)	Prec@5 100.000 (99.806)
2019-04-10 17:10:44 - INFO - TRAINING - Epoch: [64][250/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.3931 (0.2558)	Prec@1 85.000 (91.179)	Prec@5 100.000 (99.801)
2019-04-10 17:10:47 - INFO - TRAINING - Epoch: [64][300/450]	Time 0.056 (0.054)	Data 0.012 (0.014)	Loss 0.3206 (0.2616)	Prec@1 87.000 (90.927)	Prec@5 100.000 (99.804)
2019-04-10 17:10:49 - INFO - TRAINING - Epoch: [64][350/450]	Time 0.050 (0.054)	Data 0.022 (0.014)	Loss 0.3544 (0.2630)	Prec@1 88.000 (90.912)	Prec@5 100.000 (99.809)
2019-04-10 17:10:52 - INFO - TRAINING - Epoch: [64][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2642 (0.2634)	Prec@1 92.000 (90.878)	Prec@5 100.000 (99.808)
2019-04-10 17:10:55 - INFO - EVALUATING - Epoch: [64][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.3520 (0.3520)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:10:56 - INFO - EVALUATING - Epoch: [64][0/100]	Time 0.017 (0.017)	Data 0.012 (0.012)	Loss 0.2868 (0.2868)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:10:57 - INFO - EVALUATING - Epoch: [64][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2970 (0.3869)	Prec@1 90.000 (87.549)	Prec@5 100.000 (99.471)
2019-04-10 17:10:58 - INFO - 
 Epoch: 65	Training Loss 0.2650 	Training Prec@1 90.813 	Training Prec@5 99.804 	Validation Loss 0.3691 	Validation Prec@1 87.480 	Validation Prec@5 99.520 	Test Loss 0.3866 	Test Prec@1  87.110 	Test Prec@5  99.600 

2019-04-10 17:10:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:10:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:10:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:10:58 - INFO - TRAINING - Epoch: [65][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2641 (0.2641)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:01 - INFO - TRAINING - Epoch: [65][50/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.2462 (0.2790)	Prec@1 94.000 (90.451)	Prec@5 100.000 (99.765)
2019-04-10 17:11:03 - INFO - TRAINING - Epoch: [65][100/450]	Time 0.058 (0.056)	Data 0.013 (0.014)	Loss 0.1350 (0.2808)	Prec@1 96.000 (90.267)	Prec@5 100.000 (99.792)
2019-04-10 17:11:06 - INFO - TRAINING - Epoch: [65][150/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.1095 (0.2721)	Prec@1 97.000 (90.596)	Prec@5 100.000 (99.781)
2019-04-10 17:11:09 - INFO - TRAINING - Epoch: [65][200/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.2060 (0.2690)	Prec@1 94.000 (90.726)	Prec@5 99.000 (99.791)
2019-04-10 17:11:12 - INFO - TRAINING - Epoch: [65][250/450]	Time 0.058 (0.056)	Data 0.014 (0.014)	Loss 0.2464 (0.2684)	Prec@1 91.000 (90.777)	Prec@5 100.000 (99.805)
2019-04-10 17:11:15 - INFO - TRAINING - Epoch: [65][300/450]	Time 0.058 (0.056)	Data 0.014 (0.014)	Loss 0.2467 (0.2671)	Prec@1 91.000 (90.847)	Prec@5 100.000 (99.791)
2019-04-10 17:11:17 - INFO - TRAINING - Epoch: [65][350/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.1896 (0.2674)	Prec@1 92.000 (90.823)	Prec@5 100.000 (99.798)
2019-04-10 17:11:20 - INFO - TRAINING - Epoch: [65][400/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.2459 (0.2657)	Prec@1 88.000 (90.898)	Prec@5 99.000 (99.788)
2019-04-10 17:11:23 - INFO - EVALUATING - Epoch: [65][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.2642 (0.2642)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:24 - INFO - EVALUATING - Epoch: [65][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3438 (0.3438)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:25 - INFO - EVALUATING - Epoch: [65][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2642 (0.4386)	Prec@1 91.000 (85.471)	Prec@5 99.000 (99.275)
2019-04-10 17:11:25 - INFO - 
 Epoch: 66	Training Loss 0.2650 	Training Prec@1 90.913 	Training Prec@5 99.787 	Validation Loss 0.4140 	Validation Prec@1 86.020 	Validation Prec@5 99.480 	Test Loss 0.4264 	Test Prec@1  85.580 	Test Prec@5  99.380 

2019-04-10 17:11:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:11:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:11:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:11:26 - INFO - TRAINING - Epoch: [66][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.3515 (0.3515)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:28 - INFO - TRAINING - Epoch: [66][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.2145 (0.2588)	Prec@1 95.000 (90.824)	Prec@5 100.000 (99.882)
2019-04-10 17:11:31 - INFO - TRAINING - Epoch: [66][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2737 (0.2532)	Prec@1 92.000 (91.099)	Prec@5 100.000 (99.921)
2019-04-10 17:11:34 - INFO - TRAINING - Epoch: [66][150/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2161 (0.2524)	Prec@1 92.000 (91.066)	Prec@5 100.000 (99.914)
2019-04-10 17:11:36 - INFO - TRAINING - Epoch: [66][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.3144 (0.2549)	Prec@1 89.000 (91.020)	Prec@5 99.000 (99.900)
2019-04-10 17:11:39 - INFO - TRAINING - Epoch: [66][250/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.3070 (0.2570)	Prec@1 91.000 (91.020)	Prec@5 100.000 (99.869)
2019-04-10 17:11:42 - INFO - TRAINING - Epoch: [66][300/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.3471 (0.2589)	Prec@1 87.000 (91.017)	Prec@5 100.000 (99.860)
2019-04-10 17:11:44 - INFO - TRAINING - Epoch: [66][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.3676 (0.2584)	Prec@1 91.000 (91.051)	Prec@5 99.000 (99.858)
2019-04-10 17:11:47 - INFO - TRAINING - Epoch: [66][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2648 (0.2567)	Prec@1 91.000 (91.100)	Prec@5 100.000 (99.863)
2019-04-10 17:11:50 - INFO - EVALUATING - Epoch: [66][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.5074 (0.5074)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:51 - INFO - EVALUATING - Epoch: [66][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4135 (0.4135)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:11:52 - INFO - EVALUATING - Epoch: [66][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3731 (0.4349)	Prec@1 87.000 (85.490)	Prec@5 99.000 (99.353)
2019-04-10 17:11:53 - INFO - 
 Epoch: 67	Training Loss 0.2568 	Training Prec@1 91.124 	Training Prec@5 99.858 	Validation Loss 0.4343 	Validation Prec@1 85.860 	Validation Prec@5 99.400 	Test Loss 0.4247 	Test Prec@1  85.920 	Test Prec@5  99.390 

2019-04-10 17:11:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:11:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:11:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:11:53 - INFO - TRAINING - Epoch: [67][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1946 (0.1946)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:11:56 - INFO - TRAINING - Epoch: [67][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.2518 (0.2454)	Prec@1 88.000 (91.294)	Prec@5 100.000 (99.863)
2019-04-10 17:11:58 - INFO - TRAINING - Epoch: [67][100/450]	Time 0.058 (0.057)	Data 0.012 (0.014)	Loss 0.1437 (0.2522)	Prec@1 94.000 (91.089)	Prec@5 100.000 (99.891)
2019-04-10 17:12:01 - INFO - TRAINING - Epoch: [67][150/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.2070 (0.2496)	Prec@1 95.000 (91.225)	Prec@5 100.000 (99.887)
2019-04-10 17:12:04 - INFO - TRAINING - Epoch: [67][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.2451 (0.2476)	Prec@1 93.000 (91.443)	Prec@5 100.000 (99.881)
2019-04-10 17:12:07 - INFO - TRAINING - Epoch: [67][250/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.2474 (0.2467)	Prec@1 92.000 (91.410)	Prec@5 100.000 (99.880)
2019-04-10 17:12:10 - INFO - TRAINING - Epoch: [67][300/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.2986 (0.2474)	Prec@1 90.000 (91.405)	Prec@5 100.000 (99.874)
2019-04-10 17:12:12 - INFO - TRAINING - Epoch: [67][350/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1344 (0.2460)	Prec@1 98.000 (91.453)	Prec@5 100.000 (99.880)
2019-04-10 17:12:15 - INFO - TRAINING - Epoch: [67][400/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.1407 (0.2492)	Prec@1 96.000 (91.367)	Prec@5 100.000 (99.868)
2019-04-10 17:12:18 - INFO - EVALUATING - Epoch: [67][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.3888 (0.3888)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 17:12:18 - INFO - EVALUATING - Epoch: [67][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4363 (0.4363)	Prec@1 86.000 (86.000)	Prec@5 98.000 (98.000)
2019-04-10 17:12:19 - INFO - EVALUATING - Epoch: [67][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2939 (0.4452)	Prec@1 93.000 (85.490)	Prec@5 99.000 (99.118)
2019-04-10 17:12:20 - INFO - 
 Epoch: 68	Training Loss 0.2484 	Training Prec@1 91.382 	Training Prec@5 99.869 	Validation Loss 0.4324 	Validation Prec@1 85.740 	Validation Prec@5 99.400 	Test Loss 0.4405 	Test Prec@1  85.700 	Test Prec@5  99.270 

2019-04-10 17:12:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:12:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:12:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:12:20 - INFO - TRAINING - Epoch: [68][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.2922 (0.2922)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:12:23 - INFO - TRAINING - Epoch: [68][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.2029 (0.2339)	Prec@1 95.000 (92.255)	Prec@5 99.000 (99.804)
2019-04-10 17:12:26 - INFO - TRAINING - Epoch: [68][100/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.2730 (0.2458)	Prec@1 91.000 (91.772)	Prec@5 99.000 (99.832)
2019-04-10 17:12:28 - INFO - TRAINING - Epoch: [68][150/450]	Time 0.055 (0.054)	Data 0.014 (0.013)	Loss 0.2845 (0.2473)	Prec@1 91.000 (91.464)	Prec@5 100.000 (99.828)
2019-04-10 17:12:31 - INFO - TRAINING - Epoch: [68][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.2010 (0.2437)	Prec@1 91.000 (91.552)	Prec@5 100.000 (99.851)
2019-04-10 17:12:34 - INFO - TRAINING - Epoch: [68][250/450]	Time 0.053 (0.054)	Data 0.013 (0.013)	Loss 0.2283 (0.2438)	Prec@1 93.000 (91.602)	Prec@5 100.000 (99.873)
2019-04-10 17:12:37 - INFO - TRAINING - Epoch: [68][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1946 (0.2442)	Prec@1 95.000 (91.625)	Prec@5 100.000 (99.860)
2019-04-10 17:12:39 - INFO - TRAINING - Epoch: [68][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1924 (0.2445)	Prec@1 92.000 (91.615)	Prec@5 100.000 (99.855)
2019-04-10 17:12:42 - INFO - TRAINING - Epoch: [68][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1134 (0.2444)	Prec@1 98.000 (91.668)	Prec@5 100.000 (99.848)
2019-04-10 17:12:45 - INFO - EVALUATING - Epoch: [68][0/50]	Time 0.042 (0.042)	Data 0.013 (0.013)	Loss 0.4614 (0.4614)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:12:46 - INFO - EVALUATING - Epoch: [68][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4084 (0.4084)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:12:46 - INFO - EVALUATING - Epoch: [68][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3364 (0.4070)	Prec@1 89.000 (86.549)	Prec@5 99.000 (99.353)
2019-04-10 17:12:47 - INFO - 
 Epoch: 69	Training Loss 0.2447 	Training Prec@1 91.658 	Training Prec@5 99.851 	Validation Loss 0.4037 	Validation Prec@1 86.500 	Validation Prec@5 99.600 	Test Loss 0.4092 	Test Prec@1  86.740 	Test Prec@5  99.440 

2019-04-10 17:12:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:12:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:12:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:12:47 - INFO - TRAINING - Epoch: [69][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.2029 (0.2029)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:12:50 - INFO - TRAINING - Epoch: [69][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2578 (0.2375)	Prec@1 91.000 (91.784)	Prec@5 100.000 (99.922)
2019-04-10 17:12:53 - INFO - TRAINING - Epoch: [69][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2369 (0.2402)	Prec@1 90.000 (91.614)	Prec@5 100.000 (99.842)
2019-04-10 17:12:56 - INFO - TRAINING - Epoch: [69][150/450]	Time 0.056 (0.054)	Data 0.015 (0.014)	Loss 0.2665 (0.2377)	Prec@1 90.000 (91.801)	Prec@5 99.000 (99.848)
2019-04-10 17:12:58 - INFO - TRAINING - Epoch: [69][200/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.1633 (0.2353)	Prec@1 95.000 (91.950)	Prec@5 100.000 (99.851)
2019-04-10 17:13:01 - INFO - TRAINING - Epoch: [69][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1788 (0.2381)	Prec@1 94.000 (91.825)	Prec@5 100.000 (99.857)
2019-04-10 17:13:04 - INFO - TRAINING - Epoch: [69][300/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.2131 (0.2372)	Prec@1 93.000 (91.824)	Prec@5 100.000 (99.857)
2019-04-10 17:13:07 - INFO - TRAINING - Epoch: [69][350/450]	Time 0.055 (0.054)	Data 0.014 (0.015)	Loss 0.1872 (0.2368)	Prec@1 94.000 (91.883)	Prec@5 100.000 (99.849)
2019-04-10 17:13:09 - INFO - TRAINING - Epoch: [69][400/450]	Time 0.056 (0.054)	Data 0.014 (0.015)	Loss 0.2430 (0.2370)	Prec@1 90.000 (91.860)	Prec@5 100.000 (99.855)
2019-04-10 17:13:12 - INFO - EVALUATING - Epoch: [69][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.4720 (0.4720)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-04-10 17:13:13 - INFO - EVALUATING - Epoch: [69][0/100]	Time 0.017 (0.017)	Data 0.012 (0.012)	Loss 0.4406 (0.4406)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:13:14 - INFO - EVALUATING - Epoch: [69][50/100]	Time 0.018 (0.018)	Data 0.010 (0.011)	Loss 0.3084 (0.4160)	Prec@1 88.000 (86.667)	Prec@5 99.000 (99.412)
2019-04-10 17:13:15 - INFO - 
 Epoch: 70	Training Loss 0.2377 	Training Prec@1 91.880 	Training Prec@5 99.847 	Validation Loss 0.3788 	Validation Prec@1 87.020 	Validation Prec@5 99.660 	Test Loss 0.4020 	Test Prec@1  86.990 	Test Prec@5  99.530 

2019-04-10 17:13:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:13:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:13:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:13:15 - INFO - TRAINING - Epoch: [70][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.2909 (0.2909)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:13:18 - INFO - TRAINING - Epoch: [70][50/450]	Time 0.055 (0.055)	Data 0.014 (0.015)	Loss 0.2432 (0.2286)	Prec@1 89.000 (92.039)	Prec@5 100.000 (99.863)
2019-04-10 17:13:20 - INFO - TRAINING - Epoch: [70][100/450]	Time 0.053 (0.055)	Data 0.015 (0.015)	Loss 0.1480 (0.2213)	Prec@1 94.000 (92.366)	Prec@5 100.000 (99.901)
2019-04-10 17:13:23 - INFO - TRAINING - Epoch: [70][150/450]	Time 0.054 (0.055)	Data 0.012 (0.015)	Loss 0.2902 (0.2185)	Prec@1 90.000 (92.470)	Prec@5 100.000 (99.914)
2019-04-10 17:13:26 - INFO - TRAINING - Epoch: [70][200/450]	Time 0.064 (0.055)	Data 0.012 (0.014)	Loss 0.2279 (0.2174)	Prec@1 90.000 (92.602)	Prec@5 100.000 (99.915)
2019-04-10 17:13:29 - INFO - TRAINING - Epoch: [70][250/450]	Time 0.047 (0.056)	Data 0.021 (0.014)	Loss 0.1892 (0.2217)	Prec@1 91.000 (92.422)	Prec@5 100.000 (99.904)
2019-04-10 17:13:32 - INFO - TRAINING - Epoch: [70][300/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1638 (0.2241)	Prec@1 94.000 (92.322)	Prec@5 100.000 (99.907)
2019-04-10 17:13:34 - INFO - TRAINING - Epoch: [70][350/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.2185 (0.2277)	Prec@1 92.000 (92.151)	Prec@5 100.000 (99.883)
2019-04-10 17:13:37 - INFO - TRAINING - Epoch: [70][400/450]	Time 0.055 (0.056)	Data 0.013 (0.015)	Loss 0.1828 (0.2288)	Prec@1 94.000 (92.125)	Prec@5 100.000 (99.890)
2019-04-10 17:13:40 - INFO - EVALUATING - Epoch: [70][0/50]	Time 0.044 (0.044)	Data 0.010 (0.010)	Loss 0.2079 (0.2079)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:13:41 - INFO - EVALUATING - Epoch: [70][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.3424 (0.3424)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:13:42 - INFO - EVALUATING - Epoch: [70][50/100]	Time 0.019 (0.019)	Data 0.010 (0.010)	Loss 0.3668 (0.4160)	Prec@1 87.000 (86.922)	Prec@5 98.000 (99.431)
2019-04-10 17:13:43 - INFO - 
 Epoch: 71	Training Loss 0.2297 	Training Prec@1 92.127 	Training Prec@5 99.893 	Validation Loss 0.3887 	Validation Prec@1 87.980 	Validation Prec@5 99.540 	Test Loss 0.4152 	Test Prec@1  86.670 	Test Prec@5  99.480 

2019-04-10 17:13:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:13:43 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:13:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:13:43 - INFO - TRAINING - Epoch: [71][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1841 (0.1841)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:13:46 - INFO - TRAINING - Epoch: [71][50/450]	Time 0.057 (0.056)	Data 0.015 (0.014)	Loss 0.3176 (0.2342)	Prec@1 91.000 (91.922)	Prec@5 100.000 (99.843)
2019-04-10 17:13:48 - INFO - TRAINING - Epoch: [71][100/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.2259 (0.2351)	Prec@1 92.000 (91.921)	Prec@5 100.000 (99.851)
2019-04-10 17:13:51 - INFO - TRAINING - Epoch: [71][150/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.2618 (0.2350)	Prec@1 91.000 (91.987)	Prec@5 100.000 (99.841)
2019-04-10 17:13:54 - INFO - TRAINING - Epoch: [71][200/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.3619 (0.2330)	Prec@1 92.000 (92.070)	Prec@5 98.000 (99.856)
2019-04-10 17:13:57 - INFO - TRAINING - Epoch: [71][250/450]	Time 0.051 (0.055)	Data 0.028 (0.014)	Loss 0.2594 (0.2333)	Prec@1 90.000 (92.048)	Prec@5 99.000 (99.853)
2019-04-10 17:13:59 - INFO - TRAINING - Epoch: [71][300/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.2345 (0.2319)	Prec@1 92.000 (92.113)	Prec@5 100.000 (99.854)
2019-04-10 17:14:02 - INFO - TRAINING - Epoch: [71][350/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.2332 (0.2336)	Prec@1 92.000 (92.068)	Prec@5 100.000 (99.852)
2019-04-10 17:14:05 - INFO - TRAINING - Epoch: [71][400/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1407 (0.2333)	Prec@1 95.000 (92.047)	Prec@5 100.000 (99.860)
2019-04-10 17:14:07 - INFO - EVALUATING - Epoch: [71][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.4152 (0.4152)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:14:08 - INFO - EVALUATING - Epoch: [71][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4592 (0.4592)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:14:09 - INFO - EVALUATING - Epoch: [71][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.2825 (0.4223)	Prec@1 91.000 (86.490)	Prec@5 100.000 (99.431)
2019-04-10 17:14:10 - INFO - 
 Epoch: 72	Training Loss 0.2316 	Training Prec@1 92.096 	Training Prec@5 99.851 	Validation Loss 0.3885 	Validation Prec@1 87.880 	Validation Prec@5 99.620 	Test Loss 0.4126 	Test Prec@1  86.620 	Test Prec@5  99.490 

2019-04-10 17:14:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:14:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:14:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:14:10 - INFO - TRAINING - Epoch: [72][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2981 (0.2981)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:14:13 - INFO - TRAINING - Epoch: [72][50/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.2366 (0.2365)	Prec@1 89.000 (91.922)	Prec@5 100.000 (99.824)
2019-04-10 17:14:16 - INFO - TRAINING - Epoch: [72][100/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.1871 (0.2199)	Prec@1 93.000 (92.416)	Prec@5 100.000 (99.871)
2019-04-10 17:14:18 - INFO - TRAINING - Epoch: [72][150/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.2300 (0.2211)	Prec@1 90.000 (92.417)	Prec@5 100.000 (99.874)
2019-04-10 17:14:21 - INFO - TRAINING - Epoch: [72][200/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1484 (0.2221)	Prec@1 95.000 (92.423)	Prec@5 100.000 (99.881)
2019-04-10 17:14:24 - INFO - TRAINING - Epoch: [72][250/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.2344 (0.2234)	Prec@1 92.000 (92.390)	Prec@5 100.000 (99.865)
2019-04-10 17:14:27 - INFO - TRAINING - Epoch: [72][300/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.2136 (0.2231)	Prec@1 92.000 (92.385)	Prec@5 100.000 (99.870)
2019-04-10 17:14:29 - INFO - TRAINING - Epoch: [72][350/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.1940 (0.2253)	Prec@1 94.000 (92.279)	Prec@5 100.000 (99.869)
2019-04-10 17:14:32 - INFO - TRAINING - Epoch: [72][400/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.2718 (0.2230)	Prec@1 92.000 (92.314)	Prec@5 100.000 (99.875)
2019-04-10 17:14:35 - INFO - EVALUATING - Epoch: [72][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.3961 (0.3961)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:14:36 - INFO - EVALUATING - Epoch: [72][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3503 (0.3503)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:14:36 - INFO - EVALUATING - Epoch: [72][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3231 (0.3879)	Prec@1 91.000 (87.569)	Prec@5 98.000 (99.373)
2019-04-10 17:14:37 - INFO - 
 Epoch: 73	Training Loss 0.2228 	Training Prec@1 92.358 	Training Prec@5 99.862 	Validation Loss 0.3950 	Validation Prec@1 87.820 	Validation Prec@5 99.620 	Test Loss 0.3880 	Test Prec@1  87.780 	Test Prec@5  99.450 

2019-04-10 17:14:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:14:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:14:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:14:37 - INFO - TRAINING - Epoch: [73][0/450]	Time 0.033 (0.033)	Data 0.013 (0.013)	Loss 0.1524 (0.1524)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:14:40 - INFO - TRAINING - Epoch: [73][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.1994 (0.2153)	Prec@1 93.000 (92.608)	Prec@5 100.000 (99.902)
2019-04-10 17:14:43 - INFO - TRAINING - Epoch: [73][100/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1406 (0.2175)	Prec@1 95.000 (92.554)	Prec@5 100.000 (99.901)
2019-04-10 17:14:46 - INFO - TRAINING - Epoch: [73][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1846 (0.2163)	Prec@1 94.000 (92.616)	Prec@5 100.000 (99.868)
2019-04-10 17:14:48 - INFO - TRAINING - Epoch: [73][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2010 (0.2136)	Prec@1 92.000 (92.706)	Prec@5 100.000 (99.876)
2019-04-10 17:14:51 - INFO - TRAINING - Epoch: [73][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2275 (0.2122)	Prec@1 91.000 (92.733)	Prec@5 100.000 (99.884)
2019-04-10 17:14:54 - INFO - TRAINING - Epoch: [73][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2461 (0.2126)	Prec@1 93.000 (92.711)	Prec@5 100.000 (99.890)
2019-04-10 17:14:56 - INFO - TRAINING - Epoch: [73][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1692 (0.2120)	Prec@1 95.000 (92.749)	Prec@5 100.000 (99.895)
2019-04-10 17:14:59 - INFO - TRAINING - Epoch: [73][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.2935 (0.2159)	Prec@1 91.000 (92.579)	Prec@5 99.000 (99.893)
2019-04-10 17:15:02 - INFO - EVALUATING - Epoch: [73][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4678 (0.4678)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:15:03 - INFO - EVALUATING - Epoch: [73][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2816 (0.2816)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:15:04 - INFO - EVALUATING - Epoch: [73][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3176 (0.3843)	Prec@1 89.000 (87.725)	Prec@5 99.000 (99.392)
2019-04-10 17:15:04 - INFO - 
 Epoch: 74	Training Loss 0.2171 	Training Prec@1 92.549 	Training Prec@5 99.893 	Validation Loss 0.3652 	Validation Prec@1 88.120 	Validation Prec@5 99.540 	Test Loss 0.3760 	Test Prec@1  87.590 	Test Prec@5  99.550 

2019-04-10 17:15:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:15:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:15:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:15:05 - INFO - TRAINING - Epoch: [74][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1831 (0.1831)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:15:07 - INFO - TRAINING - Epoch: [74][50/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2342 (0.2110)	Prec@1 91.000 (92.804)	Prec@5 100.000 (99.922)
2019-04-10 17:15:10 - INFO - TRAINING - Epoch: [74][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2298 (0.2059)	Prec@1 92.000 (93.059)	Prec@5 100.000 (99.881)
2019-04-10 17:15:13 - INFO - TRAINING - Epoch: [74][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1594 (0.2055)	Prec@1 95.000 (92.960)	Prec@5 100.000 (99.887)
2019-04-10 17:15:15 - INFO - TRAINING - Epoch: [74][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2653 (0.2067)	Prec@1 90.000 (92.881)	Prec@5 100.000 (99.886)
2019-04-10 17:15:18 - INFO - TRAINING - Epoch: [74][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1658 (0.2076)	Prec@1 92.000 (92.801)	Prec@5 100.000 (99.888)
2019-04-10 17:15:21 - INFO - TRAINING - Epoch: [74][300/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.2442 (0.2079)	Prec@1 91.000 (92.797)	Prec@5 100.000 (99.894)
2019-04-10 17:15:24 - INFO - TRAINING - Epoch: [74][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1600 (0.2099)	Prec@1 94.000 (92.792)	Prec@5 100.000 (99.883)
2019-04-10 17:15:26 - INFO - TRAINING - Epoch: [74][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1860 (0.2098)	Prec@1 94.000 (92.758)	Prec@5 100.000 (99.885)
2019-04-10 17:15:29 - INFO - EVALUATING - Epoch: [74][0/50]	Time 0.043 (0.043)	Data 0.010 (0.010)	Loss 0.3364 (0.3364)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:15:30 - INFO - EVALUATING - Epoch: [74][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3892 (0.3892)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:15:31 - INFO - EVALUATING - Epoch: [74][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2915 (0.3926)	Prec@1 92.000 (87.569)	Prec@5 100.000 (99.510)
2019-04-10 17:15:32 - INFO - 
 Epoch: 75	Training Loss 0.2102 	Training Prec@1 92.744 	Training Prec@5 99.889 	Validation Loss 0.3590 	Validation Prec@1 88.640 	Validation Prec@5 99.620 	Test Loss 0.3757 	Test Prec@1  87.870 	Test Prec@5  99.590 

2019-04-10 17:15:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:15:32 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:15:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:15:32 - INFO - TRAINING - Epoch: [75][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1697 (0.1697)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:15:35 - INFO - TRAINING - Epoch: [75][50/450]	Time 0.056 (0.054)	Data 0.012 (0.014)	Loss 0.1622 (0.2161)	Prec@1 96.000 (92.667)	Prec@5 100.000 (99.882)
2019-04-10 17:15:37 - INFO - TRAINING - Epoch: [75][100/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1174 (0.2104)	Prec@1 95.000 (93.059)	Prec@5 100.000 (99.851)
2019-04-10 17:15:40 - INFO - TRAINING - Epoch: [75][150/450]	Time 0.046 (0.054)	Data 0.021 (0.014)	Loss 0.1951 (0.1993)	Prec@1 95.000 (93.305)	Prec@5 100.000 (99.881)
2019-04-10 17:15:43 - INFO - TRAINING - Epoch: [75][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1815 (0.2002)	Prec@1 96.000 (93.279)	Prec@5 100.000 (99.900)
2019-04-10 17:15:46 - INFO - TRAINING - Epoch: [75][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1848 (0.1988)	Prec@1 95.000 (93.283)	Prec@5 100.000 (99.912)
2019-04-10 17:15:48 - INFO - TRAINING - Epoch: [75][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1672 (0.1989)	Prec@1 94.000 (93.239)	Prec@5 100.000 (99.917)
2019-04-10 17:15:51 - INFO - TRAINING - Epoch: [75][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2720 (0.1989)	Prec@1 93.000 (93.242)	Prec@5 99.000 (99.915)
2019-04-10 17:15:54 - INFO - TRAINING - Epoch: [75][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2139 (0.1993)	Prec@1 91.000 (93.217)	Prec@5 100.000 (99.915)
2019-04-10 17:15:56 - INFO - EVALUATING - Epoch: [75][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4263 (0.4263)	Prec@1 88.000 (88.000)	Prec@5 98.000 (98.000)
2019-04-10 17:15:57 - INFO - EVALUATING - Epoch: [75][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3784 (0.3784)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:15:58 - INFO - EVALUATING - Epoch: [75][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2711 (0.3904)	Prec@1 92.000 (87.471)	Prec@5 100.000 (99.451)
2019-04-10 17:15:59 - INFO - 
 Epoch: 76	Training Loss 0.2026 	Training Prec@1 93.111 	Training Prec@5 99.909 	Validation Loss 0.3779 	Validation Prec@1 88.360 	Validation Prec@5 99.480 	Test Loss 0.3881 	Test Prec@1  87.510 	Test Prec@5  99.600 

2019-04-10 17:15:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:15:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:15:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:15:59 - INFO - TRAINING - Epoch: [76][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2843 (0.2843)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:16:02 - INFO - TRAINING - Epoch: [76][50/450]	Time 0.056 (0.054)	Data 0.013 (0.014)	Loss 0.1638 (0.1822)	Prec@1 95.000 (93.804)	Prec@5 100.000 (99.922)
2019-04-10 17:16:05 - INFO - TRAINING - Epoch: [76][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1312 (0.1825)	Prec@1 95.000 (93.881)	Prec@5 100.000 (99.921)
2019-04-10 17:16:07 - INFO - TRAINING - Epoch: [76][150/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.1571 (0.1903)	Prec@1 94.000 (93.563)	Prec@5 100.000 (99.921)
2019-04-10 17:16:10 - INFO - TRAINING - Epoch: [76][200/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.1778 (0.1940)	Prec@1 93.000 (93.378)	Prec@5 100.000 (99.930)
2019-04-10 17:16:13 - INFO - TRAINING - Epoch: [76][250/450]	Time 0.057 (0.055)	Data 0.012 (0.014)	Loss 0.2216 (0.1962)	Prec@1 94.000 (93.331)	Prec@5 100.000 (99.920)
2019-04-10 17:16:16 - INFO - TRAINING - Epoch: [76][300/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.2160 (0.1972)	Prec@1 91.000 (93.309)	Prec@5 100.000 (99.914)
2019-04-10 17:16:19 - INFO - TRAINING - Epoch: [76][350/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1595 (0.1979)	Prec@1 96.000 (93.316)	Prec@5 100.000 (99.912)
2019-04-10 17:16:21 - INFO - TRAINING - Epoch: [76][400/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.2340 (0.1993)	Prec@1 94.000 (93.247)	Prec@5 100.000 (99.910)
2019-04-10 17:16:24 - INFO - EVALUATING - Epoch: [76][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.4170 (0.4170)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:16:25 - INFO - EVALUATING - Epoch: [76][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2817 (0.2817)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:16:26 - INFO - EVALUATING - Epoch: [76][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1490 (0.3704)	Prec@1 94.000 (88.157)	Prec@5 100.000 (99.510)
2019-04-10 17:16:27 - INFO - 
 Epoch: 77	Training Loss 0.1994 	Training Prec@1 93.222 	Training Prec@5 99.911 	Validation Loss 0.3594 	Validation Prec@1 88.640 	Validation Prec@5 99.660 	Test Loss 0.3653 	Test Prec@1  88.320 	Test Prec@5  99.590 

2019-04-10 17:16:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:16:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:16:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:16:27 - INFO - TRAINING - Epoch: [77][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1903 (0.1903)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:16:30 - INFO - TRAINING - Epoch: [77][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1282 (0.1903)	Prec@1 97.000 (93.549)	Prec@5 100.000 (99.922)
2019-04-10 17:16:32 - INFO - TRAINING - Epoch: [77][100/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1425 (0.1932)	Prec@1 97.000 (93.446)	Prec@5 100.000 (99.941)
2019-04-10 17:16:35 - INFO - TRAINING - Epoch: [77][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1187 (0.1883)	Prec@1 96.000 (93.576)	Prec@5 100.000 (99.927)
2019-04-10 17:16:38 - INFO - TRAINING - Epoch: [77][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1784 (0.1914)	Prec@1 94.000 (93.418)	Prec@5 100.000 (99.925)
2019-04-10 17:16:41 - INFO - TRAINING - Epoch: [77][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2263 (0.1908)	Prec@1 92.000 (93.307)	Prec@5 100.000 (99.936)
2019-04-10 17:16:43 - INFO - TRAINING - Epoch: [77][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1682 (0.1898)	Prec@1 95.000 (93.326)	Prec@5 100.000 (99.924)
2019-04-10 17:16:46 - INFO - TRAINING - Epoch: [77][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1914 (0.1913)	Prec@1 94.000 (93.308)	Prec@5 100.000 (99.932)
2019-04-10 17:16:49 - INFO - TRAINING - Epoch: [77][400/450]	Time 0.049 (0.054)	Data 0.020 (0.014)	Loss 0.2123 (0.1910)	Prec@1 92.000 (93.352)	Prec@5 100.000 (99.925)
2019-04-10 17:16:51 - INFO - EVALUATING - Epoch: [77][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4454 (0.4454)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:16:52 - INFO - EVALUATING - Epoch: [77][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3521 (0.3521)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:16:53 - INFO - EVALUATING - Epoch: [77][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2981 (0.3870)	Prec@1 91.000 (87.333)	Prec@5 99.000 (99.451)
2019-04-10 17:16:54 - INFO - 
 Epoch: 78	Training Loss 0.1921 	Training Prec@1 93.324 	Training Prec@5 99.931 	Validation Loss 0.3613 	Validation Prec@1 88.160 	Validation Prec@5 99.620 	Test Loss 0.3841 	Test Prec@1  87.290 	Test Prec@5  99.530 

2019-04-10 17:16:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:16:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:16:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:16:54 - INFO - TRAINING - Epoch: [78][0/450]	Time 0.033 (0.033)	Data 0.015 (0.015)	Loss 0.1824 (0.1824)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:16:57 - INFO - TRAINING - Epoch: [78][50/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.3664 (0.1849)	Prec@1 88.000 (93.941)	Prec@5 100.000 (99.902)
2019-04-10 17:17:00 - INFO - TRAINING - Epoch: [78][100/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1374 (0.1823)	Prec@1 94.000 (93.891)	Prec@5 100.000 (99.931)
2019-04-10 17:17:03 - INFO - TRAINING - Epoch: [78][150/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.2546 (0.1848)	Prec@1 89.000 (93.689)	Prec@5 100.000 (99.934)
2019-04-10 17:17:05 - INFO - TRAINING - Epoch: [78][200/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.2431 (0.1843)	Prec@1 92.000 (93.756)	Prec@5 100.000 (99.940)
2019-04-10 17:17:08 - INFO - TRAINING - Epoch: [78][250/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1581 (0.1835)	Prec@1 94.000 (93.793)	Prec@5 100.000 (99.940)
2019-04-10 17:17:11 - INFO - TRAINING - Epoch: [78][300/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.2905 (0.1847)	Prec@1 91.000 (93.797)	Prec@5 100.000 (99.927)
2019-04-10 17:17:14 - INFO - TRAINING - Epoch: [78][350/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.2793 (0.1865)	Prec@1 89.000 (93.744)	Prec@5 100.000 (99.929)
2019-04-10 17:17:17 - INFO - TRAINING - Epoch: [78][400/450]	Time 0.058 (0.057)	Data 0.013 (0.014)	Loss 0.2908 (0.1873)	Prec@1 88.000 (93.708)	Prec@5 100.000 (99.928)
2019-04-10 17:17:20 - INFO - EVALUATING - Epoch: [78][0/50]	Time 0.045 (0.045)	Data 0.011 (0.011)	Loss 0.5083 (0.5083)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 17:17:21 - INFO - EVALUATING - Epoch: [78][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.2944 (0.2944)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:17:21 - INFO - EVALUATING - Epoch: [78][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3715 (0.4032)	Prec@1 88.000 (87.176)	Prec@5 100.000 (99.412)
2019-04-10 17:17:22 - INFO - 
 Epoch: 79	Training Loss 0.1878 	Training Prec@1 93.651 	Training Prec@5 99.929 	Validation Loss 0.3966 	Validation Prec@1 87.880 	Validation Prec@5 99.440 	Test Loss 0.3902 	Test Prec@1  87.390 	Test Prec@5  99.440 

2019-04-10 17:17:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:17:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:17:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:17:23 - INFO - TRAINING - Epoch: [79][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1907 (0.1907)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:17:25 - INFO - TRAINING - Epoch: [79][50/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.1391 (0.1814)	Prec@1 96.000 (93.863)	Prec@5 100.000 (99.941)
2019-04-10 17:17:28 - INFO - TRAINING - Epoch: [79][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0902 (0.1801)	Prec@1 97.000 (93.822)	Prec@5 100.000 (99.950)
2019-04-10 17:17:31 - INFO - TRAINING - Epoch: [79][150/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.1629 (0.1866)	Prec@1 94.000 (93.596)	Prec@5 100.000 (99.940)
2019-04-10 17:17:33 - INFO - TRAINING - Epoch: [79][200/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.3265 (0.1876)	Prec@1 93.000 (93.547)	Prec@5 100.000 (99.930)
2019-04-10 17:17:36 - INFO - TRAINING - Epoch: [79][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1498 (0.1827)	Prec@1 94.000 (93.657)	Prec@5 100.000 (99.936)
2019-04-10 17:17:39 - INFO - TRAINING - Epoch: [79][300/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1972 (0.1809)	Prec@1 93.000 (93.757)	Prec@5 100.000 (99.944)
2019-04-10 17:17:41 - INFO - TRAINING - Epoch: [79][350/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.2615 (0.1798)	Prec@1 91.000 (93.766)	Prec@5 100.000 (99.946)
2019-04-10 17:17:44 - INFO - TRAINING - Epoch: [79][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1838 (0.1810)	Prec@1 94.000 (93.708)	Prec@5 100.000 (99.943)
2019-04-10 17:17:47 - INFO - EVALUATING - Epoch: [79][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3107 (0.3107)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:17:48 - INFO - EVALUATING - Epoch: [79][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3823 (0.3823)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:17:48 - INFO - EVALUATING - Epoch: [79][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2451 (0.3940)	Prec@1 92.000 (87.392)	Prec@5 100.000 (99.490)
2019-04-10 17:17:49 - INFO - 
 Epoch: 80	Training Loss 0.1813 	Training Prec@1 93.698 	Training Prec@5 99.938 	Validation Loss 0.3905 	Validation Prec@1 88.040 	Validation Prec@5 99.580 	Test Loss 0.3908 	Test Prec@1  87.440 	Test Prec@5  99.560 

2019-04-10 17:17:49 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:17:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:17:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:17:49 - INFO - TRAINING - Epoch: [80][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1800 (0.1800)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:17:52 - INFO - TRAINING - Epoch: [80][50/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.2507 (0.1745)	Prec@1 92.000 (93.784)	Prec@5 100.000 (99.961)
2019-04-10 17:17:55 - INFO - TRAINING - Epoch: [80][100/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1038 (0.1706)	Prec@1 97.000 (93.941)	Prec@5 100.000 (99.960)
2019-04-10 17:17:58 - INFO - TRAINING - Epoch: [80][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0767 (0.1738)	Prec@1 98.000 (93.934)	Prec@5 100.000 (99.960)
2019-04-10 17:18:00 - INFO - TRAINING - Epoch: [80][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2283 (0.1754)	Prec@1 93.000 (93.910)	Prec@5 100.000 (99.955)
2019-04-10 17:18:03 - INFO - TRAINING - Epoch: [80][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1100 (0.1743)	Prec@1 96.000 (93.908)	Prec@5 100.000 (99.956)
2019-04-10 17:18:06 - INFO - TRAINING - Epoch: [80][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2219 (0.1756)	Prec@1 93.000 (93.874)	Prec@5 100.000 (99.947)
2019-04-10 17:18:08 - INFO - TRAINING - Epoch: [80][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.2909 (0.1792)	Prec@1 85.000 (93.692)	Prec@5 100.000 (99.940)
2019-04-10 17:18:11 - INFO - TRAINING - Epoch: [80][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0827 (0.1816)	Prec@1 98.000 (93.608)	Prec@5 100.000 (99.943)
2019-04-10 17:18:14 - INFO - EVALUATING - Epoch: [80][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.3584 (0.3584)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:18:15 - INFO - EVALUATING - Epoch: [80][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2921 (0.2921)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:18:16 - INFO - EVALUATING - Epoch: [80][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1633 (0.3804)	Prec@1 94.000 (87.843)	Prec@5 100.000 (99.549)
2019-04-10 17:18:16 - INFO - 
 Epoch: 81	Training Loss 0.1818 	Training Prec@1 93.616 	Training Prec@5 99.936 	Validation Loss 0.3721 	Validation Prec@1 88.260 	Validation Prec@5 99.580 	Test Loss 0.3660 	Test Prec@1  88.030 	Test Prec@5  99.590 

2019-04-10 17:18:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:18:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:18:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:18:17 - INFO - TRAINING - Epoch: [81][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.2702 (0.2702)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:18:19 - INFO - TRAINING - Epoch: [81][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.2593 (0.1722)	Prec@1 90.000 (94.255)	Prec@5 99.000 (99.922)
2019-04-10 17:18:22 - INFO - TRAINING - Epoch: [81][100/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.3011 (0.1758)	Prec@1 89.000 (94.089)	Prec@5 100.000 (99.911)
2019-04-10 17:18:25 - INFO - TRAINING - Epoch: [81][150/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.1674 (0.1735)	Prec@1 95.000 (94.159)	Prec@5 100.000 (99.934)
2019-04-10 17:18:28 - INFO - TRAINING - Epoch: [81][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0771 (0.1711)	Prec@1 97.000 (94.244)	Prec@5 100.000 (99.930)
2019-04-10 17:18:31 - INFO - TRAINING - Epoch: [81][250/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.1573 (0.1726)	Prec@1 94.000 (94.187)	Prec@5 100.000 (99.928)
2019-04-10 17:18:34 - INFO - TRAINING - Epoch: [81][300/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.1291 (0.1699)	Prec@1 95.000 (94.213)	Prec@5 100.000 (99.940)
2019-04-10 17:18:37 - INFO - TRAINING - Epoch: [81][350/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.1853 (0.1719)	Prec@1 92.000 (94.140)	Prec@5 99.000 (99.943)
2019-04-10 17:18:39 - INFO - TRAINING - Epoch: [81][400/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.1438 (0.1719)	Prec@1 96.000 (94.132)	Prec@5 100.000 (99.945)
2019-04-10 17:18:42 - INFO - EVALUATING - Epoch: [81][0/50]	Time 0.040 (0.040)	Data 0.012 (0.012)	Loss 0.4076 (0.4076)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:18:43 - INFO - EVALUATING - Epoch: [81][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3473 (0.3473)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:18:44 - INFO - EVALUATING - Epoch: [81][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.2327 (0.3944)	Prec@1 91.000 (87.627)	Prec@5 100.000 (99.373)
2019-04-10 17:18:44 - INFO - 
 Epoch: 82	Training Loss 0.1721 	Training Prec@1 94.091 	Training Prec@5 99.944 	Validation Loss 0.3914 	Validation Prec@1 87.520 	Validation Prec@5 99.500 	Test Loss 0.3800 	Test Prec@1  88.150 	Test Prec@5  99.440 

2019-04-10 17:18:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:18:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:18:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:18:45 - INFO - TRAINING - Epoch: [82][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1003 (0.1003)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:18:47 - INFO - TRAINING - Epoch: [82][50/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1389 (0.1713)	Prec@1 95.000 (94.020)	Prec@5 100.000 (99.980)
2019-04-10 17:18:50 - INFO - TRAINING - Epoch: [82][100/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1343 (0.1649)	Prec@1 95.000 (94.277)	Prec@5 100.000 (99.950)
2019-04-10 17:18:53 - INFO - TRAINING - Epoch: [82][150/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2545 (0.1615)	Prec@1 90.000 (94.397)	Prec@5 99.000 (99.947)
2019-04-10 17:18:55 - INFO - TRAINING - Epoch: [82][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2133 (0.1631)	Prec@1 93.000 (94.279)	Prec@5 100.000 (99.945)
2019-04-10 17:18:58 - INFO - TRAINING - Epoch: [82][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2011 (0.1634)	Prec@1 93.000 (94.299)	Prec@5 100.000 (99.952)
2019-04-10 17:19:01 - INFO - TRAINING - Epoch: [82][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1504 (0.1645)	Prec@1 92.000 (94.246)	Prec@5 100.000 (99.934)
2019-04-10 17:19:04 - INFO - TRAINING - Epoch: [82][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1924 (0.1655)	Prec@1 94.000 (94.174)	Prec@5 100.000 (99.937)
2019-04-10 17:19:06 - INFO - TRAINING - Epoch: [82][400/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1693 (0.1677)	Prec@1 95.000 (94.157)	Prec@5 100.000 (99.935)
2019-04-10 17:19:09 - INFO - EVALUATING - Epoch: [82][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.3152 (0.3152)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:19:10 - INFO - EVALUATING - Epoch: [82][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3609 (0.3609)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:19:11 - INFO - EVALUATING - Epoch: [82][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2406 (0.3889)	Prec@1 94.000 (87.980)	Prec@5 99.000 (99.529)
2019-04-10 17:19:12 - INFO - 
 Epoch: 83	Training Loss 0.1680 	Training Prec@1 94.140 	Training Prec@5 99.936 	Validation Loss 0.3743 	Validation Prec@1 88.340 	Validation Prec@5 99.480 	Test Loss 0.3846 	Test Prec@1  88.330 	Test Prec@5  99.480 

2019-04-10 17:19:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:19:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:19:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:19:12 - INFO - TRAINING - Epoch: [83][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0782 (0.0782)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:19:15 - INFO - TRAINING - Epoch: [83][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.1635 (0.1544)	Prec@1 94.000 (94.725)	Prec@5 100.000 (99.980)
2019-04-10 17:19:17 - INFO - TRAINING - Epoch: [83][100/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.2663 (0.1565)	Prec@1 91.000 (94.386)	Prec@5 100.000 (99.950)
2019-04-10 17:19:20 - INFO - TRAINING - Epoch: [83][150/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1875 (0.1629)	Prec@1 95.000 (94.311)	Prec@5 100.000 (99.947)
2019-04-10 17:19:23 - INFO - TRAINING - Epoch: [83][200/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1865 (0.1622)	Prec@1 95.000 (94.279)	Prec@5 100.000 (99.945)
2019-04-10 17:19:26 - INFO - TRAINING - Epoch: [83][250/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0923 (0.1654)	Prec@1 98.000 (94.191)	Prec@5 100.000 (99.944)
2019-04-10 17:19:28 - INFO - TRAINING - Epoch: [83][300/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1585 (0.1652)	Prec@1 94.000 (94.203)	Prec@5 100.000 (99.937)
2019-04-10 17:19:31 - INFO - TRAINING - Epoch: [83][350/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.2513 (0.1663)	Prec@1 89.000 (94.191)	Prec@5 100.000 (99.937)
2019-04-10 17:19:34 - INFO - TRAINING - Epoch: [83][400/450]	Time 0.059 (0.055)	Data 0.013 (0.014)	Loss 0.1712 (0.1675)	Prec@1 93.000 (94.167)	Prec@5 100.000 (99.943)
2019-04-10 17:19:36 - INFO - EVALUATING - Epoch: [83][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.2507 (0.2507)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:19:37 - INFO - EVALUATING - Epoch: [83][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4300 (0.4300)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:19:38 - INFO - EVALUATING - Epoch: [83][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2412 (0.3937)	Prec@1 94.000 (87.941)	Prec@5 99.000 (99.451)
2019-04-10 17:19:39 - INFO - 
 Epoch: 84	Training Loss 0.1680 	Training Prec@1 94.156 	Training Prec@5 99.936 	Validation Loss 0.3839 	Validation Prec@1 88.280 	Validation Prec@5 99.540 	Test Loss 0.3917 	Test Prec@1  88.220 	Test Prec@5  99.530 

2019-04-10 17:19:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:19:39 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:19:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:19:39 - INFO - TRAINING - Epoch: [84][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0954 (0.0954)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:19:42 - INFO - TRAINING - Epoch: [84][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1658 (0.1580)	Prec@1 95.000 (94.569)	Prec@5 100.000 (99.941)
2019-04-10 17:19:45 - INFO - TRAINING - Epoch: [84][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1972 (0.1559)	Prec@1 93.000 (94.762)	Prec@5 100.000 (99.950)
2019-04-10 17:19:47 - INFO - TRAINING - Epoch: [84][150/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.1054 (0.1550)	Prec@1 96.000 (94.682)	Prec@5 100.000 (99.960)
2019-04-10 17:19:50 - INFO - TRAINING - Epoch: [84][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2395 (0.1584)	Prec@1 93.000 (94.522)	Prec@5 100.000 (99.955)
2019-04-10 17:19:53 - INFO - TRAINING - Epoch: [84][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0941 (0.1576)	Prec@1 98.000 (94.534)	Prec@5 100.000 (99.956)
2019-04-10 17:19:56 - INFO - TRAINING - Epoch: [84][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0961 (0.1573)	Prec@1 97.000 (94.568)	Prec@5 100.000 (99.944)
2019-04-10 17:19:58 - INFO - TRAINING - Epoch: [84][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1573 (0.1585)	Prec@1 93.000 (94.507)	Prec@5 100.000 (99.937)
2019-04-10 17:20:01 - INFO - TRAINING - Epoch: [84][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1531 (0.1617)	Prec@1 95.000 (94.414)	Prec@5 100.000 (99.930)
2019-04-10 17:20:04 - INFO - EVALUATING - Epoch: [84][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3434 (0.3434)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:20:05 - INFO - EVALUATING - Epoch: [84][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.4490 (0.4490)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-04-10 17:20:05 - INFO - EVALUATING - Epoch: [84][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2247 (0.3592)	Prec@1 91.000 (88.882)	Prec@5 100.000 (99.412)
2019-04-10 17:20:06 - INFO - 
 Epoch: 85	Training Loss 0.1607 	Training Prec@1 94.460 	Training Prec@5 99.931 	Validation Loss 0.3636 	Validation Prec@1 88.780 	Validation Prec@5 99.640 	Test Loss 0.3560 	Test Prec@1  88.960 	Test Prec@5  99.550 

2019-04-10 17:20:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:20:06 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:20:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:20:07 - INFO - TRAINING - Epoch: [85][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1771 (0.1771)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:20:09 - INFO - TRAINING - Epoch: [85][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2469 (0.1519)	Prec@1 93.000 (94.784)	Prec@5 100.000 (99.980)
2019-04-10 17:20:12 - INFO - TRAINING - Epoch: [85][100/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1507 (0.1450)	Prec@1 96.000 (94.941)	Prec@5 100.000 (99.970)
2019-04-10 17:20:15 - INFO - TRAINING - Epoch: [85][150/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0898 (0.1507)	Prec@1 97.000 (94.762)	Prec@5 100.000 (99.960)
2019-04-10 17:20:17 - INFO - TRAINING - Epoch: [85][200/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.2590 (0.1512)	Prec@1 95.000 (94.826)	Prec@5 99.000 (99.950)
2019-04-10 17:20:20 - INFO - TRAINING - Epoch: [85][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1257 (0.1505)	Prec@1 98.000 (94.837)	Prec@5 100.000 (99.956)
2019-04-10 17:20:23 - INFO - TRAINING - Epoch: [85][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.2106 (0.1556)	Prec@1 91.000 (94.724)	Prec@5 100.000 (99.953)
2019-04-10 17:20:26 - INFO - TRAINING - Epoch: [85][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2877 (0.1577)	Prec@1 90.000 (94.607)	Prec@5 100.000 (99.957)
2019-04-10 17:20:28 - INFO - TRAINING - Epoch: [85][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1241 (0.1579)	Prec@1 97.000 (94.606)	Prec@5 100.000 (99.958)
2019-04-10 17:20:31 - INFO - EVALUATING - Epoch: [85][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3132 (0.3132)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:20:32 - INFO - EVALUATING - Epoch: [85][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3442 (0.3442)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:20:33 - INFO - EVALUATING - Epoch: [85][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2193 (0.3740)	Prec@1 91.000 (88.059)	Prec@5 100.000 (99.471)
2019-04-10 17:20:34 - INFO - 
 Epoch: 86	Training Loss 0.1595 	Training Prec@1 94.511 	Training Prec@5 99.956 	Validation Loss 0.3517 	Validation Prec@1 89.000 	Validation Prec@5 99.660 	Test Loss 0.3647 	Test Prec@1  88.530 	Test Prec@5  99.490 

2019-04-10 17:20:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:20:34 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:20:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:20:34 - INFO - TRAINING - Epoch: [86][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1671 (0.1671)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:20:37 - INFO - TRAINING - Epoch: [86][50/450]	Time 0.049 (0.055)	Data 0.021 (0.014)	Loss 0.1957 (0.1433)	Prec@1 95.000 (95.294)	Prec@5 100.000 (100.000)
2019-04-10 17:20:39 - INFO - TRAINING - Epoch: [86][100/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0915 (0.1504)	Prec@1 98.000 (94.980)	Prec@5 100.000 (100.000)
2019-04-10 17:20:42 - INFO - TRAINING - Epoch: [86][150/450]	Time 0.060 (0.055)	Data 0.012 (0.014)	Loss 0.1485 (0.1529)	Prec@1 93.000 (94.921)	Prec@5 100.000 (99.987)
2019-04-10 17:20:45 - INFO - TRAINING - Epoch: [86][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1239 (0.1500)	Prec@1 97.000 (94.975)	Prec@5 100.000 (99.980)
2019-04-10 17:20:47 - INFO - TRAINING - Epoch: [86][250/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.1065 (0.1513)	Prec@1 98.000 (94.892)	Prec@5 100.000 (99.980)
2019-04-10 17:20:50 - INFO - TRAINING - Epoch: [86][300/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.1669 (0.1506)	Prec@1 96.000 (94.877)	Prec@5 100.000 (99.977)
2019-04-10 17:20:53 - INFO - TRAINING - Epoch: [86][350/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.1234 (0.1505)	Prec@1 98.000 (94.877)	Prec@5 100.000 (99.974)
2019-04-10 17:20:56 - INFO - TRAINING - Epoch: [86][400/450]	Time 0.056 (0.055)	Data 0.013 (0.014)	Loss 0.2063 (0.1527)	Prec@1 92.000 (94.815)	Prec@5 100.000 (99.978)
2019-04-10 17:20:59 - INFO - EVALUATING - Epoch: [86][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.3812 (0.3812)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:00 - INFO - EVALUATING - Epoch: [86][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2531 (0.2531)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:00 - INFO - EVALUATING - Epoch: [86][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.3823 (0.3783)	Prec@1 89.000 (88.353)	Prec@5 100.000 (99.471)
2019-04-10 17:21:01 - INFO - 
 Epoch: 87	Training Loss 0.1522 	Training Prec@1 94.804 	Training Prec@5 99.978 	Validation Loss 0.3546 	Validation Prec@1 88.780 	Validation Prec@5 99.640 	Test Loss 0.3729 	Test Prec@1  88.410 	Test Prec@5  99.520 

2019-04-10 17:21:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:21:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:21:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:21:02 - INFO - TRAINING - Epoch: [87][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.2700 (0.2700)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:04 - INFO - TRAINING - Epoch: [87][50/450]	Time 0.056 (0.055)	Data 0.012 (0.014)	Loss 0.1334 (0.1501)	Prec@1 96.000 (95.059)	Prec@5 100.000 (99.961)
2019-04-10 17:21:07 - INFO - TRAINING - Epoch: [87][100/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0540 (0.1515)	Prec@1 99.000 (94.931)	Prec@5 100.000 (99.960)
2019-04-10 17:21:10 - INFO - TRAINING - Epoch: [87][150/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.1620 (0.1540)	Prec@1 94.000 (94.801)	Prec@5 100.000 (99.974)
2019-04-10 17:21:13 - INFO - TRAINING - Epoch: [87][200/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.1355 (0.1517)	Prec@1 97.000 (94.866)	Prec@5 100.000 (99.970)
2019-04-10 17:21:15 - INFO - TRAINING - Epoch: [87][250/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.1517 (0.1530)	Prec@1 95.000 (94.825)	Prec@5 100.000 (99.964)
2019-04-10 17:21:18 - INFO - TRAINING - Epoch: [87][300/450]	Time 0.060 (0.055)	Data 0.012 (0.014)	Loss 0.1258 (0.1527)	Prec@1 98.000 (94.857)	Prec@5 100.000 (99.963)
2019-04-10 17:21:21 - INFO - TRAINING - Epoch: [87][350/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1773 (0.1529)	Prec@1 94.000 (94.815)	Prec@5 100.000 (99.969)
2019-04-10 17:21:23 - INFO - TRAINING - Epoch: [87][400/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.1341 (0.1532)	Prec@1 96.000 (94.805)	Prec@5 100.000 (99.965)
2019-04-10 17:21:26 - INFO - EVALUATING - Epoch: [87][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.3709 (0.3709)	Prec@1 88.000 (88.000)	Prec@5 98.000 (98.000)
2019-04-10 17:21:27 - INFO - EVALUATING - Epoch: [87][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3632 (0.3632)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:21:28 - INFO - EVALUATING - Epoch: [87][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2914 (0.3986)	Prec@1 89.000 (87.922)	Prec@5 100.000 (99.529)
2019-04-10 17:21:29 - INFO - 
 Epoch: 88	Training Loss 0.1524 	Training Prec@1 94.813 	Training Prec@5 99.964 	Validation Loss 0.3784 	Validation Prec@1 88.160 	Validation Prec@5 99.540 	Test Loss 0.3817 	Test Prec@1  88.140 	Test Prec@5  99.650 

2019-04-10 17:21:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:21:29 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:21:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:21:29 - INFO - TRAINING - Epoch: [88][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1089 (0.1089)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:32 - INFO - TRAINING - Epoch: [88][50/450]	Time 0.055 (0.053)	Data 0.012 (0.014)	Loss 0.1212 (0.1334)	Prec@1 96.000 (95.353)	Prec@5 100.000 (100.000)
2019-04-10 17:21:34 - INFO - TRAINING - Epoch: [88][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1084 (0.1366)	Prec@1 97.000 (95.376)	Prec@5 100.000 (99.980)
2019-04-10 17:21:37 - INFO - TRAINING - Epoch: [88][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1538 (0.1351)	Prec@1 93.000 (95.391)	Prec@5 100.000 (99.980)
2019-04-10 17:21:40 - INFO - TRAINING - Epoch: [88][200/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.2119 (0.1407)	Prec@1 90.000 (95.164)	Prec@5 100.000 (99.965)
2019-04-10 17:21:43 - INFO - TRAINING - Epoch: [88][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1714 (0.1404)	Prec@1 96.000 (95.167)	Prec@5 100.000 (99.964)
2019-04-10 17:21:45 - INFO - TRAINING - Epoch: [88][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1846 (0.1432)	Prec@1 92.000 (95.076)	Prec@5 100.000 (99.970)
2019-04-10 17:21:48 - INFO - TRAINING - Epoch: [88][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1438 (0.1448)	Prec@1 96.000 (95.003)	Prec@5 100.000 (99.963)
2019-04-10 17:21:51 - INFO - TRAINING - Epoch: [88][400/450]	Time 0.055 (0.054)	Data 0.015 (0.014)	Loss 0.1189 (0.1455)	Prec@1 96.000 (94.978)	Prec@5 100.000 (99.955)
2019-04-10 17:21:53 - INFO - EVALUATING - Epoch: [88][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.3458 (0.3458)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:54 - INFO - EVALUATING - Epoch: [88][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2325 (0.2325)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:21:55 - INFO - EVALUATING - Epoch: [88][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2887 (0.3530)	Prec@1 90.000 (89.235)	Prec@5 99.000 (99.431)
2019-04-10 17:21:56 - INFO - 
 Epoch: 89	Training Loss 0.1452 	Training Prec@1 94.989 	Training Prec@5 99.953 	Validation Loss 0.3530 	Validation Prec@1 89.220 	Validation Prec@5 99.680 	Test Loss 0.3481 	Test Prec@1  89.200 	Test Prec@5  99.530 

2019-04-10 17:21:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:21:56 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:21:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:21:56 - INFO - TRAINING - Epoch: [89][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1953 (0.1953)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:21:59 - INFO - TRAINING - Epoch: [89][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.1190 (0.1492)	Prec@1 96.000 (94.824)	Prec@5 100.000 (99.980)
2019-04-10 17:22:02 - INFO - TRAINING - Epoch: [89][100/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.1420 (0.1412)	Prec@1 96.000 (95.109)	Prec@5 100.000 (99.970)
2019-04-10 17:22:05 - INFO - TRAINING - Epoch: [89][150/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.1473 (0.1449)	Prec@1 94.000 (95.053)	Prec@5 100.000 (99.967)
2019-04-10 17:22:08 - INFO - TRAINING - Epoch: [89][200/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1129 (0.1425)	Prec@1 95.000 (95.174)	Prec@5 100.000 (99.970)
2019-04-10 17:22:10 - INFO - TRAINING - Epoch: [89][250/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1315 (0.1438)	Prec@1 94.000 (95.084)	Prec@5 100.000 (99.972)
2019-04-10 17:22:13 - INFO - TRAINING - Epoch: [89][300/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1274 (0.1439)	Prec@1 96.000 (95.043)	Prec@5 100.000 (99.977)
2019-04-10 17:22:16 - INFO - TRAINING - Epoch: [89][350/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.2245 (0.1437)	Prec@1 93.000 (95.048)	Prec@5 100.000 (99.977)
2019-04-10 17:22:19 - INFO - TRAINING - Epoch: [89][400/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.1159 (0.1423)	Prec@1 97.000 (95.107)	Prec@5 100.000 (99.978)
2019-04-10 17:22:21 - INFO - EVALUATING - Epoch: [89][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4147 (0.4147)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:22:22 - INFO - EVALUATING - Epoch: [89][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3265 (0.3265)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:22:23 - INFO - EVALUATING - Epoch: [89][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1992 (0.3588)	Prec@1 92.000 (89.216)	Prec@5 100.000 (99.490)
2019-04-10 17:22:24 - INFO - 
 Epoch: 90	Training Loss 0.1426 	Training Prec@1 95.087 	Training Prec@5 99.980 	Validation Loss 0.3326 	Validation Prec@1 89.400 	Validation Prec@5 99.600 	Test Loss 0.3531 	Test Prec@1  89.340 	Test Prec@5  99.510 

2019-04-10 17:22:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:22:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:22:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:22:24 - INFO - TRAINING - Epoch: [90][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1571 (0.1571)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:22:27 - INFO - TRAINING - Epoch: [90][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.1008 (0.1383)	Prec@1 96.000 (95.216)	Prec@5 100.000 (99.980)
2019-04-10 17:22:29 - INFO - TRAINING - Epoch: [90][100/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.1314 (0.1448)	Prec@1 95.000 (95.109)	Prec@5 100.000 (99.941)
2019-04-10 17:22:32 - INFO - TRAINING - Epoch: [90][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1137 (0.1449)	Prec@1 96.000 (95.119)	Prec@5 100.000 (99.954)
2019-04-10 17:22:35 - INFO - TRAINING - Epoch: [90][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1096 (0.1397)	Prec@1 97.000 (95.239)	Prec@5 100.000 (99.960)
2019-04-10 17:22:38 - INFO - TRAINING - Epoch: [90][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.2024 (0.1396)	Prec@1 91.000 (95.223)	Prec@5 99.000 (99.960)
2019-04-10 17:22:40 - INFO - TRAINING - Epoch: [90][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0702 (0.1419)	Prec@1 98.000 (95.133)	Prec@5 100.000 (99.967)
2019-04-10 17:22:43 - INFO - TRAINING - Epoch: [90][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1177 (0.1412)	Prec@1 96.000 (95.131)	Prec@5 100.000 (99.966)
2019-04-10 17:22:46 - INFO - TRAINING - Epoch: [90][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1809 (0.1406)	Prec@1 93.000 (95.140)	Prec@5 100.000 (99.968)
2019-04-10 17:22:48 - INFO - EVALUATING - Epoch: [90][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.5257 (0.5257)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-04-10 17:22:49 - INFO - EVALUATING - Epoch: [90][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3124 (0.3124)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:22:50 - INFO - EVALUATING - Epoch: [90][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3358 (0.3694)	Prec@1 90.000 (88.706)	Prec@5 99.000 (99.373)
2019-04-10 17:22:51 - INFO - 
 Epoch: 91	Training Loss 0.1412 	Training Prec@1 95.136 	Training Prec@5 99.962 	Validation Loss 0.3463 	Validation Prec@1 89.760 	Validation Prec@5 99.560 	Test Loss 0.3617 	Test Prec@1  89.010 	Test Prec@5  99.490 

2019-04-10 17:22:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:22:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:22:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:22:51 - INFO - TRAINING - Epoch: [91][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.1124 (0.1124)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:22:54 - INFO - TRAINING - Epoch: [91][50/450]	Time 0.055 (0.053)	Data 0.012 (0.013)	Loss 0.0663 (0.1360)	Prec@1 97.000 (95.118)	Prec@5 100.000 (99.980)
2019-04-10 17:22:57 - INFO - TRAINING - Epoch: [91][100/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.2218 (0.1366)	Prec@1 92.000 (95.257)	Prec@5 100.000 (99.980)
2019-04-10 17:22:59 - INFO - TRAINING - Epoch: [91][150/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.1522 (0.1394)	Prec@1 95.000 (95.146)	Prec@5 100.000 (99.974)
2019-04-10 17:23:02 - INFO - TRAINING - Epoch: [91][200/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.2302 (0.1385)	Prec@1 89.000 (95.139)	Prec@5 100.000 (99.970)
2019-04-10 17:23:05 - INFO - TRAINING - Epoch: [91][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1385 (0.1393)	Prec@1 96.000 (95.159)	Prec@5 100.000 (99.976)
2019-04-10 17:23:08 - INFO - TRAINING - Epoch: [91][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0629 (0.1393)	Prec@1 97.000 (95.136)	Prec@5 100.000 (99.980)
2019-04-10 17:23:10 - INFO - TRAINING - Epoch: [91][350/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0749 (0.1379)	Prec@1 97.000 (95.162)	Prec@5 100.000 (99.983)
2019-04-10 17:23:13 - INFO - TRAINING - Epoch: [91][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1990 (0.1374)	Prec@1 94.000 (95.190)	Prec@5 100.000 (99.985)
2019-04-10 17:23:16 - INFO - EVALUATING - Epoch: [91][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.1356 (0.1356)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:23:17 - INFO - EVALUATING - Epoch: [91][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4065 (0.4065)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:23:17 - INFO - EVALUATING - Epoch: [91][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2245 (0.3925)	Prec@1 92.000 (88.137)	Prec@5 100.000 (99.431)
2019-04-10 17:23:18 - INFO - 
 Epoch: 92	Training Loss 0.1363 	Training Prec@1 95.222 	Training Prec@5 99.984 	Validation Loss 0.3630 	Validation Prec@1 89.280 	Validation Prec@5 99.580 	Test Loss 0.3816 	Test Prec@1  88.490 	Test Prec@5  99.540 

2019-04-10 17:23:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:23:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:23:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:23:19 - INFO - TRAINING - Epoch: [92][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1519 (0.1519)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:23:21 - INFO - TRAINING - Epoch: [92][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.1823 (0.1307)	Prec@1 93.000 (95.431)	Prec@5 100.000 (100.000)
2019-04-10 17:23:24 - INFO - TRAINING - Epoch: [92][100/450]	Time 0.061 (0.056)	Data 0.012 (0.014)	Loss 0.1376 (0.1291)	Prec@1 96.000 (95.554)	Prec@5 100.000 (100.000)
2019-04-10 17:23:27 - INFO - TRAINING - Epoch: [92][150/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1120 (0.1260)	Prec@1 97.000 (95.642)	Prec@5 100.000 (99.987)
2019-04-10 17:23:30 - INFO - TRAINING - Epoch: [92][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.1040 (0.1276)	Prec@1 97.000 (95.612)	Prec@5 100.000 (99.985)
2019-04-10 17:23:32 - INFO - TRAINING - Epoch: [92][250/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0688 (0.1286)	Prec@1 97.000 (95.542)	Prec@5 100.000 (99.988)
2019-04-10 17:23:35 - INFO - TRAINING - Epoch: [92][300/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.1059 (0.1272)	Prec@1 95.000 (95.648)	Prec@5 100.000 (99.987)
2019-04-10 17:23:38 - INFO - TRAINING - Epoch: [92][350/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0965 (0.1278)	Prec@1 96.000 (95.658)	Prec@5 100.000 (99.986)
2019-04-10 17:23:41 - INFO - TRAINING - Epoch: [92][400/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1460 (0.1279)	Prec@1 95.000 (95.681)	Prec@5 100.000 (99.985)
2019-04-10 17:23:43 - INFO - EVALUATING - Epoch: [92][0/50]	Time 0.040 (0.040)	Data 0.010 (0.010)	Loss 0.5576 (0.5576)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-04-10 17:23:44 - INFO - EVALUATING - Epoch: [92][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3190 (0.3190)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:23:45 - INFO - EVALUATING - Epoch: [92][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3109 (0.3989)	Prec@1 90.000 (88.216)	Prec@5 99.000 (99.471)
2019-04-10 17:23:46 - INFO - 
 Epoch: 93	Training Loss 0.1277 	Training Prec@1 95.664 	Training Prec@5 99.980 	Validation Loss 0.3778 	Validation Prec@1 88.260 	Validation Prec@5 99.700 	Test Loss 0.3895 	Test Prec@1  88.550 	Test Prec@5  99.520 

2019-04-10 17:23:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:23:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:23:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:23:46 - INFO - TRAINING - Epoch: [93][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1704 (0.1704)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:23:49 - INFO - TRAINING - Epoch: [93][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.2258 (0.1184)	Prec@1 90.000 (95.706)	Prec@5 100.000 (100.000)
2019-04-10 17:23:52 - INFO - TRAINING - Epoch: [93][100/450]	Time 0.049 (0.056)	Data 0.022 (0.014)	Loss 0.0645 (0.1149)	Prec@1 97.000 (95.931)	Prec@5 100.000 (99.980)
2019-04-10 17:23:54 - INFO - TRAINING - Epoch: [93][150/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1219 (0.1217)	Prec@1 94.000 (95.702)	Prec@5 100.000 (99.974)
2019-04-10 17:23:57 - INFO - TRAINING - Epoch: [93][200/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.1336 (0.1233)	Prec@1 94.000 (95.607)	Prec@5 100.000 (99.980)
2019-04-10 17:24:00 - INFO - TRAINING - Epoch: [93][250/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0689 (0.1250)	Prec@1 97.000 (95.558)	Prec@5 100.000 (99.972)
2019-04-10 17:24:03 - INFO - TRAINING - Epoch: [93][300/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1090 (0.1237)	Prec@1 97.000 (95.611)	Prec@5 100.000 (99.977)
2019-04-10 17:24:05 - INFO - TRAINING - Epoch: [93][350/450]	Time 0.053 (0.055)	Data 0.014 (0.014)	Loss 0.1220 (0.1261)	Prec@1 95.000 (95.530)	Prec@5 100.000 (99.974)
2019-04-10 17:24:08 - INFO - TRAINING - Epoch: [93][400/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.1403 (0.1279)	Prec@1 96.000 (95.486)	Prec@5 100.000 (99.978)
2019-04-10 17:24:11 - INFO - EVALUATING - Epoch: [93][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.3439 (0.3439)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:24:11 - INFO - EVALUATING - Epoch: [93][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2598 (0.2598)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:24:12 - INFO - EVALUATING - Epoch: [93][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1731 (0.3991)	Prec@1 95.000 (88.529)	Prec@5 100.000 (99.294)
2019-04-10 17:24:13 - INFO - 
 Epoch: 94	Training Loss 0.1281 	Training Prec@1 95.467 	Training Prec@5 99.978 	Validation Loss 0.3707 	Validation Prec@1 89.100 	Validation Prec@5 99.640 	Test Loss 0.3886 	Test Prec@1  88.670 	Test Prec@5  99.420 

2019-04-10 17:24:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:24:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:24:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:24:13 - INFO - TRAINING - Epoch: [94][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1328 (0.1328)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:24:16 - INFO - TRAINING - Epoch: [94][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.3293 (0.1297)	Prec@1 92.000 (95.510)	Prec@5 100.000 (100.000)
2019-04-10 17:24:19 - INFO - TRAINING - Epoch: [94][100/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0822 (0.1280)	Prec@1 96.000 (95.515)	Prec@5 100.000 (99.990)
2019-04-10 17:24:22 - INFO - TRAINING - Epoch: [94][150/450]	Time 0.056 (0.057)	Data 0.012 (0.014)	Loss 0.1325 (0.1275)	Prec@1 96.000 (95.642)	Prec@5 100.000 (99.980)
2019-04-10 17:24:25 - INFO - TRAINING - Epoch: [94][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.1777 (0.1252)	Prec@1 95.000 (95.706)	Prec@5 100.000 (99.970)
2019-04-10 17:24:28 - INFO - TRAINING - Epoch: [94][250/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.0581 (0.1264)	Prec@1 99.000 (95.641)	Prec@5 100.000 (99.968)
2019-04-10 17:24:31 - INFO - TRAINING - Epoch: [94][300/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.2797 (0.1265)	Prec@1 90.000 (95.618)	Prec@5 100.000 (99.970)
2019-04-10 17:24:33 - INFO - TRAINING - Epoch: [94][350/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.2616 (0.1272)	Prec@1 92.000 (95.601)	Prec@5 100.000 (99.974)
2019-04-10 17:24:36 - INFO - TRAINING - Epoch: [94][400/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0591 (0.1261)	Prec@1 97.000 (95.651)	Prec@5 100.000 (99.978)
2019-04-10 17:24:39 - INFO - EVALUATING - Epoch: [94][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.3195 (0.3195)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:24:40 - INFO - EVALUATING - Epoch: [94][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2894 (0.2894)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:24:41 - INFO - EVALUATING - Epoch: [94][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.2783 (0.3705)	Prec@1 90.000 (88.882)	Prec@5 100.000 (99.451)
2019-04-10 17:24:42 - INFO - 
 Epoch: 95	Training Loss 0.1281 	Training Prec@1 95.576 	Training Prec@5 99.976 	Validation Loss 0.3454 	Validation Prec@1 89.380 	Validation Prec@5 99.540 	Test Loss 0.3676 	Test Prec@1  88.840 	Test Prec@5  99.500 

2019-04-10 17:24:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:24:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:24:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:24:42 - INFO - TRAINING - Epoch: [95][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1142 (0.1142)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:24:45 - INFO - TRAINING - Epoch: [95][50/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0321 (0.1243)	Prec@1 100.000 (95.804)	Prec@5 100.000 (99.961)
2019-04-10 17:24:47 - INFO - TRAINING - Epoch: [95][100/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0808 (0.1193)	Prec@1 96.000 (95.970)	Prec@5 100.000 (99.980)
2019-04-10 17:24:50 - INFO - TRAINING - Epoch: [95][150/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0740 (0.1249)	Prec@1 97.000 (95.768)	Prec@5 100.000 (99.974)
2019-04-10 17:24:53 - INFO - TRAINING - Epoch: [95][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0972 (0.1242)	Prec@1 95.000 (95.871)	Prec@5 100.000 (99.970)
2019-04-10 17:24:55 - INFO - TRAINING - Epoch: [95][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1226 (0.1260)	Prec@1 95.000 (95.817)	Prec@5 100.000 (99.964)
2019-04-10 17:24:58 - INFO - TRAINING - Epoch: [95][300/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1770 (0.1252)	Prec@1 96.000 (95.824)	Prec@5 100.000 (99.967)
2019-04-10 17:25:01 - INFO - TRAINING - Epoch: [95][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1516 (0.1265)	Prec@1 96.000 (95.809)	Prec@5 100.000 (99.966)
2019-04-10 17:25:04 - INFO - TRAINING - Epoch: [95][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0855 (0.1250)	Prec@1 95.000 (95.850)	Prec@5 100.000 (99.970)
2019-04-10 17:25:06 - INFO - EVALUATING - Epoch: [95][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.2011 (0.2011)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:25:07 - INFO - EVALUATING - Epoch: [95][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2504 (0.2504)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:25:08 - INFO - EVALUATING - Epoch: [95][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2707 (0.3545)	Prec@1 88.000 (89.275)	Prec@5 100.000 (99.627)
2019-04-10 17:25:09 - INFO - 
 Epoch: 96	Training Loss 0.1252 	Training Prec@1 95.844 	Training Prec@5 99.969 	Validation Loss 0.3409 	Validation Prec@1 89.660 	Validation Prec@5 99.660 	Test Loss 0.3570 	Test Prec@1  89.400 	Test Prec@5  99.580 

2019-04-10 17:25:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:25:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:25:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:25:09 - INFO - TRAINING - Epoch: [96][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0516 (0.0516)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:25:12 - INFO - TRAINING - Epoch: [96][50/450]	Time 0.058 (0.056)	Data 0.013 (0.013)	Loss 0.0905 (0.1176)	Prec@1 98.000 (95.804)	Prec@5 100.000 (100.000)
2019-04-10 17:25:15 - INFO - TRAINING - Epoch: [96][100/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1080 (0.1210)	Prec@1 95.000 (95.822)	Prec@5 100.000 (99.990)
2019-04-10 17:25:18 - INFO - TRAINING - Epoch: [96][150/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.1453 (0.1217)	Prec@1 95.000 (95.795)	Prec@5 100.000 (99.980)
2019-04-10 17:25:20 - INFO - TRAINING - Epoch: [96][200/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0879 (0.1206)	Prec@1 98.000 (95.846)	Prec@5 100.000 (99.975)
2019-04-10 17:25:23 - INFO - TRAINING - Epoch: [96][250/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0846 (0.1199)	Prec@1 98.000 (95.888)	Prec@5 100.000 (99.980)
2019-04-10 17:25:26 - INFO - TRAINING - Epoch: [96][300/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0870 (0.1206)	Prec@1 97.000 (95.867)	Prec@5 100.000 (99.977)
2019-04-10 17:25:28 - INFO - TRAINING - Epoch: [96][350/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.1312 (0.1215)	Prec@1 95.000 (95.809)	Prec@5 100.000 (99.977)
2019-04-10 17:25:31 - INFO - TRAINING - Epoch: [96][400/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.2901 (0.1232)	Prec@1 91.000 (95.766)	Prec@5 99.000 (99.973)
2019-04-10 17:25:34 - INFO - EVALUATING - Epoch: [96][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3115 (0.3115)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:25:35 - INFO - EVALUATING - Epoch: [96][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2791 (0.2791)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:25:36 - INFO - EVALUATING - Epoch: [96][50/100]	Time 0.017 (0.018)	Data 0.010 (0.010)	Loss 0.3026 (0.3855)	Prec@1 87.000 (88.078)	Prec@5 100.000 (99.490)
2019-04-10 17:25:36 - INFO - 
 Epoch: 97	Training Loss 0.1239 	Training Prec@1 95.753 	Training Prec@5 99.973 	Validation Loss 0.3588 	Validation Prec@1 88.840 	Validation Prec@5 99.560 	Test Loss 0.3773 	Test Prec@1  88.530 	Test Prec@5  99.520 

2019-04-10 17:25:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:25:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:25:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:25:37 - INFO - TRAINING - Epoch: [97][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0550 (0.0550)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:25:39 - INFO - TRAINING - Epoch: [97][50/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.0983 (0.1192)	Prec@1 96.000 (95.882)	Prec@5 100.000 (99.961)
2019-04-10 17:25:42 - INFO - TRAINING - Epoch: [97][100/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.1124 (0.1164)	Prec@1 93.000 (95.960)	Prec@5 100.000 (99.970)
2019-04-10 17:25:45 - INFO - TRAINING - Epoch: [97][150/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1462 (0.1175)	Prec@1 96.000 (95.940)	Prec@5 99.000 (99.960)
2019-04-10 17:25:48 - INFO - TRAINING - Epoch: [97][200/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1008 (0.1205)	Prec@1 95.000 (95.796)	Prec@5 100.000 (99.970)
2019-04-10 17:25:51 - INFO - TRAINING - Epoch: [97][250/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.2095 (0.1214)	Prec@1 91.000 (95.773)	Prec@5 100.000 (99.972)
2019-04-10 17:25:53 - INFO - TRAINING - Epoch: [97][300/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0508 (0.1201)	Prec@1 99.000 (95.831)	Prec@5 100.000 (99.973)
2019-04-10 17:25:56 - INFO - TRAINING - Epoch: [97][350/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0504 (0.1184)	Prec@1 99.000 (95.858)	Prec@5 100.000 (99.974)
2019-04-10 17:25:59 - INFO - TRAINING - Epoch: [97][400/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0946 (0.1178)	Prec@1 95.000 (95.863)	Prec@5 100.000 (99.975)
2019-04-10 17:26:01 - INFO - EVALUATING - Epoch: [97][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.1330 (0.1330)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:26:02 - INFO - EVALUATING - Epoch: [97][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2017 (0.2017)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:26:03 - INFO - EVALUATING - Epoch: [97][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1962 (0.3758)	Prec@1 89.000 (89.275)	Prec@5 100.000 (99.471)
2019-04-10 17:26:04 - INFO - 
 Epoch: 98	Training Loss 0.1190 	Training Prec@1 95.856 	Training Prec@5 99.976 	Validation Loss 0.3617 	Validation Prec@1 89.660 	Validation Prec@5 99.660 	Test Loss 0.3673 	Test Prec@1  89.280 	Test Prec@5  99.530 

2019-04-10 17:26:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:26:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:26:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:26:04 - INFO - TRAINING - Epoch: [98][0/450]	Time 0.032 (0.032)	Data 0.013 (0.013)	Loss 0.0962 (0.0962)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:26:07 - INFO - TRAINING - Epoch: [98][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0852 (0.1207)	Prec@1 97.000 (95.745)	Prec@5 100.000 (100.000)
2019-04-10 17:26:10 - INFO - TRAINING - Epoch: [98][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0757 (0.1128)	Prec@1 97.000 (95.901)	Prec@5 100.000 (100.000)
2019-04-10 17:26:12 - INFO - TRAINING - Epoch: [98][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1188 (0.1162)	Prec@1 96.000 (95.868)	Prec@5 100.000 (99.993)
2019-04-10 17:26:15 - INFO - TRAINING - Epoch: [98][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1197 (0.1178)	Prec@1 95.000 (95.950)	Prec@5 100.000 (99.995)
2019-04-10 17:26:18 - INFO - TRAINING - Epoch: [98][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2556 (0.1193)	Prec@1 89.000 (95.865)	Prec@5 100.000 (99.980)
2019-04-10 17:26:20 - INFO - TRAINING - Epoch: [98][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0574 (0.1205)	Prec@1 98.000 (95.804)	Prec@5 100.000 (99.973)
2019-04-10 17:26:23 - INFO - TRAINING - Epoch: [98][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0552 (0.1204)	Prec@1 97.000 (95.809)	Prec@5 100.000 (99.969)
2019-04-10 17:26:26 - INFO - TRAINING - Epoch: [98][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0669 (0.1187)	Prec@1 98.000 (95.863)	Prec@5 100.000 (99.970)
2019-04-10 17:26:29 - INFO - EVALUATING - Epoch: [98][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3698 (0.3698)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:26:29 - INFO - EVALUATING - Epoch: [98][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3035 (0.3035)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:26:30 - INFO - EVALUATING - Epoch: [98][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2310 (0.3363)	Prec@1 95.000 (89.686)	Prec@5 100.000 (99.647)
2019-04-10 17:26:31 - INFO - 
 Epoch: 99	Training Loss 0.1190 	Training Prec@1 95.860 	Training Prec@5 99.971 	Validation Loss 0.3322 	Validation Prec@1 89.960 	Validation Prec@5 99.600 	Test Loss 0.3456 	Test Prec@1  89.330 	Test Prec@5  99.640 

2019-04-10 17:26:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:26:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:26:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:26:31 - INFO - TRAINING - Epoch: [99][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0733 (0.0733)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:26:34 - INFO - TRAINING - Epoch: [99][50/450]	Time 0.056 (0.053)	Data 0.012 (0.014)	Loss 0.1170 (0.0962)	Prec@1 95.000 (96.804)	Prec@5 100.000 (99.980)
2019-04-10 17:26:37 - INFO - TRAINING - Epoch: [99][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1236 (0.0980)	Prec@1 97.000 (96.822)	Prec@5 100.000 (99.980)
2019-04-10 17:26:40 - INFO - TRAINING - Epoch: [99][150/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0639 (0.1040)	Prec@1 97.000 (96.523)	Prec@5 100.000 (99.987)
2019-04-10 17:26:42 - INFO - TRAINING - Epoch: [99][200/450]	Time 0.057 (0.054)	Data 0.013 (0.014)	Loss 0.0427 (0.1071)	Prec@1 100.000 (96.299)	Prec@5 100.000 (99.980)
2019-04-10 17:26:45 - INFO - TRAINING - Epoch: [99][250/450]	Time 0.057 (0.055)	Data 0.012 (0.014)	Loss 0.0984 (0.1096)	Prec@1 96.000 (96.223)	Prec@5 100.000 (99.972)
2019-04-10 17:26:48 - INFO - TRAINING - Epoch: [99][300/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0493 (0.1096)	Prec@1 98.000 (96.186)	Prec@5 100.000 (99.973)
2019-04-10 17:26:51 - INFO - TRAINING - Epoch: [99][350/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.1659 (0.1110)	Prec@1 93.000 (96.162)	Prec@5 100.000 (99.972)
2019-04-10 17:26:53 - INFO - TRAINING - Epoch: [99][400/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1224 (0.1104)	Prec@1 97.000 (96.182)	Prec@5 100.000 (99.973)
2019-04-10 17:26:56 - INFO - EVALUATING - Epoch: [99][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.4622 (0.4622)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-04-10 17:26:57 - INFO - EVALUATING - Epoch: [99][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3092 (0.3092)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:26:58 - INFO - EVALUATING - Epoch: [99][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2675 (0.3770)	Prec@1 91.000 (89.137)	Prec@5 100.000 (99.412)
2019-04-10 17:26:59 - INFO - 
 Epoch: 100	Training Loss 0.1131 	Training Prec@1 96.093 	Training Prec@5 99.971 	Validation Loss 0.3663 	Validation Prec@1 89.200 	Validation Prec@5 99.620 	Test Loss 0.3833 	Test Prec@1  88.900 	Test Prec@5  99.550 

2019-04-10 17:26:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:26:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:26:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:26:59 - INFO - TRAINING - Epoch: [100][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0418 (0.0418)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:27:02 - INFO - TRAINING - Epoch: [100][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0979 (0.1107)	Prec@1 96.000 (95.961)	Prec@5 100.000 (99.980)
2019-04-10 17:27:04 - INFO - TRAINING - Epoch: [100][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1471 (0.1115)	Prec@1 91.000 (95.901)	Prec@5 100.000 (99.960)
2019-04-10 17:27:07 - INFO - TRAINING - Epoch: [100][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2690 (0.1100)	Prec@1 94.000 (96.093)	Prec@5 100.000 (99.967)
2019-04-10 17:27:10 - INFO - TRAINING - Epoch: [100][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1048 (0.1089)	Prec@1 98.000 (96.174)	Prec@5 100.000 (99.975)
2019-04-10 17:27:13 - INFO - TRAINING - Epoch: [100][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1108 (0.1080)	Prec@1 98.000 (96.239)	Prec@5 100.000 (99.976)
2019-04-10 17:27:15 - INFO - TRAINING - Epoch: [100][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1096 (0.1095)	Prec@1 96.000 (96.213)	Prec@5 100.000 (99.980)
2019-04-10 17:27:18 - INFO - TRAINING - Epoch: [100][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1206 (0.1119)	Prec@1 93.000 (96.148)	Prec@5 100.000 (99.972)
2019-04-10 17:27:21 - INFO - TRAINING - Epoch: [100][400/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0421 (0.1121)	Prec@1 98.000 (96.155)	Prec@5 100.000 (99.975)
2019-04-10 17:27:23 - INFO - EVALUATING - Epoch: [100][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.3323 (0.3323)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:27:24 - INFO - EVALUATING - Epoch: [100][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3364 (0.3364)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:27:25 - INFO - EVALUATING - Epoch: [100][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.0921 (0.3566)	Prec@1 96.000 (89.765)	Prec@5 100.000 (99.588)
2019-04-10 17:27:26 - INFO - 
 Epoch: 101	Training Loss 0.1115 	Training Prec@1 96.182 	Training Prec@5 99.976 	Validation Loss 0.3519 	Validation Prec@1 89.860 	Validation Prec@5 99.680 	Test Loss 0.3643 	Test Prec@1  89.370 	Test Prec@5  99.620 

2019-04-10 17:27:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:27:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:27:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:27:26 - INFO - TRAINING - Epoch: [101][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0727 (0.0727)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:27:29 - INFO - TRAINING - Epoch: [101][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1159 (0.1135)	Prec@1 94.000 (95.902)	Prec@5 100.000 (100.000)
2019-04-10 17:27:32 - INFO - TRAINING - Epoch: [101][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0621 (0.1072)	Prec@1 98.000 (96.218)	Prec@5 100.000 (99.990)
2019-04-10 17:27:34 - INFO - TRAINING - Epoch: [101][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1632 (0.1078)	Prec@1 95.000 (96.252)	Prec@5 100.000 (99.993)
2019-04-10 17:27:37 - INFO - TRAINING - Epoch: [101][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2186 (0.1060)	Prec@1 92.000 (96.294)	Prec@5 100.000 (99.985)
2019-04-10 17:27:40 - INFO - TRAINING - Epoch: [101][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1411 (0.1060)	Prec@1 95.000 (96.307)	Prec@5 100.000 (99.988)
2019-04-10 17:27:43 - INFO - TRAINING - Epoch: [101][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1043 (0.1063)	Prec@1 97.000 (96.312)	Prec@5 100.000 (99.987)
2019-04-10 17:27:45 - INFO - TRAINING - Epoch: [101][350/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1545 (0.1067)	Prec@1 96.000 (96.322)	Prec@5 100.000 (99.986)
2019-04-10 17:27:48 - INFO - TRAINING - Epoch: [101][400/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0684 (0.1080)	Prec@1 98.000 (96.287)	Prec@5 100.000 (99.983)
2019-04-10 17:27:51 - INFO - EVALUATING - Epoch: [101][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.3842 (0.3842)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:27:52 - INFO - EVALUATING - Epoch: [101][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3304 (0.3304)	Prec@1 90.000 (90.000)	Prec@5 98.000 (98.000)
2019-04-10 17:27:53 - INFO - EVALUATING - Epoch: [101][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2215 (0.3805)	Prec@1 92.000 (89.373)	Prec@5 100.000 (99.451)
2019-04-10 17:27:53 - INFO - 
 Epoch: 102	Training Loss 0.1092 	Training Prec@1 96.236 	Training Prec@5 99.980 	Validation Loss 0.3594 	Validation Prec@1 89.740 	Validation Prec@5 99.600 	Test Loss 0.3662 	Test Prec@1  89.500 	Test Prec@5  99.530 

2019-04-10 17:27:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:27:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:27:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:27:54 - INFO - TRAINING - Epoch: [102][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1682 (0.1682)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:27:56 - INFO - TRAINING - Epoch: [102][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0523 (0.1182)	Prec@1 99.000 (96.176)	Prec@5 100.000 (99.980)
2019-04-10 17:27:59 - INFO - TRAINING - Epoch: [102][100/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0967 (0.1114)	Prec@1 97.000 (96.356)	Prec@5 100.000 (99.990)
2019-04-10 17:28:02 - INFO - TRAINING - Epoch: [102][150/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.1385 (0.1073)	Prec@1 93.000 (96.397)	Prec@5 100.000 (99.993)
2019-04-10 17:28:05 - INFO - TRAINING - Epoch: [102][200/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1345 (0.1082)	Prec@1 95.000 (96.308)	Prec@5 100.000 (99.995)
2019-04-10 17:28:08 - INFO - TRAINING - Epoch: [102][250/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.1799 (0.1104)	Prec@1 92.000 (96.155)	Prec@5 100.000 (99.996)
2019-04-10 17:28:10 - INFO - TRAINING - Epoch: [102][300/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0864 (0.1104)	Prec@1 97.000 (96.176)	Prec@5 100.000 (99.997)
2019-04-10 17:28:13 - INFO - TRAINING - Epoch: [102][350/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0730 (0.1094)	Prec@1 99.000 (96.245)	Prec@5 100.000 (99.997)
2019-04-10 17:28:16 - INFO - TRAINING - Epoch: [102][400/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.2363 (0.1102)	Prec@1 89.000 (96.257)	Prec@5 100.000 (99.995)
2019-04-10 17:28:18 - INFO - EVALUATING - Epoch: [102][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.1919 (0.1919)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:28:19 - INFO - EVALUATING - Epoch: [102][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2724 (0.2724)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:28:20 - INFO - EVALUATING - Epoch: [102][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1816 (0.3822)	Prec@1 94.000 (88.745)	Prec@5 100.000 (99.549)
2019-04-10 17:28:21 - INFO - 
 Epoch: 103	Training Loss 0.1120 	Training Prec@1 96.182 	Training Prec@5 99.996 	Validation Loss 0.3765 	Validation Prec@1 89.140 	Validation Prec@5 99.700 	Test Loss 0.3769 	Test Prec@1  89.070 	Test Prec@5  99.620 

2019-04-10 17:28:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:28:21 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:28:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:28:21 - INFO - TRAINING - Epoch: [103][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0658 (0.0658)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:28:24 - INFO - TRAINING - Epoch: [103][50/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0313 (0.1054)	Prec@1 99.000 (96.451)	Prec@5 100.000 (99.980)
2019-04-10 17:28:27 - INFO - TRAINING - Epoch: [103][100/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0363 (0.1071)	Prec@1 99.000 (96.347)	Prec@5 100.000 (99.990)
2019-04-10 17:28:30 - INFO - TRAINING - Epoch: [103][150/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.1440 (0.1055)	Prec@1 96.000 (96.404)	Prec@5 100.000 (99.993)
2019-04-10 17:28:33 - INFO - TRAINING - Epoch: [103][200/450]	Time 0.064 (0.057)	Data 0.012 (0.014)	Loss 0.0818 (0.1061)	Prec@1 98.000 (96.403)	Prec@5 100.000 (99.990)
2019-04-10 17:28:35 - INFO - TRAINING - Epoch: [103][250/450]	Time 0.058 (0.057)	Data 0.012 (0.014)	Loss 0.1462 (0.1047)	Prec@1 94.000 (96.490)	Prec@5 100.000 (99.992)
2019-04-10 17:28:38 - INFO - TRAINING - Epoch: [103][300/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.2411 (0.1045)	Prec@1 91.000 (96.475)	Prec@5 100.000 (99.990)
2019-04-10 17:28:41 - INFO - TRAINING - Epoch: [103][350/450]	Time 0.054 (0.057)	Data 0.013 (0.014)	Loss 0.0805 (0.1044)	Prec@1 97.000 (96.507)	Prec@5 100.000 (99.991)
2019-04-10 17:28:44 - INFO - TRAINING - Epoch: [103][400/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.1553 (0.1048)	Prec@1 92.000 (96.461)	Prec@5 100.000 (99.988)
2019-04-10 17:28:46 - INFO - EVALUATING - Epoch: [103][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.2695 (0.2695)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:28:47 - INFO - EVALUATING - Epoch: [103][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2802 (0.2802)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:28:48 - INFO - EVALUATING - Epoch: [103][50/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2701 (0.3723)	Prec@1 90.000 (89.510)	Prec@5 100.000 (99.431)
2019-04-10 17:28:49 - INFO - 
 Epoch: 104	Training Loss 0.1050 	Training Prec@1 96.444 	Training Prec@5 99.987 	Validation Loss 0.3537 	Validation Prec@1 89.660 	Validation Prec@5 99.720 	Test Loss 0.3637 	Test Prec@1  89.620 	Test Prec@5  99.510 

2019-04-10 17:28:49 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:28:49 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:28:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:28:49 - INFO - TRAINING - Epoch: [104][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1010 (0.1010)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:28:52 - INFO - TRAINING - Epoch: [104][50/450]	Time 0.059 (0.054)	Data 0.013 (0.014)	Loss 0.1262 (0.1069)	Prec@1 96.000 (96.314)	Prec@5 100.000 (99.980)
2019-04-10 17:28:55 - INFO - TRAINING - Epoch: [104][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1205 (0.1025)	Prec@1 96.000 (96.505)	Prec@5 100.000 (99.980)
2019-04-10 17:28:57 - INFO - TRAINING - Epoch: [104][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0555 (0.1097)	Prec@1 99.000 (96.265)	Prec@5 100.000 (99.974)
2019-04-10 17:29:00 - INFO - TRAINING - Epoch: [104][200/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1308 (0.1088)	Prec@1 96.000 (96.289)	Prec@5 100.000 (99.980)
2019-04-10 17:29:03 - INFO - TRAINING - Epoch: [104][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0750 (0.1056)	Prec@1 98.000 (96.386)	Prec@5 100.000 (99.980)
2019-04-10 17:29:05 - INFO - TRAINING - Epoch: [104][300/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0360 (0.1074)	Prec@1 100.000 (96.276)	Prec@5 100.000 (99.983)
2019-04-10 17:29:08 - INFO - TRAINING - Epoch: [104][350/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.1473 (0.1057)	Prec@1 93.000 (96.336)	Prec@5 100.000 (99.986)
2019-04-10 17:29:11 - INFO - TRAINING - Epoch: [104][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0625 (0.1060)	Prec@1 98.000 (96.354)	Prec@5 100.000 (99.980)
2019-04-10 17:29:13 - INFO - EVALUATING - Epoch: [104][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.5557 (0.5557)	Prec@1 87.000 (87.000)	Prec@5 98.000 (98.000)
2019-04-10 17:29:14 - INFO - EVALUATING - Epoch: [104][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3211 (0.3211)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:29:15 - INFO - EVALUATING - Epoch: [104][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3168 (0.3743)	Prec@1 91.000 (88.608)	Prec@5 100.000 (99.588)
2019-04-10 17:29:16 - INFO - 
 Epoch: 105	Training Loss 0.1055 	Training Prec@1 96.393 	Training Prec@5 99.982 	Validation Loss 0.3476 	Validation Prec@1 90.020 	Validation Prec@5 99.580 	Test Loss 0.3730 	Test Prec@1  88.860 	Test Prec@5  99.620 

2019-04-10 17:29:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:29:16 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:29:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:29:16 - INFO - TRAINING - Epoch: [105][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0425 (0.0425)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:29:19 - INFO - TRAINING - Epoch: [105][50/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0411 (0.1031)	Prec@1 99.000 (96.333)	Prec@5 100.000 (100.000)
2019-04-10 17:29:22 - INFO - TRAINING - Epoch: [105][100/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1096 (0.1095)	Prec@1 95.000 (96.257)	Prec@5 100.000 (99.980)
2019-04-10 17:29:24 - INFO - TRAINING - Epoch: [105][150/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1192 (0.1068)	Prec@1 95.000 (96.298)	Prec@5 100.000 (99.987)
2019-04-10 17:29:27 - INFO - TRAINING - Epoch: [105][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0424 (0.1030)	Prec@1 99.000 (96.433)	Prec@5 100.000 (99.990)
2019-04-10 17:29:30 - INFO - TRAINING - Epoch: [105][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0497 (0.1036)	Prec@1 98.000 (96.406)	Prec@5 100.000 (99.992)
2019-04-10 17:29:33 - INFO - TRAINING - Epoch: [105][300/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.3016 (0.1045)	Prec@1 91.000 (96.402)	Prec@5 98.000 (99.987)
2019-04-10 17:29:35 - INFO - TRAINING - Epoch: [105][350/450]	Time 0.048 (0.054)	Data 0.013 (0.013)	Loss 0.1375 (0.1034)	Prec@1 94.000 (96.481)	Prec@5 100.000 (99.977)
2019-04-10 17:29:38 - INFO - TRAINING - Epoch: [105][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0720 (0.1041)	Prec@1 97.000 (96.456)	Prec@5 100.000 (99.980)
2019-04-10 17:29:41 - INFO - EVALUATING - Epoch: [105][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.2655 (0.2655)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:29:42 - INFO - EVALUATING - Epoch: [105][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3466 (0.3466)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:29:42 - INFO - EVALUATING - Epoch: [105][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2639 (0.3645)	Prec@1 93.000 (89.294)	Prec@5 100.000 (99.510)
2019-04-10 17:29:43 - INFO - 
 Epoch: 106	Training Loss 0.1045 	Training Prec@1 96.451 	Training Prec@5 99.982 	Validation Loss 0.3658 	Validation Prec@1 89.500 	Validation Prec@5 99.600 	Test Loss 0.3661 	Test Prec@1  89.270 	Test Prec@5  99.570 

2019-04-10 17:29:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:29:43 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:29:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:29:43 - INFO - TRAINING - Epoch: [106][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0934 (0.0934)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:29:46 - INFO - TRAINING - Epoch: [106][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.0618 (0.1070)	Prec@1 98.000 (96.549)	Prec@5 100.000 (100.000)
2019-04-10 17:29:49 - INFO - TRAINING - Epoch: [106][100/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.1129 (0.1017)	Prec@1 97.000 (96.713)	Prec@5 100.000 (99.990)
2019-04-10 17:29:52 - INFO - TRAINING - Epoch: [106][150/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.1078 (0.1003)	Prec@1 96.000 (96.662)	Prec@5 100.000 (99.980)
2019-04-10 17:29:54 - INFO - TRAINING - Epoch: [106][200/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0611 (0.1003)	Prec@1 98.000 (96.612)	Prec@5 100.000 (99.975)
2019-04-10 17:29:57 - INFO - TRAINING - Epoch: [106][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1080 (0.1008)	Prec@1 96.000 (96.566)	Prec@5 100.000 (99.980)
2019-04-10 17:30:00 - INFO - TRAINING - Epoch: [106][300/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0518 (0.1004)	Prec@1 98.000 (96.591)	Prec@5 100.000 (99.973)
2019-04-10 17:30:03 - INFO - TRAINING - Epoch: [106][350/450]	Time 0.056 (0.055)	Data 0.012 (0.013)	Loss 0.1005 (0.0999)	Prec@1 97.000 (96.630)	Prec@5 100.000 (99.974)
2019-04-10 17:30:05 - INFO - TRAINING - Epoch: [106][400/450]	Time 0.056 (0.055)	Data 0.013 (0.013)	Loss 0.0429 (0.0987)	Prec@1 99.000 (96.653)	Prec@5 100.000 (99.975)
2019-04-10 17:30:08 - INFO - EVALUATING - Epoch: [106][0/50]	Time 0.044 (0.044)	Data 0.012 (0.012)	Loss 0.4958 (0.4958)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:30:09 - INFO - EVALUATING - Epoch: [106][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3544 (0.3544)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:30:10 - INFO - EVALUATING - Epoch: [106][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.2019 (0.3733)	Prec@1 91.000 (88.765)	Prec@5 100.000 (99.490)
2019-04-10 17:30:11 - INFO - 
 Epoch: 107	Training Loss 0.0985 	Training Prec@1 96.656 	Training Prec@5 99.976 	Validation Loss 0.3583 	Validation Prec@1 89.500 	Validation Prec@5 99.580 	Test Loss 0.3661 	Test Prec@1  89.420 	Test Prec@5  99.540 

2019-04-10 17:30:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:30:11 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:30:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:30:11 - INFO - TRAINING - Epoch: [107][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0595 (0.0595)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:30:14 - INFO - TRAINING - Epoch: [107][50/450]	Time 0.055 (0.053)	Data 0.014 (0.015)	Loss 0.0296 (0.0949)	Prec@1 99.000 (96.510)	Prec@5 100.000 (99.980)
2019-04-10 17:30:17 - INFO - TRAINING - Epoch: [107][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0995 (0.0944)	Prec@1 97.000 (96.634)	Prec@5 100.000 (99.980)
2019-04-10 17:30:19 - INFO - TRAINING - Epoch: [107][150/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0913 (0.0964)	Prec@1 96.000 (96.616)	Prec@5 100.000 (99.987)
2019-04-10 17:30:22 - INFO - TRAINING - Epoch: [107][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1391 (0.0967)	Prec@1 95.000 (96.617)	Prec@5 100.000 (99.990)
2019-04-10 17:30:25 - INFO - TRAINING - Epoch: [107][250/450]	Time 0.049 (0.054)	Data 0.021 (0.014)	Loss 0.1434 (0.0972)	Prec@1 95.000 (96.558)	Prec@5 100.000 (99.992)
2019-04-10 17:30:27 - INFO - TRAINING - Epoch: [107][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.2079 (0.0991)	Prec@1 95.000 (96.538)	Prec@5 100.000 (99.990)
2019-04-10 17:30:30 - INFO - TRAINING - Epoch: [107][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0892 (0.0984)	Prec@1 96.000 (96.524)	Prec@5 100.000 (99.989)
2019-04-10 17:30:33 - INFO - TRAINING - Epoch: [107][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1247 (0.0989)	Prec@1 95.000 (96.534)	Prec@5 100.000 (99.990)
2019-04-10 17:30:35 - INFO - EVALUATING - Epoch: [107][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.2813 (0.2813)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:30:36 - INFO - EVALUATING - Epoch: [107][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2947 (0.2947)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:30:37 - INFO - EVALUATING - Epoch: [107][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3399 (0.3671)	Prec@1 90.000 (89.176)	Prec@5 100.000 (99.392)
2019-04-10 17:30:38 - INFO - 
 Epoch: 108	Training Loss 0.0996 	Training Prec@1 96.524 	Training Prec@5 99.987 	Validation Loss 0.3452 	Validation Prec@1 90.160 	Validation Prec@5 99.720 	Test Loss 0.3626 	Test Prec@1  89.460 	Test Prec@5  99.520 

2019-04-10 17:30:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:30:38 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:30:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:30:38 - INFO - TRAINING - Epoch: [108][0/450]	Time 0.031 (0.031)	Data 0.014 (0.014)	Loss 0.1122 (0.1122)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:30:41 - INFO - TRAINING - Epoch: [108][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1042 (0.0964)	Prec@1 96.000 (96.863)	Prec@5 100.000 (99.980)
2019-04-10 17:30:44 - INFO - TRAINING - Epoch: [108][100/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.1386 (0.0962)	Prec@1 96.000 (96.802)	Prec@5 100.000 (99.990)
2019-04-10 17:30:47 - INFO - TRAINING - Epoch: [108][150/450]	Time 0.057 (0.057)	Data 0.013 (0.014)	Loss 0.0459 (0.0943)	Prec@1 100.000 (96.861)	Prec@5 100.000 (99.993)
2019-04-10 17:30:50 - INFO - TRAINING - Epoch: [108][200/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.2333 (0.0944)	Prec@1 93.000 (96.821)	Prec@5 100.000 (99.995)
2019-04-10 17:30:52 - INFO - TRAINING - Epoch: [108][250/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1998 (0.0959)	Prec@1 95.000 (96.657)	Prec@5 100.000 (99.996)
2019-04-10 17:30:55 - INFO - TRAINING - Epoch: [108][300/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0884 (0.0958)	Prec@1 95.000 (96.674)	Prec@5 100.000 (99.997)
2019-04-10 17:30:58 - INFO - TRAINING - Epoch: [108][350/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0583 (0.0970)	Prec@1 97.000 (96.624)	Prec@5 100.000 (99.994)
2019-04-10 17:31:01 - INFO - TRAINING - Epoch: [108][400/450]	Time 0.059 (0.056)	Data 0.014 (0.014)	Loss 0.1606 (0.0973)	Prec@1 94.000 (96.648)	Prec@5 100.000 (99.995)
2019-04-10 17:31:03 - INFO - EVALUATING - Epoch: [108][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.5310 (0.5310)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-04-10 17:31:04 - INFO - EVALUATING - Epoch: [108][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3052 (0.3052)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:31:05 - INFO - EVALUATING - Epoch: [108][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2398 (0.3550)	Prec@1 93.000 (89.902)	Prec@5 100.000 (99.392)
2019-04-10 17:31:06 - INFO - 
 Epoch: 109	Training Loss 0.0963 	Training Prec@1 96.691 	Training Prec@5 99.996 	Validation Loss 0.3379 	Validation Prec@1 90.080 	Validation Prec@5 99.760 	Test Loss 0.3537 	Test Prec@1  89.920 	Test Prec@5  99.550 

2019-04-10 17:31:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:31:06 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:31:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:31:06 - INFO - TRAINING - Epoch: [109][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0923 (0.0923)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:31:09 - INFO - TRAINING - Epoch: [109][50/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0398 (0.0907)	Prec@1 99.000 (96.980)	Prec@5 100.000 (100.000)
2019-04-10 17:31:11 - INFO - TRAINING - Epoch: [109][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1674 (0.0917)	Prec@1 94.000 (96.921)	Prec@5 100.000 (99.990)
2019-04-10 17:31:14 - INFO - TRAINING - Epoch: [109][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0691 (0.0953)	Prec@1 98.000 (96.874)	Prec@5 100.000 (99.987)
2019-04-10 17:31:17 - INFO - TRAINING - Epoch: [109][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.2009 (0.0978)	Prec@1 95.000 (96.811)	Prec@5 100.000 (99.985)
2019-04-10 17:31:19 - INFO - TRAINING - Epoch: [109][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.2136 (0.0951)	Prec@1 96.000 (96.861)	Prec@5 100.000 (99.984)
2019-04-10 17:31:22 - INFO - TRAINING - Epoch: [109][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1092 (0.0962)	Prec@1 95.000 (96.777)	Prec@5 100.000 (99.987)
2019-04-10 17:31:25 - INFO - TRAINING - Epoch: [109][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0887 (0.0952)	Prec@1 96.000 (96.821)	Prec@5 100.000 (99.989)
2019-04-10 17:31:28 - INFO - TRAINING - Epoch: [109][400/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0630 (0.0961)	Prec@1 98.000 (96.793)	Prec@5 100.000 (99.985)
2019-04-10 17:31:30 - INFO - EVALUATING - Epoch: [109][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.3617 (0.3617)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:31:31 - INFO - EVALUATING - Epoch: [109][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2857 (0.2857)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:31:32 - INFO - EVALUATING - Epoch: [109][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2497 (0.3791)	Prec@1 92.000 (89.412)	Prec@5 100.000 (99.471)
2019-04-10 17:31:33 - INFO - 
 Epoch: 110	Training Loss 0.0957 	Training Prec@1 96.789 	Training Prec@5 99.987 	Validation Loss 0.3618 	Validation Prec@1 90.060 	Validation Prec@5 99.560 	Test Loss 0.3716 	Test Prec@1  89.490 	Test Prec@5  99.530 

2019-04-10 17:31:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:31:33 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:31:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:31:33 - INFO - TRAINING - Epoch: [110][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0739 (0.0739)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:31:36 - INFO - TRAINING - Epoch: [110][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1605 (0.0948)	Prec@1 95.000 (96.706)	Prec@5 100.000 (100.000)
2019-04-10 17:31:39 - INFO - TRAINING - Epoch: [110][100/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.1945 (0.0901)	Prec@1 95.000 (96.950)	Prec@5 100.000 (100.000)
2019-04-10 17:31:42 - INFO - TRAINING - Epoch: [110][150/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1665 (0.0933)	Prec@1 94.000 (96.901)	Prec@5 100.000 (100.000)
2019-04-10 17:31:44 - INFO - TRAINING - Epoch: [110][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.0453 (0.0935)	Prec@1 97.000 (96.876)	Prec@5 100.000 (100.000)
2019-04-10 17:31:47 - INFO - TRAINING - Epoch: [110][250/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.0362 (0.0900)	Prec@1 99.000 (96.976)	Prec@5 100.000 (100.000)
2019-04-10 17:31:50 - INFO - TRAINING - Epoch: [110][300/450]	Time 0.049 (0.055)	Data 0.022 (0.014)	Loss 0.0917 (0.0897)	Prec@1 98.000 (96.990)	Prec@5 100.000 (100.000)
2019-04-10 17:31:52 - INFO - TRAINING - Epoch: [110][350/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.0768 (0.0906)	Prec@1 96.000 (96.952)	Prec@5 100.000 (99.994)
2019-04-10 17:31:55 - INFO - TRAINING - Epoch: [110][400/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1804 (0.0900)	Prec@1 93.000 (96.940)	Prec@5 100.000 (99.995)
2019-04-10 17:31:58 - INFO - EVALUATING - Epoch: [110][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4527 (0.4527)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:31:59 - INFO - EVALUATING - Epoch: [110][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3351 (0.3351)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:32:00 - INFO - EVALUATING - Epoch: [110][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2242 (0.3742)	Prec@1 94.000 (89.549)	Prec@5 100.000 (99.549)
2019-04-10 17:32:00 - INFO - 
 Epoch: 111	Training Loss 0.0905 	Training Prec@1 96.900 	Training Prec@5 99.996 	Validation Loss 0.3732 	Validation Prec@1 89.320 	Validation Prec@5 99.740 	Test Loss 0.3769 	Test Prec@1  89.610 	Test Prec@5  99.580 

2019-04-10 17:32:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:32:01 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:32:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:32:01 - INFO - TRAINING - Epoch: [111][0/450]	Time 0.034 (0.034)	Data 0.013 (0.013)	Loss 0.0671 (0.0671)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:32:03 - INFO - TRAINING - Epoch: [111][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.0639 (0.1031)	Prec@1 97.000 (96.471)	Prec@5 100.000 (100.000)
2019-04-10 17:32:06 - INFO - TRAINING - Epoch: [111][100/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0550 (0.1000)	Prec@1 99.000 (96.436)	Prec@5 100.000 (100.000)
2019-04-10 17:32:09 - INFO - TRAINING - Epoch: [111][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0688 (0.0987)	Prec@1 98.000 (96.510)	Prec@5 100.000 (100.000)
2019-04-10 17:32:11 - INFO - TRAINING - Epoch: [111][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0375 (0.0964)	Prec@1 99.000 (96.627)	Prec@5 100.000 (100.000)
2019-04-10 17:32:14 - INFO - TRAINING - Epoch: [111][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1273 (0.0940)	Prec@1 96.000 (96.709)	Prec@5 100.000 (99.996)
2019-04-10 17:32:17 - INFO - TRAINING - Epoch: [111][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0403 (0.0926)	Prec@1 98.000 (96.794)	Prec@5 100.000 (99.997)
2019-04-10 17:32:20 - INFO - TRAINING - Epoch: [111][350/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1015 (0.0929)	Prec@1 96.000 (96.803)	Prec@5 100.000 (99.991)
2019-04-10 17:32:22 - INFO - TRAINING - Epoch: [111][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0755 (0.0944)	Prec@1 96.000 (96.791)	Prec@5 100.000 (99.988)
2019-04-10 17:32:25 - INFO - EVALUATING - Epoch: [111][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.2764 (0.2764)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:32:26 - INFO - EVALUATING - Epoch: [111][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3194 (0.3194)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:32:27 - INFO - EVALUATING - Epoch: [111][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1863 (0.3587)	Prec@1 95.000 (89.882)	Prec@5 100.000 (99.549)
2019-04-10 17:32:28 - INFO - 
 Epoch: 112	Training Loss 0.0936 	Training Prec@1 96.813 	Training Prec@5 99.989 	Validation Loss 0.3439 	Validation Prec@1 89.860 	Validation Prec@5 99.640 	Test Loss 0.3564 	Test Prec@1  89.620 	Test Prec@5  99.570 

2019-04-10 17:32:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:32:28 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:32:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:32:28 - INFO - TRAINING - Epoch: [112][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0953 (0.0953)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:32:31 - INFO - TRAINING - Epoch: [112][50/450]	Time 0.055 (0.053)	Data 0.014 (0.015)	Loss 0.1772 (0.0921)	Prec@1 93.000 (96.745)	Prec@5 100.000 (100.000)
2019-04-10 17:32:33 - INFO - TRAINING - Epoch: [112][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1396 (0.0930)	Prec@1 96.000 (96.752)	Prec@5 100.000 (100.000)
2019-04-10 17:32:36 - INFO - TRAINING - Epoch: [112][150/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0395 (0.0877)	Prec@1 99.000 (96.921)	Prec@5 100.000 (100.000)
2019-04-10 17:32:39 - INFO - TRAINING - Epoch: [112][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1108 (0.0863)	Prec@1 95.000 (97.030)	Prec@5 100.000 (99.995)
2019-04-10 17:32:42 - INFO - TRAINING - Epoch: [112][250/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0682 (0.0872)	Prec@1 97.000 (97.040)	Prec@5 100.000 (99.996)
2019-04-10 17:32:44 - INFO - TRAINING - Epoch: [112][300/450]	Time 0.057 (0.055)	Data 0.012 (0.014)	Loss 0.0689 (0.0888)	Prec@1 98.000 (96.963)	Prec@5 100.000 (99.993)
2019-04-10 17:32:47 - INFO - TRAINING - Epoch: [112][350/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.0321 (0.0888)	Prec@1 100.000 (96.954)	Prec@5 100.000 (99.994)
2019-04-10 17:32:50 - INFO - TRAINING - Epoch: [112][400/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.1533 (0.0890)	Prec@1 92.000 (96.935)	Prec@5 100.000 (99.990)
2019-04-10 17:32:53 - INFO - EVALUATING - Epoch: [112][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3412 (0.3412)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:32:54 - INFO - EVALUATING - Epoch: [112][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2849 (0.2849)	Prec@1 94.000 (94.000)	Prec@5 98.000 (98.000)
2019-04-10 17:32:54 - INFO - EVALUATING - Epoch: [112][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.3853 (0.3804)	Prec@1 89.000 (89.314)	Prec@5 100.000 (99.490)
2019-04-10 17:32:55 - INFO - 
 Epoch: 113	Training Loss 0.0881 	Training Prec@1 96.953 	Training Prec@5 99.989 	Validation Loss 0.3535 	Validation Prec@1 90.000 	Validation Prec@5 99.680 	Test Loss 0.3799 	Test Prec@1  89.370 	Test Prec@5  99.570 

2019-04-10 17:32:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:32:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:32:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:32:56 - INFO - TRAINING - Epoch: [113][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1265 (0.1265)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:32:58 - INFO - TRAINING - Epoch: [113][50/450]	Time 0.054 (0.055)	Data 0.017 (0.014)	Loss 0.0484 (0.0917)	Prec@1 98.000 (96.725)	Prec@5 100.000 (99.980)
2019-04-10 17:33:01 - INFO - TRAINING - Epoch: [113][100/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.0789 (0.0907)	Prec@1 96.000 (96.762)	Prec@5 100.000 (99.980)
2019-04-10 17:33:04 - INFO - TRAINING - Epoch: [113][150/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1542 (0.0870)	Prec@1 93.000 (96.934)	Prec@5 100.000 (99.987)
2019-04-10 17:33:06 - INFO - TRAINING - Epoch: [113][200/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1191 (0.0863)	Prec@1 94.000 (96.990)	Prec@5 100.000 (99.990)
2019-04-10 17:33:09 - INFO - TRAINING - Epoch: [113][250/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.0454 (0.0848)	Prec@1 99.000 (97.048)	Prec@5 100.000 (99.988)
2019-04-10 17:33:12 - INFO - TRAINING - Epoch: [113][300/450]	Time 0.053 (0.054)	Data 0.015 (0.014)	Loss 0.0411 (0.0863)	Prec@1 98.000 (96.973)	Prec@5 100.000 (99.990)
2019-04-10 17:33:15 - INFO - TRAINING - Epoch: [113][350/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.1141 (0.0855)	Prec@1 95.000 (97.006)	Prec@5 100.000 (99.986)
2019-04-10 17:33:17 - INFO - TRAINING - Epoch: [113][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0725 (0.0859)	Prec@1 98.000 (97.010)	Prec@5 100.000 (99.985)
2019-04-10 17:33:20 - INFO - EVALUATING - Epoch: [113][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.1182 (0.1182)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:33:21 - INFO - EVALUATING - Epoch: [113][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2862 (0.2862)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:33:22 - INFO - EVALUATING - Epoch: [113][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3058 (0.3687)	Prec@1 89.000 (89.686)	Prec@5 99.000 (99.549)
2019-04-10 17:33:23 - INFO - 
 Epoch: 114	Training Loss 0.0882 	Training Prec@1 96.929 	Training Prec@5 99.987 	Validation Loss 0.3484 	Validation Prec@1 89.880 	Validation Prec@5 99.620 	Test Loss 0.3674 	Test Prec@1  89.670 	Test Prec@5  99.620 

2019-04-10 17:33:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:33:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:33:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:33:23 - INFO - TRAINING - Epoch: [114][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1716 (0.1716)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:33:26 - INFO - TRAINING - Epoch: [114][50/450]	Time 0.057 (0.056)	Data 0.013 (0.014)	Loss 0.0319 (0.0843)	Prec@1 99.000 (96.961)	Prec@5 100.000 (99.980)
2019-04-10 17:33:29 - INFO - TRAINING - Epoch: [114][100/450]	Time 0.057 (0.056)	Data 0.015 (0.015)	Loss 0.1298 (0.0824)	Prec@1 93.000 (96.881)	Prec@5 100.000 (99.990)
2019-04-10 17:33:31 - INFO - TRAINING - Epoch: [114][150/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0459 (0.0856)	Prec@1 99.000 (96.821)	Prec@5 100.000 (99.993)
2019-04-10 17:33:34 - INFO - TRAINING - Epoch: [114][200/450]	Time 0.056 (0.056)	Data 0.014 (0.015)	Loss 0.0565 (0.0877)	Prec@1 99.000 (96.856)	Prec@5 100.000 (99.995)
2019-04-10 17:33:37 - INFO - TRAINING - Epoch: [114][250/450]	Time 0.054 (0.055)	Data 0.022 (0.015)	Loss 0.0816 (0.0872)	Prec@1 97.000 (96.865)	Prec@5 100.000 (99.996)
2019-04-10 17:33:40 - INFO - TRAINING - Epoch: [114][300/450]	Time 0.059 (0.055)	Data 0.014 (0.015)	Loss 0.0652 (0.0880)	Prec@1 99.000 (96.867)	Prec@5 100.000 (99.990)
2019-04-10 17:33:42 - INFO - TRAINING - Epoch: [114][350/450]	Time 0.053 (0.055)	Data 0.014 (0.015)	Loss 0.1005 (0.0887)	Prec@1 98.000 (96.812)	Prec@5 100.000 (99.991)
2019-04-10 17:33:45 - INFO - TRAINING - Epoch: [114][400/450]	Time 0.054 (0.055)	Data 0.014 (0.015)	Loss 0.0997 (0.0871)	Prec@1 95.000 (96.870)	Prec@5 100.000 (99.990)
2019-04-10 17:33:48 - INFO - EVALUATING - Epoch: [114][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4370 (0.4370)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-04-10 17:33:48 - INFO - EVALUATING - Epoch: [114][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3032 (0.3032)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:33:49 - INFO - EVALUATING - Epoch: [114][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2181 (0.3599)	Prec@1 92.000 (90.176)	Prec@5 100.000 (99.392)
2019-04-10 17:33:50 - INFO - 
 Epoch: 115	Training Loss 0.0871 	Training Prec@1 96.878 	Training Prec@5 99.991 	Validation Loss 0.3486 	Validation Prec@1 90.040 	Validation Prec@5 99.720 	Test Loss 0.3663 	Test Prec@1  89.810 	Test Prec@5  99.450 

2019-04-10 17:33:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:33:50 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:33:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:33:50 - INFO - TRAINING - Epoch: [115][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0524 (0.0524)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:33:53 - INFO - TRAINING - Epoch: [115][50/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.1393 (0.0766)	Prec@1 96.000 (97.196)	Prec@5 100.000 (100.000)
2019-04-10 17:33:56 - INFO - TRAINING - Epoch: [115][100/450]	Time 0.052 (0.054)	Data 0.014 (0.014)	Loss 0.1066 (0.0809)	Prec@1 96.000 (97.248)	Prec@5 100.000 (100.000)
2019-04-10 17:33:59 - INFO - TRAINING - Epoch: [115][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1043 (0.0799)	Prec@1 96.000 (97.212)	Prec@5 100.000 (100.000)
2019-04-10 17:34:01 - INFO - TRAINING - Epoch: [115][200/450]	Time 0.059 (0.054)	Data 0.013 (0.014)	Loss 0.0493 (0.0778)	Prec@1 99.000 (97.289)	Prec@5 100.000 (100.000)
2019-04-10 17:34:04 - INFO - TRAINING - Epoch: [115][250/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.0216 (0.0802)	Prec@1 99.000 (97.235)	Prec@5 100.000 (99.988)
2019-04-10 17:34:07 - INFO - TRAINING - Epoch: [115][300/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.1314 (0.0803)	Prec@1 96.000 (97.246)	Prec@5 100.000 (99.990)
2019-04-10 17:34:10 - INFO - TRAINING - Epoch: [115][350/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.1005 (0.0816)	Prec@1 96.000 (97.199)	Prec@5 100.000 (99.991)
2019-04-10 17:34:12 - INFO - TRAINING - Epoch: [115][400/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.0363 (0.0808)	Prec@1 99.000 (97.264)	Prec@5 100.000 (99.990)
2019-04-10 17:34:15 - INFO - EVALUATING - Epoch: [115][0/50]	Time 0.037 (0.037)	Data 0.012 (0.012)	Loss 0.2165 (0.2165)	Prec@1 96.000 (96.000)	Prec@5 98.000 (98.000)
2019-04-10 17:34:16 - INFO - EVALUATING - Epoch: [115][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.1606 (0.1606)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:34:17 - INFO - EVALUATING - Epoch: [115][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2374 (0.3584)	Prec@1 91.000 (89.627)	Prec@5 100.000 (99.471)
2019-04-10 17:34:18 - INFO - 
 Epoch: 116	Training Loss 0.0825 	Training Prec@1 97.198 	Training Prec@5 99.991 	Validation Loss 0.3563 	Validation Prec@1 90.060 	Validation Prec@5 99.600 	Test Loss 0.3638 	Test Prec@1  89.660 	Test Prec@5  99.570 

2019-04-10 17:34:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:34:18 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:34:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:34:18 - INFO - TRAINING - Epoch: [116][0/450]	Time 0.032 (0.032)	Data 0.013 (0.013)	Loss 0.2840 (0.2840)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:34:21 - INFO - TRAINING - Epoch: [116][50/450]	Time 0.054 (0.055)	Data 0.012 (0.013)	Loss 0.0454 (0.0876)	Prec@1 98.000 (97.137)	Prec@5 100.000 (100.000)
2019-04-10 17:34:23 - INFO - TRAINING - Epoch: [116][100/450]	Time 0.054 (0.055)	Data 0.012 (0.013)	Loss 0.0394 (0.0860)	Prec@1 98.000 (97.109)	Prec@5 100.000 (99.980)
2019-04-10 17:34:26 - INFO - TRAINING - Epoch: [116][150/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.1068 (0.0816)	Prec@1 97.000 (97.199)	Prec@5 100.000 (99.980)
2019-04-10 17:34:29 - INFO - TRAINING - Epoch: [116][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0578 (0.0795)	Prec@1 98.000 (97.299)	Prec@5 100.000 (99.985)
2019-04-10 17:34:31 - INFO - TRAINING - Epoch: [116][250/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0314 (0.0826)	Prec@1 99.000 (97.163)	Prec@5 100.000 (99.988)
2019-04-10 17:34:34 - INFO - TRAINING - Epoch: [116][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0792 (0.0828)	Prec@1 96.000 (97.156)	Prec@5 100.000 (99.983)
2019-04-10 17:34:37 - INFO - TRAINING - Epoch: [116][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0916 (0.0835)	Prec@1 97.000 (97.111)	Prec@5 100.000 (99.986)
2019-04-10 17:34:39 - INFO - TRAINING - Epoch: [116][400/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0401 (0.0832)	Prec@1 99.000 (97.130)	Prec@5 100.000 (99.985)
2019-04-10 17:34:42 - INFO - EVALUATING - Epoch: [116][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.2505 (0.2505)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:34:43 - INFO - EVALUATING - Epoch: [116][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.2351 (0.2351)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:34:44 - INFO - EVALUATING - Epoch: [116][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2273 (0.3621)	Prec@1 93.000 (89.373)	Prec@5 100.000 (99.667)
2019-04-10 17:34:45 - INFO - 
 Epoch: 117	Training Loss 0.0831 	Training Prec@1 97.131 	Training Prec@5 99.984 	Validation Loss 0.3526 	Validation Prec@1 90.040 	Validation Prec@5 99.600 	Test Loss 0.3639 	Test Prec@1  89.640 	Test Prec@5  99.660 

2019-04-10 17:34:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:34:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:34:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:34:45 - INFO - TRAINING - Epoch: [117][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0897 (0.0897)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:34:48 - INFO - TRAINING - Epoch: [117][50/450]	Time 0.059 (0.056)	Data 0.012 (0.014)	Loss 0.0965 (0.0783)	Prec@1 98.000 (97.216)	Prec@5 100.000 (99.961)
2019-04-10 17:34:51 - INFO - TRAINING - Epoch: [117][100/450]	Time 0.053 (0.055)	Data 0.015 (0.015)	Loss 0.0424 (0.0842)	Prec@1 99.000 (97.089)	Prec@5 100.000 (99.980)
2019-04-10 17:34:53 - INFO - TRAINING - Epoch: [117][150/450]	Time 0.054 (0.055)	Data 0.016 (0.015)	Loss 0.0364 (0.0832)	Prec@1 98.000 (97.099)	Prec@5 100.000 (99.987)
2019-04-10 17:34:56 - INFO - TRAINING - Epoch: [117][200/450]	Time 0.052 (0.055)	Data 0.012 (0.015)	Loss 0.0594 (0.0829)	Prec@1 98.000 (97.174)	Prec@5 100.000 (99.990)
2019-04-10 17:34:59 - INFO - TRAINING - Epoch: [117][250/450]	Time 0.052 (0.054)	Data 0.013 (0.015)	Loss 0.1333 (0.0830)	Prec@1 95.000 (97.116)	Prec@5 100.000 (99.992)
2019-04-10 17:35:01 - INFO - TRAINING - Epoch: [117][300/450]	Time 0.055 (0.054)	Data 0.012 (0.015)	Loss 0.0976 (0.0848)	Prec@1 97.000 (97.096)	Prec@5 100.000 (99.993)
2019-04-10 17:35:04 - INFO - TRAINING - Epoch: [117][350/450]	Time 0.056 (0.055)	Data 0.012 (0.015)	Loss 0.0409 (0.0846)	Prec@1 98.000 (97.120)	Prec@5 100.000 (99.994)
2019-04-10 17:35:07 - INFO - TRAINING - Epoch: [117][400/450]	Time 0.058 (0.055)	Data 0.012 (0.015)	Loss 0.1306 (0.0865)	Prec@1 95.000 (97.037)	Prec@5 100.000 (99.990)
2019-04-10 17:35:10 - INFO - EVALUATING - Epoch: [117][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.3038 (0.3038)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:35:11 - INFO - EVALUATING - Epoch: [117][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3272 (0.3272)	Prec@1 90.000 (90.000)	Prec@5 98.000 (98.000)
2019-04-10 17:35:11 - INFO - EVALUATING - Epoch: [117][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2787 (0.3747)	Prec@1 92.000 (89.412)	Prec@5 100.000 (99.529)
2019-04-10 17:35:12 - INFO - 
 Epoch: 118	Training Loss 0.0859 	Training Prec@1 97.060 	Training Prec@5 99.991 	Validation Loss 0.3706 	Validation Prec@1 89.540 	Validation Prec@5 99.660 	Test Loss 0.3707 	Test Prec@1  89.540 	Test Prec@5  99.540 

2019-04-10 17:35:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:35:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:35:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:35:13 - INFO - TRAINING - Epoch: [118][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0754 (0.0754)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:35:15 - INFO - TRAINING - Epoch: [118][50/450]	Time 0.056 (0.055)	Data 0.013 (0.014)	Loss 0.0883 (0.0856)	Prec@1 95.000 (96.980)	Prec@5 100.000 (100.000)
2019-04-10 17:35:18 - INFO - TRAINING - Epoch: [118][100/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0978 (0.0824)	Prec@1 96.000 (97.099)	Prec@5 100.000 (100.000)
2019-04-10 17:35:21 - INFO - TRAINING - Epoch: [118][150/450]	Time 0.055 (0.054)	Data 0.015 (0.014)	Loss 0.1113 (0.0814)	Prec@1 96.000 (97.113)	Prec@5 100.000 (100.000)
2019-04-10 17:35:23 - INFO - TRAINING - Epoch: [118][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0400 (0.0805)	Prec@1 100.000 (97.179)	Prec@5 100.000 (99.995)
2019-04-10 17:35:26 - INFO - TRAINING - Epoch: [118][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0127 (0.0809)	Prec@1 100.000 (97.203)	Prec@5 100.000 (99.996)
2019-04-10 17:35:29 - INFO - TRAINING - Epoch: [118][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1064 (0.0809)	Prec@1 95.000 (97.226)	Prec@5 100.000 (99.993)
2019-04-10 17:35:32 - INFO - TRAINING - Epoch: [118][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0849 (0.0817)	Prec@1 97.000 (97.194)	Prec@5 100.000 (99.994)
2019-04-10 17:35:34 - INFO - TRAINING - Epoch: [118][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0237 (0.0823)	Prec@1 100.000 (97.182)	Prec@5 100.000 (99.995)
2019-04-10 17:35:37 - INFO - EVALUATING - Epoch: [118][0/50]	Time 0.040 (0.040)	Data 0.012 (0.012)	Loss 0.3789 (0.3789)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:35:38 - INFO - EVALUATING - Epoch: [118][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3128 (0.3128)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:35:39 - INFO - EVALUATING - Epoch: [118][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2923 (0.3624)	Prec@1 91.000 (89.980)	Prec@5 100.000 (99.608)
2019-04-10 17:35:40 - INFO - 
 Epoch: 119	Training Loss 0.0820 	Training Prec@1 97.211 	Training Prec@5 99.996 	Validation Loss 0.3424 	Validation Prec@1 90.500 	Validation Prec@5 99.780 	Test Loss 0.3650 	Test Prec@1  89.960 	Test Prec@5  99.660 

2019-04-10 17:35:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:35:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:35:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:35:40 - INFO - TRAINING - Epoch: [119][0/450]	Time 0.035 (0.035)	Data 0.013 (0.013)	Loss 0.0569 (0.0569)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:35:42 - INFO - TRAINING - Epoch: [119][50/450]	Time 0.055 (0.053)	Data 0.014 (0.015)	Loss 0.0695 (0.0765)	Prec@1 97.000 (97.490)	Prec@5 100.000 (100.000)
2019-04-10 17:35:45 - INFO - TRAINING - Epoch: [119][100/450]	Time 0.054 (0.053)	Data 0.014 (0.015)	Loss 0.0365 (0.0787)	Prec@1 99.000 (97.347)	Prec@5 100.000 (99.990)
2019-04-10 17:35:48 - INFO - TRAINING - Epoch: [119][150/450]	Time 0.056 (0.053)	Data 0.014 (0.015)	Loss 0.1067 (0.0791)	Prec@1 97.000 (97.311)	Prec@5 100.000 (99.993)
2019-04-10 17:35:51 - INFO - TRAINING - Epoch: [119][200/450]	Time 0.055 (0.054)	Data 0.013 (0.015)	Loss 0.0500 (0.0779)	Prec@1 99.000 (97.353)	Prec@5 100.000 (99.995)
2019-04-10 17:35:53 - INFO - TRAINING - Epoch: [119][250/450]	Time 0.055 (0.054)	Data 0.013 (0.015)	Loss 0.1481 (0.0782)	Prec@1 93.000 (97.327)	Prec@5 100.000 (99.996)
2019-04-10 17:35:56 - INFO - TRAINING - Epoch: [119][300/450]	Time 0.055 (0.054)	Data 0.028 (0.015)	Loss 0.1069 (0.0772)	Prec@1 96.000 (97.405)	Prec@5 99.000 (99.990)
2019-04-10 17:35:59 - INFO - TRAINING - Epoch: [119][350/450]	Time 0.053 (0.054)	Data 0.013 (0.015)	Loss 0.1061 (0.0779)	Prec@1 96.000 (97.385)	Prec@5 100.000 (99.991)
2019-04-10 17:36:01 - INFO - TRAINING - Epoch: [119][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1164 (0.0793)	Prec@1 96.000 (97.334)	Prec@5 100.000 (99.993)
2019-04-10 17:36:04 - INFO - EVALUATING - Epoch: [119][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.1979 (0.1979)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:36:05 - INFO - EVALUATING - Epoch: [119][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3368 (0.3368)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:36:06 - INFO - EVALUATING - Epoch: [119][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1591 (0.3678)	Prec@1 94.000 (89.882)	Prec@5 100.000 (99.529)
2019-04-10 17:36:07 - INFO - 
 Epoch: 120	Training Loss 0.0789 	Training Prec@1 97.318 	Training Prec@5 99.993 	Validation Loss 0.3450 	Validation Prec@1 90.500 	Validation Prec@5 99.560 	Test Loss 0.3703 	Test Prec@1  89.810 	Test Prec@5  99.530 

2019-04-10 17:36:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:36:07 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:36:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:36:07 - INFO - TRAINING - Epoch: [120][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1147 (0.1147)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:36:10 - INFO - TRAINING - Epoch: [120][50/450]	Time 0.055 (0.056)	Data 0.013 (0.015)	Loss 0.0783 (0.0817)	Prec@1 97.000 (97.137)	Prec@5 100.000 (100.000)
2019-04-10 17:36:13 - INFO - TRAINING - Epoch: [120][100/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0519 (0.0805)	Prec@1 98.000 (97.059)	Prec@5 100.000 (100.000)
2019-04-10 17:36:16 - INFO - TRAINING - Epoch: [120][150/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.0500 (0.0800)	Prec@1 98.000 (97.106)	Prec@5 100.000 (99.980)
2019-04-10 17:36:18 - INFO - TRAINING - Epoch: [120][200/450]	Time 0.062 (0.056)	Data 0.014 (0.014)	Loss 0.1069 (0.0785)	Prec@1 97.000 (97.224)	Prec@5 100.000 (99.985)
2019-04-10 17:36:21 - INFO - TRAINING - Epoch: [120][250/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0732 (0.0780)	Prec@1 97.000 (97.275)	Prec@5 100.000 (99.988)
2019-04-10 17:36:24 - INFO - TRAINING - Epoch: [120][300/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0397 (0.0776)	Prec@1 98.000 (97.236)	Prec@5 100.000 (99.990)
2019-04-10 17:36:26 - INFO - TRAINING - Epoch: [120][350/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0359 (0.0772)	Prec@1 99.000 (97.288)	Prec@5 100.000 (99.991)
2019-04-10 17:36:29 - INFO - TRAINING - Epoch: [120][400/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0508 (0.0772)	Prec@1 97.000 (97.269)	Prec@5 100.000 (99.993)
2019-04-10 17:36:32 - INFO - EVALUATING - Epoch: [120][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.6132 (0.6132)	Prec@1 86.000 (86.000)	Prec@5 98.000 (98.000)
2019-04-10 17:36:33 - INFO - EVALUATING - Epoch: [120][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3207 (0.3207)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:36:34 - INFO - EVALUATING - Epoch: [120][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2960 (0.3751)	Prec@1 91.000 (89.686)	Prec@5 100.000 (99.588)
2019-04-10 17:36:34 - INFO - 
 Epoch: 121	Training Loss 0.0777 	Training Prec@1 97.258 	Training Prec@5 99.993 	Validation Loss 0.3609 	Validation Prec@1 89.680 	Validation Prec@5 99.580 	Test Loss 0.3756 	Test Prec@1  89.660 	Test Prec@5  99.580 

2019-04-10 17:36:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:36:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:36:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:36:35 - INFO - TRAINING - Epoch: [121][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0876 (0.0876)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:36:37 - INFO - TRAINING - Epoch: [121][50/450]	Time 0.056 (0.055)	Data 0.013 (0.015)	Loss 0.0723 (0.0725)	Prec@1 97.000 (97.294)	Prec@5 100.000 (100.000)
2019-04-10 17:36:40 - INFO - TRAINING - Epoch: [121][100/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0773 (0.0734)	Prec@1 96.000 (97.297)	Prec@5 100.000 (100.000)
2019-04-10 17:36:43 - INFO - TRAINING - Epoch: [121][150/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0986 (0.0747)	Prec@1 97.000 (97.285)	Prec@5 100.000 (100.000)
2019-04-10 17:36:46 - INFO - TRAINING - Epoch: [121][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0812 (0.0742)	Prec@1 97.000 (97.348)	Prec@5 100.000 (100.000)
2019-04-10 17:36:49 - INFO - TRAINING - Epoch: [121][250/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0513 (0.0767)	Prec@1 99.000 (97.319)	Prec@5 100.000 (100.000)
2019-04-10 17:36:51 - INFO - TRAINING - Epoch: [121][300/450]	Time 0.065 (0.056)	Data 0.012 (0.014)	Loss 0.1653 (0.0781)	Prec@1 95.000 (97.272)	Prec@5 99.000 (99.990)
2019-04-10 17:36:54 - INFO - TRAINING - Epoch: [121][350/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0722 (0.0785)	Prec@1 99.000 (97.205)	Prec@5 100.000 (99.991)
2019-04-10 17:36:57 - INFO - TRAINING - Epoch: [121][400/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.1960 (0.0783)	Prec@1 93.000 (97.237)	Prec@5 100.000 (99.988)
2019-04-10 17:37:00 - INFO - EVALUATING - Epoch: [121][0/50]	Time 0.044 (0.044)	Data 0.012 (0.012)	Loss 0.4690 (0.4690)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:01 - INFO - EVALUATING - Epoch: [121][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2845 (0.2845)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:02 - INFO - EVALUATING - Epoch: [121][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2125 (0.3870)	Prec@1 90.000 (89.490)	Prec@5 100.000 (99.333)
2019-04-10 17:37:03 - INFO - 
 Epoch: 122	Training Loss 0.0784 	Training Prec@1 97.220 	Training Prec@5 99.989 	Validation Loss 0.3565 	Validation Prec@1 90.200 	Validation Prec@5 99.620 	Test Loss 0.3782 	Test Prec@1  89.570 	Test Prec@5  99.510 

2019-04-10 17:37:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:37:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:37:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:37:03 - INFO - TRAINING - Epoch: [122][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0988 (0.0988)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:06 - INFO - TRAINING - Epoch: [122][50/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.0920 (0.0735)	Prec@1 98.000 (97.725)	Prec@5 100.000 (99.980)
2019-04-10 17:37:08 - INFO - TRAINING - Epoch: [122][100/450]	Time 0.053 (0.053)	Data 0.013 (0.014)	Loss 0.0810 (0.0730)	Prec@1 97.000 (97.564)	Prec@5 100.000 (99.990)
2019-04-10 17:37:11 - INFO - TRAINING - Epoch: [122][150/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.0610 (0.0758)	Prec@1 99.000 (97.411)	Prec@5 100.000 (99.993)
2019-04-10 17:37:14 - INFO - TRAINING - Epoch: [122][200/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.0600 (0.0768)	Prec@1 98.000 (97.428)	Prec@5 100.000 (99.995)
2019-04-10 17:37:16 - INFO - TRAINING - Epoch: [122][250/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0521 (0.0771)	Prec@1 98.000 (97.434)	Prec@5 100.000 (99.988)
2019-04-10 17:37:19 - INFO - TRAINING - Epoch: [122][300/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.0596 (0.0776)	Prec@1 98.000 (97.439)	Prec@5 100.000 (99.990)
2019-04-10 17:37:22 - INFO - TRAINING - Epoch: [122][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0469 (0.0769)	Prec@1 99.000 (97.430)	Prec@5 100.000 (99.991)
2019-04-10 17:37:24 - INFO - TRAINING - Epoch: [122][400/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0591 (0.0758)	Prec@1 99.000 (97.479)	Prec@5 100.000 (99.993)
2019-04-10 17:37:27 - INFO - EVALUATING - Epoch: [122][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3489 (0.3489)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:28 - INFO - EVALUATING - Epoch: [122][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3063 (0.3063)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:37:29 - INFO - EVALUATING - Epoch: [122][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2289 (0.3727)	Prec@1 91.000 (89.647)	Prec@5 100.000 (99.471)
2019-04-10 17:37:30 - INFO - 
 Epoch: 123	Training Loss 0.0745 	Training Prec@1 97.538 	Training Prec@5 99.993 	Validation Loss 0.3413 	Validation Prec@1 90.420 	Validation Prec@5 99.740 	Test Loss 0.3646 	Test Prec@1  89.790 	Test Prec@5  99.590 

2019-04-10 17:37:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:37:30 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:37:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:37:30 - INFO - TRAINING - Epoch: [123][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1610 (0.1610)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:32 - INFO - TRAINING - Epoch: [123][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.0705 (0.0797)	Prec@1 98.000 (97.431)	Prec@5 100.000 (100.000)
2019-04-10 17:37:35 - INFO - TRAINING - Epoch: [123][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0641 (0.0818)	Prec@1 99.000 (97.307)	Prec@5 100.000 (99.990)
2019-04-10 17:37:38 - INFO - TRAINING - Epoch: [123][150/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0671 (0.0767)	Prec@1 97.000 (97.450)	Prec@5 100.000 (99.993)
2019-04-10 17:37:41 - INFO - TRAINING - Epoch: [123][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0257 (0.0782)	Prec@1 99.000 (97.433)	Prec@5 100.000 (99.995)
2019-04-10 17:37:43 - INFO - TRAINING - Epoch: [123][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1233 (0.0777)	Prec@1 95.000 (97.430)	Prec@5 100.000 (99.996)
2019-04-10 17:37:46 - INFO - TRAINING - Epoch: [123][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0529 (0.0787)	Prec@1 99.000 (97.382)	Prec@5 100.000 (99.997)
2019-04-10 17:37:49 - INFO - TRAINING - Epoch: [123][350/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.1423 (0.0798)	Prec@1 97.000 (97.311)	Prec@5 100.000 (99.994)
2019-04-10 17:37:51 - INFO - TRAINING - Epoch: [123][400/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0840 (0.0784)	Prec@1 97.000 (97.342)	Prec@5 100.000 (99.993)
2019-04-10 17:37:54 - INFO - EVALUATING - Epoch: [123][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.4383 (0.4383)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:37:55 - INFO - EVALUATING - Epoch: [123][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3275 (0.3275)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:37:56 - INFO - EVALUATING - Epoch: [123][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2584 (0.3546)	Prec@1 93.000 (90.098)	Prec@5 99.000 (99.627)
2019-04-10 17:37:57 - INFO - 
 Epoch: 124	Training Loss 0.0791 	Training Prec@1 97.309 	Training Prec@5 99.991 	Validation Loss 0.3504 	Validation Prec@1 90.340 	Validation Prec@5 99.580 	Test Loss 0.3533 	Test Prec@1  89.920 	Test Prec@5  99.650 

2019-04-10 17:37:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:37:57 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:37:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:37:57 - INFO - TRAINING - Epoch: [124][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1194 (0.1194)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:38:00 - INFO - TRAINING - Epoch: [124][50/450]	Time 0.055 (0.053)	Data 0.013 (0.014)	Loss 0.0499 (0.0784)	Prec@1 99.000 (97.647)	Prec@5 100.000 (100.000)
2019-04-10 17:38:02 - INFO - TRAINING - Epoch: [124][100/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0539 (0.0777)	Prec@1 98.000 (97.465)	Prec@5 100.000 (99.990)
2019-04-10 17:38:05 - INFO - TRAINING - Epoch: [124][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0864 (0.0766)	Prec@1 98.000 (97.430)	Prec@5 100.000 (99.980)
2019-04-10 17:38:08 - INFO - TRAINING - Epoch: [124][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0218 (0.0743)	Prec@1 99.000 (97.527)	Prec@5 100.000 (99.980)
2019-04-10 17:38:10 - INFO - TRAINING - Epoch: [124][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0435 (0.0759)	Prec@1 98.000 (97.386)	Prec@5 100.000 (99.980)
2019-04-10 17:38:13 - INFO - TRAINING - Epoch: [124][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0636 (0.0742)	Prec@1 96.000 (97.439)	Prec@5 100.000 (99.983)
2019-04-10 17:38:16 - INFO - TRAINING - Epoch: [124][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0627 (0.0742)	Prec@1 98.000 (97.407)	Prec@5 100.000 (99.986)
2019-04-10 17:38:18 - INFO - TRAINING - Epoch: [124][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0891 (0.0746)	Prec@1 97.000 (97.424)	Prec@5 100.000 (99.988)
2019-04-10 17:38:21 - INFO - EVALUATING - Epoch: [124][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.5453 (0.5453)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 17:38:22 - INFO - EVALUATING - Epoch: [124][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2858 (0.2858)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:38:23 - INFO - EVALUATING - Epoch: [124][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1813 (0.3638)	Prec@1 95.000 (90.216)	Prec@5 100.000 (99.451)
2019-04-10 17:38:24 - INFO - 
 Epoch: 125	Training Loss 0.0752 	Training Prec@1 97.384 	Training Prec@5 99.989 	Validation Loss 0.3521 	Validation Prec@1 90.080 	Validation Prec@5 99.700 	Test Loss 0.3580 	Test Prec@1  90.130 	Test Prec@5  99.540 

2019-04-10 17:38:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:38:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:38:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:38:24 - INFO - TRAINING - Epoch: [125][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0840 (0.0840)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:38:27 - INFO - TRAINING - Epoch: [125][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0715 (0.0764)	Prec@1 97.000 (97.196)	Prec@5 100.000 (99.980)
2019-04-10 17:38:30 - INFO - TRAINING - Epoch: [125][100/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0653 (0.0698)	Prec@1 97.000 (97.564)	Prec@5 100.000 (99.990)
2019-04-10 17:38:32 - INFO - TRAINING - Epoch: [125][150/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.0222 (0.0678)	Prec@1 100.000 (97.728)	Prec@5 100.000 (99.993)
2019-04-10 17:38:35 - INFO - TRAINING - Epoch: [125][200/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0268 (0.0695)	Prec@1 99.000 (97.677)	Prec@5 100.000 (99.995)
2019-04-10 17:38:38 - INFO - TRAINING - Epoch: [125][250/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0609 (0.0718)	Prec@1 98.000 (97.614)	Prec@5 100.000 (99.996)
2019-04-10 17:38:40 - INFO - TRAINING - Epoch: [125][300/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0847 (0.0716)	Prec@1 98.000 (97.618)	Prec@5 100.000 (99.997)
2019-04-10 17:38:43 - INFO - TRAINING - Epoch: [125][350/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.0562 (0.0721)	Prec@1 99.000 (97.581)	Prec@5 100.000 (99.997)
2019-04-10 17:38:46 - INFO - TRAINING - Epoch: [125][400/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.1106 (0.0716)	Prec@1 96.000 (97.589)	Prec@5 100.000 (99.998)
2019-04-10 17:38:49 - INFO - EVALUATING - Epoch: [125][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3705 (0.3705)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:38:49 - INFO - EVALUATING - Epoch: [125][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3440 (0.3440)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:38:50 - INFO - EVALUATING - Epoch: [125][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3056 (0.3797)	Prec@1 88.000 (89.529)	Prec@5 100.000 (99.569)
2019-04-10 17:38:51 - INFO - 
 Epoch: 126	Training Loss 0.0714 	Training Prec@1 97.591 	Training Prec@5 99.998 	Validation Loss 0.3721 	Validation Prec@1 90.040 	Validation Prec@5 99.780 	Test Loss 0.3813 	Test Prec@1  89.550 	Test Prec@5  99.570 

2019-04-10 17:38:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:38:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:38:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:38:51 - INFO - TRAINING - Epoch: [126][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0684 (0.0684)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:38:54 - INFO - TRAINING - Epoch: [126][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1365 (0.0725)	Prec@1 95.000 (97.412)	Prec@5 100.000 (100.000)
2019-04-10 17:38:57 - INFO - TRAINING - Epoch: [126][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0457 (0.0682)	Prec@1 99.000 (97.624)	Prec@5 100.000 (100.000)
2019-04-10 17:39:00 - INFO - TRAINING - Epoch: [126][150/450]	Time 0.062 (0.054)	Data 0.014 (0.014)	Loss 0.0410 (0.0684)	Prec@1 98.000 (97.583)	Prec@5 100.000 (99.993)
2019-04-10 17:39:02 - INFO - TRAINING - Epoch: [126][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0177 (0.0704)	Prec@1 100.000 (97.488)	Prec@5 100.000 (99.995)
2019-04-10 17:39:05 - INFO - TRAINING - Epoch: [126][250/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0251 (0.0716)	Prec@1 100.000 (97.454)	Prec@5 100.000 (99.996)
2019-04-10 17:39:08 - INFO - TRAINING - Epoch: [126][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0297 (0.0718)	Prec@1 98.000 (97.462)	Prec@5 100.000 (99.997)
2019-04-10 17:39:10 - INFO - TRAINING - Epoch: [126][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0421 (0.0731)	Prec@1 99.000 (97.433)	Prec@5 100.000 (99.997)
2019-04-10 17:39:13 - INFO - TRAINING - Epoch: [126][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0879 (0.0731)	Prec@1 97.000 (97.436)	Prec@5 100.000 (99.995)
2019-04-10 17:39:16 - INFO - EVALUATING - Epoch: [126][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.3179 (0.3179)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:39:17 - INFO - EVALUATING - Epoch: [126][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3229 (0.3229)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:39:18 - INFO - EVALUATING - Epoch: [126][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2011 (0.3704)	Prec@1 93.000 (89.686)	Prec@5 100.000 (99.569)
2019-04-10 17:39:18 - INFO - 
 Epoch: 127	Training Loss 0.0733 	Training Prec@1 97.424 	Training Prec@5 99.996 	Validation Loss 0.3561 	Validation Prec@1 90.280 	Validation Prec@5 99.620 	Test Loss 0.3652 	Test Prec@1  89.960 	Test Prec@5  99.590 

2019-04-10 17:39:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:39:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:39:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:39:19 - INFO - TRAINING - Epoch: [127][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1051 (0.1051)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:39:21 - INFO - TRAINING - Epoch: [127][50/450]	Time 0.042 (0.056)	Data 0.022 (0.014)	Loss 0.0429 (0.0760)	Prec@1 98.000 (97.569)	Prec@5 100.000 (99.961)
2019-04-10 17:39:24 - INFO - TRAINING - Epoch: [127][100/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0127 (0.0722)	Prec@1 100.000 (97.683)	Prec@5 100.000 (99.970)
2019-04-10 17:39:27 - INFO - TRAINING - Epoch: [127][150/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0673 (0.0776)	Prec@1 97.000 (97.490)	Prec@5 100.000 (99.974)
2019-04-10 17:39:30 - INFO - TRAINING - Epoch: [127][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.1067 (0.0733)	Prec@1 95.000 (97.592)	Prec@5 100.000 (99.980)
2019-04-10 17:39:33 - INFO - TRAINING - Epoch: [127][250/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0330 (0.0722)	Prec@1 99.000 (97.566)	Prec@5 100.000 (99.984)
2019-04-10 17:39:36 - INFO - TRAINING - Epoch: [127][300/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.0448 (0.0723)	Prec@1 98.000 (97.561)	Prec@5 100.000 (99.987)
2019-04-10 17:39:38 - INFO - TRAINING - Epoch: [127][350/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0847 (0.0732)	Prec@1 98.000 (97.519)	Prec@5 100.000 (99.986)
2019-04-10 17:39:41 - INFO - TRAINING - Epoch: [127][400/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0354 (0.0737)	Prec@1 99.000 (97.491)	Prec@5 100.000 (99.988)
2019-04-10 17:39:44 - INFO - EVALUATING - Epoch: [127][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.1982 (0.1982)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:39:45 - INFO - EVALUATING - Epoch: [127][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3425 (0.3425)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:39:45 - INFO - EVALUATING - Epoch: [127][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2799 (0.3650)	Prec@1 91.000 (89.745)	Prec@5 100.000 (99.725)
2019-04-10 17:39:46 - INFO - 
 Epoch: 128	Training Loss 0.0725 	Training Prec@1 97.538 	Training Prec@5 99.989 	Validation Loss 0.3591 	Validation Prec@1 90.180 	Validation Prec@5 99.680 	Test Loss 0.3730 	Test Prec@1  89.810 	Test Prec@5  99.640 

2019-04-10 17:39:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:39:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:39:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:39:47 - INFO - TRAINING - Epoch: [128][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0703 (0.0703)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:39:49 - INFO - TRAINING - Epoch: [128][50/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1664 (0.0630)	Prec@1 93.000 (97.647)	Prec@5 100.000 (100.000)
2019-04-10 17:39:52 - INFO - TRAINING - Epoch: [128][100/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0793 (0.0606)	Prec@1 96.000 (97.812)	Prec@5 100.000 (100.000)
2019-04-10 17:39:55 - INFO - TRAINING - Epoch: [128][150/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0758 (0.0636)	Prec@1 97.000 (97.689)	Prec@5 100.000 (100.000)
2019-04-10 17:39:58 - INFO - TRAINING - Epoch: [128][200/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0389 (0.0680)	Prec@1 99.000 (97.582)	Prec@5 100.000 (100.000)
2019-04-10 17:40:01 - INFO - TRAINING - Epoch: [128][250/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0549 (0.0697)	Prec@1 97.000 (97.546)	Prec@5 100.000 (100.000)
2019-04-10 17:40:03 - INFO - TRAINING - Epoch: [128][300/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.0296 (0.0714)	Prec@1 99.000 (97.502)	Prec@5 100.000 (100.000)
2019-04-10 17:40:06 - INFO - TRAINING - Epoch: [128][350/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0728 (0.0710)	Prec@1 97.000 (97.521)	Prec@5 100.000 (100.000)
2019-04-10 17:40:09 - INFO - TRAINING - Epoch: [128][400/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1236 (0.0724)	Prec@1 92.000 (97.456)	Prec@5 100.000 (99.995)
2019-04-10 17:40:11 - INFO - EVALUATING - Epoch: [128][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3346 (0.3346)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:40:12 - INFO - EVALUATING - Epoch: [128][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3348 (0.3348)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:40:13 - INFO - EVALUATING - Epoch: [128][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3194 (0.3612)	Prec@1 91.000 (89.725)	Prec@5 99.000 (99.451)
2019-04-10 17:40:14 - INFO - 
 Epoch: 129	Training Loss 0.0730 	Training Prec@1 97.462 	Training Prec@5 99.996 	Validation Loss 0.3494 	Validation Prec@1 90.040 	Validation Prec@5 99.640 	Test Loss 0.3644 	Test Prec@1  89.930 	Test Prec@5  99.530 

2019-04-10 17:40:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:40:14 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:40:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:40:14 - INFO - TRAINING - Epoch: [129][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1443 (0.1443)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:40:17 - INFO - TRAINING - Epoch: [129][50/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1895 (0.0738)	Prec@1 96.000 (97.490)	Prec@5 99.000 (99.961)
2019-04-10 17:40:20 - INFO - TRAINING - Epoch: [129][100/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0905 (0.0696)	Prec@1 96.000 (97.634)	Prec@5 100.000 (99.970)
2019-04-10 17:40:22 - INFO - TRAINING - Epoch: [129][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1384 (0.0717)	Prec@1 96.000 (97.649)	Prec@5 100.000 (99.980)
2019-04-10 17:40:25 - INFO - TRAINING - Epoch: [129][200/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.1045 (0.0697)	Prec@1 96.000 (97.751)	Prec@5 100.000 (99.985)
2019-04-10 17:40:28 - INFO - TRAINING - Epoch: [129][250/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0346 (0.0690)	Prec@1 98.000 (97.737)	Prec@5 100.000 (99.984)
2019-04-10 17:40:30 - INFO - TRAINING - Epoch: [129][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0541 (0.0696)	Prec@1 98.000 (97.674)	Prec@5 100.000 (99.987)
2019-04-10 17:40:33 - INFO - TRAINING - Epoch: [129][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1014 (0.0708)	Prec@1 96.000 (97.610)	Prec@5 100.000 (99.989)
2019-04-10 17:40:36 - INFO - TRAINING - Epoch: [129][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0115 (0.0705)	Prec@1 100.000 (97.631)	Prec@5 100.000 (99.990)
2019-04-10 17:40:39 - INFO - EVALUATING - Epoch: [129][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.3976 (0.3976)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:40:39 - INFO - EVALUATING - Epoch: [129][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2051 (0.2051)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:40:40 - INFO - EVALUATING - Epoch: [129][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2491 (0.3585)	Prec@1 90.000 (89.980)	Prec@5 100.000 (99.627)
2019-04-10 17:40:41 - INFO - 
 Epoch: 130	Training Loss 0.0699 	Training Prec@1 97.640 	Training Prec@5 99.991 	Validation Loss 0.3546 	Validation Prec@1 90.200 	Validation Prec@5 99.740 	Test Loss 0.3676 	Test Prec@1  89.950 	Test Prec@5  99.680 

2019-04-10 17:40:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:40:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:40:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:40:41 - INFO - TRAINING - Epoch: [130][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1173 (0.1173)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:40:44 - INFO - TRAINING - Epoch: [130][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0338 (0.0726)	Prec@1 99.000 (97.451)	Prec@5 100.000 (100.000)
2019-04-10 17:40:47 - INFO - TRAINING - Epoch: [130][100/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0472 (0.0705)	Prec@1 99.000 (97.465)	Prec@5 100.000 (100.000)
2019-04-10 17:40:50 - INFO - TRAINING - Epoch: [130][150/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0181 (0.0669)	Prec@1 100.000 (97.642)	Prec@5 100.000 (100.000)
2019-04-10 17:40:53 - INFO - TRAINING - Epoch: [130][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0839 (0.0684)	Prec@1 98.000 (97.597)	Prec@5 100.000 (100.000)
2019-04-10 17:40:56 - INFO - TRAINING - Epoch: [130][250/450]	Time 0.055 (0.057)	Data 0.014 (0.014)	Loss 0.0296 (0.0711)	Prec@1 99.000 (97.526)	Prec@5 100.000 (99.996)
2019-04-10 17:40:58 - INFO - TRAINING - Epoch: [130][300/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0258 (0.0714)	Prec@1 99.000 (97.545)	Prec@5 100.000 (99.997)
2019-04-10 17:41:01 - INFO - TRAINING - Epoch: [130][350/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.0868 (0.0725)	Prec@1 96.000 (97.519)	Prec@5 100.000 (99.997)
2019-04-10 17:41:04 - INFO - TRAINING - Epoch: [130][400/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.0600 (0.0723)	Prec@1 98.000 (97.526)	Prec@5 100.000 (99.995)
2019-04-10 17:41:06 - INFO - EVALUATING - Epoch: [130][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.2419 (0.2419)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:41:07 - INFO - EVALUATING - Epoch: [130][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3741 (0.3741)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:41:08 - INFO - EVALUATING - Epoch: [130][50/100]	Time 0.017 (0.017)	Data 0.009 (0.010)	Loss 0.3087 (0.3708)	Prec@1 91.000 (90.000)	Prec@5 100.000 (99.510)
2019-04-10 17:41:09 - INFO - 
 Epoch: 131	Training Loss 0.0722 	Training Prec@1 97.518 	Training Prec@5 99.993 	Validation Loss 0.3533 	Validation Prec@1 90.200 	Validation Prec@5 99.680 	Test Loss 0.3735 	Test Prec@1  89.930 	Test Prec@5  99.560 

2019-04-10 17:41:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:41:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:41:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:41:09 - INFO - TRAINING - Epoch: [131][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.1106 (0.1106)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:41:12 - INFO - TRAINING - Epoch: [131][50/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0527 (0.0833)	Prec@1 97.000 (97.176)	Prec@5 100.000 (99.961)
2019-04-10 17:41:15 - INFO - TRAINING - Epoch: [131][100/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0437 (0.0726)	Prec@1 99.000 (97.604)	Prec@5 100.000 (99.970)
2019-04-10 17:41:17 - INFO - TRAINING - Epoch: [131][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0191 (0.0694)	Prec@1 99.000 (97.689)	Prec@5 100.000 (99.980)
2019-04-10 17:41:20 - INFO - TRAINING - Epoch: [131][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1297 (0.0710)	Prec@1 97.000 (97.677)	Prec@5 100.000 (99.975)
2019-04-10 17:41:23 - INFO - TRAINING - Epoch: [131][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0297 (0.0701)	Prec@1 99.000 (97.697)	Prec@5 100.000 (99.976)
2019-04-10 17:41:25 - INFO - TRAINING - Epoch: [131][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0899 (0.0694)	Prec@1 98.000 (97.694)	Prec@5 100.000 (99.980)
2019-04-10 17:41:28 - INFO - TRAINING - Epoch: [131][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0635 (0.0696)	Prec@1 97.000 (97.689)	Prec@5 100.000 (99.980)
2019-04-10 17:41:31 - INFO - TRAINING - Epoch: [131][400/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.1291 (0.0688)	Prec@1 98.000 (97.711)	Prec@5 100.000 (99.983)
2019-04-10 17:41:34 - INFO - EVALUATING - Epoch: [131][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3375 (0.3375)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:41:34 - INFO - EVALUATING - Epoch: [131][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2733 (0.2733)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:41:35 - INFO - EVALUATING - Epoch: [131][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2749 (0.3609)	Prec@1 91.000 (90.059)	Prec@5 100.000 (99.510)
2019-04-10 17:41:36 - INFO - 
 Epoch: 132	Training Loss 0.0687 	Training Prec@1 97.720 	Training Prec@5 99.984 	Validation Loss 0.3502 	Validation Prec@1 90.580 	Validation Prec@5 99.680 	Test Loss 0.3649 	Test Prec@1  90.040 	Test Prec@5  99.600 

2019-04-10 17:41:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:41:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:41:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:41:36 - INFO - TRAINING - Epoch: [132][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0378 (0.0378)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:41:39 - INFO - TRAINING - Epoch: [132][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0749 (0.0711)	Prec@1 97.000 (97.392)	Prec@5 100.000 (100.000)
2019-04-10 17:41:42 - INFO - TRAINING - Epoch: [132][100/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0676 (0.0738)	Prec@1 97.000 (97.297)	Prec@5 100.000 (99.990)
2019-04-10 17:41:44 - INFO - TRAINING - Epoch: [132][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0770 (0.0683)	Prec@1 97.000 (97.623)	Prec@5 100.000 (99.993)
2019-04-10 17:41:47 - INFO - TRAINING - Epoch: [132][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0316 (0.0671)	Prec@1 99.000 (97.677)	Prec@5 100.000 (99.995)
2019-04-10 17:41:50 - INFO - TRAINING - Epoch: [132][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0601 (0.0646)	Prec@1 98.000 (97.785)	Prec@5 100.000 (99.996)
2019-04-10 17:41:53 - INFO - TRAINING - Epoch: [132][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0236 (0.0651)	Prec@1 99.000 (97.807)	Prec@5 100.000 (99.990)
2019-04-10 17:41:55 - INFO - TRAINING - Epoch: [132][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0301 (0.0656)	Prec@1 98.000 (97.803)	Prec@5 100.000 (99.991)
2019-04-10 17:41:58 - INFO - TRAINING - Epoch: [132][400/450]	Time 0.052 (0.054)	Data 0.012 (0.014)	Loss 0.0539 (0.0650)	Prec@1 98.000 (97.813)	Prec@5 100.000 (99.993)
2019-04-10 17:42:01 - INFO - EVALUATING - Epoch: [132][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.5925 (0.5925)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:02 - INFO - EVALUATING - Epoch: [132][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3423 (0.3423)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:02 - INFO - EVALUATING - Epoch: [132][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1939 (0.3777)	Prec@1 92.000 (89.941)	Prec@5 100.000 (99.588)
2019-04-10 17:42:03 - INFO - 
 Epoch: 133	Training Loss 0.0657 	Training Prec@1 97.789 	Training Prec@5 99.991 	Validation Loss 0.3668 	Validation Prec@1 90.600 	Validation Prec@5 99.540 	Test Loss 0.3774 	Test Prec@1  89.870 	Test Prec@5  99.570 

2019-04-10 17:42:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:42:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:42:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:42:03 - INFO - TRAINING - Epoch: [133][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0549 (0.0549)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:06 - INFO - TRAINING - Epoch: [133][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0523 (0.0663)	Prec@1 98.000 (97.824)	Prec@5 100.000 (100.000)
2019-04-10 17:42:09 - INFO - TRAINING - Epoch: [133][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0710 (0.0686)	Prec@1 98.000 (97.772)	Prec@5 100.000 (100.000)
2019-04-10 17:42:12 - INFO - TRAINING - Epoch: [133][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0823 (0.0674)	Prec@1 97.000 (97.762)	Prec@5 100.000 (100.000)
2019-04-10 17:42:14 - INFO - TRAINING - Epoch: [133][200/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0466 (0.0663)	Prec@1 98.000 (97.791)	Prec@5 100.000 (100.000)
2019-04-10 17:42:17 - INFO - TRAINING - Epoch: [133][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1059 (0.0668)	Prec@1 96.000 (97.725)	Prec@5 100.000 (100.000)
2019-04-10 17:42:20 - INFO - TRAINING - Epoch: [133][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0191 (0.0670)	Prec@1 100.000 (97.731)	Prec@5 100.000 (100.000)
2019-04-10 17:42:23 - INFO - TRAINING - Epoch: [133][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0087 (0.0664)	Prec@1 100.000 (97.741)	Prec@5 100.000 (100.000)
2019-04-10 17:42:25 - INFO - TRAINING - Epoch: [133][400/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0950 (0.0662)	Prec@1 96.000 (97.736)	Prec@5 100.000 (100.000)
2019-04-10 17:42:28 - INFO - EVALUATING - Epoch: [133][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.2021 (0.2021)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:29 - INFO - EVALUATING - Epoch: [133][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3560 (0.3560)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:42:30 - INFO - EVALUATING - Epoch: [133][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2334 (0.3946)	Prec@1 91.000 (89.490)	Prec@5 100.000 (99.569)
2019-04-10 17:42:31 - INFO - 
 Epoch: 134	Training Loss 0.0663 	Training Prec@1 97.729 	Training Prec@5 100.000 	Validation Loss 0.3756 	Validation Prec@1 90.060 	Validation Prec@5 99.660 	Test Loss 0.3807 	Test Prec@1  89.630 	Test Prec@5  99.640 

2019-04-10 17:42:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:42:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:42:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:42:31 - INFO - TRAINING - Epoch: [134][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0504 (0.0504)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:33 - INFO - TRAINING - Epoch: [134][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0734 (0.0613)	Prec@1 98.000 (97.980)	Prec@5 100.000 (100.000)
2019-04-10 17:42:36 - INFO - TRAINING - Epoch: [134][100/450]	Time 0.050 (0.054)	Data 0.021 (0.014)	Loss 0.0498 (0.0596)	Prec@1 98.000 (98.059)	Prec@5 100.000 (100.000)
2019-04-10 17:42:39 - INFO - TRAINING - Epoch: [134][150/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0134 (0.0612)	Prec@1 100.000 (98.020)	Prec@5 100.000 (100.000)
2019-04-10 17:42:42 - INFO - TRAINING - Epoch: [134][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0293 (0.0610)	Prec@1 99.000 (97.960)	Prec@5 100.000 (100.000)
2019-04-10 17:42:44 - INFO - TRAINING - Epoch: [134][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0528 (0.0622)	Prec@1 99.000 (97.940)	Prec@5 100.000 (100.000)
2019-04-10 17:42:47 - INFO - TRAINING - Epoch: [134][300/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0523 (0.0624)	Prec@1 99.000 (97.930)	Prec@5 100.000 (100.000)
2019-04-10 17:42:50 - INFO - TRAINING - Epoch: [134][350/450]	Time 0.057 (0.054)	Data 0.013 (0.014)	Loss 0.0784 (0.0633)	Prec@1 96.000 (97.832)	Prec@5 100.000 (100.000)
2019-04-10 17:42:53 - INFO - TRAINING - Epoch: [134][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1056 (0.0639)	Prec@1 97.000 (97.835)	Prec@5 100.000 (100.000)
2019-04-10 17:42:55 - INFO - EVALUATING - Epoch: [134][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3587 (0.3587)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:42:56 - INFO - EVALUATING - Epoch: [134][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3234 (0.3234)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:42:57 - INFO - EVALUATING - Epoch: [134][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1784 (0.3744)	Prec@1 95.000 (89.706)	Prec@5 100.000 (99.431)
2019-04-10 17:42:58 - INFO - 
 Epoch: 135	Training Loss 0.0639 	Training Prec@1 97.820 	Training Prec@5 100.000 	Validation Loss 0.3515 	Validation Prec@1 90.560 	Validation Prec@5 99.620 	Test Loss 0.3690 	Test Prec@1  89.940 	Test Prec@5  99.530 

2019-04-10 17:42:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:42:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:42:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:42:58 - INFO - TRAINING - Epoch: [135][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0331 (0.0331)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:43:01 - INFO - TRAINING - Epoch: [135][50/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1136 (0.0591)	Prec@1 94.000 (97.941)	Prec@5 100.000 (100.000)
2019-04-10 17:43:04 - INFO - TRAINING - Epoch: [135][100/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0531 (0.0627)	Prec@1 98.000 (97.802)	Prec@5 100.000 (100.000)
2019-04-10 17:43:06 - INFO - TRAINING - Epoch: [135][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0551 (0.0608)	Prec@1 98.000 (97.801)	Prec@5 100.000 (100.000)
2019-04-10 17:43:09 - INFO - TRAINING - Epoch: [135][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0739 (0.0632)	Prec@1 98.000 (97.761)	Prec@5 100.000 (100.000)
2019-04-10 17:43:12 - INFO - TRAINING - Epoch: [135][250/450]	Time 0.061 (0.054)	Data 0.014 (0.014)	Loss 0.0514 (0.0637)	Prec@1 99.000 (97.745)	Prec@5 100.000 (99.996)
2019-04-10 17:43:14 - INFO - TRAINING - Epoch: [135][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.1330 (0.0634)	Prec@1 94.000 (97.731)	Prec@5 100.000 (99.997)
2019-04-10 17:43:17 - INFO - TRAINING - Epoch: [135][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0922 (0.0629)	Prec@1 96.000 (97.778)	Prec@5 100.000 (99.997)
2019-04-10 17:43:20 - INFO - TRAINING - Epoch: [135][400/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0913 (0.0628)	Prec@1 97.000 (97.808)	Prec@5 100.000 (99.998)
2019-04-10 17:43:22 - INFO - EVALUATING - Epoch: [135][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.4646 (0.4646)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-04-10 17:43:23 - INFO - EVALUATING - Epoch: [135][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2685 (0.2685)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:43:24 - INFO - EVALUATING - Epoch: [135][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1510 (0.3802)	Prec@1 94.000 (90.078)	Prec@5 100.000 (99.451)
2019-04-10 17:43:25 - INFO - 
 Epoch: 136	Training Loss 0.0635 	Training Prec@1 97.793 	Training Prec@5 99.998 	Validation Loss 0.3741 	Validation Prec@1 90.040 	Validation Prec@5 99.680 	Test Loss 0.3759 	Test Prec@1  90.060 	Test Prec@5  99.550 

2019-04-10 17:43:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:43:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:43:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:43:25 - INFO - TRAINING - Epoch: [136][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0716 (0.0716)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:43:28 - INFO - TRAINING - Epoch: [136][50/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.0426 (0.0523)	Prec@1 97.000 (98.039)	Prec@5 100.000 (100.000)
2019-04-10 17:43:31 - INFO - TRAINING - Epoch: [136][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0502 (0.0571)	Prec@1 98.000 (98.089)	Prec@5 100.000 (100.000)
2019-04-10 17:43:33 - INFO - TRAINING - Epoch: [136][150/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1035 (0.0583)	Prec@1 96.000 (98.040)	Prec@5 100.000 (99.993)
2019-04-10 17:43:36 - INFO - TRAINING - Epoch: [136][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1376 (0.0580)	Prec@1 94.000 (98.060)	Prec@5 100.000 (99.995)
2019-04-10 17:43:39 - INFO - TRAINING - Epoch: [136][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0344 (0.0595)	Prec@1 100.000 (98.032)	Prec@5 100.000 (99.992)
2019-04-10 17:43:42 - INFO - TRAINING - Epoch: [136][300/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0216 (0.0604)	Prec@1 100.000 (97.980)	Prec@5 100.000 (99.993)
2019-04-10 17:43:44 - INFO - TRAINING - Epoch: [136][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0272 (0.0613)	Prec@1 99.000 (97.929)	Prec@5 100.000 (99.994)
2019-04-10 17:43:47 - INFO - TRAINING - Epoch: [136][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0197 (0.0620)	Prec@1 100.000 (97.888)	Prec@5 100.000 (99.995)
2019-04-10 17:43:50 - INFO - EVALUATING - Epoch: [136][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.3868 (0.3868)	Prec@1 93.000 (93.000)	Prec@5 98.000 (98.000)
2019-04-10 17:43:51 - INFO - EVALUATING - Epoch: [136][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2658 (0.2658)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:43:52 - INFO - EVALUATING - Epoch: [136][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1821 (0.3747)	Prec@1 92.000 (90.275)	Prec@5 100.000 (99.412)
2019-04-10 17:43:52 - INFO - 
 Epoch: 137	Training Loss 0.0620 	Training Prec@1 97.884 	Training Prec@5 99.996 	Validation Loss 0.3689 	Validation Prec@1 90.520 	Validation Prec@5 99.580 	Test Loss 0.3680 	Test Prec@1  90.200 	Test Prec@5  99.530 

2019-04-10 17:43:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:43:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:43:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:43:53 - INFO - TRAINING - Epoch: [137][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.1364 (0.1364)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:43:55 - INFO - TRAINING - Epoch: [137][50/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.0604 (0.0658)	Prec@1 97.000 (97.843)	Prec@5 100.000 (100.000)
2019-04-10 17:43:58 - INFO - TRAINING - Epoch: [137][100/450]	Time 0.054 (0.053)	Data 0.012 (0.013)	Loss 0.0385 (0.0655)	Prec@1 98.000 (97.723)	Prec@5 100.000 (100.000)
2019-04-10 17:44:01 - INFO - TRAINING - Epoch: [137][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0600 (0.0636)	Prec@1 98.000 (97.801)	Prec@5 100.000 (100.000)
2019-04-10 17:44:03 - INFO - TRAINING - Epoch: [137][200/450]	Time 0.056 (0.054)	Data 0.012 (0.013)	Loss 0.0450 (0.0622)	Prec@1 98.000 (97.816)	Prec@5 100.000 (99.995)
2019-04-10 17:44:06 - INFO - TRAINING - Epoch: [137][250/450]	Time 0.056 (0.055)	Data 0.012 (0.013)	Loss 0.0509 (0.0627)	Prec@1 97.000 (97.817)	Prec@5 100.000 (99.996)
2019-04-10 17:44:09 - INFO - TRAINING - Epoch: [137][300/450]	Time 0.055 (0.055)	Data 0.012 (0.013)	Loss 0.0978 (0.0619)	Prec@1 96.000 (97.880)	Prec@5 100.000 (99.997)
2019-04-10 17:44:12 - INFO - TRAINING - Epoch: [137][350/450]	Time 0.054 (0.055)	Data 0.012 (0.013)	Loss 0.0440 (0.0623)	Prec@1 99.000 (97.846)	Prec@5 100.000 (99.997)
2019-04-10 17:44:15 - INFO - TRAINING - Epoch: [137][400/450]	Time 0.055 (0.055)	Data 0.012 (0.013)	Loss 0.1328 (0.0619)	Prec@1 95.000 (97.860)	Prec@5 100.000 (99.998)
2019-04-10 17:44:17 - INFO - EVALUATING - Epoch: [137][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.1950 (0.1950)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:44:18 - INFO - EVALUATING - Epoch: [137][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3911 (0.3911)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:44:19 - INFO - EVALUATING - Epoch: [137][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1250 (0.3690)	Prec@1 96.000 (89.725)	Prec@5 100.000 (99.490)
2019-04-10 17:44:20 - INFO - 
 Epoch: 138	Training Loss 0.0618 	Training Prec@1 97.856 	Training Prec@5 99.998 	Validation Loss 0.3623 	Validation Prec@1 90.280 	Validation Prec@5 99.620 	Test Loss 0.3683 	Test Prec@1  89.800 	Test Prec@5  99.590 

2019-04-10 17:44:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:44:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:44:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:44:20 - INFO - TRAINING - Epoch: [138][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0452 (0.0452)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:44:23 - INFO - TRAINING - Epoch: [138][50/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1157 (0.0643)	Prec@1 97.000 (97.627)	Prec@5 100.000 (100.000)
2019-04-10 17:44:26 - INFO - TRAINING - Epoch: [138][100/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0123 (0.0597)	Prec@1 100.000 (97.941)	Prec@5 100.000 (100.000)
2019-04-10 17:44:28 - INFO - TRAINING - Epoch: [138][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0474 (0.0589)	Prec@1 98.000 (97.927)	Prec@5 100.000 (100.000)
2019-04-10 17:44:31 - INFO - TRAINING - Epoch: [138][200/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0585 (0.0599)	Prec@1 97.000 (97.886)	Prec@5 100.000 (100.000)
2019-04-10 17:44:34 - INFO - TRAINING - Epoch: [138][250/450]	Time 0.055 (0.054)	Data 0.014 (0.013)	Loss 0.0997 (0.0611)	Prec@1 97.000 (97.837)	Prec@5 100.000 (100.000)
2019-04-10 17:44:36 - INFO - TRAINING - Epoch: [138][300/450]	Time 0.054 (0.054)	Data 0.013 (0.013)	Loss 0.1359 (0.0627)	Prec@1 96.000 (97.784)	Prec@5 100.000 (99.997)
2019-04-10 17:44:39 - INFO - TRAINING - Epoch: [138][350/450]	Time 0.053 (0.054)	Data 0.013 (0.013)	Loss 0.0241 (0.0623)	Prec@1 100.000 (97.818)	Prec@5 100.000 (99.997)
2019-04-10 17:44:42 - INFO - TRAINING - Epoch: [138][400/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0179 (0.0622)	Prec@1 100.000 (97.808)	Prec@5 100.000 (99.995)
2019-04-10 17:44:44 - INFO - EVALUATING - Epoch: [138][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.3261 (0.3261)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:44:45 - INFO - EVALUATING - Epoch: [138][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2063 (0.2063)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:44:46 - INFO - EVALUATING - Epoch: [138][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1981 (0.3604)	Prec@1 89.000 (90.137)	Prec@5 100.000 (99.647)
2019-04-10 17:44:47 - INFO - 
 Epoch: 139	Training Loss 0.0619 	Training Prec@1 97.827 	Training Prec@5 99.996 	Validation Loss 0.3519 	Validation Prec@1 90.560 	Validation Prec@5 99.640 	Test Loss 0.3591 	Test Prec@1  90.380 	Test Prec@5  99.630 

2019-04-10 17:44:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:44:47 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:44:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:44:47 - INFO - TRAINING - Epoch: [139][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0231 (0.0231)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:44:50 - INFO - TRAINING - Epoch: [139][50/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0308 (0.0614)	Prec@1 99.000 (97.863)	Prec@5 100.000 (100.000)
2019-04-10 17:44:53 - INFO - TRAINING - Epoch: [139][100/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.0774 (0.0604)	Prec@1 98.000 (98.040)	Prec@5 100.000 (100.000)
2019-04-10 17:44:56 - INFO - TRAINING - Epoch: [139][150/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0271 (0.0604)	Prec@1 99.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:44:58 - INFO - TRAINING - Epoch: [139][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0276 (0.0604)	Prec@1 99.000 (98.045)	Prec@5 100.000 (100.000)
2019-04-10 17:45:01 - INFO - TRAINING - Epoch: [139][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0419 (0.0610)	Prec@1 99.000 (98.016)	Prec@5 100.000 (99.996)
2019-04-10 17:45:04 - INFO - TRAINING - Epoch: [139][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0592 (0.0604)	Prec@1 98.000 (97.990)	Prec@5 100.000 (99.997)
2019-04-10 17:45:06 - INFO - TRAINING - Epoch: [139][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0506 (0.0606)	Prec@1 98.000 (97.949)	Prec@5 100.000 (99.997)
2019-04-10 17:45:09 - INFO - TRAINING - Epoch: [139][400/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0458 (0.0605)	Prec@1 99.000 (97.958)	Prec@5 100.000 (99.998)
2019-04-10 17:45:12 - INFO - EVALUATING - Epoch: [139][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.2227 (0.2227)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:45:13 - INFO - EVALUATING - Epoch: [139][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2813 (0.2813)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:45:14 - INFO - EVALUATING - Epoch: [139][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1949 (0.3670)	Prec@1 89.000 (90.039)	Prec@5 100.000 (99.686)
2019-04-10 17:45:14 - INFO - 
 Epoch: 140	Training Loss 0.0613 	Training Prec@1 97.942 	Training Prec@5 99.998 	Validation Loss 0.3571 	Validation Prec@1 90.560 	Validation Prec@5 99.680 	Test Loss 0.3658 	Test Prec@1  90.380 	Test Prec@5  99.670 

2019-04-10 17:45:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:45:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:45:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:45:15 - INFO - TRAINING - Epoch: [140][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0324 (0.0324)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:45:18 - INFO - TRAINING - Epoch: [140][50/450]	Time 0.056 (0.056)	Data 0.013 (0.015)	Loss 0.0245 (0.0539)	Prec@1 100.000 (98.216)	Prec@5 100.000 (100.000)
2019-04-10 17:45:20 - INFO - TRAINING - Epoch: [140][100/450]	Time 0.058 (0.057)	Data 0.014 (0.015)	Loss 0.0618 (0.0552)	Prec@1 97.000 (98.218)	Prec@5 100.000 (100.000)
2019-04-10 17:45:23 - INFO - TRAINING - Epoch: [140][150/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.0986 (0.0585)	Prec@1 97.000 (98.073)	Prec@5 100.000 (100.000)
2019-04-10 17:45:26 - INFO - TRAINING - Epoch: [140][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.1732 (0.0604)	Prec@1 96.000 (97.995)	Prec@5 100.000 (100.000)
2019-04-10 17:45:29 - INFO - TRAINING - Epoch: [140][250/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0257 (0.0597)	Prec@1 99.000 (98.024)	Prec@5 100.000 (100.000)
2019-04-10 17:45:32 - INFO - TRAINING - Epoch: [140][300/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0436 (0.0594)	Prec@1 98.000 (98.007)	Prec@5 100.000 (100.000)
2019-04-10 17:45:35 - INFO - TRAINING - Epoch: [140][350/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0393 (0.0589)	Prec@1 99.000 (98.028)	Prec@5 100.000 (100.000)
2019-04-10 17:45:37 - INFO - TRAINING - Epoch: [140][400/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0773 (0.0598)	Prec@1 97.000 (97.978)	Prec@5 100.000 (99.998)
2019-04-10 17:45:40 - INFO - EVALUATING - Epoch: [140][0/50]	Time 0.049 (0.049)	Data 0.010 (0.010)	Loss 0.3477 (0.3477)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:45:41 - INFO - EVALUATING - Epoch: [140][0/100]	Time 0.018 (0.018)	Data 0.009 (0.009)	Loss 0.3176 (0.3176)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:45:42 - INFO - EVALUATING - Epoch: [140][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.2546 (0.3828)	Prec@1 91.000 (89.686)	Prec@5 100.000 (99.412)
2019-04-10 17:45:43 - INFO - 
 Epoch: 141	Training Loss 0.0601 	Training Prec@1 97.964 	Training Prec@5 99.998 	Validation Loss 0.3603 	Validation Prec@1 90.220 	Validation Prec@5 99.560 	Test Loss 0.3777 	Test Prec@1  89.850 	Test Prec@5  99.510 

2019-04-10 17:45:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:45:43 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:45:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:45:43 - INFO - TRAINING - Epoch: [141][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0278 (0.0278)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:45:46 - INFO - TRAINING - Epoch: [141][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0222 (0.0639)	Prec@1 100.000 (97.745)	Prec@5 100.000 (99.980)
2019-04-10 17:45:49 - INFO - TRAINING - Epoch: [141][100/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0507 (0.0576)	Prec@1 97.000 (98.000)	Prec@5 100.000 (99.990)
2019-04-10 17:45:51 - INFO - TRAINING - Epoch: [141][150/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0256 (0.0568)	Prec@1 99.000 (98.046)	Prec@5 100.000 (99.993)
2019-04-10 17:45:54 - INFO - TRAINING - Epoch: [141][200/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0664 (0.0605)	Prec@1 96.000 (97.925)	Prec@5 100.000 (99.990)
2019-04-10 17:45:57 - INFO - TRAINING - Epoch: [141][250/450]	Time 0.052 (0.053)	Data 0.013 (0.014)	Loss 0.0181 (0.0595)	Prec@1 100.000 (97.952)	Prec@5 100.000 (99.992)
2019-04-10 17:45:59 - INFO - TRAINING - Epoch: [141][300/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.0490 (0.0587)	Prec@1 99.000 (97.990)	Prec@5 100.000 (99.993)
2019-04-10 17:46:02 - INFO - TRAINING - Epoch: [141][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1063 (0.0593)	Prec@1 97.000 (97.991)	Prec@5 100.000 (99.994)
2019-04-10 17:46:05 - INFO - TRAINING - Epoch: [141][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0268 (0.0583)	Prec@1 99.000 (98.015)	Prec@5 100.000 (99.995)
2019-04-10 17:46:07 - INFO - EVALUATING - Epoch: [141][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.6653 (0.6653)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:46:08 - INFO - EVALUATING - Epoch: [141][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3484 (0.3484)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:46:09 - INFO - EVALUATING - Epoch: [141][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2137 (0.3838)	Prec@1 92.000 (89.784)	Prec@5 100.000 (99.588)
2019-04-10 17:46:10 - INFO - 
 Epoch: 142	Training Loss 0.0581 	Training Prec@1 98.009 	Training Prec@5 99.996 	Validation Loss 0.3767 	Validation Prec@1 90.660 	Validation Prec@5 99.580 	Test Loss 0.3755 	Test Prec@1  90.120 	Test Prec@5  99.560 

2019-04-10 17:46:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:46:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:46:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:46:10 - INFO - TRAINING - Epoch: [142][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0656 (0.0656)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:46:13 - INFO - TRAINING - Epoch: [142][50/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.0878 (0.0556)	Prec@1 97.000 (98.137)	Prec@5 100.000 (100.000)
2019-04-10 17:46:16 - INFO - TRAINING - Epoch: [142][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0774 (0.0597)	Prec@1 98.000 (97.960)	Prec@5 100.000 (99.990)
2019-04-10 17:46:18 - INFO - TRAINING - Epoch: [142][150/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0539 (0.0579)	Prec@1 99.000 (98.013)	Prec@5 100.000 (99.993)
2019-04-10 17:46:21 - INFO - TRAINING - Epoch: [142][200/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0718 (0.0575)	Prec@1 98.000 (98.050)	Prec@5 100.000 (99.995)
2019-04-10 17:46:24 - INFO - TRAINING - Epoch: [142][250/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0346 (0.0581)	Prec@1 99.000 (97.984)	Prec@5 100.000 (99.996)
2019-04-10 17:46:26 - INFO - TRAINING - Epoch: [142][300/450]	Time 0.056 (0.054)	Data 0.012 (0.014)	Loss 0.0770 (0.0585)	Prec@1 96.000 (97.947)	Prec@5 100.000 (99.993)
2019-04-10 17:46:29 - INFO - TRAINING - Epoch: [142][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0727 (0.0593)	Prec@1 98.000 (97.906)	Prec@5 100.000 (99.994)
2019-04-10 17:46:32 - INFO - TRAINING - Epoch: [142][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0455 (0.0592)	Prec@1 97.000 (97.925)	Prec@5 100.000 (99.995)
2019-04-10 17:46:35 - INFO - EVALUATING - Epoch: [142][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4150 (0.4150)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:46:35 - INFO - EVALUATING - Epoch: [142][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3083 (0.3083)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:46:36 - INFO - EVALUATING - Epoch: [142][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2571 (0.3706)	Prec@1 94.000 (89.961)	Prec@5 100.000 (99.588)
2019-04-10 17:46:37 - INFO - 
 Epoch: 143	Training Loss 0.0587 	Training Prec@1 97.922 	Training Prec@5 99.996 	Validation Loss 0.3656 	Validation Prec@1 90.380 	Validation Prec@5 99.740 	Test Loss 0.3731 	Test Prec@1  90.090 	Test Prec@5  99.600 

2019-04-10 17:46:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:46:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:46:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:46:37 - INFO - TRAINING - Epoch: [143][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0431 (0.0431)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:46:40 - INFO - TRAINING - Epoch: [143][50/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0215 (0.0564)	Prec@1 100.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:46:43 - INFO - TRAINING - Epoch: [143][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0162 (0.0596)	Prec@1 100.000 (97.931)	Prec@5 100.000 (99.990)
2019-04-10 17:46:46 - INFO - TRAINING - Epoch: [143][150/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0263 (0.0596)	Prec@1 99.000 (97.974)	Prec@5 100.000 (99.987)
2019-04-10 17:46:49 - INFO - TRAINING - Epoch: [143][200/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0119 (0.0589)	Prec@1 100.000 (97.990)	Prec@5 100.000 (99.990)
2019-04-10 17:46:51 - INFO - TRAINING - Epoch: [143][250/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0819 (0.0602)	Prec@1 98.000 (97.984)	Prec@5 100.000 (99.992)
2019-04-10 17:46:54 - INFO - TRAINING - Epoch: [143][300/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.1826 (0.0601)	Prec@1 95.000 (97.947)	Prec@5 100.000 (99.993)
2019-04-10 17:46:57 - INFO - TRAINING - Epoch: [143][350/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0450 (0.0605)	Prec@1 100.000 (97.952)	Prec@5 100.000 (99.994)
2019-04-10 17:46:59 - INFO - TRAINING - Epoch: [143][400/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0905 (0.0609)	Prec@1 98.000 (97.925)	Prec@5 100.000 (99.993)
2019-04-10 17:47:02 - INFO - EVALUATING - Epoch: [143][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.5191 (0.5191)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:03 - INFO - EVALUATING - Epoch: [143][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3215 (0.3215)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:04 - INFO - EVALUATING - Epoch: [143][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1785 (0.3692)	Prec@1 93.000 (89.824)	Prec@5 100.000 (99.549)
2019-04-10 17:47:05 - INFO - 
 Epoch: 144	Training Loss 0.0609 	Training Prec@1 97.909 	Training Prec@5 99.993 	Validation Loss 0.3825 	Validation Prec@1 90.240 	Validation Prec@5 99.580 	Test Loss 0.3707 	Test Prec@1  89.870 	Test Prec@5  99.600 

2019-04-10 17:47:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:47:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:47:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:47:05 - INFO - TRAINING - Epoch: [144][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0321 (0.0321)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:08 - INFO - TRAINING - Epoch: [144][50/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0505 (0.0544)	Prec@1 98.000 (98.235)	Prec@5 100.000 (100.000)
2019-04-10 17:47:10 - INFO - TRAINING - Epoch: [144][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0478 (0.0566)	Prec@1 98.000 (98.158)	Prec@5 100.000 (100.000)
2019-04-10 17:47:13 - INFO - TRAINING - Epoch: [144][150/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0604 (0.0594)	Prec@1 98.000 (98.013)	Prec@5 100.000 (100.000)
2019-04-10 17:47:16 - INFO - TRAINING - Epoch: [144][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.1138 (0.0605)	Prec@1 96.000 (97.960)	Prec@5 100.000 (100.000)
2019-04-10 17:47:19 - INFO - TRAINING - Epoch: [144][250/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0347 (0.0605)	Prec@1 100.000 (97.952)	Prec@5 100.000 (99.996)
2019-04-10 17:47:21 - INFO - TRAINING - Epoch: [144][300/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.1062 (0.0619)	Prec@1 96.000 (97.897)	Prec@5 100.000 (99.993)
2019-04-10 17:47:24 - INFO - TRAINING - Epoch: [144][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0660 (0.0628)	Prec@1 98.000 (97.863)	Prec@5 100.000 (99.994)
2019-04-10 17:47:27 - INFO - TRAINING - Epoch: [144][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0334 (0.0619)	Prec@1 98.000 (97.885)	Prec@5 100.000 (99.995)
2019-04-10 17:47:29 - INFO - EVALUATING - Epoch: [144][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.4929 (0.4929)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:30 - INFO - EVALUATING - Epoch: [144][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4382 (0.4382)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:31 - INFO - EVALUATING - Epoch: [144][50/100]	Time 0.017 (0.018)	Data 0.010 (0.010)	Loss 0.3413 (0.3684)	Prec@1 89.000 (90.294)	Prec@5 100.000 (99.510)
2019-04-10 17:47:32 - INFO - 
 Epoch: 145	Training Loss 0.0613 	Training Prec@1 97.931 	Training Prec@5 99.996 	Validation Loss 0.3769 	Validation Prec@1 90.400 	Validation Prec@5 99.660 	Test Loss 0.3751 	Test Prec@1  90.350 	Test Prec@5  99.560 

2019-04-10 17:47:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:47:32 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:47:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:47:32 - INFO - TRAINING - Epoch: [145][0/450]	Time 0.025 (0.025)	Data 0.012 (0.012)	Loss 0.0588 (0.0588)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:35 - INFO - TRAINING - Epoch: [145][50/450]	Time 0.055 (0.053)	Data 0.012 (0.013)	Loss 0.0141 (0.0564)	Prec@1 100.000 (98.039)	Prec@5 100.000 (99.980)
2019-04-10 17:47:38 - INFO - TRAINING - Epoch: [145][100/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0506 (0.0607)	Prec@1 98.000 (97.950)	Prec@5 100.000 (99.990)
2019-04-10 17:47:40 - INFO - TRAINING - Epoch: [145][150/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0169 (0.0613)	Prec@1 99.000 (97.960)	Prec@5 100.000 (99.993)
2019-04-10 17:47:43 - INFO - TRAINING - Epoch: [145][200/450]	Time 0.055 (0.054)	Data 0.014 (0.013)	Loss 0.0192 (0.0609)	Prec@1 100.000 (97.985)	Prec@5 100.000 (99.990)
2019-04-10 17:47:46 - INFO - TRAINING - Epoch: [145][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0175 (0.0599)	Prec@1 99.000 (98.004)	Prec@5 100.000 (99.992)
2019-04-10 17:47:48 - INFO - TRAINING - Epoch: [145][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0171 (0.0600)	Prec@1 100.000 (98.023)	Prec@5 100.000 (99.993)
2019-04-10 17:47:51 - INFO - TRAINING - Epoch: [145][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0363 (0.0587)	Prec@1 100.000 (98.051)	Prec@5 100.000 (99.994)
2019-04-10 17:47:54 - INFO - TRAINING - Epoch: [145][400/450]	Time 0.056 (0.054)	Data 0.012 (0.013)	Loss 0.0480 (0.0586)	Prec@1 99.000 (98.067)	Prec@5 100.000 (99.995)
2019-04-10 17:47:57 - INFO - EVALUATING - Epoch: [145][0/50]	Time 0.048 (0.048)	Data 0.010 (0.010)	Loss 0.3988 (0.3988)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:58 - INFO - EVALUATING - Epoch: [145][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3014 (0.3014)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 17:47:58 - INFO - EVALUATING - Epoch: [145][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2191 (0.3818)	Prec@1 91.000 (89.843)	Prec@5 100.000 (99.529)
2019-04-10 17:47:59 - INFO - 
 Epoch: 146	Training Loss 0.0589 	Training Prec@1 98.036 	Training Prec@5 99.996 	Validation Loss 0.3574 	Validation Prec@1 90.320 	Validation Prec@5 99.640 	Test Loss 0.3757 	Test Prec@1  89.890 	Test Prec@5  99.550 

2019-04-10 17:47:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:47:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:47:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:48:00 - INFO - TRAINING - Epoch: [146][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.1130 (0.1130)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:48:02 - INFO - TRAINING - Epoch: [146][50/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0860 (0.0632)	Prec@1 96.000 (97.902)	Prec@5 100.000 (100.000)
2019-04-10 17:48:05 - INFO - TRAINING - Epoch: [146][100/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.1362 (0.0631)	Prec@1 95.000 (97.931)	Prec@5 100.000 (100.000)
2019-04-10 17:48:08 - INFO - TRAINING - Epoch: [146][150/450]	Time 0.055 (0.056)	Data 0.012 (0.013)	Loss 0.0236 (0.0596)	Prec@1 100.000 (98.053)	Prec@5 100.000 (100.000)
2019-04-10 17:48:11 - INFO - TRAINING - Epoch: [146][200/450]	Time 0.056 (0.056)	Data 0.012 (0.013)	Loss 0.0298 (0.0607)	Prec@1 99.000 (98.020)	Prec@5 100.000 (100.000)
2019-04-10 17:48:14 - INFO - TRAINING - Epoch: [146][250/450]	Time 0.055 (0.056)	Data 0.012 (0.013)	Loss 0.0366 (0.0588)	Prec@1 98.000 (98.072)	Prec@5 100.000 (100.000)
2019-04-10 17:48:16 - INFO - TRAINING - Epoch: [146][300/450]	Time 0.053 (0.056)	Data 0.012 (0.013)	Loss 0.0824 (0.0590)	Prec@1 97.000 (98.040)	Prec@5 100.000 (99.997)
2019-04-10 17:48:19 - INFO - TRAINING - Epoch: [146][350/450]	Time 0.053 (0.055)	Data 0.012 (0.013)	Loss 0.1121 (0.0585)	Prec@1 97.000 (98.068)	Prec@5 100.000 (99.997)
2019-04-10 17:48:22 - INFO - TRAINING - Epoch: [146][400/450]	Time 0.053 (0.055)	Data 0.012 (0.013)	Loss 0.0262 (0.0578)	Prec@1 100.000 (98.092)	Prec@5 100.000 (99.998)
2019-04-10 17:48:24 - INFO - EVALUATING - Epoch: [146][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.2895 (0.2895)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:48:25 - INFO - EVALUATING - Epoch: [146][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3170 (0.3170)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:48:26 - INFO - EVALUATING - Epoch: [146][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.1779 (0.3747)	Prec@1 93.000 (90.196)	Prec@5 100.000 (99.569)
2019-04-10 17:48:27 - INFO - 
 Epoch: 147	Training Loss 0.0577 	Training Prec@1 98.073 	Training Prec@5 99.998 	Validation Loss 0.3682 	Validation Prec@1 90.360 	Validation Prec@5 99.640 	Test Loss 0.3661 	Test Prec@1  90.570 	Test Prec@5  99.610 

2019-04-10 17:48:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:48:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:48:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:48:27 - INFO - TRAINING - Epoch: [147][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0577 (0.0577)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:48:30 - INFO - TRAINING - Epoch: [147][50/450]	Time 0.055 (0.055)	Data 0.012 (0.013)	Loss 0.0204 (0.0472)	Prec@1 100.000 (98.392)	Prec@5 100.000 (100.000)
2019-04-10 17:48:33 - INFO - TRAINING - Epoch: [147][100/450]	Time 0.055 (0.055)	Data 0.012 (0.013)	Loss 0.0392 (0.0511)	Prec@1 99.000 (98.238)	Prec@5 100.000 (100.000)
2019-04-10 17:48:35 - INFO - TRAINING - Epoch: [147][150/450]	Time 0.056 (0.055)	Data 0.012 (0.013)	Loss 0.0547 (0.0512)	Prec@1 97.000 (98.245)	Prec@5 100.000 (99.993)
2019-04-10 17:48:38 - INFO - TRAINING - Epoch: [147][200/450]	Time 0.055 (0.056)	Data 0.012 (0.013)	Loss 0.0538 (0.0531)	Prec@1 98.000 (98.219)	Prec@5 100.000 (99.985)
2019-04-10 17:48:41 - INFO - TRAINING - Epoch: [147][250/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0364 (0.0533)	Prec@1 98.000 (98.211)	Prec@5 100.000 (99.988)
2019-04-10 17:48:44 - INFO - TRAINING - Epoch: [147][300/450]	Time 0.056 (0.056)	Data 0.012 (0.013)	Loss 0.0670 (0.0540)	Prec@1 98.000 (98.183)	Prec@5 100.000 (99.990)
2019-04-10 17:48:47 - INFO - TRAINING - Epoch: [147][350/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0291 (0.0558)	Prec@1 99.000 (98.111)	Prec@5 100.000 (99.991)
2019-04-10 17:48:50 - INFO - TRAINING - Epoch: [147][400/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0514 (0.0565)	Prec@1 98.000 (98.082)	Prec@5 100.000 (99.990)
2019-04-10 17:48:52 - INFO - EVALUATING - Epoch: [147][0/50]	Time 0.049 (0.049)	Data 0.010 (0.010)	Loss 0.5142 (0.5142)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:48:53 - INFO - EVALUATING - Epoch: [147][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3020 (0.3020)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:48:54 - INFO - EVALUATING - Epoch: [147][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.2928 (0.3726)	Prec@1 91.000 (90.196)	Prec@5 100.000 (99.529)
2019-04-10 17:48:55 - INFO - 
 Epoch: 148	Training Loss 0.0557 	Training Prec@1 98.109 	Training Prec@5 99.991 	Validation Loss 0.3732 	Validation Prec@1 90.040 	Validation Prec@5 99.740 	Test Loss 0.3625 	Test Prec@1  90.430 	Test Prec@5  99.610 

2019-04-10 17:48:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:48:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:48:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:48:55 - INFO - TRAINING - Epoch: [148][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0331 (0.0331)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:48:58 - INFO - TRAINING - Epoch: [148][50/450]	Time 0.055 (0.055)	Data 0.012 (0.013)	Loss 0.0414 (0.0536)	Prec@1 99.000 (98.039)	Prec@5 100.000 (99.980)
2019-04-10 17:49:01 - INFO - TRAINING - Epoch: [148][100/450]	Time 0.056 (0.056)	Data 0.012 (0.013)	Loss 0.0357 (0.0516)	Prec@1 99.000 (98.198)	Prec@5 100.000 (99.980)
2019-04-10 17:49:04 - INFO - TRAINING - Epoch: [148][150/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0487 (0.0544)	Prec@1 97.000 (98.139)	Prec@5 100.000 (99.987)
2019-04-10 17:49:07 - INFO - TRAINING - Epoch: [148][200/450]	Time 0.057 (0.056)	Data 0.012 (0.013)	Loss 0.0212 (0.0536)	Prec@1 99.000 (98.169)	Prec@5 100.000 (99.990)
2019-04-10 17:49:10 - INFO - TRAINING - Epoch: [148][250/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.0662 (0.0540)	Prec@1 98.000 (98.131)	Prec@5 100.000 (99.992)
2019-04-10 17:49:12 - INFO - TRAINING - Epoch: [148][300/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.0936 (0.0564)	Prec@1 96.000 (98.047)	Prec@5 100.000 (99.993)
2019-04-10 17:49:15 - INFO - TRAINING - Epoch: [148][350/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.1256 (0.0578)	Prec@1 95.000 (98.006)	Prec@5 100.000 (99.994)
2019-04-10 17:49:18 - INFO - TRAINING - Epoch: [148][400/450]	Time 0.057 (0.057)	Data 0.012 (0.013)	Loss 0.0968 (0.0575)	Prec@1 97.000 (98.007)	Prec@5 100.000 (99.995)
2019-04-10 17:49:21 - INFO - EVALUATING - Epoch: [148][0/50]	Time 0.049 (0.049)	Data 0.010 (0.010)	Loss 0.5226 (0.5226)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:49:22 - INFO - EVALUATING - Epoch: [148][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2502 (0.2502)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:49:23 - INFO - EVALUATING - Epoch: [148][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2233 (0.3961)	Prec@1 94.000 (90.118)	Prec@5 100.000 (99.471)
2019-04-10 17:49:24 - INFO - 
 Epoch: 149	Training Loss 0.0581 	Training Prec@1 98.002 	Training Prec@5 99.996 	Validation Loss 0.3678 	Validation Prec@1 90.420 	Validation Prec@5 99.640 	Test Loss 0.3820 	Test Prec@1  90.350 	Test Prec@5  99.520 

2019-04-10 17:49:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:49:24 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:49:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:49:24 - INFO - TRAINING - Epoch: [149][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0446 (0.0446)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:49:26 - INFO - TRAINING - Epoch: [149][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.0564 (0.0541)	Prec@1 98.000 (98.216)	Prec@5 100.000 (100.000)
2019-04-10 17:49:29 - INFO - TRAINING - Epoch: [149][100/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0525 (0.0522)	Prec@1 99.000 (98.267)	Prec@5 100.000 (100.000)
2019-04-10 17:49:32 - INFO - TRAINING - Epoch: [149][150/450]	Time 0.055 (0.053)	Data 0.014 (0.014)	Loss 0.0243 (0.0551)	Prec@1 100.000 (98.166)	Prec@5 100.000 (100.000)
2019-04-10 17:49:35 - INFO - TRAINING - Epoch: [149][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1099 (0.0545)	Prec@1 97.000 (98.154)	Prec@5 100.000 (100.000)
2019-04-10 17:49:37 - INFO - TRAINING - Epoch: [149][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0400 (0.0545)	Prec@1 99.000 (98.147)	Prec@5 100.000 (100.000)
2019-04-10 17:49:40 - INFO - TRAINING - Epoch: [149][300/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0529 (0.0557)	Prec@1 97.000 (98.093)	Prec@5 100.000 (99.997)
2019-04-10 17:49:43 - INFO - TRAINING - Epoch: [149][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0420 (0.0571)	Prec@1 98.000 (98.048)	Prec@5 100.000 (99.997)
2019-04-10 17:49:45 - INFO - TRAINING - Epoch: [149][400/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.1116 (0.0569)	Prec@1 97.000 (98.047)	Prec@5 100.000 (99.998)
2019-04-10 17:49:48 - INFO - EVALUATING - Epoch: [149][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.5086 (0.5086)	Prec@1 87.000 (87.000)	Prec@5 98.000 (98.000)
2019-04-10 17:49:49 - INFO - EVALUATING - Epoch: [149][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2763 (0.2763)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:49:50 - INFO - EVALUATING - Epoch: [149][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1993 (0.3841)	Prec@1 94.000 (89.961)	Prec@5 100.000 (99.431)
2019-04-10 17:49:51 - INFO - 
 Epoch: 150	Training Loss 0.0580 	Training Prec@1 98.020 	Training Prec@5 99.998 	Validation Loss 0.3582 	Validation Prec@1 90.380 	Validation Prec@5 99.580 	Test Loss 0.3750 	Test Prec@1  90.300 	Test Prec@5  99.500 

2019-04-10 17:49:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:49:51 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:49:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:49:51 - INFO - TRAINING - Epoch: [150][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0801 (0.0801)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:49:54 - INFO - TRAINING - Epoch: [150][50/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.0243 (0.0615)	Prec@1 99.000 (98.078)	Prec@5 100.000 (100.000)
2019-04-10 17:49:57 - INFO - TRAINING - Epoch: [150][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0660 (0.0601)	Prec@1 99.000 (97.990)	Prec@5 100.000 (100.000)
2019-04-10 17:50:00 - INFO - TRAINING - Epoch: [150][150/450]	Time 0.057 (0.057)	Data 0.013 (0.014)	Loss 0.1024 (0.0589)	Prec@1 96.000 (98.086)	Prec@5 100.000 (99.993)
2019-04-10 17:50:02 - INFO - TRAINING - Epoch: [150][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0348 (0.0593)	Prec@1 98.000 (98.055)	Prec@5 100.000 (99.995)
2019-04-10 17:50:05 - INFO - TRAINING - Epoch: [150][250/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0416 (0.0612)	Prec@1 99.000 (97.960)	Prec@5 100.000 (99.992)
2019-04-10 17:50:08 - INFO - TRAINING - Epoch: [150][300/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0338 (0.0603)	Prec@1 99.000 (97.963)	Prec@5 100.000 (99.990)
2019-04-10 17:50:10 - INFO - TRAINING - Epoch: [150][350/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0373 (0.0607)	Prec@1 98.000 (97.954)	Prec@5 100.000 (99.989)
2019-04-10 17:50:13 - INFO - TRAINING - Epoch: [150][400/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0139 (0.0602)	Prec@1 100.000 (98.000)	Prec@5 100.000 (99.988)
2019-04-10 17:50:16 - INFO - EVALUATING - Epoch: [150][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.2028 (0.2028)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:50:17 - INFO - EVALUATING - Epoch: [150][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2777 (0.2777)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:50:18 - INFO - EVALUATING - Epoch: [150][50/100]	Time 0.017 (0.018)	Data 0.010 (0.010)	Loss 0.2433 (0.3874)	Prec@1 91.000 (89.686)	Prec@5 100.000 (99.588)
2019-04-10 17:50:18 - INFO - 
 Epoch: 151	Training Loss 0.0596 	Training Prec@1 98.004 	Training Prec@5 99.989 	Validation Loss 0.3526 	Validation Prec@1 90.780 	Validation Prec@5 99.660 	Test Loss 0.3811 	Test Prec@1  89.950 	Test Prec@5  99.640 

2019-04-10 17:50:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:50:19 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:50:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:50:19 - INFO - TRAINING - Epoch: [151][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0268 (0.0268)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:50:21 - INFO - TRAINING - Epoch: [151][50/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0467 (0.0574)	Prec@1 99.000 (97.882)	Prec@5 100.000 (100.000)
2019-04-10 17:50:24 - INFO - TRAINING - Epoch: [151][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0583 (0.0581)	Prec@1 99.000 (97.970)	Prec@5 100.000 (100.000)
2019-04-10 17:50:27 - INFO - TRAINING - Epoch: [151][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0572 (0.0548)	Prec@1 98.000 (98.099)	Prec@5 100.000 (100.000)
2019-04-10 17:50:30 - INFO - TRAINING - Epoch: [151][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0324 (0.0534)	Prec@1 99.000 (98.174)	Prec@5 100.000 (99.995)
2019-04-10 17:50:32 - INFO - TRAINING - Epoch: [151][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0665 (0.0539)	Prec@1 98.000 (98.104)	Prec@5 100.000 (99.992)
2019-04-10 17:50:35 - INFO - TRAINING - Epoch: [151][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0442 (0.0551)	Prec@1 98.000 (98.066)	Prec@5 100.000 (99.993)
2019-04-10 17:50:38 - INFO - TRAINING - Epoch: [151][350/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0622 (0.0552)	Prec@1 98.000 (98.054)	Prec@5 100.000 (99.994)
2019-04-10 17:50:40 - INFO - TRAINING - Epoch: [151][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0518 (0.0546)	Prec@1 98.000 (98.080)	Prec@5 100.000 (99.995)
2019-04-10 17:50:43 - INFO - EVALUATING - Epoch: [151][0/50]	Time 0.034 (0.034)	Data 0.019 (0.019)	Loss 0.5586 (0.5586)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-04-10 17:50:44 - INFO - EVALUATING - Epoch: [151][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3222 (0.3222)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:50:45 - INFO - EVALUATING - Epoch: [151][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2042 (0.3795)	Prec@1 93.000 (90.176)	Prec@5 100.000 (99.608)
2019-04-10 17:50:46 - INFO - 
 Epoch: 152	Training Loss 0.0543 	Training Prec@1 98.098 	Training Prec@5 99.996 	Validation Loss 0.3771 	Validation Prec@1 90.020 	Validation Prec@5 99.660 	Test Loss 0.3780 	Test Prec@1  90.320 	Test Prec@5  99.600 

2019-04-10 17:50:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:50:46 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:50:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:50:46 - INFO - TRAINING - Epoch: [152][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0606 (0.0606)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:50:49 - INFO - TRAINING - Epoch: [152][50/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.0531 (0.0535)	Prec@1 98.000 (98.078)	Prec@5 100.000 (100.000)
2019-04-10 17:50:51 - INFO - TRAINING - Epoch: [152][100/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.0236 (0.0507)	Prec@1 99.000 (98.267)	Prec@5 100.000 (100.000)
2019-04-10 17:50:54 - INFO - TRAINING - Epoch: [152][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0622 (0.0520)	Prec@1 99.000 (98.172)	Prec@5 100.000 (99.987)
2019-04-10 17:50:57 - INFO - TRAINING - Epoch: [152][200/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0747 (0.0522)	Prec@1 96.000 (98.249)	Prec@5 100.000 (99.990)
2019-04-10 17:50:59 - INFO - TRAINING - Epoch: [152][250/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1725 (0.0532)	Prec@1 94.000 (98.199)	Prec@5 100.000 (99.988)
2019-04-10 17:51:02 - INFO - TRAINING - Epoch: [152][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0841 (0.0532)	Prec@1 97.000 (98.179)	Prec@5 100.000 (99.990)
2019-04-10 17:51:05 - INFO - TRAINING - Epoch: [152][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0122 (0.0523)	Prec@1 100.000 (98.199)	Prec@5 100.000 (99.991)
2019-04-10 17:51:08 - INFO - TRAINING - Epoch: [152][400/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.0549 (0.0523)	Prec@1 98.000 (98.192)	Prec@5 100.000 (99.993)
2019-04-10 17:51:10 - INFO - EVALUATING - Epoch: [152][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.2275 (0.2275)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:51:11 - INFO - EVALUATING - Epoch: [152][0/100]	Time 0.017 (0.017)	Data 0.012 (0.012)	Loss 0.2746 (0.2746)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:51:12 - INFO - EVALUATING - Epoch: [152][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1505 (0.3744)	Prec@1 96.000 (90.333)	Prec@5 100.000 (99.392)
2019-04-10 17:51:13 - INFO - 
 Epoch: 153	Training Loss 0.0529 	Training Prec@1 98.149 	Training Prec@5 99.993 	Validation Loss 0.3627 	Validation Prec@1 90.600 	Validation Prec@5 99.680 	Test Loss 0.3825 	Test Prec@1  90.210 	Test Prec@5  99.510 

2019-04-10 17:51:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:51:13 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:51:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:51:13 - INFO - TRAINING - Epoch: [153][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0240 (0.0240)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:51:16 - INFO - TRAINING - Epoch: [153][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0289 (0.0599)	Prec@1 99.000 (97.961)	Prec@5 100.000 (100.000)
2019-04-10 17:51:19 - INFO - TRAINING - Epoch: [153][100/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0900 (0.0561)	Prec@1 96.000 (98.109)	Prec@5 100.000 (100.000)
2019-04-10 17:51:21 - INFO - TRAINING - Epoch: [153][150/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0559 (0.0576)	Prec@1 97.000 (98.026)	Prec@5 100.000 (99.993)
2019-04-10 17:51:24 - INFO - TRAINING - Epoch: [153][200/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0440 (0.0559)	Prec@1 99.000 (98.055)	Prec@5 100.000 (99.995)
2019-04-10 17:51:27 - INFO - TRAINING - Epoch: [153][250/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0520 (0.0551)	Prec@1 98.000 (98.092)	Prec@5 100.000 (99.996)
2019-04-10 17:51:30 - INFO - TRAINING - Epoch: [153][300/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0354 (0.0554)	Prec@1 99.000 (98.100)	Prec@5 100.000 (99.993)
2019-04-10 17:51:32 - INFO - TRAINING - Epoch: [153][350/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0449 (0.0554)	Prec@1 99.000 (98.100)	Prec@5 100.000 (99.994)
2019-04-10 17:51:35 - INFO - TRAINING - Epoch: [153][400/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.1406 (0.0561)	Prec@1 97.000 (98.090)	Prec@5 100.000 (99.995)
2019-04-10 17:51:38 - INFO - EVALUATING - Epoch: [153][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.2330 (0.2330)	Prec@1 95.000 (95.000)	Prec@5 99.000 (99.000)
2019-04-10 17:51:39 - INFO - EVALUATING - Epoch: [153][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3328 (0.3328)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:51:40 - INFO - EVALUATING - Epoch: [153][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2440 (0.3831)	Prec@1 90.000 (89.941)	Prec@5 100.000 (99.471)
2019-04-10 17:51:41 - INFO - 
 Epoch: 154	Training Loss 0.0557 	Training Prec@1 98.120 	Training Prec@5 99.996 	Validation Loss 0.3655 	Validation Prec@1 90.660 	Validation Prec@5 99.620 	Test Loss 0.3805 	Test Prec@1  90.070 	Test Prec@5  99.510 

2019-04-10 17:51:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:51:41 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:51:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:51:41 - INFO - TRAINING - Epoch: [154][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0608 (0.0608)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:51:44 - INFO - TRAINING - Epoch: [154][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0422 (0.0507)	Prec@1 99.000 (98.176)	Prec@5 100.000 (100.000)
2019-04-10 17:51:46 - INFO - TRAINING - Epoch: [154][100/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.0186 (0.0529)	Prec@1 100.000 (98.248)	Prec@5 100.000 (100.000)
2019-04-10 17:51:49 - INFO - TRAINING - Epoch: [154][150/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0441 (0.0516)	Prec@1 99.000 (98.285)	Prec@5 100.000 (100.000)
2019-04-10 17:51:52 - INFO - TRAINING - Epoch: [154][200/450]	Time 0.066 (0.056)	Data 0.012 (0.014)	Loss 0.0294 (0.0525)	Prec@1 99.000 (98.254)	Prec@5 100.000 (100.000)
2019-04-10 17:51:55 - INFO - TRAINING - Epoch: [154][250/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.0209 (0.0524)	Prec@1 99.000 (98.251)	Prec@5 100.000 (100.000)
2019-04-10 17:51:58 - INFO - TRAINING - Epoch: [154][300/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0255 (0.0510)	Prec@1 99.000 (98.279)	Prec@5 100.000 (100.000)
2019-04-10 17:52:01 - INFO - TRAINING - Epoch: [154][350/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0670 (0.0514)	Prec@1 96.000 (98.225)	Prec@5 100.000 (100.000)
2019-04-10 17:52:04 - INFO - TRAINING - Epoch: [154][400/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.1558 (0.0518)	Prec@1 97.000 (98.219)	Prec@5 100.000 (100.000)
2019-04-10 17:52:06 - INFO - EVALUATING - Epoch: [154][0/50]	Time 0.048 (0.048)	Data 0.010 (0.010)	Loss 0.3349 (0.3349)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:52:07 - INFO - EVALUATING - Epoch: [154][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2759 (0.2759)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:52:08 - INFO - EVALUATING - Epoch: [154][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2276 (0.3781)	Prec@1 92.000 (90.039)	Prec@5 100.000 (99.529)
2019-04-10 17:52:09 - INFO - 
 Epoch: 155	Training Loss 0.0524 	Training Prec@1 98.202 	Training Prec@5 100.000 	Validation Loss 0.3750 	Validation Prec@1 90.200 	Validation Prec@5 99.620 	Test Loss 0.3769 	Test Prec@1  90.260 	Test Prec@5  99.570 

2019-04-10 17:52:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:52:09 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:52:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:52:09 - INFO - TRAINING - Epoch: [155][0/450]	Time 0.030 (0.030)	Data 0.012 (0.012)	Loss 0.0775 (0.0775)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:52:12 - INFO - TRAINING - Epoch: [155][50/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0325 (0.0495)	Prec@1 99.000 (98.412)	Prec@5 100.000 (100.000)
2019-04-10 17:52:15 - INFO - TRAINING - Epoch: [155][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0596 (0.0559)	Prec@1 99.000 (98.168)	Prec@5 100.000 (100.000)
2019-04-10 17:52:17 - INFO - TRAINING - Epoch: [155][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0303 (0.0552)	Prec@1 99.000 (98.172)	Prec@5 100.000 (99.993)
2019-04-10 17:52:20 - INFO - TRAINING - Epoch: [155][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1574 (0.0552)	Prec@1 96.000 (98.164)	Prec@5 100.000 (99.990)
2019-04-10 17:52:23 - INFO - TRAINING - Epoch: [155][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0270 (0.0535)	Prec@1 99.000 (98.195)	Prec@5 100.000 (99.988)
2019-04-10 17:52:25 - INFO - TRAINING - Epoch: [155][300/450]	Time 0.048 (0.054)	Data 0.022 (0.014)	Loss 0.0496 (0.0546)	Prec@1 98.000 (98.123)	Prec@5 100.000 (99.990)
2019-04-10 17:52:28 - INFO - TRAINING - Epoch: [155][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0375 (0.0546)	Prec@1 99.000 (98.145)	Prec@5 100.000 (99.991)
2019-04-10 17:52:31 - INFO - TRAINING - Epoch: [155][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0433 (0.0535)	Prec@1 98.000 (98.200)	Prec@5 100.000 (99.993)
2019-04-10 17:52:34 - INFO - EVALUATING - Epoch: [155][0/50]	Time 0.040 (0.040)	Data 0.012 (0.012)	Loss 0.3234 (0.3234)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:52:34 - INFO - EVALUATING - Epoch: [155][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2972 (0.2972)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:52:35 - INFO - EVALUATING - Epoch: [155][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2750 (0.3795)	Prec@1 89.000 (90.098)	Prec@5 100.000 (99.588)
2019-04-10 17:52:36 - INFO - 
 Epoch: 156	Training Loss 0.0531 	Training Prec@1 98.224 	Training Prec@5 99.993 	Validation Loss 0.3810 	Validation Prec@1 90.120 	Validation Prec@5 99.680 	Test Loss 0.3729 	Test Prec@1  90.190 	Test Prec@5  99.700 

2019-04-10 17:52:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:52:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:52:36 - INFO - TRAINING - Epoch: [156][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0801 (0.0801)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:52:39 - INFO - TRAINING - Epoch: [156][50/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.0583 (0.0480)	Prec@1 98.000 (98.549)	Prec@5 100.000 (100.000)
2019-04-10 17:52:42 - INFO - TRAINING - Epoch: [156][100/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.0691 (0.0493)	Prec@1 97.000 (98.327)	Prec@5 100.000 (99.990)
2019-04-10 17:52:45 - INFO - TRAINING - Epoch: [156][150/450]	Time 0.053 (0.055)	Data 0.014 (0.014)	Loss 0.0216 (0.0509)	Prec@1 99.000 (98.331)	Prec@5 100.000 (99.993)
2019-04-10 17:52:47 - INFO - TRAINING - Epoch: [156][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0272 (0.0501)	Prec@1 99.000 (98.378)	Prec@5 100.000 (99.995)
2019-04-10 17:52:50 - INFO - TRAINING - Epoch: [156][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0184 (0.0502)	Prec@1 100.000 (98.331)	Prec@5 100.000 (99.996)
2019-04-10 17:52:53 - INFO - TRAINING - Epoch: [156][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0767 (0.0509)	Prec@1 99.000 (98.312)	Prec@5 100.000 (99.997)
2019-04-10 17:52:55 - INFO - TRAINING - Epoch: [156][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0140 (0.0508)	Prec@1 100.000 (98.305)	Prec@5 100.000 (99.991)
2019-04-10 17:52:58 - INFO - TRAINING - Epoch: [156][400/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0811 (0.0511)	Prec@1 96.000 (98.279)	Prec@5 100.000 (99.990)
2019-04-10 17:53:01 - INFO - EVALUATING - Epoch: [156][0/50]	Time 0.042 (0.042)	Data 0.011 (0.011)	Loss 0.2208 (0.2208)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:02 - INFO - EVALUATING - Epoch: [156][0/100]	Time 0.017 (0.017)	Data 0.009 (0.009)	Loss 0.3271 (0.3271)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:53:02 - INFO - EVALUATING - Epoch: [156][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1739 (0.3902)	Prec@1 93.000 (89.804)	Prec@5 100.000 (99.647)
2019-04-10 17:53:03 - INFO - 
 Epoch: 157	Training Loss 0.0514 	Training Prec@1 98.256 	Training Prec@5 99.991 	Validation Loss 0.3615 	Validation Prec@1 90.520 	Validation Prec@5 99.640 	Test Loss 0.3796 	Test Prec@1  90.120 	Test Prec@5  99.670 

2019-04-10 17:53:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:53:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:53:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:53:04 - INFO - TRAINING - Epoch: [157][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0902 (0.0902)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:06 - INFO - TRAINING - Epoch: [157][50/450]	Time 0.060 (0.054)	Data 0.013 (0.014)	Loss 0.0361 (0.0556)	Prec@1 98.000 (98.059)	Prec@5 100.000 (100.000)
2019-04-10 17:53:09 - INFO - TRAINING - Epoch: [157][100/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0235 (0.0558)	Prec@1 99.000 (98.069)	Prec@5 100.000 (100.000)
2019-04-10 17:53:12 - INFO - TRAINING - Epoch: [157][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0250 (0.0560)	Prec@1 100.000 (98.073)	Prec@5 100.000 (100.000)
2019-04-10 17:53:14 - INFO - TRAINING - Epoch: [157][200/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0305 (0.0554)	Prec@1 99.000 (98.134)	Prec@5 100.000 (99.990)
2019-04-10 17:53:17 - INFO - TRAINING - Epoch: [157][250/450]	Time 0.052 (0.054)	Data 0.014 (0.014)	Loss 0.0163 (0.0549)	Prec@1 100.000 (98.163)	Prec@5 100.000 (99.992)
2019-04-10 17:53:20 - INFO - TRAINING - Epoch: [157][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0303 (0.0535)	Prec@1 98.000 (98.189)	Prec@5 100.000 (99.990)
2019-04-10 17:53:23 - INFO - TRAINING - Epoch: [157][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0690 (0.0541)	Prec@1 98.000 (98.174)	Prec@5 100.000 (99.991)
2019-04-10 17:53:25 - INFO - TRAINING - Epoch: [157][400/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0230 (0.0545)	Prec@1 100.000 (98.155)	Prec@5 100.000 (99.993)
2019-04-10 17:53:28 - INFO - EVALUATING - Epoch: [157][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.4491 (0.4491)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:29 - INFO - EVALUATING - Epoch: [157][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3322 (0.3322)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:30 - INFO - EVALUATING - Epoch: [157][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1778 (0.3778)	Prec@1 95.000 (90.510)	Prec@5 100.000 (99.549)
2019-04-10 17:53:31 - INFO - 
 Epoch: 158	Training Loss 0.0541 	Training Prec@1 98.164 	Training Prec@5 99.993 	Validation Loss 0.3788 	Validation Prec@1 90.440 	Validation Prec@5 99.600 	Test Loss 0.3807 	Test Prec@1  90.320 	Test Prec@5  99.630 

2019-04-10 17:53:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:53:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:53:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:53:31 - INFO - TRAINING - Epoch: [158][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.1243 (0.1243)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:34 - INFO - TRAINING - Epoch: [158][50/450]	Time 0.055 (0.055)	Data 0.014 (0.015)	Loss 0.0929 (0.0541)	Prec@1 96.000 (98.137)	Prec@5 100.000 (100.000)
2019-04-10 17:53:36 - INFO - TRAINING - Epoch: [158][100/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0579 (0.0548)	Prec@1 98.000 (98.139)	Prec@5 100.000 (100.000)
2019-04-10 17:53:39 - INFO - TRAINING - Epoch: [158][150/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0429 (0.0556)	Prec@1 99.000 (98.046)	Prec@5 100.000 (100.000)
2019-04-10 17:53:42 - INFO - TRAINING - Epoch: [158][200/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.0269 (0.0540)	Prec@1 99.000 (98.085)	Prec@5 100.000 (100.000)
2019-04-10 17:53:44 - INFO - TRAINING - Epoch: [158][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0500 (0.0517)	Prec@1 98.000 (98.199)	Prec@5 100.000 (100.000)
2019-04-10 17:53:47 - INFO - TRAINING - Epoch: [158][300/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0354 (0.0523)	Prec@1 99.000 (98.226)	Prec@5 100.000 (100.000)
2019-04-10 17:53:50 - INFO - TRAINING - Epoch: [158][350/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0316 (0.0526)	Prec@1 99.000 (98.199)	Prec@5 100.000 (100.000)
2019-04-10 17:53:53 - INFO - TRAINING - Epoch: [158][400/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0601 (0.0527)	Prec@1 98.000 (98.209)	Prec@5 100.000 (100.000)
2019-04-10 17:53:55 - INFO - EVALUATING - Epoch: [158][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.3318 (0.3318)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:53:56 - INFO - EVALUATING - Epoch: [158][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3086 (0.3086)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:53:57 - INFO - EVALUATING - Epoch: [158][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2273 (0.3954)	Prec@1 92.000 (89.569)	Prec@5 100.000 (99.471)
2019-04-10 17:53:58 - INFO - 
 Epoch: 159	Training Loss 0.0530 	Training Prec@1 98.193 	Training Prec@5 100.000 	Validation Loss 0.3680 	Validation Prec@1 90.280 	Validation Prec@5 99.640 	Test Loss 0.3910 	Test Prec@1  89.750 	Test Prec@5  99.540 

2019-04-10 17:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:53:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:53:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:53:58 - INFO - TRAINING - Epoch: [159][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0403 (0.0403)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:01 - INFO - TRAINING - Epoch: [159][50/450]	Time 0.054 (0.053)	Data 0.013 (0.014)	Loss 0.0332 (0.0560)	Prec@1 99.000 (97.980)	Prec@5 100.000 (100.000)
2019-04-10 17:54:04 - INFO - TRAINING - Epoch: [159][100/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0630 (0.0548)	Prec@1 97.000 (97.980)	Prec@5 100.000 (100.000)
2019-04-10 17:54:06 - INFO - TRAINING - Epoch: [159][150/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0560 (0.0564)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:09 - INFO - TRAINING - Epoch: [159][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0940 (0.0562)	Prec@1 97.000 (98.060)	Prec@5 100.000 (100.000)
2019-04-10 17:54:12 - INFO - TRAINING - Epoch: [159][250/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.1119 (0.0555)	Prec@1 97.000 (98.104)	Prec@5 100.000 (100.000)
2019-04-10 17:54:14 - INFO - TRAINING - Epoch: [159][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0096 (0.0539)	Prec@1 100.000 (98.163)	Prec@5 100.000 (100.000)
2019-04-10 17:54:17 - INFO - TRAINING - Epoch: [159][350/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0613 (0.0532)	Prec@1 97.000 (98.194)	Prec@5 100.000 (100.000)
2019-04-10 17:54:20 - INFO - TRAINING - Epoch: [159][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0915 (0.0527)	Prec@1 96.000 (98.207)	Prec@5 100.000 (100.000)
2019-04-10 17:54:23 - INFO - EVALUATING - Epoch: [159][0/50]	Time 0.040 (0.040)	Data 0.012 (0.012)	Loss 0.3072 (0.3072)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:23 - INFO - EVALUATING - Epoch: [159][0/100]	Time 0.016 (0.016)	Data 0.010 (0.010)	Loss 0.2592 (0.2592)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:54:24 - INFO - EVALUATING - Epoch: [159][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3193 (0.3897)	Prec@1 93.000 (90.176)	Prec@5 100.000 (99.471)
2019-04-10 17:54:25 - INFO - 
 Epoch: 160	Training Loss 0.0528 	Training Prec@1 98.209 	Training Prec@5 99.998 	Validation Loss 0.3592 	Validation Prec@1 90.800 	Validation Prec@5 99.720 	Test Loss 0.3793 	Test Prec@1  90.340 	Test Prec@5  99.480 

2019-04-10 17:54:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:54:25 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:54:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:54:26 - INFO - TRAINING - Epoch: [160][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.1848 (0.1848)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:28 - INFO - TRAINING - Epoch: [160][50/450]	Time 0.054 (0.054)	Data 0.014 (0.015)	Loss 0.1281 (0.0650)	Prec@1 97.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:31 - INFO - TRAINING - Epoch: [160][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0088 (0.0564)	Prec@1 100.000 (98.149)	Prec@5 100.000 (100.000)
2019-04-10 17:54:34 - INFO - TRAINING - Epoch: [160][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0185 (0.0552)	Prec@1 99.000 (98.146)	Prec@5 100.000 (99.993)
2019-04-10 17:54:36 - INFO - TRAINING - Epoch: [160][200/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0552 (0.0542)	Prec@1 98.000 (98.149)	Prec@5 100.000 (99.995)
2019-04-10 17:54:39 - INFO - TRAINING - Epoch: [160][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0587 (0.0538)	Prec@1 97.000 (98.135)	Prec@5 100.000 (99.992)
2019-04-10 17:54:42 - INFO - TRAINING - Epoch: [160][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0404 (0.0526)	Prec@1 99.000 (98.199)	Prec@5 100.000 (99.993)
2019-04-10 17:54:45 - INFO - TRAINING - Epoch: [160][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0491 (0.0535)	Prec@1 98.000 (98.168)	Prec@5 100.000 (99.994)
2019-04-10 17:54:47 - INFO - TRAINING - Epoch: [160][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0469 (0.0535)	Prec@1 98.000 (98.165)	Prec@5 100.000 (99.995)
2019-04-10 17:54:50 - INFO - EVALUATING - Epoch: [160][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.3524 (0.3524)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:54:51 - INFO - EVALUATING - Epoch: [160][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3219 (0.3219)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:54:52 - INFO - EVALUATING - Epoch: [160][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2869 (0.3889)	Prec@1 92.000 (90.216)	Prec@5 99.000 (99.431)
2019-04-10 17:54:53 - INFO - 
 Epoch: 161	Training Loss 0.0542 	Training Prec@1 98.133 	Training Prec@5 99.996 	Validation Loss 0.3587 	Validation Prec@1 90.860 	Validation Prec@5 99.760 	Test Loss 0.3798 	Test Prec@1  90.420 	Test Prec@5  99.500 

2019-04-10 17:54:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:54:53 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:54:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:54:53 - INFO - TRAINING - Epoch: [161][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0562 (0.0562)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:54:56 - INFO - TRAINING - Epoch: [161][50/450]	Time 0.053 (0.053)	Data 0.012 (0.014)	Loss 0.0226 (0.0610)	Prec@1 100.000 (98.098)	Prec@5 100.000 (100.000)
2019-04-10 17:54:58 - INFO - TRAINING - Epoch: [161][100/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0147 (0.0576)	Prec@1 99.000 (98.059)	Prec@5 100.000 (100.000)
2019-04-10 17:55:01 - INFO - TRAINING - Epoch: [161][150/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0663 (0.0562)	Prec@1 97.000 (98.066)	Prec@5 100.000 (99.993)
2019-04-10 17:55:04 - INFO - TRAINING - Epoch: [161][200/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0498 (0.0548)	Prec@1 98.000 (98.114)	Prec@5 100.000 (99.995)
2019-04-10 17:55:06 - INFO - TRAINING - Epoch: [161][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0434 (0.0527)	Prec@1 98.000 (98.215)	Prec@5 100.000 (99.992)
2019-04-10 17:55:09 - INFO - TRAINING - Epoch: [161][300/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0349 (0.0530)	Prec@1 99.000 (98.176)	Prec@5 100.000 (99.993)
2019-04-10 17:55:12 - INFO - TRAINING - Epoch: [161][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0877 (0.0532)	Prec@1 97.000 (98.174)	Prec@5 100.000 (99.994)
2019-04-10 17:55:15 - INFO - TRAINING - Epoch: [161][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0374 (0.0538)	Prec@1 99.000 (98.170)	Prec@5 100.000 (99.993)
2019-04-10 17:55:17 - INFO - EVALUATING - Epoch: [161][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.2094 (0.2094)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:18 - INFO - EVALUATING - Epoch: [161][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3007 (0.3007)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:19 - INFO - EVALUATING - Epoch: [161][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2725 (0.3909)	Prec@1 93.000 (89.745)	Prec@5 100.000 (99.392)
2019-04-10 17:55:20 - INFO - 
 Epoch: 162	Training Loss 0.0525 	Training Prec@1 98.220 	Training Prec@5 99.991 	Validation Loss 0.3687 	Validation Prec@1 90.600 	Validation Prec@5 99.740 	Test Loss 0.3905 	Test Prec@1  90.090 	Test Prec@5  99.510 

2019-04-10 17:55:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:55:20 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:55:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:55:20 - INFO - TRAINING - Epoch: [162][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0560 (0.0560)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:23 - INFO - TRAINING - Epoch: [162][50/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0462 (0.0534)	Prec@1 99.000 (98.196)	Prec@5 100.000 (100.000)
2019-04-10 17:55:26 - INFO - TRAINING - Epoch: [162][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0697 (0.0538)	Prec@1 97.000 (98.257)	Prec@5 100.000 (100.000)
2019-04-10 17:55:28 - INFO - TRAINING - Epoch: [162][150/450]	Time 0.050 (0.054)	Data 0.016 (0.014)	Loss 0.0098 (0.0537)	Prec@1 100.000 (98.245)	Prec@5 100.000 (100.000)
2019-04-10 17:55:31 - INFO - TRAINING - Epoch: [162][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0702 (0.0551)	Prec@1 98.000 (98.169)	Prec@5 100.000 (100.000)
2019-04-10 17:55:34 - INFO - TRAINING - Epoch: [162][250/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0364 (0.0566)	Prec@1 99.000 (98.147)	Prec@5 100.000 (99.992)
2019-04-10 17:55:37 - INFO - TRAINING - Epoch: [162][300/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0403 (0.0575)	Prec@1 98.000 (98.126)	Prec@5 100.000 (99.993)
2019-04-10 17:55:39 - INFO - TRAINING - Epoch: [162][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0654 (0.0562)	Prec@1 97.000 (98.145)	Prec@5 100.000 (99.994)
2019-04-10 17:55:42 - INFO - TRAINING - Epoch: [162][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0506 (0.0562)	Prec@1 98.000 (98.152)	Prec@5 100.000 (99.995)
2019-04-10 17:55:45 - INFO - EVALUATING - Epoch: [162][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.3906 (0.3906)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:46 - INFO - EVALUATING - Epoch: [162][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2646 (0.2646)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:47 - INFO - EVALUATING - Epoch: [162][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2819 (0.3888)	Prec@1 90.000 (90.020)	Prec@5 100.000 (99.471)
2019-04-10 17:55:47 - INFO - 
 Epoch: 163	Training Loss 0.0547 	Training Prec@1 98.200 	Training Prec@5 99.996 	Validation Loss 0.3721 	Validation Prec@1 90.620 	Validation Prec@5 99.600 	Test Loss 0.3948 	Test Prec@1  90.050 	Test Prec@5  99.550 

2019-04-10 17:55:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:55:48 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:55:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:55:48 - INFO - TRAINING - Epoch: [163][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0838 (0.0838)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 17:55:50 - INFO - TRAINING - Epoch: [163][50/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0400 (0.0620)	Prec@1 99.000 (97.980)	Prec@5 100.000 (99.980)
2019-04-10 17:55:53 - INFO - TRAINING - Epoch: [163][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0084 (0.0595)	Prec@1 100.000 (98.040)	Prec@5 100.000 (99.990)
2019-04-10 17:55:56 - INFO - TRAINING - Epoch: [163][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0319 (0.0568)	Prec@1 98.000 (98.086)	Prec@5 100.000 (99.993)
2019-04-10 17:55:59 - INFO - TRAINING - Epoch: [163][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0465 (0.0567)	Prec@1 99.000 (98.124)	Prec@5 100.000 (99.995)
2019-04-10 17:56:01 - INFO - TRAINING - Epoch: [163][250/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0283 (0.0554)	Prec@1 99.000 (98.127)	Prec@5 100.000 (99.996)
2019-04-10 17:56:04 - INFO - TRAINING - Epoch: [163][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0263 (0.0544)	Prec@1 99.000 (98.136)	Prec@5 100.000 (99.997)
2019-04-10 17:56:07 - INFO - TRAINING - Epoch: [163][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0156 (0.0543)	Prec@1 100.000 (98.128)	Prec@5 100.000 (99.997)
2019-04-10 17:56:09 - INFO - TRAINING - Epoch: [163][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0261 (0.0536)	Prec@1 99.000 (98.147)	Prec@5 100.000 (99.998)
2019-04-10 17:56:12 - INFO - EVALUATING - Epoch: [163][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.6464 (0.6464)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-04-10 17:56:13 - INFO - EVALUATING - Epoch: [163][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2815 (0.2815)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 17:56:14 - INFO - EVALUATING - Epoch: [163][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3164 (0.3869)	Prec@1 91.000 (89.980)	Prec@5 99.000 (99.451)
2019-04-10 17:56:15 - INFO - 
 Epoch: 164	Training Loss 0.0534 	Training Prec@1 98.149 	Training Prec@5 99.998 	Validation Loss 0.3649 	Validation Prec@1 90.780 	Validation Prec@5 99.720 	Test Loss 0.3839 	Test Prec@1  90.190 	Test Prec@5  99.540 

2019-04-10 17:56:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:56:15 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:56:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:56:15 - INFO - TRAINING - Epoch: [164][0/450]	Time 0.034 (0.034)	Data 0.013 (0.013)	Loss 0.0237 (0.0237)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:56:18 - INFO - TRAINING - Epoch: [164][50/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0184 (0.0509)	Prec@1 100.000 (98.353)	Prec@5 100.000 (100.000)
2019-04-10 17:56:20 - INFO - TRAINING - Epoch: [164][100/450]	Time 0.056 (0.054)	Data 0.014 (0.014)	Loss 0.0094 (0.0500)	Prec@1 100.000 (98.347)	Prec@5 100.000 (100.000)
2019-04-10 17:56:23 - INFO - TRAINING - Epoch: [164][150/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0618 (0.0516)	Prec@1 98.000 (98.278)	Prec@5 100.000 (100.000)
2019-04-10 17:56:26 - INFO - TRAINING - Epoch: [164][200/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0163 (0.0506)	Prec@1 100.000 (98.323)	Prec@5 100.000 (100.000)
2019-04-10 17:56:29 - INFO - TRAINING - Epoch: [164][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0445 (0.0512)	Prec@1 99.000 (98.311)	Prec@5 100.000 (100.000)
2019-04-10 17:56:31 - INFO - TRAINING - Epoch: [164][300/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0066 (0.0511)	Prec@1 100.000 (98.302)	Prec@5 100.000 (99.993)
2019-04-10 17:56:34 - INFO - TRAINING - Epoch: [164][350/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0977 (0.0518)	Prec@1 96.000 (98.274)	Prec@5 100.000 (99.994)
2019-04-10 17:56:37 - INFO - TRAINING - Epoch: [164][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0552 (0.0523)	Prec@1 98.000 (98.252)	Prec@5 100.000 (99.993)
2019-04-10 17:56:40 - INFO - EVALUATING - Epoch: [164][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.5059 (0.5059)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 17:56:40 - INFO - EVALUATING - Epoch: [164][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2942 (0.2942)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 17:56:41 - INFO - EVALUATING - Epoch: [164][50/100]	Time 0.018 (0.018)	Data 0.012 (0.011)	Loss 0.1783 (0.3871)	Prec@1 95.000 (89.804)	Prec@5 100.000 (99.529)
2019-04-10 17:56:42 - INFO - 
 Epoch: 165	Training Loss 0.0521 	Training Prec@1 98.273 	Training Prec@5 99.993 	Validation Loss 0.3769 	Validation Prec@1 90.540 	Validation Prec@5 99.640 	Test Loss 0.3770 	Test Prec@1  90.150 	Test Prec@5  99.590 

2019-04-10 17:56:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:56:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:56:42 - INFO - TRAINING - Epoch: [165][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0654 (0.0654)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:56:45 - INFO - TRAINING - Epoch: [165][50/450]	Time 0.057 (0.054)	Data 0.014 (0.014)	Loss 0.0173 (0.0511)	Prec@1 100.000 (98.020)	Prec@5 100.000 (100.000)
2019-04-10 17:56:48 - INFO - TRAINING - Epoch: [165][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0479 (0.0521)	Prec@1 99.000 (98.099)	Prec@5 100.000 (99.990)
2019-04-10 17:56:51 - INFO - TRAINING - Epoch: [165][150/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0387 (0.0509)	Prec@1 98.000 (98.185)	Prec@5 100.000 (99.993)
2019-04-10 17:56:53 - INFO - TRAINING - Epoch: [165][200/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0198 (0.0518)	Prec@1 100.000 (98.199)	Prec@5 100.000 (99.990)
2019-04-10 17:56:56 - INFO - TRAINING - Epoch: [165][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0588 (0.0517)	Prec@1 97.000 (98.171)	Prec@5 100.000 (99.992)
2019-04-10 17:56:59 - INFO - TRAINING - Epoch: [165][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0401 (0.0515)	Prec@1 99.000 (98.169)	Prec@5 100.000 (99.990)
2019-04-10 17:57:01 - INFO - TRAINING - Epoch: [165][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0791 (0.0523)	Prec@1 98.000 (98.177)	Prec@5 100.000 (99.991)
2019-04-10 17:57:04 - INFO - TRAINING - Epoch: [165][400/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0607 (0.0528)	Prec@1 98.000 (98.170)	Prec@5 100.000 (99.993)
2019-04-10 17:57:07 - INFO - EVALUATING - Epoch: [165][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.0916 (0.0916)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 17:57:08 - INFO - EVALUATING - Epoch: [165][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2870 (0.2870)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 17:57:09 - INFO - EVALUATING - Epoch: [165][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2478 (0.3749)	Prec@1 89.000 (89.725)	Prec@5 100.000 (99.588)
2019-04-10 17:57:10 - INFO - 
 Epoch: 166	Training Loss 0.0532 	Training Prec@1 98.160 	Training Prec@5 99.993 	Validation Loss 0.3584 	Validation Prec@1 90.420 	Validation Prec@5 99.720 	Test Loss 0.3718 	Test Prec@1  89.860 	Test Prec@5  99.610 

2019-04-10 17:57:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:57:10 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:57:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:57:10 - INFO - TRAINING - Epoch: [166][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0673 (0.0673)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:57:13 - INFO - TRAINING - Epoch: [166][50/450]	Time 0.055 (0.056)	Data 0.014 (0.015)	Loss 0.0285 (0.0487)	Prec@1 99.000 (98.490)	Prec@5 100.000 (100.000)
2019-04-10 17:57:15 - INFO - TRAINING - Epoch: [166][100/450]	Time 0.056 (0.055)	Data 0.014 (0.015)	Loss 0.0351 (0.0475)	Prec@1 99.000 (98.525)	Prec@5 100.000 (100.000)
2019-04-10 17:57:18 - INFO - TRAINING - Epoch: [166][150/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0053 (0.0500)	Prec@1 100.000 (98.404)	Prec@5 100.000 (99.993)
2019-04-10 17:57:21 - INFO - TRAINING - Epoch: [166][200/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0157 (0.0483)	Prec@1 99.000 (98.478)	Prec@5 100.000 (99.995)
2019-04-10 17:57:24 - INFO - TRAINING - Epoch: [166][250/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0476 (0.0493)	Prec@1 98.000 (98.398)	Prec@5 100.000 (99.996)
2019-04-10 17:57:26 - INFO - TRAINING - Epoch: [166][300/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0443 (0.0485)	Prec@1 98.000 (98.412)	Prec@5 100.000 (99.993)
2019-04-10 17:57:29 - INFO - TRAINING - Epoch: [166][350/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0704 (0.0485)	Prec@1 99.000 (98.427)	Prec@5 100.000 (99.994)
2019-04-10 17:57:32 - INFO - TRAINING - Epoch: [166][400/450]	Time 0.053 (0.055)	Data 0.012 (0.014)	Loss 0.1169 (0.0485)	Prec@1 96.000 (98.399)	Prec@5 100.000 (99.995)
2019-04-10 17:57:34 - INFO - EVALUATING - Epoch: [166][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.4380 (0.4380)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 17:57:35 - INFO - EVALUATING - Epoch: [166][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3442 (0.3442)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 17:57:36 - INFO - EVALUATING - Epoch: [166][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2377 (0.3901)	Prec@1 95.000 (89.961)	Prec@5 100.000 (99.569)
2019-04-10 17:57:37 - INFO - 
 Epoch: 167	Training Loss 0.0479 	Training Prec@1 98.429 	Training Prec@5 99.996 	Validation Loss 0.3648 	Validation Prec@1 91.080 	Validation Prec@5 99.680 	Test Loss 0.3801 	Test Prec@1  90.200 	Test Prec@5  99.570 

2019-04-10 17:57:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:57:37 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:57:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:57:37 - INFO - TRAINING - Epoch: [167][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0641 (0.0641)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:57:40 - INFO - TRAINING - Epoch: [167][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0684 (0.0447)	Prec@1 99.000 (98.490)	Prec@5 100.000 (100.000)
2019-04-10 17:57:43 - INFO - TRAINING - Epoch: [167][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0819 (0.0477)	Prec@1 96.000 (98.455)	Prec@5 100.000 (100.000)
2019-04-10 17:57:45 - INFO - TRAINING - Epoch: [167][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.1504 (0.0497)	Prec@1 96.000 (98.358)	Prec@5 100.000 (100.000)
2019-04-10 17:57:48 - INFO - TRAINING - Epoch: [167][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0406 (0.0517)	Prec@1 98.000 (98.323)	Prec@5 100.000 (100.000)
2019-04-10 17:57:51 - INFO - TRAINING - Epoch: [167][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0833 (0.0519)	Prec@1 97.000 (98.303)	Prec@5 100.000 (100.000)
2019-04-10 17:57:54 - INFO - TRAINING - Epoch: [167][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0217 (0.0510)	Prec@1 99.000 (98.349)	Prec@5 100.000 (100.000)
2019-04-10 17:57:56 - INFO - TRAINING - Epoch: [167][350/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0346 (0.0514)	Prec@1 99.000 (98.339)	Prec@5 100.000 (100.000)
2019-04-10 17:57:59 - INFO - TRAINING - Epoch: [167][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0432 (0.0521)	Prec@1 98.000 (98.287)	Prec@5 100.000 (100.000)
2019-04-10 17:58:02 - INFO - EVALUATING - Epoch: [167][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.5944 (0.5944)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:58:03 - INFO - EVALUATING - Epoch: [167][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3183 (0.3183)	Prec@1 89.000 (89.000)	Prec@5 99.000 (99.000)
2019-04-10 17:58:04 - INFO - EVALUATING - Epoch: [167][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1877 (0.3725)	Prec@1 94.000 (90.196)	Prec@5 100.000 (99.471)
2019-04-10 17:58:04 - INFO - 
 Epoch: 168	Training Loss 0.0516 	Training Prec@1 98.309 	Training Prec@5 100.000 	Validation Loss 0.3765 	Validation Prec@1 90.520 	Validation Prec@5 99.760 	Test Loss 0.3702 	Test Prec@1  90.450 	Test Prec@5  99.520 

2019-04-10 17:58:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:58:05 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:58:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:58:05 - INFO - TRAINING - Epoch: [168][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0136 (0.0136)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:58:08 - INFO - TRAINING - Epoch: [168][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0579 (0.0460)	Prec@1 98.000 (98.569)	Prec@5 100.000 (100.000)
2019-04-10 17:58:10 - INFO - TRAINING - Epoch: [168][100/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0570 (0.0471)	Prec@1 98.000 (98.485)	Prec@5 100.000 (100.000)
2019-04-10 17:58:13 - INFO - TRAINING - Epoch: [168][150/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1150 (0.0514)	Prec@1 97.000 (98.364)	Prec@5 100.000 (100.000)
2019-04-10 17:58:16 - INFO - TRAINING - Epoch: [168][200/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0091 (0.0536)	Prec@1 100.000 (98.303)	Prec@5 100.000 (100.000)
2019-04-10 17:58:19 - INFO - TRAINING - Epoch: [168][250/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0974 (0.0533)	Prec@1 97.000 (98.307)	Prec@5 100.000 (100.000)
2019-04-10 17:58:21 - INFO - TRAINING - Epoch: [168][300/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0319 (0.0513)	Prec@1 98.000 (98.336)	Prec@5 100.000 (100.000)
2019-04-10 17:58:24 - INFO - TRAINING - Epoch: [168][350/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0341 (0.0505)	Prec@1 98.000 (98.328)	Prec@5 100.000 (100.000)
2019-04-10 17:58:27 - INFO - TRAINING - Epoch: [168][400/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0815 (0.0501)	Prec@1 96.000 (98.319)	Prec@5 100.000 (100.000)
2019-04-10 17:58:29 - INFO - EVALUATING - Epoch: [168][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4416 (0.4416)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 17:58:30 - INFO - EVALUATING - Epoch: [168][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3340 (0.3340)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 17:58:31 - INFO - EVALUATING - Epoch: [168][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2346 (0.3719)	Prec@1 93.000 (90.275)	Prec@5 100.000 (99.490)
2019-04-10 17:58:32 - INFO - 
 Epoch: 169	Training Loss 0.0500 	Training Prec@1 98.338 	Training Prec@5 100.000 	Validation Loss 0.3461 	Validation Prec@1 90.880 	Validation Prec@5 99.700 	Test Loss 0.3722 	Test Prec@1  90.270 	Test Prec@5  99.580 

2019-04-10 17:58:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:58:32 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:58:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:58:32 - INFO - TRAINING - Epoch: [169][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0181 (0.0181)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:58:35 - INFO - TRAINING - Epoch: [169][50/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0637 (0.0481)	Prec@1 97.000 (98.157)	Prec@5 100.000 (100.000)
2019-04-10 17:58:38 - INFO - TRAINING - Epoch: [169][100/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0730 (0.0489)	Prec@1 97.000 (98.158)	Prec@5 100.000 (99.990)
2019-04-10 17:58:40 - INFO - TRAINING - Epoch: [169][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0470 (0.0493)	Prec@1 98.000 (98.245)	Prec@5 100.000 (99.993)
2019-04-10 17:58:43 - INFO - TRAINING - Epoch: [169][200/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0100 (0.0494)	Prec@1 100.000 (98.274)	Prec@5 100.000 (99.995)
2019-04-10 17:58:46 - INFO - TRAINING - Epoch: [169][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0923 (0.0498)	Prec@1 97.000 (98.287)	Prec@5 100.000 (99.996)
2019-04-10 17:58:49 - INFO - TRAINING - Epoch: [169][300/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0170 (0.0495)	Prec@1 100.000 (98.292)	Prec@5 100.000 (99.997)
2019-04-10 17:58:51 - INFO - TRAINING - Epoch: [169][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0459 (0.0503)	Prec@1 98.000 (98.265)	Prec@5 100.000 (99.994)
2019-04-10 17:58:54 - INFO - TRAINING - Epoch: [169][400/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0372 (0.0496)	Prec@1 99.000 (98.274)	Prec@5 100.000 (99.995)
2019-04-10 17:58:57 - INFO - EVALUATING - Epoch: [169][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.4290 (0.4290)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 17:58:58 - INFO - EVALUATING - Epoch: [169][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2339 (0.2339)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 17:58:59 - INFO - EVALUATING - Epoch: [169][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.3660 (0.3796)	Prec@1 91.000 (89.882)	Prec@5 100.000 (99.412)
2019-04-10 17:58:59 - INFO - 
 Epoch: 170	Training Loss 0.0498 	Training Prec@1 98.258 	Training Prec@5 99.996 	Validation Loss 0.3763 	Validation Prec@1 90.820 	Validation Prec@5 99.660 	Test Loss 0.3796 	Test Prec@1  90.040 	Test Prec@5  99.560 

2019-04-10 17:59:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:59:00 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:59:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:59:00 - INFO - TRAINING - Epoch: [170][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0270 (0.0270)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 17:59:02 - INFO - TRAINING - Epoch: [170][50/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0787 (0.0589)	Prec@1 98.000 (97.902)	Prec@5 100.000 (100.000)
2019-04-10 17:59:05 - INFO - TRAINING - Epoch: [170][100/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0611 (0.0543)	Prec@1 99.000 (98.050)	Prec@5 100.000 (100.000)
2019-04-10 17:59:08 - INFO - TRAINING - Epoch: [170][150/450]	Time 0.054 (0.056)	Data 0.014 (0.014)	Loss 0.0262 (0.0528)	Prec@1 99.000 (98.159)	Prec@5 100.000 (100.000)
2019-04-10 17:59:11 - INFO - TRAINING - Epoch: [170][200/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0768 (0.0540)	Prec@1 96.000 (98.159)	Prec@5 100.000 (99.990)
2019-04-10 17:59:13 - INFO - TRAINING - Epoch: [170][250/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.1229 (0.0525)	Prec@1 96.000 (98.223)	Prec@5 100.000 (99.988)
2019-04-10 17:59:16 - INFO - TRAINING - Epoch: [170][300/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0394 (0.0529)	Prec@1 98.000 (98.233)	Prec@5 100.000 (99.990)
2019-04-10 17:59:19 - INFO - TRAINING - Epoch: [170][350/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0735 (0.0526)	Prec@1 98.000 (98.248)	Prec@5 100.000 (99.991)
2019-04-10 17:59:22 - INFO - TRAINING - Epoch: [170][400/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0383 (0.0529)	Prec@1 99.000 (98.229)	Prec@5 100.000 (99.993)
2019-04-10 17:59:24 - INFO - EVALUATING - Epoch: [170][0/50]	Time 0.043 (0.043)	Data 0.010 (0.010)	Loss 0.3647 (0.3647)	Prec@1 92.000 (92.000)	Prec@5 100.000 (100.000)
2019-04-10 17:59:25 - INFO - EVALUATING - Epoch: [170][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2492 (0.2492)	Prec@1 95.000 (95.000)	Prec@5 99.000 (99.000)
2019-04-10 17:59:26 - INFO - EVALUATING - Epoch: [170][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2807 (0.3801)	Prec@1 93.000 (89.922)	Prec@5 100.000 (99.392)
2019-04-10 17:59:27 - INFO - 
 Epoch: 171	Training Loss 0.0526 	Training Prec@1 98.224 	Training Prec@5 99.993 	Validation Loss 0.3766 	Validation Prec@1 90.460 	Validation Prec@5 99.600 	Test Loss 0.3808 	Test Prec@1  90.240 	Test Prec@5  99.430 

2019-04-10 17:59:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:59:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:59:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:59:27 - INFO - TRAINING - Epoch: [171][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0430 (0.0430)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 17:59:30 - INFO - TRAINING - Epoch: [171][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.1099 (0.0524)	Prec@1 96.000 (98.255)	Prec@5 100.000 (100.000)
2019-04-10 17:59:33 - INFO - TRAINING - Epoch: [171][100/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0540 (0.0520)	Prec@1 97.000 (98.228)	Prec@5 100.000 (100.000)
2019-04-10 17:59:35 - INFO - TRAINING - Epoch: [171][150/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0142 (0.0510)	Prec@1 100.000 (98.278)	Prec@5 100.000 (100.000)
2019-04-10 17:59:38 - INFO - TRAINING - Epoch: [171][200/450]	Time 0.057 (0.055)	Data 0.014 (0.014)	Loss 0.0446 (0.0495)	Prec@1 99.000 (98.318)	Prec@5 100.000 (100.000)
2019-04-10 17:59:41 - INFO - TRAINING - Epoch: [171][250/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0584 (0.0495)	Prec@1 98.000 (98.331)	Prec@5 100.000 (100.000)
2019-04-10 17:59:44 - INFO - TRAINING - Epoch: [171][300/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0309 (0.0485)	Prec@1 99.000 (98.346)	Prec@5 100.000 (100.000)
2019-04-10 17:59:46 - INFO - TRAINING - Epoch: [171][350/450]	Time 0.053 (0.054)	Data 0.012 (0.014)	Loss 0.0239 (0.0491)	Prec@1 99.000 (98.328)	Prec@5 100.000 (100.000)
2019-04-10 17:59:49 - INFO - TRAINING - Epoch: [171][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.1544 (0.0486)	Prec@1 97.000 (98.332)	Prec@5 100.000 (100.000)
2019-04-10 17:59:52 - INFO - EVALUATING - Epoch: [171][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.2072 (0.2072)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 17:59:53 - INFO - EVALUATING - Epoch: [171][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4249 (0.4249)	Prec@1 92.000 (92.000)	Prec@5 98.000 (98.000)
2019-04-10 17:59:53 - INFO - EVALUATING - Epoch: [171][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2827 (0.3739)	Prec@1 92.000 (90.353)	Prec@5 100.000 (99.549)
2019-04-10 17:59:54 - INFO - 
 Epoch: 172	Training Loss 0.0491 	Training Prec@1 98.324 	Training Prec@5 100.000 	Validation Loss 0.3774 	Validation Prec@1 90.380 	Validation Prec@5 99.760 	Test Loss 0.3717 	Test Prec@1  90.340 	Test Prec@5  99.570 

2019-04-10 17:59:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 17:59:55 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 17:59:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 17:59:55 - INFO - TRAINING - Epoch: [172][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0343 (0.0343)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 17:59:57 - INFO - TRAINING - Epoch: [172][50/450]	Time 0.059 (0.056)	Data 0.014 (0.014)	Loss 0.0853 (0.0537)	Prec@1 96.000 (98.059)	Prec@5 100.000 (100.000)
2019-04-10 18:00:00 - INFO - TRAINING - Epoch: [172][100/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0196 (0.0507)	Prec@1 99.000 (98.218)	Prec@5 100.000 (100.000)
2019-04-10 18:00:03 - INFO - TRAINING - Epoch: [172][150/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0225 (0.0495)	Prec@1 100.000 (98.325)	Prec@5 100.000 (100.000)
2019-04-10 18:00:06 - INFO - TRAINING - Epoch: [172][200/450]	Time 0.055 (0.055)	Data 0.015 (0.014)	Loss 0.1638 (0.0493)	Prec@1 96.000 (98.308)	Prec@5 100.000 (100.000)
2019-04-10 18:00:08 - INFO - TRAINING - Epoch: [172][250/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0361 (0.0488)	Prec@1 99.000 (98.307)	Prec@5 100.000 (100.000)
2019-04-10 18:00:11 - INFO - TRAINING - Epoch: [172][300/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0600 (0.0482)	Prec@1 98.000 (98.329)	Prec@5 100.000 (100.000)
2019-04-10 18:00:14 - INFO - TRAINING - Epoch: [172][350/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0595 (0.0485)	Prec@1 98.000 (98.336)	Prec@5 100.000 (99.997)
2019-04-10 18:00:16 - INFO - TRAINING - Epoch: [172][400/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0391 (0.0489)	Prec@1 99.000 (98.307)	Prec@5 100.000 (99.998)
2019-04-10 18:00:19 - INFO - EVALUATING - Epoch: [172][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.4535 (0.4535)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:00:20 - INFO - EVALUATING - Epoch: [172][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2747 (0.2747)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 18:00:21 - INFO - EVALUATING - Epoch: [172][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2878 (0.3590)	Prec@1 91.000 (90.039)	Prec@5 100.000 (99.588)
2019-04-10 18:00:22 - INFO - 
 Epoch: 173	Training Loss 0.0499 	Training Prec@1 98.302 	Training Prec@5 99.998 	Validation Loss 0.3662 	Validation Prec@1 90.440 	Validation Prec@5 99.680 	Test Loss 0.3645 	Test Prec@1  90.110 	Test Prec@5  99.610 

2019-04-10 18:00:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:00:22 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:00:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:00:22 - INFO - TRAINING - Epoch: [173][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0299 (0.0299)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:00:25 - INFO - TRAINING - Epoch: [173][50/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.0283 (0.0607)	Prec@1 99.000 (97.765)	Prec@5 100.000 (100.000)
2019-04-10 18:00:28 - INFO - TRAINING - Epoch: [173][100/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0734 (0.0552)	Prec@1 98.000 (98.059)	Prec@5 100.000 (99.990)
2019-04-10 18:00:31 - INFO - TRAINING - Epoch: [173][150/450]	Time 0.057 (0.056)	Data 0.013 (0.014)	Loss 0.0557 (0.0522)	Prec@1 97.000 (98.152)	Prec@5 100.000 (99.993)
2019-04-10 18:00:33 - INFO - TRAINING - Epoch: [173][200/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0989 (0.0524)	Prec@1 97.000 (98.144)	Prec@5 100.000 (99.995)
2019-04-10 18:00:36 - INFO - TRAINING - Epoch: [173][250/450]	Time 0.058 (0.056)	Data 0.013 (0.014)	Loss 0.0121 (0.0517)	Prec@1 100.000 (98.171)	Prec@5 100.000 (99.996)
2019-04-10 18:00:39 - INFO - TRAINING - Epoch: [173][300/450]	Time 0.055 (0.057)	Data 0.014 (0.014)	Loss 0.0299 (0.0526)	Prec@1 100.000 (98.159)	Prec@5 100.000 (99.993)
2019-04-10 18:00:42 - INFO - TRAINING - Epoch: [173][350/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.0444 (0.0524)	Prec@1 98.000 (98.194)	Prec@5 100.000 (99.994)
2019-04-10 18:00:45 - INFO - TRAINING - Epoch: [173][400/450]	Time 0.052 (0.056)	Data 0.014 (0.014)	Loss 0.0497 (0.0524)	Prec@1 97.000 (98.197)	Prec@5 100.000 (99.995)
2019-04-10 18:00:47 - INFO - EVALUATING - Epoch: [173][0/50]	Time 0.040 (0.040)	Data 0.010 (0.010)	Loss 0.3208 (0.3208)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 18:00:48 - INFO - EVALUATING - Epoch: [173][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3212 (0.3212)	Prec@1 92.000 (92.000)	Prec@5 98.000 (98.000)
2019-04-10 18:00:49 - INFO - EVALUATING - Epoch: [173][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1511 (0.3656)	Prec@1 91.000 (90.294)	Prec@5 100.000 (99.451)
2019-04-10 18:00:50 - INFO - 
 Epoch: 174	Training Loss 0.0526 	Training Prec@1 98.200 	Training Prec@5 99.996 	Validation Loss 0.3535 	Validation Prec@1 91.080 	Validation Prec@5 99.700 	Test Loss 0.3614 	Test Prec@1  90.470 	Test Prec@5  99.560 

2019-04-10 18:00:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:00:50 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:00:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:00:50 - INFO - TRAINING - Epoch: [174][0/450]	Time 0.031 (0.031)	Data 0.014 (0.014)	Loss 0.0297 (0.0297)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:00:53 - INFO - TRAINING - Epoch: [174][50/450]	Time 0.056 (0.055)	Data 0.014 (0.015)	Loss 0.0509 (0.0447)	Prec@1 98.000 (98.549)	Prec@5 100.000 (99.980)
2019-04-10 18:00:56 - INFO - TRAINING - Epoch: [174][100/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0546 (0.0477)	Prec@1 98.000 (98.386)	Prec@5 100.000 (99.990)
2019-04-10 18:00:58 - INFO - TRAINING - Epoch: [174][150/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0385 (0.0469)	Prec@1 98.000 (98.377)	Prec@5 100.000 (99.993)
2019-04-10 18:01:01 - INFO - TRAINING - Epoch: [174][200/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0752 (0.0470)	Prec@1 97.000 (98.368)	Prec@5 100.000 (99.995)
2019-04-10 18:01:04 - INFO - TRAINING - Epoch: [174][250/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0075 (0.0461)	Prec@1 100.000 (98.414)	Prec@5 100.000 (99.996)
2019-04-10 18:01:07 - INFO - TRAINING - Epoch: [174][300/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0490 (0.0475)	Prec@1 99.000 (98.379)	Prec@5 100.000 (99.997)
2019-04-10 18:01:09 - INFO - TRAINING - Epoch: [174][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0249 (0.0486)	Prec@1 100.000 (98.370)	Prec@5 100.000 (99.997)
2019-04-10 18:01:12 - INFO - TRAINING - Epoch: [174][400/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0901 (0.0493)	Prec@1 96.000 (98.359)	Prec@5 100.000 (99.998)
2019-04-10 18:01:15 - INFO - EVALUATING - Epoch: [174][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.4805 (0.4805)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:01:15 - INFO - EVALUATING - Epoch: [174][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2598 (0.2598)	Prec@1 95.000 (95.000)	Prec@5 99.000 (99.000)
2019-04-10 18:01:16 - INFO - EVALUATING - Epoch: [174][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2276 (0.3906)	Prec@1 92.000 (90.294)	Prec@5 100.000 (99.471)
2019-04-10 18:01:17 - INFO - 
 Epoch: 175	Training Loss 0.0492 	Training Prec@1 98.367 	Training Prec@5 99.996 	Validation Loss 0.3704 	Validation Prec@1 90.700 	Validation Prec@5 99.580 	Test Loss 0.3877 	Test Prec@1  90.370 	Test Prec@5  99.470 

2019-04-10 18:01:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:01:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:01:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:01:17 - INFO - TRAINING - Epoch: [175][0/450]	Time 0.032 (0.032)	Data 0.014 (0.014)	Loss 0.0560 (0.0560)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:01:20 - INFO - TRAINING - Epoch: [175][50/450]	Time 0.056 (0.055)	Data 0.012 (0.014)	Loss 0.0428 (0.0502)	Prec@1 98.000 (98.176)	Prec@5 100.000 (100.000)
2019-04-10 18:01:23 - INFO - TRAINING - Epoch: [175][100/450]	Time 0.056 (0.055)	Data 0.015 (0.014)	Loss 0.0157 (0.0521)	Prec@1 99.000 (98.149)	Prec@5 100.000 (100.000)
2019-04-10 18:01:26 - INFO - TRAINING - Epoch: [175][150/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0787 (0.0510)	Prec@1 97.000 (98.252)	Prec@5 100.000 (100.000)
2019-04-10 18:01:28 - INFO - TRAINING - Epoch: [175][200/450]	Time 0.054 (0.055)	Data 0.014 (0.015)	Loss 0.0544 (0.0516)	Prec@1 99.000 (98.264)	Prec@5 100.000 (100.000)
2019-04-10 18:01:31 - INFO - TRAINING - Epoch: [175][250/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0920 (0.0510)	Prec@1 98.000 (98.283)	Prec@5 100.000 (100.000)
2019-04-10 18:01:34 - INFO - TRAINING - Epoch: [175][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0130 (0.0512)	Prec@1 100.000 (98.296)	Prec@5 100.000 (100.000)
2019-04-10 18:01:37 - INFO - TRAINING - Epoch: [175][350/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0102 (0.0502)	Prec@1 100.000 (98.325)	Prec@5 100.000 (100.000)
2019-04-10 18:01:39 - INFO - TRAINING - Epoch: [175][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0403 (0.0508)	Prec@1 99.000 (98.297)	Prec@5 100.000 (99.998)
2019-04-10 18:01:42 - INFO - EVALUATING - Epoch: [175][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.6944 (0.6944)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-04-10 18:01:43 - INFO - EVALUATING - Epoch: [175][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2033 (0.2033)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 18:01:44 - INFO - EVALUATING - Epoch: [175][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1461 (0.3821)	Prec@1 95.000 (90.020)	Prec@5 100.000 (99.412)
2019-04-10 18:01:45 - INFO - 
 Epoch: 176	Training Loss 0.0503 	Training Prec@1 98.307 	Training Prec@5 99.998 	Validation Loss 0.3733 	Validation Prec@1 90.620 	Validation Prec@5 99.460 	Test Loss 0.3821 	Test Prec@1  90.090 	Test Prec@5  99.510 

2019-04-10 18:01:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:01:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:01:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:01:45 - INFO - TRAINING - Epoch: [176][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0330 (0.0330)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:01:48 - INFO - TRAINING - Epoch: [176][50/450]	Time 0.055 (0.053)	Data 0.012 (0.015)	Loss 0.0279 (0.0479)	Prec@1 100.000 (98.373)	Prec@5 100.000 (100.000)
2019-04-10 18:01:50 - INFO - TRAINING - Epoch: [176][100/450]	Time 0.054 (0.054)	Data 0.013 (0.015)	Loss 0.0409 (0.0433)	Prec@1 98.000 (98.525)	Prec@5 100.000 (100.000)
2019-04-10 18:01:53 - INFO - TRAINING - Epoch: [176][150/450]	Time 0.054 (0.054)	Data 0.014 (0.015)	Loss 0.0291 (0.0445)	Prec@1 99.000 (98.477)	Prec@5 100.000 (100.000)
2019-04-10 18:01:56 - INFO - TRAINING - Epoch: [176][200/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0826 (0.0446)	Prec@1 96.000 (98.453)	Prec@5 100.000 (100.000)
2019-04-10 18:01:58 - INFO - TRAINING - Epoch: [176][250/450]	Time 0.048 (0.054)	Data 0.021 (0.014)	Loss 0.0546 (0.0444)	Prec@1 98.000 (98.474)	Prec@5 100.000 (100.000)
2019-04-10 18:02:01 - INFO - TRAINING - Epoch: [176][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0234 (0.0448)	Prec@1 100.000 (98.512)	Prec@5 100.000 (100.000)
2019-04-10 18:02:04 - INFO - TRAINING - Epoch: [176][350/450]	Time 0.049 (0.054)	Data 0.012 (0.014)	Loss 0.0532 (0.0457)	Prec@1 98.000 (98.490)	Prec@5 100.000 (100.000)
2019-04-10 18:02:07 - INFO - TRAINING - Epoch: [176][400/450]	Time 0.056 (0.054)	Data 0.012 (0.014)	Loss 0.0153 (0.0457)	Prec@1 99.000 (98.491)	Prec@5 100.000 (100.000)
2019-04-10 18:02:09 - INFO - EVALUATING - Epoch: [176][0/50]	Time 0.047 (0.047)	Data 0.010 (0.010)	Loss 0.3052 (0.3052)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 18:02:10 - INFO - EVALUATING - Epoch: [176][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4298 (0.4298)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 18:02:11 - INFO - EVALUATING - Epoch: [176][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2518 (0.3920)	Prec@1 92.000 (89.843)	Prec@5 100.000 (99.529)
2019-04-10 18:02:12 - INFO - 
 Epoch: 177	Training Loss 0.0461 	Training Prec@1 98.482 	Training Prec@5 99.998 	Validation Loss 0.3640 	Validation Prec@1 90.820 	Validation Prec@5 99.640 	Test Loss 0.3881 	Test Prec@1  89.940 	Test Prec@5  99.520 

2019-04-10 18:02:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:02:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:02:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:02:12 - INFO - TRAINING - Epoch: [177][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0235 (0.0235)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:02:15 - INFO - TRAINING - Epoch: [177][50/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0371 (0.0467)	Prec@1 99.000 (98.373)	Prec@5 100.000 (99.980)
2019-04-10 18:02:18 - INFO - TRAINING - Epoch: [177][100/450]	Time 0.055 (0.054)	Data 0.012 (0.013)	Loss 0.0339 (0.0436)	Prec@1 100.000 (98.505)	Prec@5 100.000 (99.990)
2019-04-10 18:02:20 - INFO - TRAINING - Epoch: [177][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0232 (0.0460)	Prec@1 99.000 (98.437)	Prec@5 100.000 (99.993)
2019-04-10 18:02:23 - INFO - TRAINING - Epoch: [177][200/450]	Time 0.053 (0.054)	Data 0.012 (0.013)	Loss 0.0238 (0.0468)	Prec@1 99.000 (98.423)	Prec@5 100.000 (99.995)
2019-04-10 18:02:26 - INFO - TRAINING - Epoch: [177][250/450]	Time 0.048 (0.054)	Data 0.015 (0.013)	Loss 0.0684 (0.0459)	Prec@1 97.000 (98.482)	Prec@5 100.000 (99.992)
2019-04-10 18:02:29 - INFO - TRAINING - Epoch: [177][300/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0771 (0.0468)	Prec@1 98.000 (98.432)	Prec@5 100.000 (99.993)
2019-04-10 18:02:31 - INFO - TRAINING - Epoch: [177][350/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0379 (0.0473)	Prec@1 99.000 (98.413)	Prec@5 100.000 (99.994)
2019-04-10 18:02:34 - INFO - TRAINING - Epoch: [177][400/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0489 (0.0476)	Prec@1 98.000 (98.401)	Prec@5 100.000 (99.993)
2019-04-10 18:02:37 - INFO - EVALUATING - Epoch: [177][0/50]	Time 0.046 (0.046)	Data 0.010 (0.010)	Loss 0.2040 (0.2040)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 18:02:38 - INFO - EVALUATING - Epoch: [177][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3394 (0.3394)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 18:02:38 - INFO - EVALUATING - Epoch: [177][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1792 (0.3882)	Prec@1 93.000 (90.118)	Prec@5 100.000 (99.451)
2019-04-10 18:02:39 - INFO - 
 Epoch: 178	Training Loss 0.0478 	Training Prec@1 98.407 	Training Prec@5 99.993 	Validation Loss 0.3645 	Validation Prec@1 90.740 	Validation Prec@5 99.640 	Test Loss 0.3813 	Test Prec@1  90.300 	Test Prec@5  99.590 

2019-04-10 18:02:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:02:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:02:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:02:40 - INFO - TRAINING - Epoch: [178][0/450]	Time 0.025 (0.025)	Data 0.013 (0.013)	Loss 0.0234 (0.0234)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:02:42 - INFO - TRAINING - Epoch: [178][50/450]	Time 0.057 (0.056)	Data 0.014 (0.015)	Loss 0.0402 (0.0515)	Prec@1 99.000 (98.216)	Prec@5 100.000 (100.000)
2019-04-10 18:02:45 - INFO - TRAINING - Epoch: [178][100/450]	Time 0.056 (0.057)	Data 0.013 (0.015)	Loss 0.0199 (0.0499)	Prec@1 100.000 (98.277)	Prec@5 100.000 (100.000)
2019-04-10 18:02:48 - INFO - TRAINING - Epoch: [178][150/450]	Time 0.056 (0.057)	Data 0.013 (0.015)	Loss 0.0104 (0.0495)	Prec@1 100.000 (98.285)	Prec@5 100.000 (100.000)
2019-04-10 18:02:51 - INFO - TRAINING - Epoch: [178][200/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0225 (0.0488)	Prec@1 100.000 (98.353)	Prec@5 100.000 (100.000)
2019-04-10 18:02:54 - INFO - TRAINING - Epoch: [178][250/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0910 (0.0480)	Prec@1 96.000 (98.371)	Prec@5 100.000 (100.000)
2019-04-10 18:02:56 - INFO - TRAINING - Epoch: [178][300/450]	Time 0.055 (0.056)	Data 0.013 (0.014)	Loss 0.0600 (0.0473)	Prec@1 98.000 (98.389)	Prec@5 100.000 (99.993)
2019-04-10 18:02:59 - INFO - TRAINING - Epoch: [178][350/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0341 (0.0497)	Prec@1 99.000 (98.282)	Prec@5 100.000 (99.994)
2019-04-10 18:03:02 - INFO - TRAINING - Epoch: [178][400/450]	Time 0.053 (0.055)	Data 0.013 (0.014)	Loss 0.0369 (0.0487)	Prec@1 99.000 (98.304)	Prec@5 100.000 (99.995)
2019-04-10 18:03:04 - INFO - EVALUATING - Epoch: [178][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.4753 (0.4753)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 18:03:05 - INFO - EVALUATING - Epoch: [178][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3114 (0.3114)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:03:06 - INFO - EVALUATING - Epoch: [178][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1946 (0.3972)	Prec@1 94.000 (89.980)	Prec@5 100.000 (99.490)
2019-04-10 18:03:07 - INFO - 
 Epoch: 179	Training Loss 0.0478 	Training Prec@1 98.338 	Training Prec@5 99.996 	Validation Loss 0.3553 	Validation Prec@1 90.400 	Validation Prec@5 99.760 	Test Loss 0.3847 	Test Prec@1  90.120 	Test Prec@5  99.600 

2019-04-10 18:03:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:03:07 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:03:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:03:07 - INFO - TRAINING - Epoch: [179][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0476 (0.0476)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:03:10 - INFO - TRAINING - Epoch: [179][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0162 (0.0502)	Prec@1 100.000 (98.235)	Prec@5 100.000 (100.000)
2019-04-10 18:03:13 - INFO - TRAINING - Epoch: [179][100/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0119 (0.0520)	Prec@1 100.000 (98.089)	Prec@5 100.000 (100.000)
2019-04-10 18:03:16 - INFO - TRAINING - Epoch: [179][150/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0440 (0.0512)	Prec@1 98.000 (98.179)	Prec@5 100.000 (100.000)
2019-04-10 18:03:18 - INFO - TRAINING - Epoch: [179][200/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.0252 (0.0506)	Prec@1 100.000 (98.264)	Prec@5 100.000 (100.000)
2019-04-10 18:03:21 - INFO - TRAINING - Epoch: [179][250/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0872 (0.0494)	Prec@1 96.000 (98.319)	Prec@5 100.000 (100.000)
2019-04-10 18:03:24 - INFO - TRAINING - Epoch: [179][300/450]	Time 0.059 (0.055)	Data 0.012 (0.014)	Loss 0.0417 (0.0497)	Prec@1 98.000 (98.296)	Prec@5 100.000 (100.000)
2019-04-10 18:03:27 - INFO - TRAINING - Epoch: [179][350/450]	Time 0.059 (0.056)	Data 0.013 (0.014)	Loss 0.0278 (0.0488)	Prec@1 99.000 (98.322)	Prec@5 100.000 (100.000)
2019-04-10 18:03:30 - INFO - TRAINING - Epoch: [179][400/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.1404 (0.0486)	Prec@1 95.000 (98.329)	Prec@5 100.000 (100.000)
2019-04-10 18:03:32 - INFO - EVALUATING - Epoch: [179][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.6510 (0.6510)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-04-10 18:03:33 - INFO - EVALUATING - Epoch: [179][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1872 (0.1872)	Prec@1 96.000 (96.000)	Prec@5 99.000 (99.000)
2019-04-10 18:03:34 - INFO - EVALUATING - Epoch: [179][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.2128 (0.3957)	Prec@1 94.000 (90.137)	Prec@5 100.000 (99.608)
2019-04-10 18:03:35 - INFO - 
 Epoch: 180	Training Loss 0.0490 	Training Prec@1 98.313 	Training Prec@5 100.000 	Validation Loss 0.3730 	Validation Prec@1 90.620 	Validation Prec@5 99.640 	Test Loss 0.3896 	Test Prec@1  90.130 	Test Prec@5  99.650 

2019-04-10 18:03:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:03:35 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:03:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:03:36 - INFO - TRAINING - Epoch: [180][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0390 (0.0390)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:03:38 - INFO - TRAINING - Epoch: [180][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0528 (0.0492)	Prec@1 97.000 (98.294)	Prec@5 100.000 (100.000)
2019-04-10 18:03:41 - INFO - TRAINING - Epoch: [180][100/450]	Time 0.058 (0.057)	Data 0.014 (0.014)	Loss 0.0592 (0.0457)	Prec@1 98.000 (98.505)	Prec@5 100.000 (100.000)
2019-04-10 18:03:44 - INFO - TRAINING - Epoch: [180][150/450]	Time 0.057 (0.057)	Data 0.013 (0.014)	Loss 0.0567 (0.0478)	Prec@1 96.000 (98.411)	Prec@5 100.000 (100.000)
2019-04-10 18:03:47 - INFO - TRAINING - Epoch: [180][200/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.0802 (0.0486)	Prec@1 98.000 (98.418)	Prec@5 100.000 (100.000)
2019-04-10 18:03:50 - INFO - TRAINING - Epoch: [180][250/450]	Time 0.056 (0.057)	Data 0.012 (0.014)	Loss 0.0337 (0.0498)	Prec@1 98.000 (98.375)	Prec@5 100.000 (99.996)
2019-04-10 18:03:52 - INFO - TRAINING - Epoch: [180][300/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.0426 (0.0491)	Prec@1 99.000 (98.372)	Prec@5 100.000 (99.993)
2019-04-10 18:03:55 - INFO - TRAINING - Epoch: [180][350/450]	Time 0.053 (0.056)	Data 0.014 (0.014)	Loss 0.0486 (0.0489)	Prec@1 98.000 (98.365)	Prec@5 100.000 (99.994)
2019-04-10 18:03:58 - INFO - TRAINING - Epoch: [180][400/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0664 (0.0489)	Prec@1 98.000 (98.347)	Prec@5 100.000 (99.995)
2019-04-10 18:04:00 - INFO - EVALUATING - Epoch: [180][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.1749 (0.1749)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 18:04:01 - INFO - EVALUATING - Epoch: [180][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2389 (0.2389)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 18:04:02 - INFO - EVALUATING - Epoch: [180][50/100]	Time 0.017 (0.018)	Data 0.010 (0.010)	Loss 0.2687 (0.3837)	Prec@1 90.000 (90.353)	Prec@5 100.000 (99.412)
2019-04-10 18:04:03 - INFO - 
 Epoch: 181	Training Loss 0.0489 	Training Prec@1 98.347 	Training Prec@5 99.996 	Validation Loss 0.3735 	Validation Prec@1 90.620 	Validation Prec@5 99.640 	Test Loss 0.3801 	Test Prec@1  90.560 	Test Prec@5  99.480 

2019-04-10 18:04:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:04:03 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:04:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:04:03 - INFO - TRAINING - Epoch: [181][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0515 (0.0515)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:06 - INFO - TRAINING - Epoch: [181][50/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0449 (0.0519)	Prec@1 99.000 (98.216)	Prec@5 100.000 (100.000)
2019-04-10 18:04:09 - INFO - TRAINING - Epoch: [181][100/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0066 (0.0510)	Prec@1 100.000 (98.218)	Prec@5 100.000 (100.000)
2019-04-10 18:04:11 - INFO - TRAINING - Epoch: [181][150/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0630 (0.0502)	Prec@1 97.000 (98.285)	Prec@5 100.000 (100.000)
2019-04-10 18:04:14 - INFO - TRAINING - Epoch: [181][200/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0087 (0.0489)	Prec@1 100.000 (98.348)	Prec@5 100.000 (100.000)
2019-04-10 18:04:17 - INFO - TRAINING - Epoch: [181][250/450]	Time 0.054 (0.054)	Data 0.012 (0.013)	Loss 0.0565 (0.0499)	Prec@1 98.000 (98.299)	Prec@5 100.000 (100.000)
2019-04-10 18:04:20 - INFO - TRAINING - Epoch: [181][300/450]	Time 0.056 (0.054)	Data 0.015 (0.013)	Loss 0.0161 (0.0491)	Prec@1 100.000 (98.329)	Prec@5 100.000 (100.000)
2019-04-10 18:04:22 - INFO - TRAINING - Epoch: [181][350/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0656 (0.0483)	Prec@1 97.000 (98.330)	Prec@5 100.000 (99.997)
2019-04-10 18:04:25 - INFO - TRAINING - Epoch: [181][400/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0214 (0.0484)	Prec@1 99.000 (98.314)	Prec@5 100.000 (99.998)
2019-04-10 18:04:28 - INFO - EVALUATING - Epoch: [181][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.1954 (0.1954)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:29 - INFO - EVALUATING - Epoch: [181][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2827 (0.2827)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:30 - INFO - EVALUATING - Epoch: [181][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1874 (0.3833)	Prec@1 92.000 (90.098)	Prec@5 100.000 (99.412)
2019-04-10 18:04:31 - INFO - 
 Epoch: 182	Training Loss 0.0488 	Training Prec@1 98.287 	Training Prec@5 99.998 	Validation Loss 0.3694 	Validation Prec@1 90.600 	Validation Prec@5 99.740 	Test Loss 0.3846 	Test Prec@1  90.180 	Test Prec@5  99.510 

2019-04-10 18:04:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:04:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:04:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:04:31 - INFO - TRAINING - Epoch: [182][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0346 (0.0346)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:34 - INFO - TRAINING - Epoch: [182][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0140 (0.0521)	Prec@1 100.000 (98.216)	Prec@5 100.000 (100.000)
2019-04-10 18:04:36 - INFO - TRAINING - Epoch: [182][100/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0429 (0.0504)	Prec@1 98.000 (98.277)	Prec@5 100.000 (100.000)
2019-04-10 18:04:39 - INFO - TRAINING - Epoch: [182][150/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0440 (0.0489)	Prec@1 99.000 (98.351)	Prec@5 100.000 (100.000)
2019-04-10 18:04:42 - INFO - TRAINING - Epoch: [182][200/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0788 (0.0494)	Prec@1 99.000 (98.368)	Prec@5 100.000 (100.000)
2019-04-10 18:04:45 - INFO - TRAINING - Epoch: [182][250/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.0331 (0.0494)	Prec@1 98.000 (98.375)	Prec@5 100.000 (100.000)
2019-04-10 18:04:47 - INFO - TRAINING - Epoch: [182][300/450]	Time 0.054 (0.055)	Data 0.012 (0.013)	Loss 0.0264 (0.0494)	Prec@1 100.000 (98.349)	Prec@5 100.000 (100.000)
2019-04-10 18:04:50 - INFO - TRAINING - Epoch: [182][350/450]	Time 0.057 (0.055)	Data 0.013 (0.013)	Loss 0.0085 (0.0487)	Prec@1 100.000 (98.368)	Prec@5 100.000 (100.000)
2019-04-10 18:04:53 - INFO - TRAINING - Epoch: [182][400/450]	Time 0.049 (0.055)	Data 0.020 (0.014)	Loss 0.0292 (0.0487)	Prec@1 99.000 (98.382)	Prec@5 100.000 (100.000)
2019-04-10 18:04:56 - INFO - EVALUATING - Epoch: [182][0/50]	Time 0.044 (0.044)	Data 0.013 (0.013)	Loss 0.5502 (0.5502)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:57 - INFO - EVALUATING - Epoch: [182][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3363 (0.3363)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:04:58 - INFO - EVALUATING - Epoch: [182][50/100]	Time 0.018 (0.019)	Data 0.009 (0.010)	Loss 0.2008 (0.3926)	Prec@1 92.000 (90.118)	Prec@5 100.000 (99.549)
2019-04-10 18:04:59 - INFO - 
 Epoch: 183	Training Loss 0.0489 	Training Prec@1 98.340 	Training Prec@5 100.000 	Validation Loss 0.3641 	Validation Prec@1 90.900 	Validation Prec@5 99.680 	Test Loss 0.3843 	Test Prec@1  90.220 	Test Prec@5  99.580 

2019-04-10 18:04:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:04:59 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:04:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:04:59 - INFO - TRAINING - Epoch: [183][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0427 (0.0427)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:05:02 - INFO - TRAINING - Epoch: [183][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0713 (0.0495)	Prec@1 97.000 (98.353)	Prec@5 100.000 (100.000)
2019-04-10 18:05:04 - INFO - TRAINING - Epoch: [183][100/450]	Time 0.062 (0.056)	Data 0.012 (0.014)	Loss 0.0676 (0.0489)	Prec@1 97.000 (98.376)	Prec@5 100.000 (100.000)
2019-04-10 18:05:07 - INFO - TRAINING - Epoch: [183][150/450]	Time 0.058 (0.056)	Data 0.012 (0.014)	Loss 0.0506 (0.0485)	Prec@1 97.000 (98.384)	Prec@5 100.000 (100.000)
2019-04-10 18:05:10 - INFO - TRAINING - Epoch: [183][200/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0899 (0.0498)	Prec@1 98.000 (98.343)	Prec@5 100.000 (100.000)
2019-04-10 18:05:13 - INFO - TRAINING - Epoch: [183][250/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0464 (0.0500)	Prec@1 99.000 (98.323)	Prec@5 100.000 (99.996)
2019-04-10 18:05:16 - INFO - TRAINING - Epoch: [183][300/450]	Time 0.056 (0.056)	Data 0.012 (0.014)	Loss 0.0599 (0.0486)	Prec@1 97.000 (98.375)	Prec@5 100.000 (99.993)
2019-04-10 18:05:19 - INFO - TRAINING - Epoch: [183][350/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0490 (0.0482)	Prec@1 98.000 (98.393)	Prec@5 100.000 (99.994)
2019-04-10 18:05:21 - INFO - TRAINING - Epoch: [183][400/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.0151 (0.0488)	Prec@1 100.000 (98.362)	Prec@5 100.000 (99.995)
2019-04-10 18:05:24 - INFO - EVALUATING - Epoch: [183][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.2158 (0.2158)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 18:05:25 - INFO - EVALUATING - Epoch: [183][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2986 (0.2986)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 18:05:26 - INFO - EVALUATING - Epoch: [183][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1590 (0.3868)	Prec@1 95.000 (90.000)	Prec@5 99.000 (99.392)
2019-04-10 18:05:27 - INFO - 
 Epoch: 184	Training Loss 0.0483 	Training Prec@1 98.371 	Training Prec@5 99.996 	Validation Loss 0.3560 	Validation Prec@1 91.000 	Validation Prec@5 99.620 	Test Loss 0.3761 	Test Prec@1  90.180 	Test Prec@5  99.510 

2019-04-10 18:05:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:05:27 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:05:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:05:27 - INFO - TRAINING - Epoch: [184][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0877 (0.0877)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:05:30 - INFO - TRAINING - Epoch: [184][50/450]	Time 0.054 (0.053)	Data 0.014 (0.014)	Loss 0.0690 (0.0543)	Prec@1 97.000 (98.275)	Prec@5 100.000 (100.000)
2019-04-10 18:05:33 - INFO - TRAINING - Epoch: [184][100/450]	Time 0.051 (0.053)	Data 0.014 (0.014)	Loss 0.0538 (0.0516)	Prec@1 99.000 (98.307)	Prec@5 100.000 (100.000)
2019-04-10 18:05:35 - INFO - TRAINING - Epoch: [184][150/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.0996 (0.0515)	Prec@1 96.000 (98.272)	Prec@5 100.000 (100.000)
2019-04-10 18:05:38 - INFO - TRAINING - Epoch: [184][200/450]	Time 0.054 (0.053)	Data 0.012 (0.014)	Loss 0.0489 (0.0508)	Prec@1 99.000 (98.303)	Prec@5 100.000 (100.000)
2019-04-10 18:05:41 - INFO - TRAINING - Epoch: [184][250/450]	Time 0.050 (0.054)	Data 0.014 (0.014)	Loss 0.0449 (0.0504)	Prec@1 98.000 (98.295)	Prec@5 100.000 (100.000)
2019-04-10 18:05:43 - INFO - TRAINING - Epoch: [184][300/450]	Time 0.046 (0.053)	Data 0.021 (0.014)	Loss 0.0641 (0.0508)	Prec@1 98.000 (98.269)	Prec@5 100.000 (100.000)
2019-04-10 18:05:46 - INFO - TRAINING - Epoch: [184][350/450]	Time 0.053 (0.053)	Data 0.014 (0.014)	Loss 0.0361 (0.0493)	Prec@1 99.000 (98.313)	Prec@5 100.000 (100.000)
2019-04-10 18:05:49 - INFO - TRAINING - Epoch: [184][400/450]	Time 0.055 (0.053)	Data 0.012 (0.014)	Loss 0.0692 (0.0493)	Prec@1 98.000 (98.334)	Prec@5 100.000 (100.000)
2019-04-10 18:05:51 - INFO - EVALUATING - Epoch: [184][0/50]	Time 0.037 (0.037)	Data 0.013 (0.013)	Loss 0.1652 (0.1652)	Prec@1 96.000 (96.000)	Prec@5 99.000 (99.000)
2019-04-10 18:05:52 - INFO - EVALUATING - Epoch: [184][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3398 (0.3398)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:05:53 - INFO - EVALUATING - Epoch: [184][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2035 (0.3872)	Prec@1 91.000 (89.902)	Prec@5 100.000 (99.392)
2019-04-10 18:05:54 - INFO - 
 Epoch: 185	Training Loss 0.0501 	Training Prec@1 98.291 	Training Prec@5 100.000 	Validation Loss 0.3614 	Validation Prec@1 90.420 	Validation Prec@5 99.600 	Test Loss 0.3755 	Test Prec@1  90.120 	Test Prec@5  99.480 

2019-04-10 18:05:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:05:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:05:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:05:54 - INFO - TRAINING - Epoch: [185][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0423 (0.0423)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:05:57 - INFO - TRAINING - Epoch: [185][50/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0842 (0.0538)	Prec@1 97.000 (98.039)	Prec@5 100.000 (100.000)
2019-04-10 18:06:00 - INFO - TRAINING - Epoch: [185][100/450]	Time 0.057 (0.056)	Data 0.012 (0.014)	Loss 0.0146 (0.0519)	Prec@1 100.000 (98.257)	Prec@5 100.000 (100.000)
2019-04-10 18:06:03 - INFO - TRAINING - Epoch: [185][150/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0282 (0.0514)	Prec@1 99.000 (98.245)	Prec@5 100.000 (100.000)
2019-04-10 18:06:05 - INFO - TRAINING - Epoch: [185][200/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0521 (0.0510)	Prec@1 99.000 (98.234)	Prec@5 100.000 (100.000)
2019-04-10 18:06:08 - INFO - TRAINING - Epoch: [185][250/450]	Time 0.063 (0.057)	Data 0.012 (0.014)	Loss 0.0679 (0.0512)	Prec@1 97.000 (98.275)	Prec@5 100.000 (100.000)
2019-04-10 18:06:11 - INFO - TRAINING - Epoch: [185][300/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.0497 (0.0503)	Prec@1 98.000 (98.292)	Prec@5 100.000 (99.997)
2019-04-10 18:06:14 - INFO - TRAINING - Epoch: [185][350/450]	Time 0.061 (0.057)	Data 0.013 (0.014)	Loss 0.0234 (0.0509)	Prec@1 99.000 (98.288)	Prec@5 100.000 (99.997)
2019-04-10 18:06:17 - INFO - TRAINING - Epoch: [185][400/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0133 (0.0505)	Prec@1 100.000 (98.317)	Prec@5 100.000 (99.998)
2019-04-10 18:06:20 - INFO - EVALUATING - Epoch: [185][0/50]	Time 0.043 (0.043)	Data 0.011 (0.011)	Loss 0.2260 (0.2260)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 18:06:21 - INFO - EVALUATING - Epoch: [185][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3838 (0.3838)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 18:06:21 - INFO - EVALUATING - Epoch: [185][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.2561 (0.3868)	Prec@1 92.000 (89.647)	Prec@5 100.000 (99.549)
2019-04-10 18:06:22 - INFO - 
 Epoch: 186	Training Loss 0.0509 	Training Prec@1 98.289 	Training Prec@5 99.998 	Validation Loss 0.3836 	Validation Prec@1 89.940 	Validation Prec@5 99.760 	Test Loss 0.3852 	Test Prec@1  89.950 	Test Prec@5  99.580 

2019-04-10 18:06:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:06:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:06:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:06:23 - INFO - TRAINING - Epoch: [186][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0568 (0.0568)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:06:25 - INFO - TRAINING - Epoch: [186][50/450]	Time 0.053 (0.056)	Data 0.014 (0.014)	Loss 0.0305 (0.0428)	Prec@1 99.000 (98.588)	Prec@5 100.000 (100.000)
2019-04-10 18:06:28 - INFO - TRAINING - Epoch: [186][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0242 (0.0449)	Prec@1 99.000 (98.455)	Prec@5 100.000 (100.000)
2019-04-10 18:06:31 - INFO - TRAINING - Epoch: [186][150/450]	Time 0.058 (0.056)	Data 0.015 (0.014)	Loss 0.0206 (0.0445)	Prec@1 99.000 (98.470)	Prec@5 100.000 (100.000)
2019-04-10 18:06:34 - INFO - TRAINING - Epoch: [186][200/450]	Time 0.057 (0.056)	Data 0.015 (0.014)	Loss 0.0689 (0.0436)	Prec@1 98.000 (98.468)	Prec@5 100.000 (100.000)
2019-04-10 18:06:37 - INFO - TRAINING - Epoch: [186][250/450]	Time 0.053 (0.056)	Data 0.012 (0.014)	Loss 0.0565 (0.0445)	Prec@1 97.000 (98.458)	Prec@5 100.000 (100.000)
2019-04-10 18:06:39 - INFO - TRAINING - Epoch: [186][300/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0403 (0.0452)	Prec@1 97.000 (98.435)	Prec@5 100.000 (100.000)
2019-04-10 18:06:42 - INFO - TRAINING - Epoch: [186][350/450]	Time 0.050 (0.055)	Data 0.014 (0.014)	Loss 0.1010 (0.0460)	Prec@1 97.000 (98.410)	Prec@5 100.000 (100.000)
2019-04-10 18:06:45 - INFO - TRAINING - Epoch: [186][400/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0506 (0.0456)	Prec@1 99.000 (98.449)	Prec@5 100.000 (100.000)
2019-04-10 18:06:47 - INFO - EVALUATING - Epoch: [186][0/50]	Time 0.040 (0.040)	Data 0.011 (0.011)	Loss 0.4512 (0.4512)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 18:06:48 - INFO - EVALUATING - Epoch: [186][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3339 (0.3339)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 18:06:49 - INFO - EVALUATING - Epoch: [186][50/100]	Time 0.017 (0.018)	Data 0.009 (0.010)	Loss 0.2752 (0.3821)	Prec@1 91.000 (90.412)	Prec@5 100.000 (99.588)
2019-04-10 18:06:50 - INFO - 
 Epoch: 187	Training Loss 0.0458 	Training Prec@1 98.442 	Training Prec@5 100.000 	Validation Loss 0.3713 	Validation Prec@1 90.520 	Validation Prec@5 99.560 	Test Loss 0.3821 	Test Prec@1  90.430 	Test Prec@5  99.620 

2019-04-10 18:06:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:06:50 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:06:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:06:50 - INFO - TRAINING - Epoch: [187][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0792 (0.0792)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 18:06:53 - INFO - TRAINING - Epoch: [187][50/450]	Time 0.054 (0.053)	Data 0.013 (0.015)	Loss 0.0180 (0.0488)	Prec@1 100.000 (98.275)	Prec@5 100.000 (100.000)
2019-04-10 18:06:55 - INFO - TRAINING - Epoch: [187][100/450]	Time 0.053 (0.053)	Data 0.013 (0.015)	Loss 0.0286 (0.0495)	Prec@1 98.000 (98.356)	Prec@5 100.000 (100.000)
2019-04-10 18:06:58 - INFO - TRAINING - Epoch: [187][150/450]	Time 0.052 (0.054)	Data 0.014 (0.015)	Loss 0.0127 (0.0480)	Prec@1 100.000 (98.437)	Prec@5 100.000 (100.000)
2019-04-10 18:07:01 - INFO - TRAINING - Epoch: [187][200/450]	Time 0.059 (0.054)	Data 0.013 (0.015)	Loss 0.0624 (0.0473)	Prec@1 98.000 (98.423)	Prec@5 100.000 (100.000)
2019-04-10 18:07:04 - INFO - TRAINING - Epoch: [187][250/450]	Time 0.054 (0.054)	Data 0.014 (0.015)	Loss 0.0596 (0.0479)	Prec@1 99.000 (98.394)	Prec@5 100.000 (99.996)
2019-04-10 18:07:06 - INFO - TRAINING - Epoch: [187][300/450]	Time 0.054 (0.054)	Data 0.014 (0.015)	Loss 0.1138 (0.0480)	Prec@1 96.000 (98.395)	Prec@5 100.000 (99.993)
2019-04-10 18:07:09 - INFO - TRAINING - Epoch: [187][350/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0261 (0.0479)	Prec@1 99.000 (98.385)	Prec@5 100.000 (99.989)
2019-04-10 18:07:12 - INFO - TRAINING - Epoch: [187][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0670 (0.0483)	Prec@1 98.000 (98.382)	Prec@5 100.000 (99.990)
2019-04-10 18:07:14 - INFO - EVALUATING - Epoch: [187][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.1634 (0.1634)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 18:07:15 - INFO - EVALUATING - Epoch: [187][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3423 (0.3423)	Prec@1 93.000 (93.000)	Prec@5 99.000 (99.000)
2019-04-10 18:07:16 - INFO - EVALUATING - Epoch: [187][50/100]	Time 0.017 (0.018)	Data 0.010 (0.010)	Loss 0.1723 (0.3828)	Prec@1 97.000 (90.137)	Prec@5 100.000 (99.510)
2019-04-10 18:07:17 - INFO - 
 Epoch: 188	Training Loss 0.0481 	Training Prec@1 98.373 	Training Prec@5 99.991 	Validation Loss 0.3633 	Validation Prec@1 90.620 	Validation Prec@5 99.760 	Test Loss 0.3672 	Test Prec@1  90.560 	Test Prec@5  99.610 

2019-04-10 18:07:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:07:17 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:07:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:07:17 - INFO - TRAINING - Epoch: [188][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0783 (0.0783)	Prec@1 96.000 (96.000)	Prec@5 100.000 (100.000)
2019-04-10 18:07:20 - INFO - TRAINING - Epoch: [188][50/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.1508 (0.0509)	Prec@1 96.000 (98.196)	Prec@5 100.000 (99.980)
2019-04-10 18:07:23 - INFO - TRAINING - Epoch: [188][100/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0521 (0.0435)	Prec@1 97.000 (98.515)	Prec@5 100.000 (99.990)
2019-04-10 18:07:26 - INFO - TRAINING - Epoch: [188][150/450]	Time 0.058 (0.056)	Data 0.013 (0.014)	Loss 0.0125 (0.0463)	Prec@1 100.000 (98.464)	Prec@5 100.000 (99.993)
2019-04-10 18:07:28 - INFO - TRAINING - Epoch: [188][200/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0535 (0.0457)	Prec@1 99.000 (98.418)	Prec@5 100.000 (99.995)
2019-04-10 18:07:31 - INFO - TRAINING - Epoch: [188][250/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0511 (0.0470)	Prec@1 99.000 (98.382)	Prec@5 100.000 (99.992)
2019-04-10 18:07:34 - INFO - TRAINING - Epoch: [188][300/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0661 (0.0474)	Prec@1 98.000 (98.382)	Prec@5 100.000 (99.993)
2019-04-10 18:07:37 - INFO - TRAINING - Epoch: [188][350/450]	Time 0.054 (0.056)	Data 0.013 (0.014)	Loss 0.0155 (0.0475)	Prec@1 99.000 (98.359)	Prec@5 100.000 (99.994)
2019-04-10 18:07:40 - INFO - TRAINING - Epoch: [188][400/450]	Time 0.055 (0.056)	Data 0.014 (0.014)	Loss 0.0310 (0.0473)	Prec@1 99.000 (98.349)	Prec@5 100.000 (99.993)
2019-04-10 18:07:42 - INFO - EVALUATING - Epoch: [188][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.3473 (0.3473)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 18:07:43 - INFO - EVALUATING - Epoch: [188][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3264 (0.3264)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:07:44 - INFO - EVALUATING - Epoch: [188][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2787 (0.3920)	Prec@1 90.000 (90.255)	Prec@5 100.000 (99.412)
2019-04-10 18:07:45 - INFO - 
 Epoch: 189	Training Loss 0.0474 	Training Prec@1 98.360 	Training Prec@5 99.993 	Validation Loss 0.3754 	Validation Prec@1 90.860 	Validation Prec@5 99.740 	Test Loss 0.3871 	Test Prec@1  90.190 	Test Prec@5  99.530 

2019-04-10 18:07:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:07:45 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:07:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:07:45 - INFO - TRAINING - Epoch: [189][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0174 (0.0174)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 18:07:48 - INFO - TRAINING - Epoch: [189][50/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0846 (0.0469)	Prec@1 97.000 (98.451)	Prec@5 100.000 (99.980)
2019-04-10 18:07:51 - INFO - TRAINING - Epoch: [189][100/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0170 (0.0455)	Prec@1 99.000 (98.406)	Prec@5 100.000 (99.990)
2019-04-10 18:07:53 - INFO - TRAINING - Epoch: [189][150/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0430 (0.0445)	Prec@1 99.000 (98.497)	Prec@5 100.000 (99.993)
2019-04-10 18:07:56 - INFO - TRAINING - Epoch: [189][200/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0167 (0.0463)	Prec@1 100.000 (98.418)	Prec@5 100.000 (99.990)
2019-04-10 18:07:59 - INFO - TRAINING - Epoch: [189][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0305 (0.0470)	Prec@1 99.000 (98.382)	Prec@5 100.000 (99.992)
2019-04-10 18:08:01 - INFO - TRAINING - Epoch: [189][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0332 (0.0463)	Prec@1 99.000 (98.425)	Prec@5 100.000 (99.993)
2019-04-10 18:08:04 - INFO - TRAINING - Epoch: [189][350/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0359 (0.0468)	Prec@1 99.000 (98.422)	Prec@5 100.000 (99.994)
2019-04-10 18:08:07 - INFO - TRAINING - Epoch: [189][400/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1115 (0.0477)	Prec@1 96.000 (98.377)	Prec@5 100.000 (99.993)
2019-04-10 18:08:09 - INFO - EVALUATING - Epoch: [189][0/50]	Time 0.041 (0.041)	Data 0.011 (0.011)	Loss 0.6412 (0.6412)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-04-10 18:08:10 - INFO - EVALUATING - Epoch: [189][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4571 (0.4571)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:08:11 - INFO - EVALUATING - Epoch: [189][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2123 (0.3841)	Prec@1 95.000 (90.255)	Prec@5 100.000 (99.608)
2019-04-10 18:08:12 - INFO - 
 Epoch: 190	Training Loss 0.0483 	Training Prec@1 98.351 	Training Prec@5 99.993 	Validation Loss 0.3634 	Validation Prec@1 90.380 	Validation Prec@5 99.620 	Test Loss 0.3841 	Test Prec@1  90.190 	Test Prec@5  99.630 

2019-04-10 18:08:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:08:12 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:08:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:08:12 - INFO - TRAINING - Epoch: [190][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0655 (0.0655)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:08:15 - INFO - TRAINING - Epoch: [190][50/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0757 (0.0504)	Prec@1 97.000 (98.059)	Prec@5 100.000 (100.000)
2019-04-10 18:08:18 - INFO - TRAINING - Epoch: [190][100/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0370 (0.0487)	Prec@1 98.000 (98.257)	Prec@5 100.000 (100.000)
2019-04-10 18:08:20 - INFO - TRAINING - Epoch: [190][150/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0692 (0.0463)	Prec@1 97.000 (98.331)	Prec@5 100.000 (100.000)
2019-04-10 18:08:23 - INFO - TRAINING - Epoch: [190][200/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0203 (0.0459)	Prec@1 100.000 (98.393)	Prec@5 100.000 (100.000)
2019-04-10 18:08:26 - INFO - TRAINING - Epoch: [190][250/450]	Time 0.055 (0.054)	Data 0.012 (0.014)	Loss 0.0656 (0.0454)	Prec@1 98.000 (98.422)	Prec@5 100.000 (100.000)
2019-04-10 18:08:29 - INFO - TRAINING - Epoch: [190][300/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0145 (0.0452)	Prec@1 100.000 (98.425)	Prec@5 100.000 (100.000)
2019-04-10 18:08:31 - INFO - TRAINING - Epoch: [190][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0324 (0.0446)	Prec@1 100.000 (98.447)	Prec@5 100.000 (100.000)
2019-04-10 18:08:34 - INFO - TRAINING - Epoch: [190][400/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0661 (0.0450)	Prec@1 98.000 (98.424)	Prec@5 100.000 (100.000)
2019-04-10 18:08:37 - INFO - EVALUATING - Epoch: [190][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.3548 (0.3548)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:08:38 - INFO - EVALUATING - Epoch: [190][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3034 (0.3034)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:08:38 - INFO - EVALUATING - Epoch: [190][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2461 (0.3975)	Prec@1 94.000 (89.941)	Prec@5 100.000 (99.294)
2019-04-10 18:08:39 - INFO - 
 Epoch: 191	Training Loss 0.0454 	Training Prec@1 98.431 	Training Prec@5 100.000 	Validation Loss 0.3733 	Validation Prec@1 90.720 	Validation Prec@5 99.680 	Test Loss 0.3851 	Test Prec@1  90.280 	Test Prec@5  99.460 

2019-04-10 18:08:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:08:40 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:08:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:08:40 - INFO - TRAINING - Epoch: [191][0/450]	Time 0.029 (0.029)	Data 0.013 (0.013)	Loss 0.0557 (0.0557)	Prec@1 97.000 (97.000)	Prec@5 100.000 (100.000)
2019-04-10 18:08:42 - INFO - TRAINING - Epoch: [191][50/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0409 (0.0431)	Prec@1 98.000 (98.510)	Prec@5 100.000 (100.000)
2019-04-10 18:08:45 - INFO - TRAINING - Epoch: [191][100/450]	Time 0.055 (0.054)	Data 0.017 (0.014)	Loss 0.0886 (0.0460)	Prec@1 97.000 (98.436)	Prec@5 100.000 (100.000)
2019-04-10 18:08:48 - INFO - TRAINING - Epoch: [191][150/450]	Time 0.055 (0.055)	Data 0.012 (0.014)	Loss 0.0208 (0.0462)	Prec@1 100.000 (98.430)	Prec@5 100.000 (100.000)
2019-04-10 18:08:51 - INFO - TRAINING - Epoch: [191][200/450]	Time 0.055 (0.055)	Data 0.013 (0.014)	Loss 0.0313 (0.0452)	Prec@1 99.000 (98.463)	Prec@5 100.000 (100.000)
2019-04-10 18:08:53 - INFO - TRAINING - Epoch: [191][250/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0535 (0.0446)	Prec@1 98.000 (98.514)	Prec@5 100.000 (100.000)
2019-04-10 18:08:56 - INFO - TRAINING - Epoch: [191][300/450]	Time 0.058 (0.055)	Data 0.013 (0.014)	Loss 0.0328 (0.0432)	Prec@1 99.000 (98.535)	Prec@5 100.000 (100.000)
2019-04-10 18:08:59 - INFO - TRAINING - Epoch: [191][350/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0109 (0.0435)	Prec@1 100.000 (98.524)	Prec@5 100.000 (100.000)
2019-04-10 18:09:02 - INFO - TRAINING - Epoch: [191][400/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0512 (0.0436)	Prec@1 99.000 (98.529)	Prec@5 100.000 (100.000)
2019-04-10 18:09:05 - INFO - EVALUATING - Epoch: [191][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.5467 (0.5467)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-04-10 18:09:06 - INFO - EVALUATING - Epoch: [191][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.2970 (0.2970)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-04-10 18:09:07 - INFO - EVALUATING - Epoch: [191][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1118 (0.3882)	Prec@1 96.000 (90.569)	Prec@5 100.000 (99.471)
2019-04-10 18:09:07 - INFO - 
 Epoch: 192	Training Loss 0.0435 	Training Prec@1 98.547 	Training Prec@5 100.000 	Validation Loss 0.3683 	Validation Prec@1 90.780 	Validation Prec@5 99.720 	Test Loss 0.3838 	Test Prec@1  90.500 	Test Prec@5  99.540 

2019-04-10 18:09:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:09:08 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:09:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:09:08 - INFO - TRAINING - Epoch: [192][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0626 (0.0626)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:09:10 - INFO - TRAINING - Epoch: [192][50/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0155 (0.0469)	Prec@1 100.000 (98.490)	Prec@5 100.000 (100.000)
2019-04-10 18:09:13 - INFO - TRAINING - Epoch: [192][100/450]	Time 0.057 (0.055)	Data 0.012 (0.014)	Loss 0.0242 (0.0496)	Prec@1 99.000 (98.287)	Prec@5 100.000 (100.000)
2019-04-10 18:09:16 - INFO - TRAINING - Epoch: [192][150/450]	Time 0.057 (0.056)	Data 0.015 (0.014)	Loss 0.0157 (0.0505)	Prec@1 100.000 (98.232)	Prec@5 100.000 (100.000)
2019-04-10 18:09:19 - INFO - TRAINING - Epoch: [192][200/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0283 (0.0491)	Prec@1 99.000 (98.289)	Prec@5 100.000 (100.000)
2019-04-10 18:09:22 - INFO - TRAINING - Epoch: [192][250/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0805 (0.0489)	Prec@1 96.000 (98.323)	Prec@5 100.000 (100.000)
2019-04-10 18:09:25 - INFO - TRAINING - Epoch: [192][300/450]	Time 0.057 (0.056)	Data 0.015 (0.014)	Loss 0.0156 (0.0484)	Prec@1 99.000 (98.336)	Prec@5 100.000 (100.000)
2019-04-10 18:09:27 - INFO - TRAINING - Epoch: [192][350/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0676 (0.0489)	Prec@1 96.000 (98.308)	Prec@5 100.000 (100.000)
2019-04-10 18:09:30 - INFO - TRAINING - Epoch: [192][400/450]	Time 0.056 (0.056)	Data 0.013 (0.014)	Loss 0.0129 (0.0497)	Prec@1 100.000 (98.284)	Prec@5 100.000 (100.000)
2019-04-10 18:09:33 - INFO - EVALUATING - Epoch: [192][0/50]	Time 0.042 (0.042)	Data 0.012 (0.012)	Loss 0.3384 (0.3384)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 18:09:34 - INFO - EVALUATING - Epoch: [192][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3271 (0.3271)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 18:09:35 - INFO - EVALUATING - Epoch: [192][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1674 (0.3764)	Prec@1 96.000 (90.706)	Prec@5 100.000 (99.490)
2019-04-10 18:09:36 - INFO - 
 Epoch: 193	Training Loss 0.0501 	Training Prec@1 98.273 	Training Prec@5 100.000 	Validation Loss 0.3714 	Validation Prec@1 90.420 	Validation Prec@5 99.620 	Test Loss 0.3779 	Test Prec@1  90.480 	Test Prec@5  99.530 

2019-04-10 18:09:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:09:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:09:36 - INFO - TRAINING - Epoch: [193][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0270 (0.0270)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:09:39 - INFO - TRAINING - Epoch: [193][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0274 (0.0425)	Prec@1 100.000 (98.588)	Prec@5 100.000 (100.000)
2019-04-10 18:09:42 - INFO - TRAINING - Epoch: [193][100/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.0193 (0.0438)	Prec@1 99.000 (98.485)	Prec@5 100.000 (100.000)
2019-04-10 18:09:44 - INFO - TRAINING - Epoch: [193][150/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0346 (0.0471)	Prec@1 99.000 (98.384)	Prec@5 100.000 (100.000)
2019-04-10 18:09:47 - INFO - TRAINING - Epoch: [193][200/450]	Time 0.055 (0.056)	Data 0.012 (0.014)	Loss 0.0267 (0.0486)	Prec@1 99.000 (98.279)	Prec@5 100.000 (100.000)
2019-04-10 18:09:50 - INFO - TRAINING - Epoch: [193][250/450]	Time 0.051 (0.056)	Data 0.021 (0.014)	Loss 0.0491 (0.0482)	Prec@1 99.000 (98.311)	Prec@5 100.000 (99.996)
2019-04-10 18:09:53 - INFO - TRAINING - Epoch: [193][300/450]	Time 0.053 (0.056)	Data 0.013 (0.014)	Loss 0.0170 (0.0483)	Prec@1 100.000 (98.312)	Prec@5 100.000 (99.993)
2019-04-10 18:09:55 - INFO - TRAINING - Epoch: [193][350/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.1236 (0.0481)	Prec@1 96.000 (98.330)	Prec@5 100.000 (99.994)
2019-04-10 18:09:58 - INFO - TRAINING - Epoch: [193][400/450]	Time 0.057 (0.055)	Data 0.013 (0.014)	Loss 0.0489 (0.0483)	Prec@1 98.000 (98.339)	Prec@5 100.000 (99.990)
2019-04-10 18:10:01 - INFO - EVALUATING - Epoch: [193][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.3725 (0.3725)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:10:02 - INFO - EVALUATING - Epoch: [193][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.4175 (0.4175)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 18:10:02 - INFO - EVALUATING - Epoch: [193][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2749 (0.3808)	Prec@1 91.000 (90.373)	Prec@5 99.000 (99.412)
2019-04-10 18:10:03 - INFO - 
 Epoch: 194	Training Loss 0.0479 	Training Prec@1 98.360 	Training Prec@5 99.991 	Validation Loss 0.3710 	Validation Prec@1 90.740 	Validation Prec@5 99.720 	Test Loss 0.3794 	Test Prec@1  90.430 	Test Prec@5  99.530 

2019-04-10 18:10:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:10:04 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:10:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:10:04 - INFO - TRAINING - Epoch: [194][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0262 (0.0262)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:10:06 - INFO - TRAINING - Epoch: [194][50/450]	Time 0.055 (0.054)	Data 0.013 (0.014)	Loss 0.0858 (0.0482)	Prec@1 95.000 (98.314)	Prec@5 100.000 (100.000)
2019-04-10 18:10:09 - INFO - TRAINING - Epoch: [194][100/450]	Time 0.052 (0.054)	Data 0.013 (0.014)	Loss 0.0139 (0.0478)	Prec@1 99.000 (98.277)	Prec@5 100.000 (100.000)
2019-04-10 18:10:12 - INFO - TRAINING - Epoch: [194][150/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0491 (0.0484)	Prec@1 99.000 (98.272)	Prec@5 100.000 (100.000)
2019-04-10 18:10:14 - INFO - TRAINING - Epoch: [194][200/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.1071 (0.0485)	Prec@1 98.000 (98.303)	Prec@5 100.000 (100.000)
2019-04-10 18:10:17 - INFO - TRAINING - Epoch: [194][250/450]	Time 0.054 (0.054)	Data 0.013 (0.014)	Loss 0.0761 (0.0493)	Prec@1 98.000 (98.267)	Prec@5 100.000 (100.000)
2019-04-10 18:10:20 - INFO - TRAINING - Epoch: [194][300/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1232 (0.0504)	Prec@1 95.000 (98.226)	Prec@5 100.000 (100.000)
2019-04-10 18:10:22 - INFO - TRAINING - Epoch: [194][350/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.0224 (0.0501)	Prec@1 99.000 (98.239)	Prec@5 100.000 (100.000)
2019-04-10 18:10:25 - INFO - TRAINING - Epoch: [194][400/450]	Time 0.053 (0.054)	Data 0.014 (0.014)	Loss 0.0245 (0.0492)	Prec@1 99.000 (98.279)	Prec@5 100.000 (100.000)
2019-04-10 18:10:28 - INFO - EVALUATING - Epoch: [194][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4774 (0.4774)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-04-10 18:10:29 - INFO - EVALUATING - Epoch: [194][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3720 (0.3720)	Prec@1 91.000 (91.000)	Prec@5 99.000 (99.000)
2019-04-10 18:10:30 - INFO - EVALUATING - Epoch: [194][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.2234 (0.3785)	Prec@1 96.000 (90.392)	Prec@5 99.000 (99.490)
2019-04-10 18:10:30 - INFO - 
 Epoch: 195	Training Loss 0.0482 	Training Prec@1 98.322 	Training Prec@5 100.000 	Validation Loss 0.3694 	Validation Prec@1 90.500 	Validation Prec@5 99.620 	Test Loss 0.3704 	Test Prec@1  90.610 	Test Prec@5  99.610 

2019-04-10 18:10:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:10:31 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:10:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:10:31 - INFO - TRAINING - Epoch: [195][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0310 (0.0310)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:10:34 - INFO - TRAINING - Epoch: [195][50/450]	Time 0.058 (0.056)	Data 0.014 (0.014)	Loss 0.0296 (0.0422)	Prec@1 99.000 (98.608)	Prec@5 100.000 (100.000)
2019-04-10 18:10:36 - INFO - TRAINING - Epoch: [195][100/450]	Time 0.054 (0.055)	Data 0.013 (0.014)	Loss 0.0293 (0.0422)	Prec@1 99.000 (98.525)	Prec@5 100.000 (100.000)
2019-04-10 18:10:39 - INFO - TRAINING - Epoch: [195][150/450]	Time 0.055 (0.055)	Data 0.014 (0.014)	Loss 0.0984 (0.0438)	Prec@1 96.000 (98.543)	Prec@5 100.000 (100.000)
2019-04-10 18:10:42 - INFO - TRAINING - Epoch: [195][200/450]	Time 0.052 (0.055)	Data 0.013 (0.014)	Loss 0.0194 (0.0442)	Prec@1 99.000 (98.502)	Prec@5 100.000 (100.000)
2019-04-10 18:10:44 - INFO - TRAINING - Epoch: [195][250/450]	Time 0.053 (0.054)	Data 0.013 (0.014)	Loss 0.1186 (0.0440)	Prec@1 95.000 (98.506)	Prec@5 100.000 (100.000)
2019-04-10 18:10:47 - INFO - TRAINING - Epoch: [195][300/450]	Time 0.054 (0.054)	Data 0.014 (0.014)	Loss 0.0489 (0.0434)	Prec@1 99.000 (98.528)	Prec@5 100.000 (100.000)
2019-04-10 18:10:50 - INFO - TRAINING - Epoch: [195][350/450]	Time 0.055 (0.054)	Data 0.014 (0.014)	Loss 0.0185 (0.0437)	Prec@1 99.000 (98.521)	Prec@5 100.000 (100.000)
2019-04-10 18:10:52 - INFO - TRAINING - Epoch: [195][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0138 (0.0446)	Prec@1 100.000 (98.516)	Prec@5 100.000 (100.000)
2019-04-10 18:10:55 - INFO - EVALUATING - Epoch: [195][0/50]	Time 0.041 (0.041)	Data 0.012 (0.012)	Loss 0.6589 (0.6589)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-04-10 18:10:56 - INFO - EVALUATING - Epoch: [195][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3918 (0.3918)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 18:10:57 - INFO - EVALUATING - Epoch: [195][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3100 (0.3845)	Prec@1 91.000 (90.137)	Prec@5 99.000 (99.314)
2019-04-10 18:10:58 - INFO - 
 Epoch: 196	Training Loss 0.0439 	Training Prec@1 98.549 	Training Prec@5 100.000 	Validation Loss 0.3622 	Validation Prec@1 90.960 	Validation Prec@5 99.720 	Test Loss 0.3821 	Test Prec@1  90.190 	Test Prec@5  99.480 

2019-04-10 18:10:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:10:58 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:10:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:10:58 - INFO - TRAINING - Epoch: [196][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0571 (0.0571)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:01 - INFO - TRAINING - Epoch: [196][50/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0478 (0.0403)	Prec@1 99.000 (98.510)	Prec@5 100.000 (100.000)
2019-04-10 18:11:04 - INFO - TRAINING - Epoch: [196][100/450]	Time 0.054 (0.056)	Data 0.012 (0.014)	Loss 0.0206 (0.0378)	Prec@1 99.000 (98.634)	Prec@5 100.000 (100.000)
2019-04-10 18:11:06 - INFO - TRAINING - Epoch: [196][150/450]	Time 0.054 (0.055)	Data 0.012 (0.014)	Loss 0.0577 (0.0409)	Prec@1 98.000 (98.570)	Prec@5 100.000 (100.000)
2019-04-10 18:11:09 - INFO - TRAINING - Epoch: [196][200/450]	Time 0.053 (0.055)	Data 0.012 (0.013)	Loss 0.1158 (0.0412)	Prec@1 97.000 (98.607)	Prec@5 100.000 (99.995)
2019-04-10 18:11:12 - INFO - TRAINING - Epoch: [196][250/450]	Time 0.055 (0.055)	Data 0.014 (0.013)	Loss 0.0352 (0.0425)	Prec@1 99.000 (98.598)	Prec@5 100.000 (99.996)
2019-04-10 18:11:15 - INFO - TRAINING - Epoch: [196][300/450]	Time 0.055 (0.055)	Data 0.014 (0.013)	Loss 0.1491 (0.0440)	Prec@1 98.000 (98.558)	Prec@5 100.000 (99.997)
2019-04-10 18:11:17 - INFO - TRAINING - Epoch: [196][350/450]	Time 0.056 (0.055)	Data 0.014 (0.014)	Loss 0.0756 (0.0443)	Prec@1 97.000 (98.556)	Prec@5 100.000 (99.994)
2019-04-10 18:11:20 - INFO - TRAINING - Epoch: [196][400/450]	Time 0.054 (0.055)	Data 0.014 (0.014)	Loss 0.0288 (0.0439)	Prec@1 99.000 (98.551)	Prec@5 100.000 (99.995)
2019-04-10 18:11:23 - INFO - EVALUATING - Epoch: [196][0/50]	Time 0.042 (0.042)	Data 0.010 (0.010)	Loss 0.2142 (0.2142)	Prec@1 94.000 (94.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:24 - INFO - EVALUATING - Epoch: [196][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3283 (0.3283)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:24 - INFO - EVALUATING - Epoch: [196][50/100]	Time 0.018 (0.018)	Data 0.009 (0.010)	Loss 0.2569 (0.3834)	Prec@1 93.000 (90.039)	Prec@5 100.000 (99.588)
2019-04-10 18:11:25 - INFO - 
 Epoch: 197	Training Loss 0.0440 	Training Prec@1 98.538 	Training Prec@5 99.996 	Validation Loss 0.3855 	Validation Prec@1 90.260 	Validation Prec@5 99.680 	Test Loss 0.3827 	Test Prec@1  90.100 	Test Prec@5  99.590 

2019-04-10 18:11:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:11:26 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:11:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:11:26 - INFO - TRAINING - Epoch: [197][0/450]	Time 0.030 (0.030)	Data 0.013 (0.013)	Loss 0.0374 (0.0374)	Prec@1 99.000 (99.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:28 - INFO - TRAINING - Epoch: [197][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0383 (0.0473)	Prec@1 98.000 (98.373)	Prec@5 100.000 (100.000)
2019-04-10 18:11:31 - INFO - TRAINING - Epoch: [197][100/450]	Time 0.056 (0.056)	Data 0.014 (0.014)	Loss 0.0890 (0.0462)	Prec@1 97.000 (98.406)	Prec@5 100.000 (100.000)
2019-04-10 18:11:34 - INFO - TRAINING - Epoch: [197][150/450]	Time 0.057 (0.057)	Data 0.014 (0.014)	Loss 0.0292 (0.0453)	Prec@1 98.000 (98.430)	Prec@5 100.000 (100.000)
2019-04-10 18:11:37 - INFO - TRAINING - Epoch: [197][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0388 (0.0464)	Prec@1 99.000 (98.383)	Prec@5 100.000 (100.000)
2019-04-10 18:11:40 - INFO - TRAINING - Epoch: [197][250/450]	Time 0.058 (0.057)	Data 0.012 (0.014)	Loss 0.0321 (0.0468)	Prec@1 100.000 (98.394)	Prec@5 100.000 (100.000)
2019-04-10 18:11:43 - INFO - TRAINING - Epoch: [197][300/450]	Time 0.057 (0.057)	Data 0.013 (0.014)	Loss 0.0150 (0.0456)	Prec@1 100.000 (98.422)	Prec@5 100.000 (100.000)
2019-04-10 18:11:45 - INFO - TRAINING - Epoch: [197][350/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.0159 (0.0460)	Prec@1 100.000 (98.442)	Prec@5 100.000 (100.000)
2019-04-10 18:11:48 - INFO - TRAINING - Epoch: [197][400/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0645 (0.0456)	Prec@1 98.000 (98.436)	Prec@5 100.000 (100.000)
2019-04-10 18:11:51 - INFO - EVALUATING - Epoch: [197][0/50]	Time 0.040 (0.040)	Data 0.013 (0.013)	Loss 0.1454 (0.1454)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:52 - INFO - EVALUATING - Epoch: [197][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.4215 (0.4215)	Prec@1 90.000 (90.000)	Prec@5 99.000 (99.000)
2019-04-10 18:11:53 - INFO - EVALUATING - Epoch: [197][50/100]	Time 0.018 (0.019)	Data 0.010 (0.010)	Loss 0.1959 (0.3938)	Prec@1 93.000 (90.000)	Prec@5 100.000 (99.588)
2019-04-10 18:11:54 - INFO - 
 Epoch: 198	Training Loss 0.0461 	Training Prec@1 98.424 	Training Prec@5 99.998 	Validation Loss 0.3749 	Validation Prec@1 90.580 	Validation Prec@5 99.600 	Test Loss 0.3806 	Test Prec@1  90.270 	Test Prec@5  99.610 

2019-04-10 18:11:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:11:54 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:11:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:11:54 - INFO - TRAINING - Epoch: [198][0/450]	Time 0.034 (0.034)	Data 0.013 (0.013)	Loss 0.0130 (0.0130)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
2019-04-10 18:11:57 - INFO - TRAINING - Epoch: [198][50/450]	Time 0.057 (0.056)	Data 0.014 (0.014)	Loss 0.0937 (0.0454)	Prec@1 98.000 (98.510)	Prec@5 100.000 (100.000)
2019-04-10 18:12:00 - INFO - TRAINING - Epoch: [198][100/450]	Time 0.056 (0.057)	Data 0.014 (0.014)	Loss 0.0048 (0.0425)	Prec@1 100.000 (98.653)	Prec@5 100.000 (100.000)
2019-04-10 18:12:03 - INFO - TRAINING - Epoch: [198][150/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.0283 (0.0430)	Prec@1 100.000 (98.596)	Prec@5 100.000 (100.000)
2019-04-10 18:12:05 - INFO - TRAINING - Epoch: [198][200/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0493 (0.0438)	Prec@1 98.000 (98.582)	Prec@5 100.000 (100.000)
2019-04-10 18:12:08 - INFO - TRAINING - Epoch: [198][250/450]	Time 0.055 (0.057)	Data 0.013 (0.014)	Loss 0.0554 (0.0430)	Prec@1 99.000 (98.598)	Prec@5 100.000 (100.000)
2019-04-10 18:12:11 - INFO - TRAINING - Epoch: [198][300/450]	Time 0.057 (0.057)	Data 0.012 (0.014)	Loss 0.0188 (0.0440)	Prec@1 99.000 (98.538)	Prec@5 100.000 (99.997)
2019-04-10 18:12:14 - INFO - TRAINING - Epoch: [198][350/450]	Time 0.056 (0.057)	Data 0.013 (0.014)	Loss 0.0791 (0.0450)	Prec@1 97.000 (98.504)	Prec@5 100.000 (99.997)
2019-04-10 18:12:17 - INFO - TRAINING - Epoch: [198][400/450]	Time 0.058 (0.057)	Data 0.014 (0.014)	Loss 0.0211 (0.0452)	Prec@1 100.000 (98.486)	Prec@5 100.000 (99.998)
2019-04-10 18:12:20 - INFO - EVALUATING - Epoch: [198][0/50]	Time 0.043 (0.043)	Data 0.012 (0.012)	Loss 0.3720 (0.3720)	Prec@1 93.000 (93.000)	Prec@5 100.000 (100.000)
2019-04-10 18:12:21 - INFO - EVALUATING - Epoch: [198][0/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.3208 (0.3208)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:12:21 - INFO - EVALUATING - Epoch: [198][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1506 (0.3814)	Prec@1 94.000 (89.843)	Prec@5 100.000 (99.529)
2019-04-10 18:12:22 - INFO - 
 Epoch: 199	Training Loss 0.0450 	Training Prec@1 98.480 	Training Prec@5 99.998 	Validation Loss 0.3701 	Validation Prec@1 91.060 	Validation Prec@5 99.640 	Test Loss 0.3816 	Test Prec@1  90.080 	Test Prec@5  99.580 

2019-04-10 18:12:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-04-10 18:12:23 - DEBUG - OPTIMIZER - setting lr = 0.03
2019-04-10 18:12:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-04-10 18:12:23 - INFO - TRAINING - Epoch: [199][0/450]	Time 0.031 (0.031)	Data 0.013 (0.013)	Loss 0.0595 (0.0595)	Prec@1 98.000 (98.000)	Prec@5 100.000 (100.000)
2019-04-10 18:12:25 - INFO - TRAINING - Epoch: [199][50/450]	Time 0.055 (0.054)	Data 0.016 (0.014)	Loss 0.0075 (0.0522)	Prec@1 100.000 (98.235)	Prec@5 100.000 (100.000)
2019-04-10 18:12:28 - INFO - TRAINING - Epoch: [199][100/450]	Time 0.055 (0.054)	Data 0.013 (0.015)	Loss 0.0898 (0.0479)	Prec@1 96.000 (98.446)	Prec@5 100.000 (100.000)
2019-04-10 18:12:31 - INFO - TRAINING - Epoch: [199][150/450]	Time 0.050 (0.054)	Data 0.015 (0.015)	Loss 0.0401 (0.0469)	Prec@1 97.000 (98.457)	Prec@5 100.000 (100.000)
2019-04-10 18:12:33 - INFO - TRAINING - Epoch: [199][200/450]	Time 0.055 (0.054)	Data 0.012 (0.015)	Loss 0.0108 (0.0448)	Prec@1 100.000 (98.542)	Prec@5 100.000 (99.995)
2019-04-10 18:12:36 - INFO - TRAINING - Epoch: [199][250/450]	Time 0.055 (0.054)	Data 0.014 (0.015)	Loss 0.0245 (0.0466)	Prec@1 99.000 (98.462)	Prec@5 100.000 (99.996)
2019-04-10 18:12:39 - INFO - TRAINING - Epoch: [199][300/450]	Time 0.053 (0.054)	Data 0.014 (0.015)	Loss 0.0165 (0.0474)	Prec@1 100.000 (98.419)	Prec@5 100.000 (99.997)
2019-04-10 18:12:42 - INFO - TRAINING - Epoch: [199][350/450]	Time 0.054 (0.054)	Data 0.013 (0.015)	Loss 0.0210 (0.0483)	Prec@1 100.000 (98.393)	Prec@5 100.000 (99.997)
2019-04-10 18:12:44 - INFO - TRAINING - Epoch: [199][400/450]	Time 0.054 (0.054)	Data 0.012 (0.014)	Loss 0.0321 (0.0485)	Prec@1 98.000 (98.387)	Prec@5 100.000 (99.998)
2019-04-10 18:12:47 - INFO - EVALUATING - Epoch: [199][0/50]	Time 0.041 (0.041)	Data 0.010 (0.010)	Loss 0.4365 (0.4365)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-04-10 18:12:48 - INFO - EVALUATING - Epoch: [199][0/100]	Time 0.017 (0.017)	Data 0.010 (0.010)	Loss 0.3077 (0.3077)	Prec@1 92.000 (92.000)	Prec@5 99.000 (99.000)
2019-04-10 18:12:49 - INFO - EVALUATING - Epoch: [199][50/100]	Time 0.018 (0.018)	Data 0.010 (0.010)	Loss 0.1441 (0.3968)	Prec@1 96.000 (90.020)	Prec@5 100.000 (99.510)
2019-04-10 18:12:50 - INFO - 
 Epoch: 200	Training Loss 0.0474 	Training Prec@1 98.422 	Training Prec@5 99.998 	Validation Loss 0.3631 	Validation Prec@1 90.760 	Validation Prec@5 99.700 	Test Loss 0.3894 	Test Prec@1  90.080 	Test Prec@5  99.600 

2019-04-10 18:12:50 - DEBUG - update_title_pos
2019-04-10 18:12:50 - DEBUG - findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/pami/anaconda3/envs/spacex/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2019-04-10 18:12:50 - DEBUG - update_title_pos
2019-04-10 18:12:50 - DEBUG - update_title_pos
2019-04-10 18:12:50 - DEBUG - update_title_pos
