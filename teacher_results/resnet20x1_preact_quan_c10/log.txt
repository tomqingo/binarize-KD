2019-05-03 16:27:35 - INFO - saving to ./results/teacher_results/2019-05-03_16-27-35
2019-05-03 16:27:35 - DEBUG - run arguments: Namespace(batch_size=100, dataset='cifar10', depth=20, epochs=200, evaluate=None, gpus='0', inflate=1, input_size=None, lr=0.02, model='resnet_preact_quan_test', model_config='', momentum=0.9, optimizer='SGD', print_freq=50, results_dir='./results/teacher_results', resume='', save='2019-05-03_16-27-35', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0, workers=4)
2019-05-03 16:27:35 - INFO - creating model resnet_preact_quan_test
2019-05-03 16:27:35 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10', 'inflate': 1, 'depth': 20, 'lr': 0.02, 'wd': 0}
2019-05-03 16:27:35 - INFO - number of parameters: 272612
2019-05-03 16:27:39 - INFO - training regime: {0: {'optimizer': 'Adam', 'weight_decay': 0, 'lr': 0.02}}
2019-05-03 16:27:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:27:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:27:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:27:39 - INFO - TRAINING - Epoch: [0][0/500]	Time 0.469 (0.469)	Data 0.297 (0.297)	Loss 2.3657 (2.3657)	Prec@1 11.000 (11.000)	Prec@5 54.000 (54.000)
2019-05-03 16:27:40 - INFO - TRAINING - Epoch: [0][50/500]	Time 0.027 (0.029)	Data 0.000 (0.006)	Loss 2.2102 (2.2661)	Prec@1 22.000 (16.039)	Prec@5 63.000 (61.686)
2019-05-03 16:27:41 - INFO - TRAINING - Epoch: [0][100/500]	Time 0.019 (0.025)	Data 0.000 (0.003)	Loss 2.0924 (2.2128)	Prec@1 25.000 (17.822)	Prec@5 72.000 (66.050)
2019-05-03 16:27:42 - INFO - TRAINING - Epoch: [0][150/500]	Time 0.015 (0.023)	Data 0.000 (0.002)	Loss 2.0450 (2.1736)	Prec@1 33.000 (19.636)	Prec@5 74.000 (69.238)
2019-05-03 16:27:43 - INFO - TRAINING - Epoch: [0][200/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 2.0334 (2.1434)	Prec@1 21.000 (20.935)	Prec@5 78.000 (71.587)
2019-05-03 16:27:44 - INFO - TRAINING - Epoch: [0][250/500]	Time 0.030 (0.022)	Data 0.000 (0.001)	Loss 2.1009 (2.1208)	Prec@1 23.000 (21.865)	Prec@5 75.000 (73.339)
2019-05-03 16:27:45 - INFO - TRAINING - Epoch: [0][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 2.1275 (2.1022)	Prec@1 24.000 (22.512)	Prec@5 77.000 (74.548)
2019-05-03 16:27:46 - INFO - TRAINING - Epoch: [0][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.9557 (2.0853)	Prec@1 29.000 (23.194)	Prec@5 85.000 (75.621)
2019-05-03 16:27:47 - INFO - TRAINING - Epoch: [0][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 1.9558 (2.0686)	Prec@1 27.000 (23.843)	Prec@5 82.000 (76.499)
2019-05-03 16:27:48 - INFO - TRAINING - Epoch: [0][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 1.8063 (2.0534)	Prec@1 35.000 (24.390)	Prec@5 91.000 (77.279)
2019-05-03 16:27:49 - INFO - EVALUATING - Epoch: [0][0/100]	Time 0.314 (0.314)	Data 0.305 (0.305)	Loss 1.8325 (1.8325)	Prec@1 40.000 (40.000)	Prec@5 86.000 (86.000)
2019-05-03 16:27:50 - INFO - EVALUATING - Epoch: [0][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.8633 (1.8764)	Prec@1 34.000 (30.961)	Prec@5 88.000 (85.765)
2019-05-03 16:27:50 - INFO - 
 Epoch: 1	Training Loss 2.0372 	Training Prec@1 24.992 	Training Prec@5 78.088 	Validation Loss 1.8740 	Validation Prec@1 30.820 	Validation Prec@5 86.000 	
2019-05-03 16:27:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:27:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:27:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:27:50 - INFO - TRAINING - Epoch: [1][0/500]	Time 0.265 (0.265)	Data 0.240 (0.240)	Loss 1.8731 (1.8731)	Prec@1 32.000 (32.000)	Prec@5 84.000 (84.000)
2019-05-03 16:27:51 - INFO - TRAINING - Epoch: [1][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 1.8787 (1.8859)	Prec@1 25.000 (30.392)	Prec@5 90.000 (84.471)
2019-05-03 16:27:52 - INFO - TRAINING - Epoch: [1][100/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 1.8763 (1.8707)	Prec@1 33.000 (30.673)	Prec@5 86.000 (84.950)
2019-05-03 16:27:53 - INFO - TRAINING - Epoch: [1][150/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 1.8155 (1.8483)	Prec@1 31.000 (31.205)	Prec@5 87.000 (85.722)
2019-05-03 16:27:54 - INFO - TRAINING - Epoch: [1][200/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 1.8194 (1.8333)	Prec@1 37.000 (31.692)	Prec@5 87.000 (86.060)
2019-05-03 16:27:55 - INFO - TRAINING - Epoch: [1][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.7689 (1.8163)	Prec@1 37.000 (32.546)	Prec@5 89.000 (86.315)
2019-05-03 16:27:56 - INFO - TRAINING - Epoch: [1][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.8252 (1.8015)	Prec@1 37.000 (33.173)	Prec@5 87.000 (86.748)
2019-05-03 16:27:57 - INFO - TRAINING - Epoch: [1][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 1.7964 (1.7890)	Prec@1 30.000 (33.755)	Prec@5 87.000 (86.966)
2019-05-03 16:27:58 - INFO - TRAINING - Epoch: [1][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 1.4971 (1.7794)	Prec@1 46.000 (34.185)	Prec@5 92.000 (87.214)
2019-05-03 16:27:59 - INFO - TRAINING - Epoch: [1][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 1.8287 (1.7728)	Prec@1 31.000 (34.435)	Prec@5 84.000 (87.304)
2019-05-03 16:28:01 - INFO - EVALUATING - Epoch: [1][0/100]	Time 0.341 (0.341)	Data 0.328 (0.328)	Loss 1.5991 (1.5991)	Prec@1 44.000 (44.000)	Prec@5 90.000 (90.000)
2019-05-03 16:28:01 - INFO - EVALUATING - Epoch: [1][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.7144 (1.6661)	Prec@1 36.000 (39.275)	Prec@5 87.000 (89.863)
2019-05-03 16:28:01 - INFO - 
 Epoch: 2	Training Loss 1.7655 	Training Prec@1 34.754 	Training Prec@5 87.420 	Validation Loss 1.6619 	Validation Prec@1 38.830 	Validation Prec@5 89.730 	
2019-05-03 16:28:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:01 - INFO - TRAINING - Epoch: [2][0/500]	Time 0.374 (0.374)	Data 0.344 (0.344)	Loss 1.7304 (1.7304)	Prec@1 36.000 (36.000)	Prec@5 87.000 (87.000)
2019-05-03 16:28:02 - INFO - TRAINING - Epoch: [2][50/500]	Time 0.025 (0.026)	Data 0.000 (0.007)	Loss 1.7304 (1.7032)	Prec@1 45.000 (37.490)	Prec@5 85.000 (88.314)
2019-05-03 16:28:03 - INFO - TRAINING - Epoch: [2][100/500]	Time 0.017 (0.023)	Data 0.000 (0.004)	Loss 1.6814 (1.6774)	Prec@1 41.000 (38.515)	Prec@5 88.000 (88.871)
2019-05-03 16:28:04 - INFO - TRAINING - Epoch: [2][150/500]	Time 0.012 (0.021)	Data 0.000 (0.002)	Loss 1.6791 (1.6739)	Prec@1 37.000 (38.477)	Prec@5 89.000 (88.967)
2019-05-03 16:28:05 - INFO - TRAINING - Epoch: [2][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.6732 (1.6714)	Prec@1 36.000 (38.448)	Prec@5 90.000 (88.970)
2019-05-03 16:28:06 - INFO - TRAINING - Epoch: [2][250/500]	Time 0.027 (0.021)	Data 0.000 (0.002)	Loss 1.7169 (1.6632)	Prec@1 41.000 (38.916)	Prec@5 88.000 (89.104)
2019-05-03 16:28:07 - INFO - TRAINING - Epoch: [2][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 1.5768 (1.6575)	Prec@1 51.000 (39.299)	Prec@5 89.000 (89.106)
2019-05-03 16:28:08 - INFO - TRAINING - Epoch: [2][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.6908 (1.6524)	Prec@1 39.000 (39.550)	Prec@5 86.000 (89.251)
2019-05-03 16:28:09 - INFO - TRAINING - Epoch: [2][400/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 1.6330 (1.6437)	Prec@1 35.000 (39.875)	Prec@5 88.000 (89.424)
2019-05-03 16:28:10 - INFO - TRAINING - Epoch: [2][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.5597 (1.6364)	Prec@1 45.000 (40.153)	Prec@5 89.000 (89.583)
2019-05-03 16:28:12 - INFO - EVALUATING - Epoch: [2][0/100]	Time 0.321 (0.321)	Data 0.314 (0.314)	Loss 1.4884 (1.4884)	Prec@1 52.000 (52.000)	Prec@5 91.000 (91.000)
2019-05-03 16:28:12 - INFO - EVALUATING - Epoch: [2][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 1.4917 (1.5515)	Prec@1 45.000 (43.353)	Prec@5 92.000 (91.471)
2019-05-03 16:28:12 - INFO - 
 Epoch: 3	Training Loss 1.6310 	Training Prec@1 40.372 	Training Prec@5 89.670 	Validation Loss 1.5499 	Validation Prec@1 43.620 	Validation Prec@5 91.530 	
2019-05-03 16:28:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:13 - INFO - TRAINING - Epoch: [3][0/500]	Time 0.379 (0.379)	Data 0.352 (0.352)	Loss 1.3778 (1.3778)	Prec@1 47.000 (47.000)	Prec@5 95.000 (95.000)
2019-05-03 16:28:14 - INFO - TRAINING - Epoch: [3][50/500]	Time 0.014 (0.026)	Data 0.000 (0.007)	Loss 1.6157 (1.5915)	Prec@1 40.000 (41.510)	Prec@5 90.000 (90.451)
2019-05-03 16:28:15 - INFO - TRAINING - Epoch: [3][100/500]	Time 0.022 (0.023)	Data 0.000 (0.004)	Loss 1.6659 (1.5898)	Prec@1 38.000 (41.634)	Prec@5 90.000 (90.604)
2019-05-03 16:28:15 - INFO - TRAINING - Epoch: [3][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 1.4892 (1.5823)	Prec@1 44.000 (42.490)	Prec@5 95.000 (90.536)
2019-05-03 16:28:17 - INFO - TRAINING - Epoch: [3][200/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 1.4822 (1.5739)	Prec@1 48.000 (42.746)	Prec@5 91.000 (90.731)
2019-05-03 16:28:18 - INFO - TRAINING - Epoch: [3][250/500]	Time 0.027 (0.021)	Data 0.000 (0.002)	Loss 1.6014 (1.5686)	Prec@1 44.000 (42.793)	Prec@5 90.000 (90.936)
2019-05-03 16:28:19 - INFO - TRAINING - Epoch: [3][300/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 1.5013 (1.5619)	Prec@1 44.000 (42.970)	Prec@5 91.000 (90.963)
2019-05-03 16:28:20 - INFO - TRAINING - Epoch: [3][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 1.5477 (1.5563)	Prec@1 38.000 (43.199)	Prec@5 87.000 (90.994)
2019-05-03 16:28:21 - INFO - TRAINING - Epoch: [3][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.2931 (1.5534)	Prec@1 56.000 (43.272)	Prec@5 95.000 (91.000)
2019-05-03 16:28:22 - INFO - TRAINING - Epoch: [3][450/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.4633 (1.5484)	Prec@1 45.000 (43.497)	Prec@5 93.000 (91.053)
2019-05-03 16:28:23 - INFO - EVALUATING - Epoch: [3][0/100]	Time 0.245 (0.245)	Data 0.236 (0.236)	Loss 1.4349 (1.4349)	Prec@1 50.000 (50.000)	Prec@5 92.000 (92.000)
2019-05-03 16:28:23 - INFO - EVALUATING - Epoch: [3][50/100]	Time 0.005 (0.010)	Data 0.000 (0.005)	Loss 1.5493 (1.5399)	Prec@1 44.000 (44.843)	Prec@5 90.000 (91.353)
2019-05-03 16:28:24 - INFO - 
 Epoch: 4	Training Loss 1.5454 	Training Prec@1 43.646 	Training Prec@5 91.050 	Validation Loss 1.5421 	Validation Prec@1 43.910 	Validation Prec@5 91.190 	
2019-05-03 16:28:24 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:24 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:24 - INFO - TRAINING - Epoch: [4][0/500]	Time 0.358 (0.358)	Data 0.339 (0.339)	Loss 1.5325 (1.5325)	Prec@1 38.000 (38.000)	Prec@5 96.000 (96.000)
2019-05-03 16:28:25 - INFO - TRAINING - Epoch: [4][50/500]	Time 0.014 (0.026)	Data 0.000 (0.007)	Loss 1.3714 (1.5177)	Prec@1 55.000 (44.824)	Prec@5 97.000 (91.235)
2019-05-03 16:28:26 - INFO - TRAINING - Epoch: [4][100/500]	Time 0.030 (0.023)	Data 0.000 (0.003)	Loss 1.3824 (1.5051)	Prec@1 50.000 (45.287)	Prec@5 95.000 (91.505)
2019-05-03 16:28:27 - INFO - TRAINING - Epoch: [4][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.3805 (1.4968)	Prec@1 57.000 (45.894)	Prec@5 91.000 (91.490)
2019-05-03 16:28:28 - INFO - TRAINING - Epoch: [4][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 1.4437 (1.4895)	Prec@1 53.000 (46.254)	Prec@5 89.000 (91.756)
2019-05-03 16:28:29 - INFO - TRAINING - Epoch: [4][250/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 1.3966 (1.4829)	Prec@1 51.000 (46.390)	Prec@5 94.000 (91.908)
2019-05-03 16:28:30 - INFO - TRAINING - Epoch: [4][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 1.5791 (1.4817)	Prec@1 50.000 (46.402)	Prec@5 92.000 (91.910)
2019-05-03 16:28:31 - INFO - TRAINING - Epoch: [4][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.4590 (1.4741)	Prec@1 50.000 (46.672)	Prec@5 91.000 (92.034)
2019-05-03 16:28:32 - INFO - TRAINING - Epoch: [4][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.2004 (1.4650)	Prec@1 58.000 (46.965)	Prec@5 96.000 (92.185)
2019-05-03 16:28:33 - INFO - TRAINING - Epoch: [4][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 1.4618 (1.4615)	Prec@1 43.000 (47.084)	Prec@5 94.000 (92.286)
2019-05-03 16:28:34 - INFO - EVALUATING - Epoch: [4][0/100]	Time 0.332 (0.332)	Data 0.323 (0.323)	Loss 1.4177 (1.4177)	Prec@1 47.000 (47.000)	Prec@5 92.000 (92.000)
2019-05-03 16:28:34 - INFO - EVALUATING - Epoch: [4][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 1.4937 (1.4510)	Prec@1 50.000 (47.765)	Prec@5 90.000 (93.020)
2019-05-03 16:28:35 - INFO - 
 Epoch: 5	Training Loss 1.4574 	Training Prec@1 47.318 	Training Prec@5 92.392 	Validation Loss 1.4393 	Validation Prec@1 47.850 	Validation Prec@5 93.350 	
2019-05-03 16:28:35 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:35 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:35 - INFO - TRAINING - Epoch: [5][0/500]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 1.5178 (1.5178)	Prec@1 49.000 (49.000)	Prec@5 89.000 (89.000)
2019-05-03 16:28:36 - INFO - TRAINING - Epoch: [5][50/500]	Time 0.022 (0.026)	Data 0.000 (0.006)	Loss 1.3643 (1.4485)	Prec@1 52.000 (48.706)	Prec@5 90.000 (91.980)
2019-05-03 16:28:37 - INFO - TRAINING - Epoch: [5][100/500]	Time 0.022 (0.023)	Data 0.000 (0.003)	Loss 1.5602 (1.4475)	Prec@1 48.000 (48.396)	Prec@5 91.000 (92.267)
2019-05-03 16:28:38 - INFO - TRAINING - Epoch: [5][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 1.2976 (1.4325)	Prec@1 52.000 (48.735)	Prec@5 93.000 (92.662)
2019-05-03 16:28:39 - INFO - TRAINING - Epoch: [5][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.3672 (1.4192)	Prec@1 51.000 (49.184)	Prec@5 91.000 (92.866)
2019-05-03 16:28:40 - INFO - TRAINING - Epoch: [5][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.4016 (1.4097)	Prec@1 54.000 (49.474)	Prec@5 92.000 (92.988)
2019-05-03 16:28:41 - INFO - TRAINING - Epoch: [5][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.5785 (1.4079)	Prec@1 40.000 (49.591)	Prec@5 88.000 (92.980)
2019-05-03 16:28:42 - INFO - TRAINING - Epoch: [5][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.5174 (1.3980)	Prec@1 53.000 (49.966)	Prec@5 95.000 (93.154)
2019-05-03 16:28:43 - INFO - TRAINING - Epoch: [5][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0784 (1.3964)	Prec@1 65.000 (49.958)	Prec@5 98.000 (93.162)
2019-05-03 16:28:44 - INFO - TRAINING - Epoch: [5][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.3616 (1.3893)	Prec@1 54.000 (50.197)	Prec@5 95.000 (93.310)
2019-05-03 16:28:45 - INFO - EVALUATING - Epoch: [5][0/100]	Time 0.345 (0.345)	Data 0.335 (0.335)	Loss 1.3113 (1.3113)	Prec@1 51.000 (51.000)	Prec@5 95.000 (95.000)
2019-05-03 16:28:46 - INFO - EVALUATING - Epoch: [5][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 1.3026 (1.3407)	Prec@1 54.000 (52.216)	Prec@5 92.000 (94.255)
2019-05-03 16:28:46 - INFO - 
 Epoch: 6	Training Loss 1.3854 	Training Prec@1 50.408 	Training Prec@5 93.340 	Validation Loss 1.3545 	Validation Prec@1 51.730 	Validation Prec@5 93.980 	
2019-05-03 16:28:46 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:46 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:46 - INFO - TRAINING - Epoch: [6][0/500]	Time 0.371 (0.371)	Data 0.346 (0.346)	Loss 1.3541 (1.3541)	Prec@1 50.000 (50.000)	Prec@5 93.000 (93.000)
2019-05-03 16:28:47 - INFO - TRAINING - Epoch: [6][50/500]	Time 0.023 (0.026)	Data 0.000 (0.007)	Loss 1.5249 (1.3460)	Prec@1 39.000 (52.255)	Prec@5 95.000 (93.765)
2019-05-03 16:28:48 - INFO - TRAINING - Epoch: [6][100/500]	Time 0.024 (0.022)	Data 0.000 (0.004)	Loss 1.2655 (1.3519)	Prec@1 51.000 (51.693)	Prec@5 97.000 (93.693)
2019-05-03 16:28:49 - INFO - TRAINING - Epoch: [6][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 1.4459 (1.3474)	Prec@1 49.000 (51.848)	Prec@5 92.000 (93.722)
2019-05-03 16:28:50 - INFO - TRAINING - Epoch: [6][200/500]	Time 0.026 (0.021)	Data 0.000 (0.002)	Loss 1.3933 (1.3462)	Prec@1 57.000 (51.866)	Prec@5 92.000 (93.920)
2019-05-03 16:28:51 - INFO - TRAINING - Epoch: [6][250/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 1.3605 (1.3422)	Prec@1 51.000 (52.048)	Prec@5 94.000 (93.888)
2019-05-03 16:28:52 - INFO - TRAINING - Epoch: [6][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 1.2187 (1.3388)	Prec@1 57.000 (52.156)	Prec@5 96.000 (93.940)
2019-05-03 16:28:53 - INFO - TRAINING - Epoch: [6][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.5272 (1.3366)	Prec@1 47.000 (52.231)	Prec@5 93.000 (93.897)
2019-05-03 16:28:54 - INFO - TRAINING - Epoch: [6][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 1.3278 (1.3309)	Prec@1 59.000 (52.511)	Prec@5 95.000 (93.958)
2019-05-03 16:28:55 - INFO - TRAINING - Epoch: [6][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 1.0442 (1.3250)	Prec@1 66.000 (52.774)	Prec@5 96.000 (93.993)
2019-05-03 16:28:56 - INFO - EVALUATING - Epoch: [6][0/100]	Time 0.328 (0.328)	Data 0.318 (0.318)	Loss 1.3399 (1.3399)	Prec@1 54.000 (54.000)	Prec@5 91.000 (91.000)
2019-05-03 16:28:57 - INFO - EVALUATING - Epoch: [6][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.4637 (1.3071)	Prec@1 51.000 (54.333)	Prec@5 92.000 (94.804)
2019-05-03 16:28:57 - INFO - 
 Epoch: 7	Training Loss 1.3187 	Training Prec@1 53.118 	Training Prec@5 94.056 	Validation Loss 1.3085 	Validation Prec@1 53.780 	Validation Prec@5 94.650 	
2019-05-03 16:28:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:28:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:28:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:28:57 - INFO - TRAINING - Epoch: [7][0/500]	Time 0.348 (0.348)	Data 0.321 (0.321)	Loss 1.3133 (1.3133)	Prec@1 44.000 (44.000)	Prec@5 94.000 (94.000)
2019-05-03 16:28:58 - INFO - TRAINING - Epoch: [7][50/500]	Time 0.017 (0.025)	Data 0.000 (0.006)	Loss 1.2942 (1.3146)	Prec@1 55.000 (53.020)	Prec@5 95.000 (94.098)
2019-05-03 16:28:59 - INFO - TRAINING - Epoch: [7][100/500]	Time 0.028 (0.022)	Data 0.000 (0.003)	Loss 1.1002 (1.2838)	Prec@1 59.000 (54.426)	Prec@5 95.000 (94.356)
2019-05-03 16:29:00 - INFO - TRAINING - Epoch: [7][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 1.4209 (1.2943)	Prec@1 49.000 (54.026)	Prec@5 94.000 (94.185)
2019-05-03 16:29:01 - INFO - TRAINING - Epoch: [7][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 1.1877 (1.2919)	Prec@1 58.000 (54.438)	Prec@5 97.000 (94.189)
2019-05-03 16:29:02 - INFO - TRAINING - Epoch: [7][250/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 1.1873 (1.2837)	Prec@1 55.000 (54.681)	Prec@5 94.000 (94.303)
2019-05-03 16:29:03 - INFO - TRAINING - Epoch: [7][300/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.2965 (1.2778)	Prec@1 57.000 (54.834)	Prec@5 89.000 (94.399)
2019-05-03 16:29:04 - INFO - TRAINING - Epoch: [7][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.2668 (1.2730)	Prec@1 51.000 (55.088)	Prec@5 95.000 (94.387)
2019-05-03 16:29:05 - INFO - TRAINING - Epoch: [7][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 1.2763 (1.2664)	Prec@1 51.000 (55.357)	Prec@5 93.000 (94.424)
2019-05-03 16:29:06 - INFO - TRAINING - Epoch: [7][450/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 1.2963 (1.2631)	Prec@1 52.000 (55.408)	Prec@5 95.000 (94.488)
2019-05-03 16:29:08 - INFO - EVALUATING - Epoch: [7][0/100]	Time 0.346 (0.346)	Data 0.332 (0.332)	Loss 1.2830 (1.2830)	Prec@1 59.000 (59.000)	Prec@5 93.000 (93.000)
2019-05-03 16:29:08 - INFO - EVALUATING - Epoch: [7][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.3210 (1.3416)	Prec@1 52.000 (52.627)	Prec@5 93.000 (93.725)
2019-05-03 16:29:08 - INFO - 
 Epoch: 8	Training Loss 1.2555 	Training Prec@1 55.630 	Training Prec@5 94.544 	Validation Loss 1.3459 	Validation Prec@1 52.620 	Validation Prec@5 93.540 	
2019-05-03 16:29:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:29:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:29:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:29:09 - INFO - TRAINING - Epoch: [8][0/500]	Time 0.334 (0.334)	Data 0.313 (0.313)	Loss 1.2884 (1.2884)	Prec@1 55.000 (55.000)	Prec@5 97.000 (97.000)
2019-05-03 16:29:10 - INFO - TRAINING - Epoch: [8][50/500]	Time 0.016 (0.026)	Data 0.000 (0.006)	Loss 1.2541 (1.2582)	Prec@1 58.000 (55.353)	Prec@5 93.000 (94.529)
2019-05-03 16:29:11 - INFO - TRAINING - Epoch: [8][100/500]	Time 0.015 (0.023)	Data 0.000 (0.003)	Loss 1.3221 (1.2460)	Prec@1 59.000 (55.713)	Prec@5 94.000 (94.584)
2019-05-03 16:29:12 - INFO - TRAINING - Epoch: [8][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 1.0717 (1.2454)	Prec@1 59.000 (55.649)	Prec@5 98.000 (94.556)
2019-05-03 16:29:13 - INFO - TRAINING - Epoch: [8][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.1689 (1.2341)	Prec@1 61.000 (56.234)	Prec@5 93.000 (94.697)
2019-05-03 16:29:13 - INFO - TRAINING - Epoch: [8][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.0146 (1.2265)	Prec@1 65.000 (56.637)	Prec@5 98.000 (94.689)
2019-05-03 16:29:15 - INFO - TRAINING - Epoch: [8][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.9974 (1.2211)	Prec@1 66.000 (56.880)	Prec@5 98.000 (94.728)
2019-05-03 16:29:16 - INFO - TRAINING - Epoch: [8][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.1685 (1.2183)	Prec@1 63.000 (56.991)	Prec@5 93.000 (94.721)
2019-05-03 16:29:17 - INFO - TRAINING - Epoch: [8][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.4092 (1.2130)	Prec@1 50.000 (57.202)	Prec@5 93.000 (94.798)
2019-05-03 16:29:17 - INFO - TRAINING - Epoch: [8][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.2207 (1.2075)	Prec@1 58.000 (57.463)	Prec@5 92.000 (94.898)
2019-05-03 16:29:19 - INFO - EVALUATING - Epoch: [8][0/100]	Time 0.342 (0.342)	Data 0.333 (0.333)	Loss 1.1600 (1.1600)	Prec@1 61.000 (61.000)	Prec@5 95.000 (95.000)
2019-05-03 16:29:19 - INFO - EVALUATING - Epoch: [8][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.2565 (1.2578)	Prec@1 51.000 (54.608)	Prec@5 96.000 (94.706)
2019-05-03 16:29:19 - INFO - 
 Epoch: 9	Training Loss 1.2038 	Training Prec@1 57.532 	Training Prec@5 94.960 	Validation Loss 1.2674 	Validation Prec@1 54.800 	Validation Prec@5 94.670 	
2019-05-03 16:29:19 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:29:19 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:29:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:29:20 - INFO - TRAINING - Epoch: [9][0/500]	Time 0.348 (0.348)	Data 0.321 (0.321)	Loss 1.1408 (1.1408)	Prec@1 55.000 (55.000)	Prec@5 99.000 (99.000)
2019-05-03 16:29:21 - INFO - TRAINING - Epoch: [9][50/500]	Time 0.014 (0.026)	Data 0.000 (0.006)	Loss 1.1320 (1.1661)	Prec@1 61.000 (58.353)	Prec@5 96.000 (95.569)
2019-05-03 16:29:22 - INFO - TRAINING - Epoch: [9][100/500]	Time 0.015 (0.024)	Data 0.000 (0.003)	Loss 1.0999 (1.1771)	Prec@1 63.000 (58.208)	Prec@5 98.000 (95.604)
2019-05-03 16:29:23 - INFO - TRAINING - Epoch: [9][150/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 1.1203 (1.1707)	Prec@1 62.000 (58.642)	Prec@5 95.000 (95.503)
2019-05-03 16:29:24 - INFO - TRAINING - Epoch: [9][200/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 1.1740 (1.1790)	Prec@1 64.000 (58.214)	Prec@5 97.000 (95.378)
2019-05-03 16:29:25 - INFO - TRAINING - Epoch: [9][250/500]	Time 0.017 (0.022)	Data 0.000 (0.001)	Loss 1.1040 (1.1774)	Prec@1 58.000 (58.315)	Prec@5 97.000 (95.331)
2019-05-03 16:29:26 - INFO - TRAINING - Epoch: [9][300/500]	Time 0.024 (0.022)	Data 0.000 (0.001)	Loss 1.0095 (1.1723)	Prec@1 64.000 (58.535)	Prec@5 96.000 (95.372)
2019-05-03 16:29:27 - INFO - TRAINING - Epoch: [9][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 1.1492 (1.1744)	Prec@1 60.000 (58.444)	Prec@5 95.000 (95.356)
2019-05-03 16:29:28 - INFO - TRAINING - Epoch: [9][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.0107 (1.1771)	Prec@1 61.000 (58.349)	Prec@5 98.000 (95.324)
2019-05-03 16:29:29 - INFO - TRAINING - Epoch: [9][450/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 1.2104 (1.1701)	Prec@1 56.000 (58.701)	Prec@5 97.000 (95.392)
2019-05-03 16:29:30 - INFO - EVALUATING - Epoch: [9][0/100]	Time 0.324 (0.324)	Data 0.317 (0.317)	Loss 1.1810 (1.1810)	Prec@1 58.000 (58.000)	Prec@5 95.000 (95.000)
2019-05-03 16:29:30 - INFO - EVALUATING - Epoch: [9][50/100]	Time 0.007 (0.012)	Data 0.000 (0.006)	Loss 1.2841 (1.3094)	Prec@1 58.000 (53.667)	Prec@5 95.000 (94.412)
2019-05-03 16:29:31 - INFO - 
 Epoch: 10	Training Loss 1.1679 	Training Prec@1 58.830 	Training Prec@5 95.428 	Validation Loss 1.3109 	Validation Prec@1 53.410 	Validation Prec@5 94.490 	
2019-05-03 16:29:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:29:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:29:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:29:31 - INFO - TRAINING - Epoch: [10][0/500]	Time 0.366 (0.366)	Data 0.338 (0.338)	Loss 1.0480 (1.0480)	Prec@1 61.000 (61.000)	Prec@5 96.000 (96.000)
2019-05-03 16:29:32 - INFO - TRAINING - Epoch: [10][50/500]	Time 0.022 (0.026)	Data 0.000 (0.007)	Loss 1.0949 (1.1578)	Prec@1 63.000 (60.098)	Prec@5 98.000 (95.647)
2019-05-03 16:29:33 - INFO - TRAINING - Epoch: [10][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 1.2978 (1.1653)	Prec@1 50.000 (59.178)	Prec@5 98.000 (95.644)
2019-05-03 16:29:34 - INFO - TRAINING - Epoch: [10][150/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 1.4303 (1.1566)	Prec@1 49.000 (59.311)	Prec@5 93.000 (95.603)
2019-05-03 16:29:35 - INFO - TRAINING - Epoch: [10][200/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 1.0089 (1.1585)	Prec@1 62.000 (59.229)	Prec@5 98.000 (95.687)
2019-05-03 16:29:36 - INFO - TRAINING - Epoch: [10][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.1846 (1.1554)	Prec@1 58.000 (59.371)	Prec@5 95.000 (95.701)
2019-05-03 16:29:37 - INFO - TRAINING - Epoch: [10][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 1.2944 (1.1551)	Prec@1 49.000 (59.336)	Prec@5 97.000 (95.731)
2019-05-03 16:29:38 - INFO - TRAINING - Epoch: [10][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.1705 (1.1553)	Prec@1 61.000 (59.342)	Prec@5 95.000 (95.615)
2019-05-03 16:29:39 - INFO - TRAINING - Epoch: [10][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9669 (1.1517)	Prec@1 68.000 (59.444)	Prec@5 98.000 (95.613)
2019-05-03 16:29:40 - INFO - TRAINING - Epoch: [10][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 1.1108 (1.1447)	Prec@1 65.000 (59.820)	Prec@5 93.000 (95.636)
2019-05-03 16:29:41 - INFO - EVALUATING - Epoch: [10][0/100]	Time 0.338 (0.338)	Data 0.331 (0.331)	Loss 1.0998 (1.0998)	Prec@1 61.000 (61.000)	Prec@5 94.000 (94.000)
2019-05-03 16:29:41 - INFO - EVALUATING - Epoch: [10][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.9816 (1.0646)	Prec@1 71.000 (63.216)	Prec@5 97.000 (96.353)
2019-05-03 16:29:42 - INFO - 
 Epoch: 11	Training Loss 1.1428 	Training Prec@1 59.932 	Training Prec@5 95.650 	Validation Loss 1.0768 	Validation Prec@1 62.690 	Validation Prec@5 96.310 	
2019-05-03 16:29:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:29:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:29:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:29:42 - INFO - TRAINING - Epoch: [11][0/500]	Time 0.358 (0.358)	Data 0.332 (0.332)	Loss 0.9523 (0.9523)	Prec@1 66.000 (66.000)	Prec@5 96.000 (96.000)
2019-05-03 16:29:43 - INFO - TRAINING - Epoch: [11][50/500]	Time 0.012 (0.026)	Data 0.000 (0.007)	Loss 1.1088 (1.1304)	Prec@1 58.000 (60.412)	Prec@5 94.000 (95.412)
2019-05-03 16:29:44 - INFO - TRAINING - Epoch: [11][100/500]	Time 0.014 (0.023)	Data 0.000 (0.003)	Loss 1.1898 (1.1278)	Prec@1 53.000 (60.426)	Prec@5 99.000 (95.663)
2019-05-03 16:29:45 - INFO - TRAINING - Epoch: [11][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 1.3591 (1.1275)	Prec@1 59.000 (60.530)	Prec@5 90.000 (95.649)
2019-05-03 16:29:46 - INFO - TRAINING - Epoch: [11][200/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.9110 (1.1204)	Prec@1 69.000 (60.761)	Prec@5 98.000 (95.667)
2019-05-03 16:29:47 - INFO - TRAINING - Epoch: [11][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 1.1871 (1.1226)	Prec@1 60.000 (60.598)	Prec@5 95.000 (95.797)
2019-05-03 16:29:48 - INFO - TRAINING - Epoch: [11][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9822 (1.1155)	Prec@1 66.000 (61.017)	Prec@5 98.000 (95.850)
2019-05-03 16:29:49 - INFO - TRAINING - Epoch: [11][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 1.1994 (1.1122)	Prec@1 64.000 (61.046)	Prec@5 92.000 (95.900)
2019-05-03 16:29:50 - INFO - TRAINING - Epoch: [11][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 1.3899 (1.1140)	Prec@1 54.000 (60.938)	Prec@5 91.000 (95.878)
2019-05-03 16:29:51 - INFO - TRAINING - Epoch: [11][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.9278 (1.1116)	Prec@1 66.000 (61.047)	Prec@5 98.000 (95.889)
2019-05-03 16:29:52 - INFO - EVALUATING - Epoch: [11][0/100]	Time 0.369 (0.369)	Data 0.359 (0.359)	Loss 1.3505 (1.3505)	Prec@1 58.000 (58.000)	Prec@5 90.000 (90.000)
2019-05-03 16:29:53 - INFO - EVALUATING - Epoch: [11][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 1.4890 (1.3795)	Prec@1 48.000 (53.549)	Prec@5 91.000 (92.961)
2019-05-03 16:29:53 - INFO - 
 Epoch: 12	Training Loss 1.1089 	Training Prec@1 61.158 	Training Prec@5 95.892 	Validation Loss 1.3830 	Validation Prec@1 53.230 	Validation Prec@5 93.200 	
2019-05-03 16:29:53 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:29:53 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:29:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:29:53 - INFO - TRAINING - Epoch: [12][0/500]	Time 0.359 (0.359)	Data 0.330 (0.330)	Loss 1.0190 (1.0190)	Prec@1 64.000 (64.000)	Prec@5 97.000 (97.000)
2019-05-03 16:29:54 - INFO - TRAINING - Epoch: [12][50/500]	Time 0.018 (0.026)	Data 0.000 (0.007)	Loss 1.1471 (1.1296)	Prec@1 57.000 (60.471)	Prec@5 94.000 (96.078)
2019-05-03 16:29:55 - INFO - TRAINING - Epoch: [12][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 1.3423 (1.1160)	Prec@1 50.000 (60.713)	Prec@5 98.000 (96.050)
2019-05-03 16:29:56 - INFO - TRAINING - Epoch: [12][150/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 1.1825 (1.1028)	Prec@1 60.000 (61.119)	Prec@5 92.000 (96.245)
2019-05-03 16:29:57 - INFO - TRAINING - Epoch: [12][200/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 1.0261 (1.0938)	Prec@1 63.000 (61.612)	Prec@5 97.000 (96.318)
2019-05-03 16:29:58 - INFO - TRAINING - Epoch: [12][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.2228 (1.0946)	Prec@1 59.000 (61.570)	Prec@5 93.000 (96.203)
2019-05-03 16:29:59 - INFO - TRAINING - Epoch: [12][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.8813 (1.0920)	Prec@1 67.000 (61.764)	Prec@5 96.000 (96.226)
2019-05-03 16:30:00 - INFO - TRAINING - Epoch: [12][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.1726 (1.0982)	Prec@1 64.000 (61.541)	Prec@5 96.000 (96.137)
2019-05-03 16:30:01 - INFO - TRAINING - Epoch: [12][400/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.9453 (1.0957)	Prec@1 66.000 (61.668)	Prec@5 99.000 (96.147)
2019-05-03 16:30:02 - INFO - TRAINING - Epoch: [12][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 1.1208 (1.0961)	Prec@1 58.000 (61.643)	Prec@5 97.000 (96.171)
2019-05-03 16:30:03 - INFO - EVALUATING - Epoch: [12][0/100]	Time 0.273 (0.273)	Data 0.262 (0.262)	Loss 1.9840 (1.9840)	Prec@1 43.000 (43.000)	Prec@5 79.000 (79.000)
2019-05-03 16:30:04 - INFO - EVALUATING - Epoch: [12][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 2.3494 (2.0792)	Prec@1 33.000 (37.706)	Prec@5 73.000 (78.157)
2019-05-03 16:30:04 - INFO - 
 Epoch: 13	Training Loss 1.0938 	Training Prec@1 61.766 	Training Prec@5 96.164 	Validation Loss 2.0865 	Validation Prec@1 37.500 	Validation Prec@5 78.050 	
2019-05-03 16:30:04 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:04 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:04 - INFO - TRAINING - Epoch: [13][0/500]	Time 0.351 (0.351)	Data 0.331 (0.331)	Loss 1.0797 (1.0797)	Prec@1 64.000 (64.000)	Prec@5 96.000 (96.000)
2019-05-03 16:30:05 - INFO - TRAINING - Epoch: [13][50/500]	Time 0.033 (0.026)	Data 0.000 (0.007)	Loss 1.0739 (1.1146)	Prec@1 60.000 (60.353)	Prec@5 98.000 (96.510)
2019-05-03 16:30:06 - INFO - TRAINING - Epoch: [13][100/500]	Time 0.020 (0.022)	Data 0.000 (0.003)	Loss 1.1338 (1.0939)	Prec@1 62.000 (61.396)	Prec@5 98.000 (96.713)
2019-05-03 16:30:07 - INFO - TRAINING - Epoch: [13][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 1.0819 (1.0799)	Prec@1 64.000 (62.066)	Prec@5 97.000 (96.563)
2019-05-03 16:30:08 - INFO - TRAINING - Epoch: [13][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 1.1888 (1.0776)	Prec@1 59.000 (62.308)	Prec@5 97.000 (96.527)
2019-05-03 16:30:09 - INFO - TRAINING - Epoch: [13][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.0991 (1.0718)	Prec@1 67.000 (62.470)	Prec@5 95.000 (96.546)
2019-05-03 16:30:10 - INFO - TRAINING - Epoch: [13][300/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 1.1547 (1.0710)	Prec@1 61.000 (62.618)	Prec@5 96.000 (96.485)
2019-05-03 16:30:11 - INFO - TRAINING - Epoch: [13][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 1.2037 (1.0760)	Prec@1 57.000 (62.595)	Prec@5 96.000 (96.368)
2019-05-03 16:30:12 - INFO - TRAINING - Epoch: [13][400/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.9008 (1.0704)	Prec@1 66.000 (62.746)	Prec@5 98.000 (96.384)
2019-05-03 16:30:13 - INFO - TRAINING - Epoch: [13][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 1.2575 (1.0672)	Prec@1 60.000 (62.876)	Prec@5 97.000 (96.384)
2019-05-03 16:30:15 - INFO - EVALUATING - Epoch: [13][0/100]	Time 0.345 (0.345)	Data 0.331 (0.331)	Loss 1.1890 (1.1890)	Prec@1 56.000 (56.000)	Prec@5 98.000 (98.000)
2019-05-03 16:30:15 - INFO - EVALUATING - Epoch: [13][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.5059 (1.4534)	Prec@1 51.000 (50.373)	Prec@5 93.000 (91.863)
2019-05-03 16:30:15 - INFO - 
 Epoch: 14	Training Loss 1.0647 	Training Prec@1 63.052 	Training Prec@5 96.382 	Validation Loss 1.4599 	Validation Prec@1 50.000 	Validation Prec@5 91.510 	
2019-05-03 16:30:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:15 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:15 - INFO - TRAINING - Epoch: [14][0/500]	Time 0.359 (0.359)	Data 0.329 (0.329)	Loss 1.0372 (1.0372)	Prec@1 62.000 (62.000)	Prec@5 96.000 (96.000)
2019-05-03 16:30:17 - INFO - TRAINING - Epoch: [14][50/500]	Time 0.027 (0.027)	Data 0.000 (0.007)	Loss 1.1034 (1.0711)	Prec@1 62.000 (62.549)	Prec@5 95.000 (96.098)
2019-05-03 16:30:18 - INFO - TRAINING - Epoch: [14][100/500]	Time 0.025 (0.024)	Data 0.000 (0.003)	Loss 1.1737 (1.0718)	Prec@1 69.000 (62.752)	Prec@5 96.000 (96.040)
2019-05-03 16:30:19 - INFO - TRAINING - Epoch: [14][150/500]	Time 0.026 (0.023)	Data 0.000 (0.002)	Loss 0.9361 (1.0717)	Prec@1 71.000 (62.682)	Prec@5 96.000 (96.192)
2019-05-03 16:30:20 - INFO - TRAINING - Epoch: [14][200/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.8534 (1.0596)	Prec@1 65.000 (63.184)	Prec@5 100.000 (96.383)
2019-05-03 16:30:21 - INFO - TRAINING - Epoch: [14][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 1.1164 (1.0625)	Prec@1 55.000 (63.028)	Prec@5 94.000 (96.363)
2019-05-03 16:30:21 - INFO - TRAINING - Epoch: [14][300/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 1.0891 (1.0552)	Prec@1 58.000 (63.159)	Prec@5 96.000 (96.425)
2019-05-03 16:30:22 - INFO - TRAINING - Epoch: [14][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 1.2795 (1.0543)	Prec@1 50.000 (63.242)	Prec@5 98.000 (96.419)
2019-05-03 16:30:23 - INFO - TRAINING - Epoch: [14][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 1.1066 (1.0530)	Prec@1 59.000 (63.294)	Prec@5 98.000 (96.409)
2019-05-03 16:30:24 - INFO - TRAINING - Epoch: [14][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.9749 (1.0553)	Prec@1 67.000 (63.246)	Prec@5 98.000 (96.397)
2019-05-03 16:30:25 - INFO - EVALUATING - Epoch: [14][0/100]	Time 0.334 (0.334)	Data 0.319 (0.319)	Loss 1.2131 (1.2131)	Prec@1 59.000 (59.000)	Prec@5 91.000 (91.000)
2019-05-03 16:30:26 - INFO - EVALUATING - Epoch: [14][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 1.3821 (1.3086)	Prec@1 54.000 (56.431)	Prec@5 89.000 (91.804)
2019-05-03 16:30:26 - INFO - 
 Epoch: 15	Training Loss 1.0553 	Training Prec@1 63.268 	Training Prec@5 96.376 	Validation Loss 1.3140 	Validation Prec@1 55.990 	Validation Prec@5 92.020 	
2019-05-03 16:30:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:26 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:26 - INFO - TRAINING - Epoch: [15][0/500]	Time 0.361 (0.361)	Data 0.343 (0.343)	Loss 0.9922 (0.9922)	Prec@1 60.000 (60.000)	Prec@5 96.000 (96.000)
2019-05-03 16:30:27 - INFO - TRAINING - Epoch: [15][50/500]	Time 0.027 (0.026)	Data 0.000 (0.007)	Loss 1.2582 (1.0639)	Prec@1 58.000 (63.000)	Prec@5 94.000 (96.333)
2019-05-03 16:30:28 - INFO - TRAINING - Epoch: [15][100/500]	Time 0.026 (0.024)	Data 0.000 (0.004)	Loss 1.0730 (1.0443)	Prec@1 65.000 (63.871)	Prec@5 97.000 (96.446)
2019-05-03 16:30:29 - INFO - TRAINING - Epoch: [15][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.9148 (1.0415)	Prec@1 69.000 (63.695)	Prec@5 97.000 (96.417)
2019-05-03 16:30:30 - INFO - TRAINING - Epoch: [15][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9856 (1.0327)	Prec@1 72.000 (64.259)	Prec@5 96.000 (96.498)
2019-05-03 16:30:31 - INFO - TRAINING - Epoch: [15][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8596 (1.0351)	Prec@1 71.000 (64.084)	Prec@5 96.000 (96.482)
2019-05-03 16:30:32 - INFO - TRAINING - Epoch: [15][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 1.0657 (1.0319)	Prec@1 66.000 (64.239)	Prec@5 94.000 (96.449)
2019-05-03 16:30:33 - INFO - TRAINING - Epoch: [15][350/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 1.0208 (1.0298)	Prec@1 69.000 (64.205)	Prec@5 96.000 (96.447)
2019-05-03 16:30:34 - INFO - TRAINING - Epoch: [15][400/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 1.1939 (1.0349)	Prec@1 61.000 (64.067)	Prec@5 95.000 (96.451)
2019-05-03 16:30:35 - INFO - TRAINING - Epoch: [15][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.9487 (1.0344)	Prec@1 67.000 (64.118)	Prec@5 98.000 (96.477)
2019-05-03 16:30:36 - INFO - EVALUATING - Epoch: [15][0/100]	Time 0.259 (0.259)	Data 0.253 (0.253)	Loss 1.3883 (1.3883)	Prec@1 51.000 (51.000)	Prec@5 91.000 (91.000)
2019-05-03 16:30:37 - INFO - EVALUATING - Epoch: [15][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 1.4052 (1.3920)	Prec@1 48.000 (51.255)	Prec@5 96.000 (92.608)
2019-05-03 16:30:37 - INFO - 
 Epoch: 16	Training Loss 1.0373 	Training Prec@1 64.072 	Training Prec@5 96.430 	Validation Loss 1.4157 	Validation Prec@1 50.360 	Validation Prec@5 92.340 	
2019-05-03 16:30:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:37 - INFO - TRAINING - Epoch: [16][0/500]	Time 0.354 (0.354)	Data 0.333 (0.333)	Loss 0.9125 (0.9125)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 16:30:38 - INFO - TRAINING - Epoch: [16][50/500]	Time 0.019 (0.027)	Data 0.000 (0.007)	Loss 1.0254 (1.0286)	Prec@1 64.000 (64.000)	Prec@5 93.000 (96.196)
2019-05-03 16:30:39 - INFO - TRAINING - Epoch: [16][100/500]	Time 0.016 (0.023)	Data 0.000 (0.003)	Loss 0.9106 (1.0258)	Prec@1 67.000 (64.248)	Prec@5 96.000 (96.396)
2019-05-03 16:30:40 - INFO - TRAINING - Epoch: [16][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 1.2156 (1.0282)	Prec@1 62.000 (64.000)	Prec@5 95.000 (96.629)
2019-05-03 16:30:41 - INFO - TRAINING - Epoch: [16][200/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.8981 (1.0252)	Prec@1 67.000 (64.119)	Prec@5 100.000 (96.667)
2019-05-03 16:30:42 - INFO - TRAINING - Epoch: [16][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.9708 (1.0262)	Prec@1 68.000 (64.207)	Prec@5 97.000 (96.598)
2019-05-03 16:30:43 - INFO - TRAINING - Epoch: [16][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 1.0846 (1.0262)	Prec@1 60.000 (64.229)	Prec@5 97.000 (96.588)
2019-05-03 16:30:44 - INFO - TRAINING - Epoch: [16][350/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 1.0716 (1.0254)	Prec@1 64.000 (64.424)	Prec@5 96.000 (96.561)
2019-05-03 16:30:45 - INFO - TRAINING - Epoch: [16][400/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.9338 (1.0244)	Prec@1 65.000 (64.404)	Prec@5 97.000 (96.603)
2019-05-03 16:30:46 - INFO - TRAINING - Epoch: [16][450/500]	Time 0.031 (0.020)	Data 0.000 (0.001)	Loss 0.9752 (1.0253)	Prec@1 70.000 (64.415)	Prec@5 97.000 (96.610)
2019-05-03 16:30:47 - INFO - EVALUATING - Epoch: [16][0/100]	Time 0.326 (0.326)	Data 0.317 (0.317)	Loss 1.1210 (1.1210)	Prec@1 60.000 (60.000)	Prec@5 96.000 (96.000)
2019-05-03 16:30:48 - INFO - EVALUATING - Epoch: [16][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.1616 (1.2015)	Prec@1 61.000 (58.961)	Prec@5 95.000 (94.235)
2019-05-03 16:30:48 - INFO - 
 Epoch: 17	Training Loss 1.0240 	Training Prec@1 64.460 	Training Prec@5 96.682 	Validation Loss 1.2181 	Validation Prec@1 58.140 	Validation Prec@5 94.230 	
2019-05-03 16:30:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:48 - INFO - TRAINING - Epoch: [17][0/500]	Time 0.372 (0.372)	Data 0.344 (0.344)	Loss 1.0944 (1.0944)	Prec@1 66.000 (66.000)	Prec@5 97.000 (97.000)
2019-05-03 16:30:49 - INFO - TRAINING - Epoch: [17][50/500]	Time 0.024 (0.027)	Data 0.000 (0.007)	Loss 1.1928 (1.0678)	Prec@1 59.000 (63.020)	Prec@5 97.000 (95.961)
2019-05-03 16:30:50 - INFO - TRAINING - Epoch: [17][100/500]	Time 0.013 (0.023)	Data 0.000 (0.004)	Loss 1.0907 (1.0375)	Prec@1 61.000 (64.218)	Prec@5 95.000 (96.248)
2019-05-03 16:30:51 - INFO - TRAINING - Epoch: [17][150/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.9123 (1.0267)	Prec@1 74.000 (64.497)	Prec@5 97.000 (96.483)
2019-05-03 16:30:52 - INFO - TRAINING - Epoch: [17][200/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 1.0492 (1.0266)	Prec@1 64.000 (64.483)	Prec@5 95.000 (96.418)
2019-05-03 16:30:53 - INFO - TRAINING - Epoch: [17][250/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.9827 (1.0203)	Prec@1 64.000 (64.566)	Prec@5 95.000 (96.502)
2019-05-03 16:30:54 - INFO - TRAINING - Epoch: [17][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.9492 (1.0217)	Prec@1 68.000 (64.561)	Prec@5 98.000 (96.532)
2019-05-03 16:30:55 - INFO - TRAINING - Epoch: [17][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 1.1608 (1.0214)	Prec@1 65.000 (64.624)	Prec@5 95.000 (96.524)
2019-05-03 16:30:56 - INFO - TRAINING - Epoch: [17][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8632 (1.0171)	Prec@1 73.000 (64.781)	Prec@5 96.000 (96.581)
2019-05-03 16:30:57 - INFO - TRAINING - Epoch: [17][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.9745 (1.0192)	Prec@1 72.000 (64.727)	Prec@5 97.000 (96.625)
2019-05-03 16:30:58 - INFO - EVALUATING - Epoch: [17][0/100]	Time 0.325 (0.325)	Data 0.316 (0.316)	Loss 1.2082 (1.2082)	Prec@1 58.000 (58.000)	Prec@5 95.000 (95.000)
2019-05-03 16:30:59 - INFO - EVALUATING - Epoch: [17][50/100]	Time 0.010 (0.012)	Data 0.000 (0.006)	Loss 1.3274 (1.3126)	Prec@1 52.000 (55.510)	Prec@5 97.000 (94.569)
2019-05-03 16:30:59 - INFO - 
 Epoch: 18	Training Loss 1.0196 	Training Prec@1 64.760 	Training Prec@5 96.638 	Validation Loss 1.3255 	Validation Prec@1 54.950 	Validation Prec@5 94.430 	
2019-05-03 16:30:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:30:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:30:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:30:59 - INFO - TRAINING - Epoch: [18][0/500]	Time 0.372 (0.372)	Data 0.344 (0.344)	Loss 0.7766 (0.7766)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-03 16:31:00 - INFO - TRAINING - Epoch: [18][50/500]	Time 0.021 (0.026)	Data 0.000 (0.007)	Loss 0.8595 (1.0351)	Prec@1 70.000 (64.471)	Prec@5 97.000 (96.392)
2019-05-03 16:31:01 - INFO - TRAINING - Epoch: [18][100/500]	Time 0.022 (0.023)	Data 0.000 (0.004)	Loss 0.9781 (1.0276)	Prec@1 69.000 (64.733)	Prec@5 94.000 (96.564)
2019-05-03 16:31:02 - INFO - TRAINING - Epoch: [18][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.8939 (1.0114)	Prec@1 67.000 (65.146)	Prec@5 98.000 (96.709)
2019-05-03 16:31:03 - INFO - TRAINING - Epoch: [18][200/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 1.2149 (1.0123)	Prec@1 57.000 (64.930)	Prec@5 96.000 (96.687)
2019-05-03 16:31:04 - INFO - TRAINING - Epoch: [18][250/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.9000 (1.0137)	Prec@1 67.000 (64.809)	Prec@5 97.000 (96.637)
2019-05-03 16:31:05 - INFO - TRAINING - Epoch: [18][300/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 1.1941 (1.0103)	Prec@1 55.000 (64.801)	Prec@5 96.000 (96.744)
2019-05-03 16:31:06 - INFO - TRAINING - Epoch: [18][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 1.1281 (1.0090)	Prec@1 60.000 (64.855)	Prec@5 97.000 (96.726)
2019-05-03 16:31:07 - INFO - TRAINING - Epoch: [18][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 1.0566 (1.0053)	Prec@1 67.000 (65.070)	Prec@5 96.000 (96.748)
2019-05-03 16:31:08 - INFO - TRAINING - Epoch: [18][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 1.1371 (1.0065)	Prec@1 64.000 (65.011)	Prec@5 97.000 (96.727)
2019-05-03 16:31:09 - INFO - EVALUATING - Epoch: [18][0/100]	Time 0.330 (0.330)	Data 0.322 (0.322)	Loss 1.0430 (1.0430)	Prec@1 63.000 (63.000)	Prec@5 96.000 (96.000)
2019-05-03 16:31:09 - INFO - EVALUATING - Epoch: [18][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.1488 (1.1706)	Prec@1 58.000 (59.471)	Prec@5 97.000 (95.471)
2019-05-03 16:31:10 - INFO - 
 Epoch: 19	Training Loss 1.0048 	Training Prec@1 65.108 	Training Prec@5 96.746 	Validation Loss 1.1867 	Validation Prec@1 59.320 	Validation Prec@5 95.600 	
2019-05-03 16:31:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:31:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:31:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:31:10 - INFO - TRAINING - Epoch: [19][0/500]	Time 0.351 (0.351)	Data 0.320 (0.320)	Loss 0.9807 (0.9807)	Prec@1 63.000 (63.000)	Prec@5 96.000 (96.000)
2019-05-03 16:31:11 - INFO - TRAINING - Epoch: [19][50/500]	Time 0.016 (0.026)	Data 0.000 (0.006)	Loss 0.9928 (1.0004)	Prec@1 63.000 (65.157)	Prec@5 96.000 (96.706)
2019-05-03 16:31:12 - INFO - TRAINING - Epoch: [19][100/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 1.0636 (0.9997)	Prec@1 58.000 (65.366)	Prec@5 98.000 (96.802)
2019-05-03 16:31:13 - INFO - TRAINING - Epoch: [19][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.9796 (1.0000)	Prec@1 63.000 (65.258)	Prec@5 96.000 (96.735)
2019-05-03 16:31:14 - INFO - TRAINING - Epoch: [19][200/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 1.1546 (0.9927)	Prec@1 59.000 (65.517)	Prec@5 95.000 (96.831)
2019-05-03 16:31:15 - INFO - TRAINING - Epoch: [19][250/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.9784 (0.9925)	Prec@1 65.000 (65.514)	Prec@5 94.000 (96.873)
2019-05-03 16:31:16 - INFO - TRAINING - Epoch: [19][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 1.1015 (0.9886)	Prec@1 59.000 (65.648)	Prec@5 96.000 (96.900)
2019-05-03 16:31:17 - INFO - TRAINING - Epoch: [19][350/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.8918 (0.9893)	Prec@1 63.000 (65.638)	Prec@5 98.000 (96.866)
2019-05-03 16:31:17 - INFO - TRAINING - Epoch: [19][400/500]	Time 0.017 (0.019)	Data 0.000 (0.001)	Loss 0.9565 (0.9893)	Prec@1 67.000 (65.658)	Prec@5 95.000 (96.860)
2019-05-03 16:31:18 - INFO - TRAINING - Epoch: [19][450/500]	Time 0.018 (0.019)	Data 0.000 (0.001)	Loss 1.0530 (0.9936)	Prec@1 63.000 (65.512)	Prec@5 96.000 (96.871)
2019-05-03 16:31:20 - INFO - EVALUATING - Epoch: [19][0/100]	Time 0.324 (0.324)	Data 0.312 (0.312)	Loss 1.2267 (1.2267)	Prec@1 56.000 (56.000)	Prec@5 94.000 (94.000)
2019-05-03 16:31:20 - INFO - EVALUATING - Epoch: [19][50/100]	Time 0.008 (0.012)	Data 0.000 (0.006)	Loss 1.1909 (1.2280)	Prec@1 57.000 (57.706)	Prec@5 97.000 (94.333)
2019-05-03 16:31:20 - INFO - 
 Epoch: 20	Training Loss 0.9975 	Training Prec@1 65.430 	Training Prec@5 96.820 	Validation Loss 1.2377 	Validation Prec@1 57.120 	Validation Prec@5 94.190 	
2019-05-03 16:31:20 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:31:20 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:31:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:31:20 - INFO - TRAINING - Epoch: [20][0/500]	Time 0.358 (0.358)	Data 0.326 (0.326)	Loss 1.0048 (1.0048)	Prec@1 65.000 (65.000)	Prec@5 95.000 (95.000)
2019-05-03 16:31:21 - INFO - TRAINING - Epoch: [20][50/500]	Time 0.027 (0.026)	Data 0.000 (0.007)	Loss 1.0173 (0.9744)	Prec@1 67.000 (66.549)	Prec@5 97.000 (96.863)
2019-05-03 16:31:22 - INFO - TRAINING - Epoch: [20][100/500]	Time 0.019 (0.022)	Data 0.000 (0.003)	Loss 1.0867 (0.9957)	Prec@1 62.000 (65.743)	Prec@5 95.000 (96.653)
2019-05-03 16:31:23 - INFO - TRAINING - Epoch: [20][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 1.0933 (0.9944)	Prec@1 57.000 (65.841)	Prec@5 97.000 (96.589)
2019-05-03 16:31:24 - INFO - TRAINING - Epoch: [20][200/500]	Time 0.018 (0.020)	Data 0.000 (0.002)	Loss 0.8391 (0.9908)	Prec@1 72.000 (65.806)	Prec@5 100.000 (96.706)
2019-05-03 16:31:25 - INFO - TRAINING - Epoch: [20][250/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 1.0781 (0.9961)	Prec@1 65.000 (65.645)	Prec@5 95.000 (96.709)
2019-05-03 16:31:26 - INFO - TRAINING - Epoch: [20][300/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.9156 (0.9902)	Prec@1 67.000 (65.894)	Prec@5 99.000 (96.714)
2019-05-03 16:31:27 - INFO - TRAINING - Epoch: [20][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 1.0959 (0.9940)	Prec@1 56.000 (65.672)	Prec@5 97.000 (96.735)
2019-05-03 16:31:28 - INFO - TRAINING - Epoch: [20][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.8935 (0.9927)	Prec@1 68.000 (65.658)	Prec@5 98.000 (96.753)
2019-05-03 16:31:29 - INFO - TRAINING - Epoch: [20][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.9767 (0.9905)	Prec@1 65.000 (65.714)	Prec@5 97.000 (96.778)
2019-05-03 16:31:30 - INFO - EVALUATING - Epoch: [20][0/100]	Time 0.344 (0.344)	Data 0.336 (0.336)	Loss 1.3874 (1.3874)	Prec@1 50.000 (50.000)	Prec@5 96.000 (96.000)
2019-05-03 16:31:31 - INFO - EVALUATING - Epoch: [20][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.4827 (1.4065)	Prec@1 48.000 (50.686)	Prec@5 90.000 (93.275)
2019-05-03 16:31:31 - INFO - 
 Epoch: 21	Training Loss 0.9896 	Training Prec@1 65.710 	Training Prec@5 96.788 	Validation Loss 1.4191 	Validation Prec@1 50.560 	Validation Prec@5 93.210 	
2019-05-03 16:31:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:31:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:31:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:31:31 - INFO - TRAINING - Epoch: [21][0/500]	Time 0.364 (0.364)	Data 0.337 (0.337)	Loss 0.9912 (0.9912)	Prec@1 63.000 (63.000)	Prec@5 99.000 (99.000)
2019-05-03 16:31:32 - INFO - TRAINING - Epoch: [21][50/500]	Time 0.016 (0.025)	Data 0.000 (0.007)	Loss 0.9693 (0.9868)	Prec@1 67.000 (65.314)	Prec@5 98.000 (96.961)
2019-05-03 16:31:33 - INFO - TRAINING - Epoch: [21][100/500]	Time 0.023 (0.023)	Data 0.000 (0.003)	Loss 0.9410 (0.9818)	Prec@1 74.000 (65.673)	Prec@5 93.000 (97.059)
2019-05-03 16:31:34 - INFO - TRAINING - Epoch: [21][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.8056 (0.9701)	Prec@1 76.000 (65.934)	Prec@5 97.000 (97.152)
2019-05-03 16:31:35 - INFO - TRAINING - Epoch: [21][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9056 (0.9740)	Prec@1 73.000 (65.955)	Prec@5 97.000 (97.129)
2019-05-03 16:31:36 - INFO - TRAINING - Epoch: [21][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8625 (0.9694)	Prec@1 64.000 (66.199)	Prec@5 98.000 (97.104)
2019-05-03 16:31:37 - INFO - TRAINING - Epoch: [21][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 1.0597 (0.9682)	Prec@1 60.000 (66.269)	Prec@5 95.000 (97.110)
2019-05-03 16:31:38 - INFO - TRAINING - Epoch: [21][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.9360 (0.9692)	Prec@1 70.000 (66.148)	Prec@5 96.000 (97.140)
2019-05-03 16:31:39 - INFO - TRAINING - Epoch: [21][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.8666 (0.9690)	Prec@1 69.000 (66.145)	Prec@5 98.000 (97.100)
2019-05-03 16:31:40 - INFO - TRAINING - Epoch: [21][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 1.0341 (0.9699)	Prec@1 63.000 (66.135)	Prec@5 97.000 (97.131)
2019-05-03 16:31:41 - INFO - EVALUATING - Epoch: [21][0/100]	Time 0.266 (0.266)	Data 0.259 (0.259)	Loss 1.2220 (1.2220)	Prec@1 54.000 (54.000)	Prec@5 94.000 (94.000)
2019-05-03 16:31:42 - INFO - EVALUATING - Epoch: [21][50/100]	Time 0.007 (0.011)	Data 0.000 (0.006)	Loss 1.1962 (1.2068)	Prec@1 62.000 (58.431)	Prec@5 97.000 (94.980)
2019-05-03 16:31:42 - INFO - 
 Epoch: 22	Training Loss 0.9723 	Training Prec@1 66.054 	Training Prec@5 97.064 	Validation Loss 1.2376 	Validation Prec@1 57.570 	Validation Prec@5 94.750 	
2019-05-03 16:31:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:31:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:31:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:31:42 - INFO - TRAINING - Epoch: [22][0/500]	Time 0.349 (0.349)	Data 0.325 (0.325)	Loss 0.9892 (0.9892)	Prec@1 68.000 (68.000)	Prec@5 98.000 (98.000)
2019-05-03 16:31:43 - INFO - TRAINING - Epoch: [22][50/500]	Time 0.014 (0.023)	Data 0.000 (0.006)	Loss 1.0232 (0.9937)	Prec@1 64.000 (66.020)	Prec@5 96.000 (96.961)
2019-05-03 16:31:44 - INFO - TRAINING - Epoch: [22][100/500]	Time 0.018 (0.020)	Data 0.000 (0.003)	Loss 0.8752 (0.9712)	Prec@1 75.000 (66.901)	Prec@5 96.000 (96.851)
2019-05-03 16:31:45 - INFO - TRAINING - Epoch: [22][150/500]	Time 0.016 (0.019)	Data 0.000 (0.002)	Loss 0.8894 (0.9610)	Prec@1 68.000 (67.205)	Prec@5 98.000 (96.974)
2019-05-03 16:31:46 - INFO - TRAINING - Epoch: [22][200/500]	Time 0.019 (0.019)	Data 0.000 (0.002)	Loss 1.0858 (0.9642)	Prec@1 63.000 (67.080)	Prec@5 95.000 (96.970)
2019-05-03 16:31:47 - INFO - TRAINING - Epoch: [22][250/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.9393 (0.9632)	Prec@1 59.000 (67.084)	Prec@5 97.000 (96.996)
2019-05-03 16:31:48 - INFO - TRAINING - Epoch: [22][300/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.8384 (0.9632)	Prec@1 67.000 (67.070)	Prec@5 100.000 (97.040)
2019-05-03 16:31:49 - INFO - TRAINING - Epoch: [22][350/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 1.0172 (0.9635)	Prec@1 63.000 (66.966)	Prec@5 94.000 (97.046)
2019-05-03 16:31:49 - INFO - TRAINING - Epoch: [22][400/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 1.0526 (0.9638)	Prec@1 63.000 (66.950)	Prec@5 96.000 (97.020)
2019-05-03 16:31:50 - INFO - TRAINING - Epoch: [22][450/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 1.1287 (0.9637)	Prec@1 61.000 (66.887)	Prec@5 99.000 (97.042)
2019-05-03 16:31:52 - INFO - EVALUATING - Epoch: [22][0/100]	Time 0.331 (0.331)	Data 0.324 (0.324)	Loss 1.0127 (1.0127)	Prec@1 67.000 (67.000)	Prec@5 98.000 (98.000)
2019-05-03 16:31:52 - INFO - EVALUATING - Epoch: [22][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.0037 (1.1659)	Prec@1 66.000 (58.588)	Prec@5 99.000 (96.039)
2019-05-03 16:31:52 - INFO - 
 Epoch: 23	Training Loss 0.9616 	Training Prec@1 66.960 	Training Prec@5 97.066 	Validation Loss 1.1845 	Validation Prec@1 57.660 	Validation Prec@5 95.880 	
2019-05-03 16:31:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:31:52 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:31:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:31:53 - INFO - TRAINING - Epoch: [23][0/500]	Time 0.373 (0.373)	Data 0.347 (0.347)	Loss 0.9621 (0.9621)	Prec@1 67.000 (67.000)	Prec@5 98.000 (98.000)
2019-05-03 16:31:54 - INFO - TRAINING - Epoch: [23][50/500]	Time 0.020 (0.027)	Data 0.000 (0.007)	Loss 1.0233 (0.9936)	Prec@1 70.000 (66.667)	Prec@5 99.000 (96.373)
2019-05-03 16:31:55 - INFO - TRAINING - Epoch: [23][100/500]	Time 0.023 (0.024)	Data 0.000 (0.004)	Loss 0.8334 (0.9639)	Prec@1 69.000 (67.248)	Prec@5 99.000 (96.762)
2019-05-03 16:31:56 - INFO - TRAINING - Epoch: [23][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.8234 (0.9548)	Prec@1 78.000 (67.417)	Prec@5 97.000 (96.907)
2019-05-03 16:31:56 - INFO - TRAINING - Epoch: [23][200/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.9108 (0.9471)	Prec@1 70.000 (67.662)	Prec@5 96.000 (97.005)
2019-05-03 16:31:57 - INFO - TRAINING - Epoch: [23][250/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 1.1122 (0.9463)	Prec@1 63.000 (67.673)	Prec@5 94.000 (97.048)
2019-05-03 16:31:58 - INFO - TRAINING - Epoch: [23][300/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.8559 (0.9430)	Prec@1 72.000 (67.844)	Prec@5 99.000 (97.100)
2019-05-03 16:31:59 - INFO - TRAINING - Epoch: [23][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.8345 (0.9432)	Prec@1 73.000 (67.821)	Prec@5 98.000 (97.077)
2019-05-03 16:32:00 - INFO - TRAINING - Epoch: [23][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.9808 (0.9416)	Prec@1 72.000 (67.763)	Prec@5 96.000 (97.135)
2019-05-03 16:32:01 - INFO - TRAINING - Epoch: [23][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 1.0069 (0.9400)	Prec@1 67.000 (67.863)	Prec@5 97.000 (97.160)
2019-05-03 16:32:02 - INFO - EVALUATING - Epoch: [23][0/100]	Time 0.264 (0.264)	Data 0.256 (0.256)	Loss 1.1135 (1.1135)	Prec@1 59.000 (59.000)	Prec@5 93.000 (93.000)
2019-05-03 16:32:03 - INFO - EVALUATING - Epoch: [23][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 1.3276 (1.2178)	Prec@1 51.000 (57.882)	Prec@5 95.000 (94.765)
2019-05-03 16:32:03 - INFO - 
 Epoch: 24	Training Loss 0.9394 	Training Prec@1 67.856 	Training Prec@5 97.164 	Validation Loss 1.2151 	Validation Prec@1 57.940 	Validation Prec@5 94.890 	
2019-05-03 16:32:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:03 - INFO - TRAINING - Epoch: [24][0/500]	Time 0.359 (0.359)	Data 0.338 (0.338)	Loss 1.0031 (1.0031)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-03 16:32:04 - INFO - TRAINING - Epoch: [24][50/500]	Time 0.017 (0.026)	Data 0.000 (0.007)	Loss 1.0554 (0.9441)	Prec@1 63.000 (68.137)	Prec@5 97.000 (96.941)
2019-05-03 16:32:05 - INFO - TRAINING - Epoch: [24][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.9201 (0.9395)	Prec@1 68.000 (68.010)	Prec@5 98.000 (97.079)
2019-05-03 16:32:06 - INFO - TRAINING - Epoch: [24][150/500]	Time 0.020 (0.023)	Data 0.000 (0.002)	Loss 1.0010 (0.9427)	Prec@1 70.000 (67.735)	Prec@5 98.000 (97.040)
2019-05-03 16:32:07 - INFO - TRAINING - Epoch: [24][200/500]	Time 0.012 (0.022)	Data 0.000 (0.002)	Loss 0.7497 (0.9435)	Prec@1 79.000 (67.721)	Prec@5 98.000 (97.015)
2019-05-03 16:32:08 - INFO - TRAINING - Epoch: [24][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 1.0071 (0.9423)	Prec@1 67.000 (67.713)	Prec@5 97.000 (97.068)
2019-05-03 16:32:09 - INFO - TRAINING - Epoch: [24][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 1.0376 (0.9413)	Prec@1 66.000 (67.708)	Prec@5 97.000 (97.100)
2019-05-03 16:32:10 - INFO - TRAINING - Epoch: [24][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6328 (0.9363)	Prec@1 78.000 (67.812)	Prec@5 99.000 (97.151)
2019-05-03 16:32:11 - INFO - TRAINING - Epoch: [24][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 1.0336 (0.9387)	Prec@1 64.000 (67.748)	Prec@5 96.000 (97.135)
2019-05-03 16:32:12 - INFO - TRAINING - Epoch: [24][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.9498 (0.9389)	Prec@1 66.000 (67.656)	Prec@5 100.000 (97.173)
2019-05-03 16:32:14 - INFO - EVALUATING - Epoch: [24][0/100]	Time 0.249 (0.249)	Data 0.243 (0.243)	Loss 1.1015 (1.1015)	Prec@1 64.000 (64.000)	Prec@5 95.000 (95.000)
2019-05-03 16:32:14 - INFO - EVALUATING - Epoch: [24][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 1.4383 (1.3364)	Prec@1 54.000 (55.549)	Prec@5 94.000 (94.176)
2019-05-03 16:32:14 - INFO - 
 Epoch: 25	Training Loss 0.9360 	Training Prec@1 67.732 	Training Prec@5 97.174 	Validation Loss 1.3426 	Validation Prec@1 55.660 	Validation Prec@5 94.260 	
2019-05-03 16:32:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:14 - INFO - TRAINING - Epoch: [25][0/500]	Time 0.343 (0.343)	Data 0.313 (0.313)	Loss 0.9188 (0.9188)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-03 16:32:15 - INFO - TRAINING - Epoch: [25][50/500]	Time 0.021 (0.026)	Data 0.000 (0.006)	Loss 1.0036 (0.9551)	Prec@1 64.000 (67.176)	Prec@5 98.000 (97.412)
2019-05-03 16:32:16 - INFO - TRAINING - Epoch: [25][100/500]	Time 0.021 (0.023)	Data 0.000 (0.003)	Loss 0.7221 (0.9440)	Prec@1 71.000 (67.386)	Prec@5 99.000 (97.327)
2019-05-03 16:32:17 - INFO - TRAINING - Epoch: [25][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.8930 (0.9347)	Prec@1 73.000 (67.854)	Prec@5 97.000 (97.252)
2019-05-03 16:32:19 - INFO - TRAINING - Epoch: [25][200/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.8559 (0.9281)	Prec@1 68.000 (67.910)	Prec@5 99.000 (97.313)
2019-05-03 16:32:20 - INFO - TRAINING - Epoch: [25][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8175 (0.9239)	Prec@1 68.000 (68.008)	Prec@5 99.000 (97.255)
2019-05-03 16:32:20 - INFO - TRAINING - Epoch: [25][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.8248 (0.9191)	Prec@1 70.000 (68.266)	Prec@5 100.000 (97.276)
2019-05-03 16:32:22 - INFO - TRAINING - Epoch: [25][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7857 (0.9187)	Prec@1 74.000 (68.219)	Prec@5 97.000 (97.299)
2019-05-03 16:32:23 - INFO - TRAINING - Epoch: [25][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8271 (0.9205)	Prec@1 70.000 (68.147)	Prec@5 98.000 (97.292)
2019-05-03 16:32:24 - INFO - TRAINING - Epoch: [25][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8045 (0.9192)	Prec@1 75.000 (68.191)	Prec@5 98.000 (97.306)
2019-05-03 16:32:25 - INFO - EVALUATING - Epoch: [25][0/100]	Time 0.350 (0.350)	Data 0.341 (0.341)	Loss 0.8772 (0.8772)	Prec@1 68.000 (68.000)	Prec@5 97.000 (97.000)
2019-05-03 16:32:25 - INFO - EVALUATING - Epoch: [25][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.9333 (0.9551)	Prec@1 74.000 (67.196)	Prec@5 98.000 (97.059)
2019-05-03 16:32:25 - INFO - 
 Epoch: 26	Training Loss 0.9166 	Training Prec@1 68.350 	Training Prec@5 97.344 	Validation Loss 0.9766 	Validation Prec@1 66.330 	Validation Prec@5 97.050 	
2019-05-03 16:32:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:26 - INFO - TRAINING - Epoch: [26][0/500]	Time 0.369 (0.369)	Data 0.342 (0.342)	Loss 1.0409 (1.0409)	Prec@1 62.000 (62.000)	Prec@5 96.000 (96.000)
2019-05-03 16:32:27 - INFO - TRAINING - Epoch: [26][50/500]	Time 0.026 (0.027)	Data 0.000 (0.007)	Loss 0.7426 (0.9439)	Prec@1 77.000 (67.235)	Prec@5 98.000 (97.294)
2019-05-03 16:32:28 - INFO - TRAINING - Epoch: [26][100/500]	Time 0.015 (0.024)	Data 0.000 (0.004)	Loss 0.8378 (0.9331)	Prec@1 70.000 (68.267)	Prec@5 97.000 (97.386)
2019-05-03 16:32:29 - INFO - TRAINING - Epoch: [26][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.9996 (0.9203)	Prec@1 65.000 (68.735)	Prec@5 98.000 (97.397)
2019-05-03 16:32:30 - INFO - TRAINING - Epoch: [26][200/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.8775 (0.9164)	Prec@1 72.000 (68.896)	Prec@5 99.000 (97.318)
2019-05-03 16:32:31 - INFO - TRAINING - Epoch: [26][250/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.8910 (0.9175)	Prec@1 69.000 (68.801)	Prec@5 99.000 (97.295)
2019-05-03 16:32:32 - INFO - TRAINING - Epoch: [26][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.9218 (0.9159)	Prec@1 67.000 (68.817)	Prec@5 96.000 (97.292)
2019-05-03 16:32:33 - INFO - TRAINING - Epoch: [26][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.9075 (0.9092)	Prec@1 71.000 (68.989)	Prec@5 98.000 (97.328)
2019-05-03 16:32:34 - INFO - TRAINING - Epoch: [26][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.8470 (0.9071)	Prec@1 69.000 (69.047)	Prec@5 97.000 (97.327)
2019-05-03 16:32:35 - INFO - TRAINING - Epoch: [26][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7335 (0.9064)	Prec@1 74.000 (69.078)	Prec@5 99.000 (97.377)
2019-05-03 16:32:36 - INFO - EVALUATING - Epoch: [26][0/100]	Time 0.312 (0.312)	Data 0.306 (0.306)	Loss 0.9747 (0.9747)	Prec@1 62.000 (62.000)	Prec@5 98.000 (98.000)
2019-05-03 16:32:36 - INFO - EVALUATING - Epoch: [26][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.9543 (1.0030)	Prec@1 63.000 (65.667)	Prec@5 96.000 (96.745)
2019-05-03 16:32:36 - INFO - 
 Epoch: 27	Training Loss 0.9087 	Training Prec@1 68.954 	Training Prec@5 97.362 	Validation Loss 1.0165 	Validation Prec@1 65.190 	Validation Prec@5 96.880 	
2019-05-03 16:32:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:37 - INFO - TRAINING - Epoch: [27][0/500]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.8075 (0.8075)	Prec@1 65.000 (65.000)	Prec@5 100.000 (100.000)
2019-05-03 16:32:38 - INFO - TRAINING - Epoch: [27][50/500]	Time 0.033 (0.025)	Data 0.000 (0.007)	Loss 0.9925 (0.9356)	Prec@1 67.000 (67.843)	Prec@5 97.000 (97.373)
2019-05-03 16:32:39 - INFO - TRAINING - Epoch: [27][100/500]	Time 0.032 (0.022)	Data 0.000 (0.003)	Loss 0.7012 (0.9001)	Prec@1 76.000 (69.139)	Prec@5 99.000 (97.455)
2019-05-03 16:32:40 - INFO - TRAINING - Epoch: [27][150/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 0.7562 (0.8918)	Prec@1 74.000 (69.344)	Prec@5 100.000 (97.464)
2019-05-03 16:32:41 - INFO - TRAINING - Epoch: [27][200/500]	Time 0.028 (0.021)	Data 0.000 (0.002)	Loss 0.9145 (0.8954)	Prec@1 68.000 (69.065)	Prec@5 99.000 (97.443)
2019-05-03 16:32:42 - INFO - TRAINING - Epoch: [27][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7587 (0.8976)	Prec@1 73.000 (68.948)	Prec@5 100.000 (97.442)
2019-05-03 16:32:43 - INFO - TRAINING - Epoch: [27][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6648 (0.8938)	Prec@1 78.000 (69.113)	Prec@5 99.000 (97.505)
2019-05-03 16:32:44 - INFO - TRAINING - Epoch: [27][350/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 1.0488 (0.8938)	Prec@1 68.000 (69.217)	Prec@5 93.000 (97.487)
2019-05-03 16:32:45 - INFO - TRAINING - Epoch: [27][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.7480 (0.8942)	Prec@1 75.000 (69.192)	Prec@5 96.000 (97.514)
2019-05-03 16:32:45 - INFO - TRAINING - Epoch: [27][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6619 (0.8918)	Prec@1 74.000 (69.244)	Prec@5 100.000 (97.523)
2019-05-03 16:32:47 - INFO - EVALUATING - Epoch: [27][0/100]	Time 0.328 (0.328)	Data 0.318 (0.318)	Loss 1.0735 (1.0735)	Prec@1 64.000 (64.000)	Prec@5 91.000 (91.000)
2019-05-03 16:32:47 - INFO - EVALUATING - Epoch: [27][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.2545 (1.2768)	Prec@1 56.000 (56.804)	Prec@5 91.000 (93.667)
2019-05-03 16:32:47 - INFO - 
 Epoch: 28	Training Loss 0.8912 	Training Prec@1 69.320 	Training Prec@5 97.524 	Validation Loss 1.2857 	Validation Prec@1 56.430 	Validation Prec@5 93.610 	
2019-05-03 16:32:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:48 - INFO - TRAINING - Epoch: [28][0/500]	Time 0.365 (0.365)	Data 0.337 (0.337)	Loss 1.0102 (1.0102)	Prec@1 68.000 (68.000)	Prec@5 96.000 (96.000)
2019-05-03 16:32:49 - INFO - TRAINING - Epoch: [28][50/500]	Time 0.024 (0.028)	Data 0.000 (0.007)	Loss 0.8276 (0.8834)	Prec@1 72.000 (70.627)	Prec@5 99.000 (97.784)
2019-05-03 16:32:50 - INFO - TRAINING - Epoch: [28][100/500]	Time 0.027 (0.025)	Data 0.000 (0.003)	Loss 1.0156 (0.8753)	Prec@1 69.000 (70.287)	Prec@5 92.000 (97.703)
2019-05-03 16:32:51 - INFO - TRAINING - Epoch: [28][150/500]	Time 0.017 (0.023)	Data 0.000 (0.002)	Loss 0.8522 (0.8774)	Prec@1 74.000 (70.106)	Prec@5 99.000 (97.623)
2019-05-03 16:32:52 - INFO - TRAINING - Epoch: [28][200/500]	Time 0.022 (0.023)	Data 0.000 (0.002)	Loss 0.7841 (0.8775)	Prec@1 73.000 (70.090)	Prec@5 99.000 (97.547)
2019-05-03 16:32:53 - INFO - TRAINING - Epoch: [28][250/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.9858 (0.8755)	Prec@1 62.000 (69.960)	Prec@5 98.000 (97.530)
2019-05-03 16:32:54 - INFO - TRAINING - Epoch: [28][300/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.8285 (0.8756)	Prec@1 77.000 (70.110)	Prec@5 96.000 (97.508)
2019-05-03 16:32:55 - INFO - TRAINING - Epoch: [28][350/500]	Time 0.023 (0.022)	Data 0.000 (0.001)	Loss 0.9173 (0.8783)	Prec@1 69.000 (69.986)	Prec@5 97.000 (97.504)
2019-05-03 16:32:56 - INFO - TRAINING - Epoch: [28][400/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 1.1187 (0.8772)	Prec@1 66.000 (69.970)	Prec@5 95.000 (97.549)
2019-05-03 16:32:57 - INFO - TRAINING - Epoch: [28][450/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.7560 (0.8762)	Prec@1 75.000 (69.996)	Prec@5 99.000 (97.583)
2019-05-03 16:32:58 - INFO - EVALUATING - Epoch: [28][0/100]	Time 0.259 (0.259)	Data 0.247 (0.247)	Loss 1.5744 (1.5744)	Prec@1 54.000 (54.000)	Prec@5 85.000 (85.000)
2019-05-03 16:32:59 - INFO - EVALUATING - Epoch: [28][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 1.6426 (1.5747)	Prec@1 46.000 (50.863)	Prec@5 87.000 (88.255)
2019-05-03 16:32:59 - INFO - 
 Epoch: 29	Training Loss 0.8740 	Training Prec@1 70.110 	Training Prec@5 97.582 	Validation Loss 1.5752 	Validation Prec@1 51.030 	Validation Prec@5 88.050 	
2019-05-03 16:32:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:32:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:32:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:32:59 - INFO - TRAINING - Epoch: [29][0/500]	Time 0.341 (0.341)	Data 0.317 (0.317)	Loss 0.9396 (0.9396)	Prec@1 70.000 (70.000)	Prec@5 97.000 (97.000)
2019-05-03 16:33:00 - INFO - TRAINING - Epoch: [29][50/500]	Time 0.019 (0.026)	Data 0.000 (0.006)	Loss 0.9421 (0.8949)	Prec@1 67.000 (69.353)	Prec@5 93.000 (97.353)
2019-05-03 16:33:01 - INFO - TRAINING - Epoch: [29][100/500]	Time 0.015 (0.023)	Data 0.000 (0.003)	Loss 0.9952 (0.8826)	Prec@1 65.000 (69.614)	Prec@5 97.000 (97.446)
2019-05-03 16:33:02 - INFO - TRAINING - Epoch: [29][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.7532 (0.8760)	Prec@1 75.000 (69.841)	Prec@5 98.000 (97.536)
2019-05-03 16:33:03 - INFO - TRAINING - Epoch: [29][200/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.8873 (0.8742)	Prec@1 67.000 (69.945)	Prec@5 99.000 (97.582)
2019-05-03 16:33:04 - INFO - TRAINING - Epoch: [29][250/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 1.0404 (0.8671)	Prec@1 62.000 (70.215)	Prec@5 99.000 (97.633)
2019-05-03 16:33:05 - INFO - TRAINING - Epoch: [29][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8741 (0.8636)	Prec@1 72.000 (70.332)	Prec@5 95.000 (97.691)
2019-05-03 16:33:06 - INFO - TRAINING - Epoch: [29][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 1.0150 (0.8660)	Prec@1 61.000 (70.325)	Prec@5 99.000 (97.675)
2019-05-03 16:33:07 - INFO - TRAINING - Epoch: [29][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8319 (0.8604)	Prec@1 70.000 (70.506)	Prec@5 99.000 (97.686)
2019-05-03 16:33:08 - INFO - TRAINING - Epoch: [29][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8151 (0.8602)	Prec@1 68.000 (70.596)	Prec@5 98.000 (97.663)
2019-05-03 16:33:09 - INFO - EVALUATING - Epoch: [29][0/100]	Time 0.346 (0.346)	Data 0.335 (0.335)	Loss 1.7391 (1.7391)	Prec@1 48.000 (48.000)	Prec@5 85.000 (85.000)
2019-05-03 16:33:10 - INFO - EVALUATING - Epoch: [29][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 1.8851 (1.8204)	Prec@1 42.000 (45.255)	Prec@5 86.000 (85.392)
2019-05-03 16:33:10 - INFO - 
 Epoch: 30	Training Loss 0.8605 	Training Prec@1 70.502 	Training Prec@5 97.688 	Validation Loss 1.8173 	Validation Prec@1 45.350 	Validation Prec@5 85.510 	
2019-05-03 16:33:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:33:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:33:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:33:10 - INFO - TRAINING - Epoch: [30][0/500]	Time 0.337 (0.337)	Data 0.307 (0.307)	Loss 0.8868 (0.8868)	Prec@1 71.000 (71.000)	Prec@5 97.000 (97.000)
2019-05-03 16:33:11 - INFO - TRAINING - Epoch: [30][50/500]	Time 0.023 (0.025)	Data 0.000 (0.006)	Loss 0.8321 (0.8706)	Prec@1 73.000 (70.020)	Prec@5 97.000 (97.588)
2019-05-03 16:33:12 - INFO - TRAINING - Epoch: [30][100/500]	Time 0.024 (0.023)	Data 0.000 (0.003)	Loss 0.7698 (0.8459)	Prec@1 72.000 (70.851)	Prec@5 100.000 (97.941)
2019-05-03 16:33:13 - INFO - TRAINING - Epoch: [30][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.8640 (0.8488)	Prec@1 73.000 (70.795)	Prec@5 97.000 (97.947)
2019-05-03 16:33:14 - INFO - TRAINING - Epoch: [30][200/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.9897 (0.8522)	Prec@1 70.000 (70.766)	Prec@5 98.000 (97.801)
2019-05-03 16:33:15 - INFO - TRAINING - Epoch: [30][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7806 (0.8522)	Prec@1 74.000 (70.920)	Prec@5 98.000 (97.817)
2019-05-03 16:33:16 - INFO - TRAINING - Epoch: [30][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8520 (0.8544)	Prec@1 74.000 (70.973)	Prec@5 97.000 (97.787)
2019-05-03 16:33:17 - INFO - TRAINING - Epoch: [30][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.9529 (0.8532)	Prec@1 67.000 (71.031)	Prec@5 98.000 (97.786)
2019-05-03 16:33:18 - INFO - TRAINING - Epoch: [30][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7865 (0.8553)	Prec@1 73.000 (70.890)	Prec@5 99.000 (97.815)
2019-05-03 16:33:19 - INFO - TRAINING - Epoch: [30][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7741 (0.8530)	Prec@1 72.000 (71.029)	Prec@5 97.000 (97.807)
2019-05-03 16:33:20 - INFO - EVALUATING - Epoch: [30][0/100]	Time 0.326 (0.326)	Data 0.317 (0.317)	Loss 0.8568 (0.8568)	Prec@1 70.000 (70.000)	Prec@5 99.000 (99.000)
2019-05-03 16:33:21 - INFO - EVALUATING - Epoch: [30][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.8577 (0.8840)	Prec@1 66.000 (69.549)	Prec@5 99.000 (97.314)
2019-05-03 16:33:21 - INFO - 
 Epoch: 31	Training Loss 0.8556 	Training Prec@1 70.936 	Training Prec@5 97.796 	Validation Loss 0.8739 	Validation Prec@1 69.870 	Validation Prec@5 97.620 	
2019-05-03 16:33:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:33:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:33:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:33:21 - INFO - TRAINING - Epoch: [31][0/500]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.6829 (0.6829)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-05-03 16:33:22 - INFO - TRAINING - Epoch: [31][50/500]	Time 0.025 (0.026)	Data 0.000 (0.006)	Loss 0.7620 (0.8503)	Prec@1 78.000 (70.412)	Prec@5 97.000 (97.941)
2019-05-03 16:33:23 - INFO - TRAINING - Epoch: [31][100/500]	Time 0.012 (0.023)	Data 0.000 (0.003)	Loss 0.8668 (0.8342)	Prec@1 71.000 (71.337)	Prec@5 97.000 (98.119)
2019-05-03 16:33:24 - INFO - TRAINING - Epoch: [31][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.8071 (0.8413)	Prec@1 73.000 (71.185)	Prec@5 97.000 (98.040)
2019-05-03 16:33:25 - INFO - TRAINING - Epoch: [31][200/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.7013 (0.8372)	Prec@1 77.000 (71.398)	Prec@5 100.000 (98.045)
2019-05-03 16:33:26 - INFO - TRAINING - Epoch: [31][250/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.8491 (0.8398)	Prec@1 67.000 (71.414)	Prec@5 100.000 (97.964)
2019-05-03 16:33:27 - INFO - TRAINING - Epoch: [31][300/500]	Time 0.033 (0.020)	Data 0.000 (0.001)	Loss 0.7675 (0.8475)	Prec@1 75.000 (71.123)	Prec@5 99.000 (97.917)
2019-05-03 16:33:28 - INFO - TRAINING - Epoch: [31][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.7879 (0.8457)	Prec@1 71.000 (71.046)	Prec@5 99.000 (97.934)
2019-05-03 16:33:29 - INFO - TRAINING - Epoch: [31][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7866 (0.8457)	Prec@1 72.000 (71.027)	Prec@5 100.000 (97.898)
2019-05-03 16:33:30 - INFO - TRAINING - Epoch: [31][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.8752 (0.8464)	Prec@1 73.000 (70.967)	Prec@5 98.000 (97.871)
2019-05-03 16:33:31 - INFO - EVALUATING - Epoch: [31][0/100]	Time 0.348 (0.348)	Data 0.338 (0.338)	Loss 1.2704 (1.2704)	Prec@1 51.000 (51.000)	Prec@5 95.000 (95.000)
2019-05-03 16:33:32 - INFO - EVALUATING - Epoch: [31][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.4555 (1.2928)	Prec@1 54.000 (56.882)	Prec@5 93.000 (95.255)
2019-05-03 16:33:32 - INFO - 
 Epoch: 32	Training Loss 0.8449 	Training Prec@1 71.094 	Training Prec@5 97.856 	Validation Loss 1.3063 	Validation Prec@1 55.650 	Validation Prec@5 95.200 	
2019-05-03 16:33:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:33:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:33:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:33:32 - INFO - TRAINING - Epoch: [32][0/500]	Time 0.365 (0.365)	Data 0.336 (0.336)	Loss 0.8562 (0.8562)	Prec@1 75.000 (75.000)	Prec@5 96.000 (96.000)
2019-05-03 16:33:33 - INFO - TRAINING - Epoch: [32][50/500]	Time 0.013 (0.025)	Data 0.000 (0.007)	Loss 1.0037 (0.8705)	Prec@1 66.000 (69.961)	Prec@5 94.000 (97.647)
2019-05-03 16:33:34 - INFO - TRAINING - Epoch: [32][100/500]	Time 0.021 (0.022)	Data 0.000 (0.003)	Loss 0.7243 (0.8404)	Prec@1 75.000 (70.970)	Prec@5 97.000 (97.891)
2019-05-03 16:33:35 - INFO - TRAINING - Epoch: [32][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.8095 (0.8367)	Prec@1 69.000 (71.344)	Prec@5 99.000 (97.861)
2019-05-03 16:33:36 - INFO - TRAINING - Epoch: [32][200/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.7317 (0.8373)	Prec@1 77.000 (71.383)	Prec@5 99.000 (97.831)
2019-05-03 16:33:37 - INFO - TRAINING - Epoch: [32][250/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7843 (0.8339)	Prec@1 73.000 (71.574)	Prec@5 99.000 (97.900)
2019-05-03 16:33:38 - INFO - TRAINING - Epoch: [32][300/500]	Time 0.031 (0.020)	Data 0.000 (0.001)	Loss 0.7660 (0.8315)	Prec@1 74.000 (71.595)	Prec@5 98.000 (97.884)
2019-05-03 16:33:39 - INFO - TRAINING - Epoch: [32][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.9809 (0.8310)	Prec@1 65.000 (71.655)	Prec@5 98.000 (97.880)
2019-05-03 16:33:40 - INFO - TRAINING - Epoch: [32][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8961 (0.8319)	Prec@1 70.000 (71.534)	Prec@5 95.000 (97.870)
2019-05-03 16:33:41 - INFO - TRAINING - Epoch: [32][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.8928 (0.8318)	Prec@1 72.000 (71.550)	Prec@5 99.000 (97.851)
2019-05-03 16:33:42 - INFO - EVALUATING - Epoch: [32][0/100]	Time 0.342 (0.342)	Data 0.335 (0.335)	Loss 1.2390 (1.2390)	Prec@1 64.000 (64.000)	Prec@5 92.000 (92.000)
2019-05-03 16:33:42 - INFO - EVALUATING - Epoch: [32][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 1.1118 (1.1725)	Prec@1 65.000 (62.137)	Prec@5 94.000 (93.941)
2019-05-03 16:33:43 - INFO - 
 Epoch: 33	Training Loss 0.8314 	Training Prec@1 71.530 	Training Prec@5 97.846 	Validation Loss 1.1977 	Validation Prec@1 61.350 	Validation Prec@5 93.840 	
2019-05-03 16:33:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:33:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:33:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:33:43 - INFO - TRAINING - Epoch: [33][0/500]	Time 0.337 (0.337)	Data 0.308 (0.308)	Loss 0.9516 (0.9516)	Prec@1 65.000 (65.000)	Prec@5 97.000 (97.000)
2019-05-03 16:33:44 - INFO - TRAINING - Epoch: [33][50/500]	Time 0.020 (0.025)	Data 0.000 (0.006)	Loss 0.6870 (0.8177)	Prec@1 76.000 (72.745)	Prec@5 99.000 (97.961)
2019-05-03 16:33:45 - INFO - TRAINING - Epoch: [33][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 0.9165 (0.8082)	Prec@1 65.000 (72.792)	Prec@5 96.000 (98.119)
2019-05-03 16:33:46 - INFO - TRAINING - Epoch: [33][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.7277 (0.8087)	Prec@1 76.000 (72.722)	Prec@5 97.000 (98.199)
2019-05-03 16:33:47 - INFO - TRAINING - Epoch: [33][200/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 0.9902 (0.8113)	Prec@1 68.000 (72.602)	Prec@5 95.000 (98.179)
2019-05-03 16:33:48 - INFO - TRAINING - Epoch: [33][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7509 (0.8163)	Prec@1 80.000 (72.534)	Prec@5 100.000 (98.163)
2019-05-03 16:33:49 - INFO - TRAINING - Epoch: [33][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8789 (0.8182)	Prec@1 73.000 (72.439)	Prec@5 99.000 (98.130)
2019-05-03 16:33:50 - INFO - TRAINING - Epoch: [33][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7733 (0.8187)	Prec@1 76.000 (72.424)	Prec@5 99.000 (98.080)
2019-05-03 16:33:51 - INFO - TRAINING - Epoch: [33][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.7224 (0.8188)	Prec@1 75.000 (72.451)	Prec@5 99.000 (98.027)
2019-05-03 16:33:52 - INFO - TRAINING - Epoch: [33][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6473 (0.8186)	Prec@1 79.000 (72.408)	Prec@5 99.000 (98.009)
2019-05-03 16:33:53 - INFO - EVALUATING - Epoch: [33][0/100]	Time 0.315 (0.315)	Data 0.309 (0.309)	Loss 1.0973 (1.0973)	Prec@1 59.000 (59.000)	Prec@5 94.000 (94.000)
2019-05-03 16:33:53 - INFO - EVALUATING - Epoch: [33][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 1.2913 (1.1487)	Prec@1 58.000 (60.902)	Prec@5 93.000 (95.784)
2019-05-03 16:33:54 - INFO - 
 Epoch: 34	Training Loss 0.8197 	Training Prec@1 72.390 	Training Prec@5 98.010 	Validation Loss 1.1628 	Validation Prec@1 61.190 	Validation Prec@5 95.810 	
2019-05-03 16:33:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:33:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:33:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:33:54 - INFO - TRAINING - Epoch: [34][0/500]	Time 0.386 (0.386)	Data 0.352 (0.352)	Loss 0.7915 (0.7915)	Prec@1 74.000 (74.000)	Prec@5 100.000 (100.000)
2019-05-03 16:33:55 - INFO - TRAINING - Epoch: [34][50/500]	Time 0.020 (0.026)	Data 0.000 (0.007)	Loss 0.7740 (0.8446)	Prec@1 70.000 (71.000)	Prec@5 99.000 (97.980)
2019-05-03 16:33:56 - INFO - TRAINING - Epoch: [34][100/500]	Time 0.025 (0.023)	Data 0.000 (0.004)	Loss 0.8766 (0.8239)	Prec@1 70.000 (71.465)	Prec@5 99.000 (98.099)
2019-05-03 16:33:57 - INFO - TRAINING - Epoch: [34][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7918 (0.8182)	Prec@1 69.000 (71.854)	Prec@5 99.000 (97.940)
2019-05-03 16:33:58 - INFO - TRAINING - Epoch: [34][200/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.7217 (0.8084)	Prec@1 76.000 (72.318)	Prec@5 100.000 (98.010)
2019-05-03 16:33:59 - INFO - TRAINING - Epoch: [34][250/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.6549 (0.8115)	Prec@1 81.000 (72.223)	Prec@5 100.000 (97.976)
2019-05-03 16:34:00 - INFO - TRAINING - Epoch: [34][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7225 (0.8116)	Prec@1 76.000 (72.266)	Prec@5 98.000 (97.967)
2019-05-03 16:34:01 - INFO - TRAINING - Epoch: [34][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8043 (0.8107)	Prec@1 72.000 (72.487)	Prec@5 99.000 (97.889)
2019-05-03 16:34:02 - INFO - TRAINING - Epoch: [34][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.9730 (0.8105)	Prec@1 65.000 (72.504)	Prec@5 96.000 (97.928)
2019-05-03 16:34:03 - INFO - TRAINING - Epoch: [34][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.8025 (0.8140)	Prec@1 73.000 (72.333)	Prec@5 100.000 (97.920)
2019-05-03 16:34:04 - INFO - EVALUATING - Epoch: [34][0/100]	Time 0.344 (0.344)	Data 0.336 (0.336)	Loss 1.0465 (1.0465)	Prec@1 64.000 (64.000)	Prec@5 98.000 (98.000)
2019-05-03 16:34:05 - INFO - EVALUATING - Epoch: [34][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.8463 (0.9661)	Prec@1 74.000 (67.039)	Prec@5 97.000 (96.529)
2019-05-03 16:34:05 - INFO - 
 Epoch: 35	Training Loss 0.8116 	Training Prec@1 72.382 	Training Prec@5 97.964 	Validation Loss 0.9712 	Validation Prec@1 66.490 	Validation Prec@5 96.970 	
2019-05-03 16:34:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:34:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:34:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:34:05 - INFO - TRAINING - Epoch: [35][0/500]	Time 0.341 (0.341)	Data 0.313 (0.313)	Loss 0.6746 (0.6746)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-05-03 16:34:06 - INFO - TRAINING - Epoch: [35][50/500]	Time 0.028 (0.026)	Data 0.000 (0.006)	Loss 0.8281 (0.8106)	Prec@1 71.000 (72.412)	Prec@5 97.000 (98.157)
2019-05-03 16:34:07 - INFO - TRAINING - Epoch: [35][100/500]	Time 0.023 (0.024)	Data 0.000 (0.003)	Loss 0.8501 (0.8146)	Prec@1 69.000 (72.495)	Prec@5 100.000 (98.099)
2019-05-03 16:34:08 - INFO - TRAINING - Epoch: [35][150/500]	Time 0.019 (0.023)	Data 0.000 (0.002)	Loss 0.8419 (0.8074)	Prec@1 71.000 (72.894)	Prec@5 96.000 (98.060)
2019-05-03 16:34:09 - INFO - TRAINING - Epoch: [35][200/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.8509 (0.8099)	Prec@1 71.000 (72.791)	Prec@5 97.000 (97.965)
2019-05-03 16:34:10 - INFO - TRAINING - Epoch: [35][250/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.8562 (0.8048)	Prec@1 73.000 (72.833)	Prec@5 98.000 (98.044)
2019-05-03 16:34:11 - INFO - TRAINING - Epoch: [35][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.8767 (0.8084)	Prec@1 72.000 (72.728)	Prec@5 98.000 (98.020)
2019-05-03 16:34:12 - INFO - TRAINING - Epoch: [35][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7147 (0.8067)	Prec@1 78.000 (72.746)	Prec@5 99.000 (98.031)
2019-05-03 16:34:13 - INFO - TRAINING - Epoch: [35][400/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7603 (0.8043)	Prec@1 80.000 (72.783)	Prec@5 97.000 (98.047)
2019-05-03 16:34:14 - INFO - TRAINING - Epoch: [35][450/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7733 (0.8035)	Prec@1 76.000 (72.823)	Prec@5 100.000 (98.044)
2019-05-03 16:34:16 - INFO - EVALUATING - Epoch: [35][0/100]	Time 0.334 (0.334)	Data 0.322 (0.322)	Loss 0.7313 (0.7313)	Prec@1 72.000 (72.000)	Prec@5 100.000 (100.000)
2019-05-03 16:34:16 - INFO - EVALUATING - Epoch: [35][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.9615 (0.9645)	Prec@1 67.000 (67.608)	Prec@5 95.000 (97.216)
2019-05-03 16:34:16 - INFO - 
 Epoch: 36	Training Loss 0.8029 	Training Prec@1 72.822 	Training Prec@5 98.022 	Validation Loss 0.9696 	Validation Prec@1 66.920 	Validation Prec@5 97.340 	
2019-05-03 16:34:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:34:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:34:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:34:17 - INFO - TRAINING - Epoch: [36][0/500]	Time 0.347 (0.347)	Data 0.321 (0.321)	Loss 0.7069 (0.7069)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:34:18 - INFO - TRAINING - Epoch: [36][50/500]	Time 0.025 (0.026)	Data 0.000 (0.006)	Loss 0.7994 (0.7904)	Prec@1 69.000 (73.451)	Prec@5 96.000 (98.078)
2019-05-03 16:34:19 - INFO - TRAINING - Epoch: [36][100/500]	Time 0.021 (0.023)	Data 0.000 (0.003)	Loss 0.7281 (0.7805)	Prec@1 76.000 (73.743)	Prec@5 97.000 (98.099)
2019-05-03 16:34:20 - INFO - TRAINING - Epoch: [36][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.8076 (0.7905)	Prec@1 70.000 (73.311)	Prec@5 100.000 (98.099)
2019-05-03 16:34:21 - INFO - TRAINING - Epoch: [36][200/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 1.0651 (0.7854)	Prec@1 65.000 (73.562)	Prec@5 94.000 (98.139)
2019-05-03 16:34:22 - INFO - TRAINING - Epoch: [36][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8093 (0.7876)	Prec@1 68.000 (73.442)	Prec@5 99.000 (98.088)
2019-05-03 16:34:22 - INFO - TRAINING - Epoch: [36][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8490 (0.7921)	Prec@1 68.000 (73.286)	Prec@5 98.000 (98.066)
2019-05-03 16:34:23 - INFO - TRAINING - Epoch: [36][350/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.5750 (0.7890)	Prec@1 80.000 (73.348)	Prec@5 100.000 (98.074)
2019-05-03 16:34:24 - INFO - TRAINING - Epoch: [36][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.8309 (0.7865)	Prec@1 71.000 (73.434)	Prec@5 99.000 (98.082)
2019-05-03 16:34:25 - INFO - TRAINING - Epoch: [36][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7602 (0.7871)	Prec@1 75.000 (73.412)	Prec@5 99.000 (98.067)
2019-05-03 16:34:27 - INFO - EVALUATING - Epoch: [36][0/100]	Time 0.303 (0.303)	Data 0.294 (0.294)	Loss 1.0766 (1.0766)	Prec@1 65.000 (65.000)	Prec@5 93.000 (93.000)
2019-05-03 16:34:27 - INFO - EVALUATING - Epoch: [36][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 1.4176 (1.3615)	Prec@1 58.000 (57.255)	Prec@5 90.000 (92.667)
2019-05-03 16:34:27 - INFO - 
 Epoch: 37	Training Loss 0.7908 	Training Prec@1 73.308 	Training Prec@5 98.048 	Validation Loss 1.3546 	Validation Prec@1 57.340 	Validation Prec@5 92.650 	
2019-05-03 16:34:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:34:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:34:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:34:28 - INFO - TRAINING - Epoch: [37][0/500]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.9171 (0.9171)	Prec@1 74.000 (74.000)	Prec@5 96.000 (96.000)
2019-05-03 16:34:29 - INFO - TRAINING - Epoch: [37][50/500]	Time 0.030 (0.027)	Data 0.000 (0.007)	Loss 0.8233 (0.8050)	Prec@1 71.000 (72.941)	Prec@5 97.000 (97.745)
2019-05-03 16:34:30 - INFO - TRAINING - Epoch: [37][100/500]	Time 0.015 (0.023)	Data 0.000 (0.003)	Loss 0.9367 (0.8074)	Prec@1 67.000 (72.970)	Prec@5 99.000 (97.802)
2019-05-03 16:34:31 - INFO - TRAINING - Epoch: [37][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.6122 (0.7920)	Prec@1 80.000 (73.113)	Prec@5 98.000 (98.007)
2019-05-03 16:34:32 - INFO - TRAINING - Epoch: [37][200/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.8002 (0.7803)	Prec@1 70.000 (73.423)	Prec@5 99.000 (98.154)
2019-05-03 16:34:33 - INFO - TRAINING - Epoch: [37][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7018 (0.7786)	Prec@1 78.000 (73.586)	Prec@5 98.000 (98.159)
2019-05-03 16:34:34 - INFO - TRAINING - Epoch: [37][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8954 (0.7847)	Prec@1 68.000 (73.399)	Prec@5 97.000 (98.106)
2019-05-03 16:34:35 - INFO - TRAINING - Epoch: [37][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.8952 (0.7832)	Prec@1 71.000 (73.416)	Prec@5 95.000 (98.103)
2019-05-03 16:34:36 - INFO - TRAINING - Epoch: [37][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.8028 (0.7847)	Prec@1 72.000 (73.309)	Prec@5 97.000 (98.095)
2019-05-03 16:34:37 - INFO - TRAINING - Epoch: [37][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7982 (0.7841)	Prec@1 75.000 (73.341)	Prec@5 97.000 (98.075)
2019-05-03 16:34:38 - INFO - EVALUATING - Epoch: [37][0/100]	Time 0.262 (0.262)	Data 0.250 (0.250)	Loss 0.7782 (0.7782)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-03 16:34:38 - INFO - EVALUATING - Epoch: [37][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.7975 (0.8489)	Prec@1 77.000 (71.176)	Prec@5 97.000 (97.490)
2019-05-03 16:34:38 - INFO - 
 Epoch: 38	Training Loss 0.7843 	Training Prec@1 73.334 	Training Prec@5 98.096 	Validation Loss 0.8410 	Validation Prec@1 71.460 	Validation Prec@5 97.700 	
2019-05-03 16:34:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:34:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:34:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:34:39 - INFO - TRAINING - Epoch: [38][0/500]	Time 0.253 (0.253)	Data 0.228 (0.228)	Loss 0.6268 (0.6268)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-05-03 16:34:40 - INFO - TRAINING - Epoch: [38][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.7657 (0.7355)	Prec@1 75.000 (75.196)	Prec@5 98.000 (98.275)
2019-05-03 16:34:41 - INFO - TRAINING - Epoch: [38][100/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.7950 (0.7575)	Prec@1 77.000 (74.149)	Prec@5 97.000 (98.099)
2019-05-03 16:34:42 - INFO - TRAINING - Epoch: [38][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.7035 (0.7581)	Prec@1 73.000 (74.139)	Prec@5 100.000 (98.159)
2019-05-03 16:34:43 - INFO - TRAINING - Epoch: [38][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7475 (0.7555)	Prec@1 77.000 (74.388)	Prec@5 97.000 (98.244)
2019-05-03 16:34:44 - INFO - TRAINING - Epoch: [38][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7544 (0.7596)	Prec@1 76.000 (74.223)	Prec@5 97.000 (98.195)
2019-05-03 16:34:45 - INFO - TRAINING - Epoch: [38][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7675 (0.7604)	Prec@1 73.000 (74.233)	Prec@5 98.000 (98.140)
2019-05-03 16:34:46 - INFO - TRAINING - Epoch: [38][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5751 (0.7657)	Prec@1 81.000 (74.068)	Prec@5 100.000 (98.131)
2019-05-03 16:34:47 - INFO - TRAINING - Epoch: [38][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.6418 (0.7668)	Prec@1 76.000 (73.963)	Prec@5 100.000 (98.147)
2019-05-03 16:34:48 - INFO - TRAINING - Epoch: [38][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.8160 (0.7694)	Prec@1 72.000 (73.880)	Prec@5 96.000 (98.169)
2019-05-03 16:34:49 - INFO - EVALUATING - Epoch: [38][0/100]	Time 0.350 (0.350)	Data 0.340 (0.340)	Loss 0.9227 (0.9227)	Prec@1 61.000 (61.000)	Prec@5 99.000 (99.000)
2019-05-03 16:34:49 - INFO - EVALUATING - Epoch: [38][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.0809 (1.0179)	Prec@1 64.000 (65.392)	Prec@5 96.000 (96.608)
2019-05-03 16:34:50 - INFO - 
 Epoch: 39	Training Loss 0.7700 	Training Prec@1 73.852 	Training Prec@5 98.176 	Validation Loss 1.0120 	Validation Prec@1 65.220 	Validation Prec@5 97.030 	
2019-05-03 16:34:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:34:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:34:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:34:50 - INFO - TRAINING - Epoch: [39][0/500]	Time 0.349 (0.349)	Data 0.318 (0.318)	Loss 0.9536 (0.9536)	Prec@1 69.000 (69.000)	Prec@5 96.000 (96.000)
2019-05-03 16:34:51 - INFO - TRAINING - Epoch: [39][50/500]	Time 0.030 (0.027)	Data 0.000 (0.006)	Loss 0.7448 (0.7795)	Prec@1 72.000 (73.745)	Prec@5 100.000 (98.157)
2019-05-03 16:34:52 - INFO - TRAINING - Epoch: [39][100/500]	Time 0.032 (0.023)	Data 0.000 (0.003)	Loss 0.7175 (0.7905)	Prec@1 75.000 (73.406)	Prec@5 100.000 (98.158)
2019-05-03 16:34:53 - INFO - TRAINING - Epoch: [39][150/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.6411 (0.7754)	Prec@1 80.000 (73.954)	Prec@5 99.000 (98.245)
2019-05-03 16:34:54 - INFO - TRAINING - Epoch: [39][200/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.7832 (0.7768)	Prec@1 73.000 (73.677)	Prec@5 98.000 (98.189)
2019-05-03 16:34:55 - INFO - TRAINING - Epoch: [39][250/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7609 (0.7757)	Prec@1 73.000 (73.717)	Prec@5 97.000 (98.191)
2019-05-03 16:34:56 - INFO - TRAINING - Epoch: [39][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8010 (0.7779)	Prec@1 73.000 (73.691)	Prec@5 97.000 (98.176)
2019-05-03 16:34:57 - INFO - TRAINING - Epoch: [39][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.8657 (0.7789)	Prec@1 67.000 (73.581)	Prec@5 98.000 (98.154)
2019-05-03 16:34:58 - INFO - TRAINING - Epoch: [39][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.5879 (0.7736)	Prec@1 79.000 (73.761)	Prec@5 98.000 (98.177)
2019-05-03 16:34:59 - INFO - TRAINING - Epoch: [39][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5886 (0.7723)	Prec@1 78.000 (73.823)	Prec@5 100.000 (98.155)
2019-05-03 16:35:00 - INFO - EVALUATING - Epoch: [39][0/100]	Time 0.341 (0.341)	Data 0.332 (0.332)	Loss 0.8410 (0.8410)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 16:35:00 - INFO - EVALUATING - Epoch: [39][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.9324 (0.9822)	Prec@1 68.000 (67.588)	Prec@5 97.000 (96.510)
2019-05-03 16:35:01 - INFO - 
 Epoch: 40	Training Loss 0.7728 	Training Prec@1 73.834 	Training Prec@5 98.154 	Validation Loss 0.9765 	Validation Prec@1 67.440 	Validation Prec@5 96.650 	
2019-05-03 16:35:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:01 - INFO - TRAINING - Epoch: [40][0/500]	Time 0.279 (0.279)	Data 0.247 (0.247)	Loss 0.8307 (0.8307)	Prec@1 69.000 (69.000)	Prec@5 98.000 (98.000)
2019-05-03 16:35:02 - INFO - TRAINING - Epoch: [40][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 1.0356 (0.7635)	Prec@1 67.000 (73.431)	Prec@5 98.000 (98.353)
2019-05-03 16:35:03 - INFO - TRAINING - Epoch: [40][100/500]	Time 0.013 (0.022)	Data 0.000 (0.003)	Loss 0.5670 (0.7615)	Prec@1 82.000 (74.020)	Prec@5 100.000 (98.376)
2019-05-03 16:35:04 - INFO - TRAINING - Epoch: [40][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.8521 (0.7530)	Prec@1 71.000 (74.159)	Prec@5 97.000 (98.411)
2019-05-03 16:35:05 - INFO - TRAINING - Epoch: [40][200/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6159 (0.7481)	Prec@1 81.000 (74.239)	Prec@5 99.000 (98.448)
2019-05-03 16:35:06 - INFO - TRAINING - Epoch: [40][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8329 (0.7496)	Prec@1 68.000 (74.275)	Prec@5 100.000 (98.367)
2019-05-03 16:35:07 - INFO - TRAINING - Epoch: [40][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7371 (0.7491)	Prec@1 73.000 (74.296)	Prec@5 97.000 (98.329)
2019-05-03 16:35:08 - INFO - TRAINING - Epoch: [40][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5714 (0.7495)	Prec@1 82.000 (74.442)	Prec@5 98.000 (98.328)
2019-05-03 16:35:09 - INFO - TRAINING - Epoch: [40][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.8078 (0.7497)	Prec@1 75.000 (74.486)	Prec@5 97.000 (98.334)
2019-05-03 16:35:10 - INFO - TRAINING - Epoch: [40][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7175 (0.7522)	Prec@1 75.000 (74.475)	Prec@5 97.000 (98.293)
2019-05-03 16:35:11 - INFO - EVALUATING - Epoch: [40][0/100]	Time 0.320 (0.320)	Data 0.313 (0.313)	Loss 0.7229 (0.7229)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:35:12 - INFO - EVALUATING - Epoch: [40][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.6965 (0.7532)	Prec@1 79.000 (74.784)	Prec@5 98.000 (97.902)
2019-05-03 16:35:12 - INFO - 
 Epoch: 41	Training Loss 0.7507 	Training Prec@1 74.540 	Training Prec@5 98.288 	Validation Loss 0.7689 	Validation Prec@1 73.840 	Validation Prec@5 98.040 	
2019-05-03 16:35:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:12 - INFO - TRAINING - Epoch: [41][0/500]	Time 0.360 (0.360)	Data 0.334 (0.334)	Loss 0.6554 (0.6554)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-05-03 16:35:13 - INFO - TRAINING - Epoch: [41][50/500]	Time 0.017 (0.025)	Data 0.000 (0.007)	Loss 0.7583 (0.7579)	Prec@1 72.000 (74.255)	Prec@5 99.000 (97.980)
2019-05-03 16:35:14 - INFO - TRAINING - Epoch: [41][100/500]	Time 0.025 (0.023)	Data 0.000 (0.003)	Loss 0.9581 (0.7377)	Prec@1 71.000 (75.416)	Prec@5 96.000 (98.119)
2019-05-03 16:35:15 - INFO - TRAINING - Epoch: [41][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.6752 (0.7381)	Prec@1 75.000 (75.272)	Prec@5 99.000 (98.152)
2019-05-03 16:35:16 - INFO - TRAINING - Epoch: [41][200/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.8046 (0.7460)	Prec@1 69.000 (74.915)	Prec@5 99.000 (98.129)
2019-05-03 16:35:17 - INFO - TRAINING - Epoch: [41][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.7336 (0.7506)	Prec@1 75.000 (74.733)	Prec@5 99.000 (98.120)
2019-05-03 16:35:18 - INFO - TRAINING - Epoch: [41][300/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.8100 (0.7508)	Prec@1 73.000 (74.671)	Prec@5 98.000 (98.126)
2019-05-03 16:35:19 - INFO - TRAINING - Epoch: [41][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6699 (0.7503)	Prec@1 77.000 (74.650)	Prec@5 99.000 (98.179)
2019-05-03 16:35:20 - INFO - TRAINING - Epoch: [41][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5689 (0.7500)	Prec@1 76.000 (74.613)	Prec@5 99.000 (98.197)
2019-05-03 16:35:21 - INFO - TRAINING - Epoch: [41][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.7696 (0.7497)	Prec@1 74.000 (74.572)	Prec@5 98.000 (98.224)
2019-05-03 16:35:22 - INFO - EVALUATING - Epoch: [41][0/100]	Time 0.349 (0.349)	Data 0.340 (0.340)	Loss 0.7835 (0.7835)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:35:23 - INFO - EVALUATING - Epoch: [41][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.6954 (0.8143)	Prec@1 82.000 (72.980)	Prec@5 98.000 (97.627)
2019-05-03 16:35:23 - INFO - 
 Epoch: 42	Training Loss 0.7478 	Training Prec@1 74.680 	Training Prec@5 98.250 	Validation Loss 0.8157 	Validation Prec@1 72.820 	Validation Prec@5 97.900 	
2019-05-03 16:35:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:23 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:23 - INFO - TRAINING - Epoch: [42][0/500]	Time 0.356 (0.356)	Data 0.335 (0.335)	Loss 0.7118 (0.7118)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:35:24 - INFO - TRAINING - Epoch: [42][50/500]	Time 0.027 (0.026)	Data 0.000 (0.007)	Loss 0.7633 (0.7603)	Prec@1 75.000 (74.353)	Prec@5 99.000 (98.235)
2019-05-03 16:35:25 - INFO - TRAINING - Epoch: [42][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.6626 (0.7647)	Prec@1 73.000 (74.188)	Prec@5 100.000 (98.337)
2019-05-03 16:35:26 - INFO - TRAINING - Epoch: [42][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.5976 (0.7624)	Prec@1 79.000 (74.305)	Prec@5 99.000 (98.364)
2019-05-03 16:35:27 - INFO - TRAINING - Epoch: [42][200/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.5755 (0.7573)	Prec@1 78.000 (74.711)	Prec@5 99.000 (98.274)
2019-05-03 16:35:28 - INFO - TRAINING - Epoch: [42][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.7681 (0.7558)	Prec@1 76.000 (74.749)	Prec@5 98.000 (98.251)
2019-05-03 16:35:29 - INFO - TRAINING - Epoch: [42][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8945 (0.7520)	Prec@1 66.000 (74.704)	Prec@5 99.000 (98.316)
2019-05-03 16:35:30 - INFO - TRAINING - Epoch: [42][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7833 (0.7518)	Prec@1 71.000 (74.704)	Prec@5 97.000 (98.282)
2019-05-03 16:35:31 - INFO - TRAINING - Epoch: [42][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7396 (0.7494)	Prec@1 69.000 (74.723)	Prec@5 100.000 (98.282)
2019-05-03 16:35:32 - INFO - TRAINING - Epoch: [42][450/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.7958 (0.7450)	Prec@1 79.000 (74.871)	Prec@5 98.000 (98.288)
2019-05-03 16:35:34 - INFO - EVALUATING - Epoch: [42][0/100]	Time 0.328 (0.328)	Data 0.320 (0.320)	Loss 1.6203 (1.6203)	Prec@1 47.000 (47.000)	Prec@5 91.000 (91.000)
2019-05-03 16:35:34 - INFO - EVALUATING - Epoch: [42][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 1.6514 (1.6528)	Prec@1 49.000 (51.196)	Prec@5 92.000 (88.569)
2019-05-03 16:35:34 - INFO - 
 Epoch: 43	Training Loss 0.7471 	Training Prec@1 74.804 	Training Prec@5 98.280 	Validation Loss 1.6456 	Validation Prec@1 51.440 	Validation Prec@5 88.360 	
2019-05-03 16:35:34 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:34 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:34 - INFO - TRAINING - Epoch: [43][0/500]	Time 0.254 (0.254)	Data 0.230 (0.230)	Loss 0.8094 (0.8094)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-05-03 16:35:36 - INFO - TRAINING - Epoch: [43][50/500]	Time 0.019 (0.026)	Data 0.000 (0.005)	Loss 0.7627 (0.7435)	Prec@1 73.000 (75.137)	Prec@5 99.000 (98.196)
2019-05-03 16:35:37 - INFO - TRAINING - Epoch: [43][100/500]	Time 0.025 (0.024)	Data 0.000 (0.002)	Loss 0.8864 (0.7448)	Prec@1 69.000 (74.960)	Prec@5 98.000 (98.248)
2019-05-03 16:35:38 - INFO - TRAINING - Epoch: [43][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.6451 (0.7398)	Prec@1 79.000 (75.126)	Prec@5 99.000 (98.311)
2019-05-03 16:35:38 - INFO - TRAINING - Epoch: [43][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6036 (0.7439)	Prec@1 81.000 (75.010)	Prec@5 100.000 (98.299)
2019-05-03 16:35:39 - INFO - TRAINING - Epoch: [43][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8203 (0.7425)	Prec@1 70.000 (75.008)	Prec@5 100.000 (98.375)
2019-05-03 16:35:41 - INFO - TRAINING - Epoch: [43][300/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6020 (0.7400)	Prec@1 78.000 (75.249)	Prec@5 100.000 (98.342)
2019-05-03 16:35:42 - INFO - TRAINING - Epoch: [43][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6921 (0.7386)	Prec@1 73.000 (75.131)	Prec@5 99.000 (98.356)
2019-05-03 16:35:42 - INFO - TRAINING - Epoch: [43][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.9477 (0.7381)	Prec@1 69.000 (75.175)	Prec@5 95.000 (98.372)
2019-05-03 16:35:44 - INFO - TRAINING - Epoch: [43][450/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5654 (0.7393)	Prec@1 82.000 (75.144)	Prec@5 98.000 (98.333)
2019-05-03 16:35:45 - INFO - EVALUATING - Epoch: [43][0/100]	Time 0.349 (0.349)	Data 0.342 (0.342)	Loss 1.0922 (1.0922)	Prec@1 60.000 (60.000)	Prec@5 95.000 (95.000)
2019-05-03 16:35:45 - INFO - EVALUATING - Epoch: [43][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 1.1439 (1.0975)	Prec@1 63.000 (63.412)	Prec@5 97.000 (95.784)
2019-05-03 16:35:45 - INFO - 
 Epoch: 44	Training Loss 0.7404 	Training Prec@1 75.090 	Training Prec@5 98.312 	Validation Loss 1.0923 	Validation Prec@1 63.190 	Validation Prec@5 96.010 	
2019-05-03 16:35:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:46 - INFO - TRAINING - Epoch: [44][0/500]	Time 0.336 (0.336)	Data 0.305 (0.305)	Loss 0.6042 (0.6042)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:35:47 - INFO - TRAINING - Epoch: [44][50/500]	Time 0.012 (0.025)	Data 0.000 (0.006)	Loss 0.5564 (0.7287)	Prec@1 83.000 (75.333)	Prec@5 99.000 (98.275)
2019-05-03 16:35:48 - INFO - TRAINING - Epoch: [44][100/500]	Time 0.028 (0.023)	Data 0.000 (0.003)	Loss 0.7190 (0.7175)	Prec@1 75.000 (75.871)	Prec@5 98.000 (98.366)
2019-05-03 16:35:49 - INFO - TRAINING - Epoch: [44][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.6220 (0.7305)	Prec@1 78.000 (75.245)	Prec@5 100.000 (98.344)
2019-05-03 16:35:50 - INFO - TRAINING - Epoch: [44][200/500]	Time 0.031 (0.021)	Data 0.000 (0.002)	Loss 0.9868 (0.7325)	Prec@1 67.000 (75.194)	Prec@5 98.000 (98.383)
2019-05-03 16:35:51 - INFO - TRAINING - Epoch: [44][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6695 (0.7346)	Prec@1 77.000 (75.251)	Prec@5 100.000 (98.382)
2019-05-03 16:35:52 - INFO - TRAINING - Epoch: [44][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5858 (0.7328)	Prec@1 81.000 (75.342)	Prec@5 99.000 (98.372)
2019-05-03 16:35:53 - INFO - TRAINING - Epoch: [44][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7682 (0.7302)	Prec@1 73.000 (75.473)	Prec@5 98.000 (98.350)
2019-05-03 16:35:54 - INFO - TRAINING - Epoch: [44][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6150 (0.7305)	Prec@1 79.000 (75.466)	Prec@5 99.000 (98.337)
2019-05-03 16:35:55 - INFO - TRAINING - Epoch: [44][450/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.6518 (0.7318)	Prec@1 79.000 (75.341)	Prec@5 99.000 (98.359)
2019-05-03 16:35:56 - INFO - EVALUATING - Epoch: [44][0/100]	Time 0.344 (0.344)	Data 0.336 (0.336)	Loss 0.9528 (0.9528)	Prec@1 69.000 (69.000)	Prec@5 97.000 (97.000)
2019-05-03 16:35:56 - INFO - EVALUATING - Epoch: [44][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.2210 (1.0047)	Prec@1 59.000 (66.098)	Prec@5 95.000 (97.078)
2019-05-03 16:35:57 - INFO - 
 Epoch: 45	Training Loss 0.7309 	Training Prec@1 75.388 	Training Prec@5 98.376 	Validation Loss 0.9910 	Validation Prec@1 66.300 	Validation Prec@5 97.340 	
2019-05-03 16:35:57 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:35:57 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:35:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:35:57 - INFO - TRAINING - Epoch: [45][0/500]	Time 0.264 (0.264)	Data 0.228 (0.228)	Loss 0.7491 (0.7491)	Prec@1 73.000 (73.000)	Prec@5 97.000 (97.000)
2019-05-03 16:35:58 - INFO - TRAINING - Epoch: [45][50/500]	Time 0.034 (0.025)	Data 0.000 (0.005)	Loss 0.8660 (0.7099)	Prec@1 72.000 (75.980)	Prec@5 98.000 (98.431)
2019-05-03 16:35:59 - INFO - TRAINING - Epoch: [45][100/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.8410 (0.7238)	Prec@1 73.000 (75.673)	Prec@5 100.000 (98.366)
2019-05-03 16:36:00 - INFO - TRAINING - Epoch: [45][150/500]	Time 0.012 (0.021)	Data 0.000 (0.002)	Loss 0.5566 (0.7167)	Prec@1 77.000 (75.788)	Prec@5 100.000 (98.444)
2019-05-03 16:36:01 - INFO - TRAINING - Epoch: [45][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7860 (0.7171)	Prec@1 78.000 (75.761)	Prec@5 97.000 (98.388)
2019-05-03 16:36:02 - INFO - TRAINING - Epoch: [45][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.8529 (0.7216)	Prec@1 72.000 (75.769)	Prec@5 98.000 (98.355)
2019-05-03 16:36:03 - INFO - TRAINING - Epoch: [45][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5466 (0.7234)	Prec@1 88.000 (75.631)	Prec@5 97.000 (98.355)
2019-05-03 16:36:04 - INFO - TRAINING - Epoch: [45][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.8043 (0.7233)	Prec@1 72.000 (75.533)	Prec@5 99.000 (98.353)
2019-05-03 16:36:05 - INFO - TRAINING - Epoch: [45][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5548 (0.7247)	Prec@1 84.000 (75.544)	Prec@5 99.000 (98.322)
2019-05-03 16:36:06 - INFO - TRAINING - Epoch: [45][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.7910 (0.7269)	Prec@1 73.000 (75.390)	Prec@5 98.000 (98.344)
2019-05-03 16:36:07 - INFO - EVALUATING - Epoch: [45][0/100]	Time 0.260 (0.260)	Data 0.246 (0.246)	Loss 0.7034 (0.7034)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:07 - INFO - EVALUATING - Epoch: [45][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 0.8854 (0.8579)	Prec@1 68.000 (71.471)	Prec@5 98.000 (97.647)
2019-05-03 16:36:08 - INFO - 
 Epoch: 46	Training Loss 0.7283 	Training Prec@1 75.324 	Training Prec@5 98.346 	Validation Loss 0.8625 	Validation Prec@1 70.790 	Validation Prec@5 97.830 	
2019-05-03 16:36:08 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:36:08 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:36:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:36:08 - INFO - TRAINING - Epoch: [46][0/500]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 0.7082 (0.7082)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 16:36:09 - INFO - TRAINING - Epoch: [46][50/500]	Time 0.020 (0.026)	Data 0.000 (0.007)	Loss 0.7035 (0.7168)	Prec@1 75.000 (75.941)	Prec@5 99.000 (98.373)
2019-05-03 16:36:10 - INFO - TRAINING - Epoch: [46][100/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 0.7174 (0.7236)	Prec@1 81.000 (75.802)	Prec@5 100.000 (98.396)
2019-05-03 16:36:11 - INFO - TRAINING - Epoch: [46][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.5678 (0.7222)	Prec@1 82.000 (75.755)	Prec@5 98.000 (98.490)
2019-05-03 16:36:12 - INFO - TRAINING - Epoch: [46][200/500]	Time 0.021 (0.020)	Data 0.000 (0.002)	Loss 0.7501 (0.7243)	Prec@1 75.000 (75.687)	Prec@5 99.000 (98.428)
2019-05-03 16:36:13 - INFO - TRAINING - Epoch: [46][250/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7643 (0.7210)	Prec@1 71.000 (75.737)	Prec@5 99.000 (98.430)
2019-05-03 16:36:14 - INFO - TRAINING - Epoch: [46][300/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6272 (0.7163)	Prec@1 78.000 (75.900)	Prec@5 100.000 (98.495)
2019-05-03 16:36:14 - INFO - TRAINING - Epoch: [46][350/500]	Time 0.013 (0.019)	Data 0.000 (0.001)	Loss 0.7429 (0.7169)	Prec@1 72.000 (75.840)	Prec@5 98.000 (98.444)
2019-05-03 16:36:15 - INFO - TRAINING - Epoch: [46][400/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.9451 (0.7183)	Prec@1 68.000 (75.850)	Prec@5 97.000 (98.439)
2019-05-03 16:36:16 - INFO - TRAINING - Epoch: [46][450/500]	Time 0.017 (0.019)	Data 0.000 (0.001)	Loss 0.6937 (0.7216)	Prec@1 76.000 (75.772)	Prec@5 97.000 (98.401)
2019-05-03 16:36:17 - INFO - EVALUATING - Epoch: [46][0/100]	Time 0.346 (0.346)	Data 0.330 (0.330)	Loss 0.6942 (0.6942)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 16:36:18 - INFO - EVALUATING - Epoch: [46][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6942 (0.7486)	Prec@1 76.000 (75.059)	Prec@5 97.000 (97.863)
2019-05-03 16:36:18 - INFO - 
 Epoch: 47	Training Loss 0.7222 	Training Prec@1 75.770 	Training Prec@5 98.400 	Validation Loss 0.7452 	Validation Prec@1 75.120 	Validation Prec@5 98.110 	
2019-05-03 16:36:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:36:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:36:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:36:18 - INFO - TRAINING - Epoch: [47][0/500]	Time 0.327 (0.327)	Data 0.305 (0.305)	Loss 0.6873 (0.6873)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:19 - INFO - TRAINING - Epoch: [47][50/500]	Time 0.023 (0.024)	Data 0.000 (0.006)	Loss 0.5788 (0.7358)	Prec@1 82.000 (75.627)	Prec@5 99.000 (98.176)
2019-05-03 16:36:20 - INFO - TRAINING - Epoch: [47][100/500]	Time 0.017 (0.021)	Data 0.000 (0.003)	Loss 0.6023 (0.7132)	Prec@1 81.000 (76.188)	Prec@5 99.000 (98.376)
2019-05-03 16:36:21 - INFO - TRAINING - Epoch: [47][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.8821 (0.7188)	Prec@1 69.000 (76.033)	Prec@5 99.000 (98.377)
2019-05-03 16:36:22 - INFO - TRAINING - Epoch: [47][200/500]	Time 0.018 (0.020)	Data 0.000 (0.002)	Loss 0.7591 (0.7208)	Prec@1 75.000 (75.915)	Prec@5 100.000 (98.343)
2019-05-03 16:36:23 - INFO - TRAINING - Epoch: [47][250/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.8023 (0.7188)	Prec@1 74.000 (75.992)	Prec@5 100.000 (98.390)
2019-05-03 16:36:24 - INFO - TRAINING - Epoch: [47][300/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.7221 (0.7177)	Prec@1 77.000 (76.103)	Prec@5 99.000 (98.389)
2019-05-03 16:36:25 - INFO - TRAINING - Epoch: [47][350/500]	Time 0.028 (0.019)	Data 0.000 (0.001)	Loss 0.7270 (0.7170)	Prec@1 79.000 (76.063)	Prec@5 97.000 (98.387)
2019-05-03 16:36:26 - INFO - TRAINING - Epoch: [47][400/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 0.6212 (0.7182)	Prec@1 81.000 (76.010)	Prec@5 100.000 (98.372)
2019-05-03 16:36:27 - INFO - TRAINING - Epoch: [47][450/500]	Time 0.026 (0.019)	Data 0.000 (0.001)	Loss 0.4980 (0.7180)	Prec@1 85.000 (75.989)	Prec@5 98.000 (98.406)
2019-05-03 16:36:28 - INFO - EVALUATING - Epoch: [47][0/100]	Time 0.358 (0.358)	Data 0.345 (0.345)	Loss 0.7144 (0.7144)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:28 - INFO - EVALUATING - Epoch: [47][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.8633 (0.8404)	Prec@1 75.000 (71.588)	Prec@5 97.000 (97.471)
2019-05-03 16:36:29 - INFO - 
 Epoch: 48	Training Loss 0.7166 	Training Prec@1 76.006 	Training Prec@5 98.422 	Validation Loss 0.8491 	Validation Prec@1 71.120 	Validation Prec@5 97.550 	
2019-05-03 16:36:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:36:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:36:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:36:29 - INFO - TRAINING - Epoch: [48][0/500]	Time 0.268 (0.268)	Data 0.239 (0.239)	Loss 0.8508 (0.8508)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:30 - INFO - TRAINING - Epoch: [48][50/500]	Time 0.029 (0.025)	Data 0.000 (0.005)	Loss 0.5925 (0.7037)	Prec@1 82.000 (77.059)	Prec@5 99.000 (98.784)
2019-05-03 16:36:31 - INFO - TRAINING - Epoch: [48][100/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.5818 (0.7211)	Prec@1 78.000 (76.000)	Prec@5 98.000 (98.465)
2019-05-03 16:36:32 - INFO - TRAINING - Epoch: [48][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7229 (0.7201)	Prec@1 74.000 (76.179)	Prec@5 99.000 (98.397)
2019-05-03 16:36:33 - INFO - TRAINING - Epoch: [48][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7764 (0.7135)	Prec@1 81.000 (76.423)	Prec@5 97.000 (98.413)
2019-05-03 16:36:34 - INFO - TRAINING - Epoch: [48][250/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.7103 (0.7193)	Prec@1 76.000 (76.147)	Prec@5 100.000 (98.343)
2019-05-03 16:36:35 - INFO - TRAINING - Epoch: [48][300/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6327 (0.7189)	Prec@1 80.000 (76.056)	Prec@5 100.000 (98.362)
2019-05-03 16:36:36 - INFO - TRAINING - Epoch: [48][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7486 (0.7191)	Prec@1 74.000 (75.960)	Prec@5 99.000 (98.348)
2019-05-03 16:36:37 - INFO - TRAINING - Epoch: [48][400/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.6920 (0.7149)	Prec@1 76.000 (76.097)	Prec@5 99.000 (98.362)
2019-05-03 16:36:38 - INFO - TRAINING - Epoch: [48][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5554 (0.7127)	Prec@1 82.000 (76.195)	Prec@5 98.000 (98.357)
2019-05-03 16:36:39 - INFO - EVALUATING - Epoch: [48][0/100]	Time 0.340 (0.340)	Data 0.328 (0.328)	Loss 0.8811 (0.8811)	Prec@1 68.000 (68.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:39 - INFO - EVALUATING - Epoch: [48][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 1.0218 (0.9902)	Prec@1 65.000 (67.784)	Prec@5 98.000 (96.922)
2019-05-03 16:36:39 - INFO - 
 Epoch: 49	Training Loss 0.7124 	Training Prec@1 76.202 	Training Prec@5 98.360 	Validation Loss 1.0041 	Validation Prec@1 66.880 	Validation Prec@5 97.070 	
2019-05-03 16:36:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:36:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:36:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:36:40 - INFO - TRAINING - Epoch: [49][0/500]	Time 0.259 (0.259)	Data 0.228 (0.228)	Loss 0.7581 (0.7581)	Prec@1 73.000 (73.000)	Prec@5 100.000 (100.000)
2019-05-03 16:36:41 - INFO - TRAINING - Epoch: [49][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.7209 (0.7117)	Prec@1 76.000 (76.039)	Prec@5 98.000 (98.373)
2019-05-03 16:36:42 - INFO - TRAINING - Epoch: [49][100/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.8420 (0.7152)	Prec@1 73.000 (75.901)	Prec@5 98.000 (98.455)
2019-05-03 16:36:43 - INFO - TRAINING - Epoch: [49][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.6153 (0.7079)	Prec@1 77.000 (76.232)	Prec@5 98.000 (98.483)
2019-05-03 16:36:44 - INFO - TRAINING - Epoch: [49][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.8106 (0.7030)	Prec@1 74.000 (76.478)	Prec@5 97.000 (98.522)
2019-05-03 16:36:45 - INFO - TRAINING - Epoch: [49][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7676 (0.7018)	Prec@1 75.000 (76.446)	Prec@5 98.000 (98.502)
2019-05-03 16:36:45 - INFO - TRAINING - Epoch: [49][300/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6541 (0.7027)	Prec@1 79.000 (76.382)	Prec@5 98.000 (98.512)
2019-05-03 16:36:46 - INFO - TRAINING - Epoch: [49][350/500]	Time 0.017 (0.019)	Data 0.000 (0.001)	Loss 0.5840 (0.7002)	Prec@1 79.000 (76.407)	Prec@5 100.000 (98.504)
2019-05-03 16:36:47 - INFO - TRAINING - Epoch: [49][400/500]	Time 0.026 (0.019)	Data 0.000 (0.001)	Loss 0.6702 (0.6999)	Prec@1 77.000 (76.399)	Prec@5 98.000 (98.526)
2019-05-03 16:36:48 - INFO - TRAINING - Epoch: [49][450/500]	Time 0.022 (0.019)	Data 0.000 (0.001)	Loss 0.5666 (0.7016)	Prec@1 79.000 (76.375)	Prec@5 98.000 (98.512)
2019-05-03 16:36:49 - INFO - EVALUATING - Epoch: [49][0/100]	Time 0.357 (0.357)	Data 0.345 (0.345)	Loss 0.8407 (0.8407)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:50 - INFO - EVALUATING - Epoch: [49][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.6896 (0.8023)	Prec@1 75.000 (73.490)	Prec@5 97.000 (97.608)
2019-05-03 16:36:50 - INFO - 
 Epoch: 50	Training Loss 0.6999 	Training Prec@1 76.454 	Training Prec@5 98.522 	Validation Loss 0.7965 	Validation Prec@1 73.530 	Validation Prec@5 97.820 	
2019-05-03 16:36:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:36:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:36:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:36:50 - INFO - TRAINING - Epoch: [50][0/500]	Time 0.255 (0.255)	Data 0.225 (0.225)	Loss 0.7518 (0.7518)	Prec@1 72.000 (72.000)	Prec@5 99.000 (99.000)
2019-05-03 16:36:51 - INFO - TRAINING - Epoch: [50][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.8320 (0.7011)	Prec@1 74.000 (76.000)	Prec@5 97.000 (98.647)
2019-05-03 16:36:52 - INFO - TRAINING - Epoch: [50][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7149 (0.6954)	Prec@1 80.000 (76.475)	Prec@5 97.000 (98.574)
2019-05-03 16:36:53 - INFO - TRAINING - Epoch: [50][150/500]	Time 0.021 (0.020)	Data 0.000 (0.002)	Loss 0.6519 (0.6897)	Prec@1 80.000 (76.907)	Prec@5 99.000 (98.536)
2019-05-03 16:36:54 - INFO - TRAINING - Epoch: [50][200/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.7175 (0.6892)	Prec@1 75.000 (76.761)	Prec@5 98.000 (98.552)
2019-05-03 16:36:55 - INFO - TRAINING - Epoch: [50][250/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.8262 (0.6862)	Prec@1 71.000 (76.705)	Prec@5 97.000 (98.562)
2019-05-03 16:36:56 - INFO - TRAINING - Epoch: [50][300/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.8702 (0.6895)	Prec@1 72.000 (76.681)	Prec@5 99.000 (98.588)
2019-05-03 16:36:57 - INFO - TRAINING - Epoch: [50][350/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.7781 (0.6939)	Prec@1 76.000 (76.507)	Prec@5 99.000 (98.593)
2019-05-03 16:36:58 - INFO - TRAINING - Epoch: [50][400/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.8524 (0.6923)	Prec@1 71.000 (76.613)	Prec@5 100.000 (98.613)
2019-05-03 16:36:59 - INFO - TRAINING - Epoch: [50][450/500]	Time 0.020 (0.019)	Data 0.000 (0.001)	Loss 0.6707 (0.6927)	Prec@1 77.000 (76.599)	Prec@5 96.000 (98.594)
2019-05-03 16:37:00 - INFO - EVALUATING - Epoch: [50][0/100]	Time 0.393 (0.393)	Data 0.380 (0.380)	Loss 0.7864 (0.7864)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-05-03 16:37:00 - INFO - EVALUATING - Epoch: [50][50/100]	Time 0.005 (0.013)	Data 0.000 (0.008)	Loss 0.7671 (0.9058)	Prec@1 73.000 (69.000)	Prec@5 99.000 (97.529)
2019-05-03 16:37:01 - INFO - 
 Epoch: 51	Training Loss 0.6947 	Training Prec@1 76.568 	Training Prec@5 98.590 	Validation Loss 0.9143 	Validation Prec@1 68.600 	Validation Prec@5 97.530 	
2019-05-03 16:37:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:01 - INFO - TRAINING - Epoch: [51][0/500]	Time 0.270 (0.270)	Data 0.245 (0.245)	Loss 0.6387 (0.6387)	Prec@1 78.000 (78.000)	Prec@5 97.000 (97.000)
2019-05-03 16:37:02 - INFO - TRAINING - Epoch: [51][50/500]	Time 0.020 (0.023)	Data 0.000 (0.005)	Loss 0.7419 (0.7252)	Prec@1 76.000 (75.157)	Prec@5 97.000 (98.314)
2019-05-03 16:37:03 - INFO - TRAINING - Epoch: [51][100/500]	Time 0.016 (0.020)	Data 0.000 (0.003)	Loss 0.5589 (0.6987)	Prec@1 80.000 (76.495)	Prec@5 100.000 (98.416)
2019-05-03 16:37:04 - INFO - TRAINING - Epoch: [51][150/500]	Time 0.019 (0.020)	Data 0.000 (0.002)	Loss 0.9713 (0.6983)	Prec@1 71.000 (76.483)	Prec@5 99.000 (98.430)
2019-05-03 16:37:05 - INFO - TRAINING - Epoch: [51][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7358 (0.7011)	Prec@1 77.000 (76.383)	Prec@5 96.000 (98.368)
2019-05-03 16:37:06 - INFO - TRAINING - Epoch: [51][250/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.7684 (0.6929)	Prec@1 77.000 (76.717)	Prec@5 99.000 (98.390)
2019-05-03 16:37:06 - INFO - TRAINING - Epoch: [51][300/500]	Time 0.029 (0.019)	Data 0.000 (0.001)	Loss 0.6773 (0.6917)	Prec@1 72.000 (76.774)	Prec@5 100.000 (98.405)
2019-05-03 16:37:08 - INFO - TRAINING - Epoch: [51][350/500]	Time 0.027 (0.019)	Data 0.000 (0.001)	Loss 0.7962 (0.6925)	Prec@1 68.000 (76.692)	Prec@5 100.000 (98.439)
2019-05-03 16:37:09 - INFO - TRAINING - Epoch: [51][400/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.7047 (0.6912)	Prec@1 81.000 (76.743)	Prec@5 98.000 (98.424)
2019-05-03 16:37:10 - INFO - TRAINING - Epoch: [51][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.6762 (0.6911)	Prec@1 73.000 (76.792)	Prec@5 100.000 (98.408)
2019-05-03 16:37:11 - INFO - EVALUATING - Epoch: [51][0/100]	Time 0.379 (0.379)	Data 0.365 (0.365)	Loss 0.7203 (0.7203)	Prec@1 82.000 (82.000)	Prec@5 97.000 (97.000)
2019-05-03 16:37:11 - INFO - EVALUATING - Epoch: [51][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.8142 (0.8748)	Prec@1 72.000 (70.667)	Prec@5 95.000 (97.176)
2019-05-03 16:37:11 - INFO - 
 Epoch: 52	Training Loss 0.6914 	Training Prec@1 76.776 	Training Prec@5 98.410 	Validation Loss 0.8823 	Validation Prec@1 70.380 	Validation Prec@5 97.350 	
2019-05-03 16:37:12 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:12 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:12 - INFO - TRAINING - Epoch: [52][0/500]	Time 0.276 (0.276)	Data 0.254 (0.254)	Loss 0.5885 (0.5885)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 16:37:13 - INFO - TRAINING - Epoch: [52][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.5314 (0.6933)	Prec@1 83.000 (77.157)	Prec@5 99.000 (98.569)
2019-05-03 16:37:14 - INFO - TRAINING - Epoch: [52][100/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 0.6009 (0.6871)	Prec@1 80.000 (77.050)	Prec@5 99.000 (98.653)
2019-05-03 16:37:15 - INFO - TRAINING - Epoch: [52][150/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 1.0225 (0.6903)	Prec@1 67.000 (76.868)	Prec@5 97.000 (98.656)
2019-05-03 16:37:16 - INFO - TRAINING - Epoch: [52][200/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7391 (0.6890)	Prec@1 78.000 (77.085)	Prec@5 98.000 (98.547)
2019-05-03 16:37:17 - INFO - TRAINING - Epoch: [52][250/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.6607 (0.6930)	Prec@1 79.000 (76.896)	Prec@5 100.000 (98.506)
2019-05-03 16:37:18 - INFO - TRAINING - Epoch: [52][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.4072 (0.6953)	Prec@1 86.000 (76.645)	Prec@5 99.000 (98.488)
2019-05-03 16:37:19 - INFO - TRAINING - Epoch: [52][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7018 (0.6986)	Prec@1 75.000 (76.524)	Prec@5 97.000 (98.470)
2019-05-03 16:37:20 - INFO - TRAINING - Epoch: [52][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.8481 (0.6923)	Prec@1 74.000 (76.733)	Prec@5 97.000 (98.506)
2019-05-03 16:37:21 - INFO - TRAINING - Epoch: [52][450/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.6355 (0.6895)	Prec@1 76.000 (76.787)	Prec@5 99.000 (98.550)
2019-05-03 16:37:22 - INFO - EVALUATING - Epoch: [52][0/100]	Time 0.262 (0.262)	Data 0.252 (0.252)	Loss 0.7598 (0.7598)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:37:22 - INFO - EVALUATING - Epoch: [52][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.7538 (0.7653)	Prec@1 71.000 (73.725)	Prec@5 98.000 (98.078)
2019-05-03 16:37:22 - INFO - 
 Epoch: 53	Training Loss 0.6899 	Training Prec@1 76.844 	Training Prec@5 98.530 	Validation Loss 0.7747 	Validation Prec@1 73.280 	Validation Prec@5 98.120 	
2019-05-03 16:37:23 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:23 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:23 - INFO - TRAINING - Epoch: [53][0/500]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.7124 (0.7124)	Prec@1 79.000 (79.000)	Prec@5 97.000 (97.000)
2019-05-03 16:37:24 - INFO - TRAINING - Epoch: [53][50/500]	Time 0.014 (0.025)	Data 0.000 (0.007)	Loss 0.7031 (0.6852)	Prec@1 74.000 (77.196)	Prec@5 98.000 (98.745)
2019-05-03 16:37:25 - INFO - TRAINING - Epoch: [53][100/500]	Time 0.012 (0.021)	Data 0.000 (0.004)	Loss 0.7613 (0.6908)	Prec@1 77.000 (77.089)	Prec@5 97.000 (98.594)
2019-05-03 16:37:26 - INFO - TRAINING - Epoch: [53][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.8860 (0.6887)	Prec@1 78.000 (77.139)	Prec@5 95.000 (98.649)
2019-05-03 16:37:26 - INFO - TRAINING - Epoch: [53][200/500]	Time 0.020 (0.020)	Data 0.000 (0.002)	Loss 0.7264 (0.6867)	Prec@1 75.000 (77.194)	Prec@5 98.000 (98.632)
2019-05-03 16:37:27 - INFO - TRAINING - Epoch: [53][250/500]	Time 0.016 (0.020)	Data 0.000 (0.002)	Loss 0.7684 (0.6847)	Prec@1 75.000 (77.303)	Prec@5 100.000 (98.661)
2019-05-03 16:37:28 - INFO - TRAINING - Epoch: [53][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.9257 (0.6851)	Prec@1 66.000 (77.169)	Prec@5 100.000 (98.654)
2019-05-03 16:37:29 - INFO - TRAINING - Epoch: [53][350/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.8529 (0.6867)	Prec@1 67.000 (77.120)	Prec@5 98.000 (98.593)
2019-05-03 16:37:30 - INFO - TRAINING - Epoch: [53][400/500]	Time 0.026 (0.019)	Data 0.000 (0.001)	Loss 0.6611 (0.6842)	Prec@1 74.000 (77.187)	Prec@5 100.000 (98.589)
2019-05-03 16:37:31 - INFO - TRAINING - Epoch: [53][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.6768 (0.6839)	Prec@1 78.000 (77.140)	Prec@5 100.000 (98.599)
2019-05-03 16:37:33 - INFO - EVALUATING - Epoch: [53][0/100]	Time 0.324 (0.324)	Data 0.317 (0.317)	Loss 0.9060 (0.9060)	Prec@1 68.000 (68.000)	Prec@5 98.000 (98.000)
2019-05-03 16:37:33 - INFO - EVALUATING - Epoch: [53][50/100]	Time 0.007 (0.012)	Data 0.000 (0.006)	Loss 0.8569 (0.9856)	Prec@1 78.000 (67.745)	Prec@5 97.000 (96.137)
2019-05-03 16:37:33 - INFO - 
 Epoch: 54	Training Loss 0.6823 	Training Prec@1 77.142 	Training Prec@5 98.608 	Validation Loss 0.9967 	Validation Prec@1 67.520 	Validation Prec@5 96.120 	
2019-05-03 16:37:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:33 - INFO - TRAINING - Epoch: [54][0/500]	Time 0.261 (0.261)	Data 0.236 (0.236)	Loss 0.6319 (0.6319)	Prec@1 74.000 (74.000)	Prec@5 100.000 (100.000)
2019-05-03 16:37:34 - INFO - TRAINING - Epoch: [54][50/500]	Time 0.021 (0.024)	Data 0.000 (0.005)	Loss 0.6878 (0.6797)	Prec@1 79.000 (77.216)	Prec@5 100.000 (98.569)
2019-05-03 16:37:35 - INFO - TRAINING - Epoch: [54][100/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.6574 (0.6675)	Prec@1 78.000 (77.574)	Prec@5 99.000 (98.535)
2019-05-03 16:37:36 - INFO - TRAINING - Epoch: [54][150/500]	Time 0.029 (0.021)	Data 0.000 (0.002)	Loss 0.6526 (0.6687)	Prec@1 79.000 (77.477)	Prec@5 99.000 (98.543)
2019-05-03 16:37:37 - INFO - TRAINING - Epoch: [54][200/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8007 (0.6722)	Prec@1 73.000 (77.428)	Prec@5 99.000 (98.587)
2019-05-03 16:37:38 - INFO - TRAINING - Epoch: [54][250/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.6297 (0.6738)	Prec@1 77.000 (77.382)	Prec@5 99.000 (98.582)
2019-05-03 16:37:39 - INFO - TRAINING - Epoch: [54][300/500]	Time 0.018 (0.019)	Data 0.000 (0.001)	Loss 0.7290 (0.6780)	Prec@1 76.000 (77.272)	Prec@5 97.000 (98.571)
2019-05-03 16:37:40 - INFO - TRAINING - Epoch: [54][350/500]	Time 0.021 (0.019)	Data 0.000 (0.001)	Loss 0.7419 (0.6781)	Prec@1 72.000 (77.296)	Prec@5 100.000 (98.604)
2019-05-03 16:37:41 - INFO - TRAINING - Epoch: [54][400/500]	Time 0.013 (0.019)	Data 0.000 (0.001)	Loss 0.6197 (0.6813)	Prec@1 80.000 (77.244)	Prec@5 99.000 (98.556)
2019-05-03 16:37:42 - INFO - TRAINING - Epoch: [54][450/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.7509 (0.6782)	Prec@1 74.000 (77.297)	Prec@5 99.000 (98.592)
2019-05-03 16:37:43 - INFO - EVALUATING - Epoch: [54][0/100]	Time 0.331 (0.331)	Data 0.315 (0.315)	Loss 0.7520 (0.7520)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 16:37:43 - INFO - EVALUATING - Epoch: [54][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.7471 (0.8752)	Prec@1 77.000 (70.510)	Prec@5 98.000 (97.627)
2019-05-03 16:37:43 - INFO - 
 Epoch: 55	Training Loss 0.6778 	Training Prec@1 77.290 	Training Prec@5 98.606 	Validation Loss 0.8957 	Validation Prec@1 69.740 	Validation Prec@5 97.690 	
2019-05-03 16:37:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:44 - INFO - TRAINING - Epoch: [55][0/500]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.6782 (0.6782)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 16:37:45 - INFO - TRAINING - Epoch: [55][50/500]	Time 0.021 (0.023)	Data 0.000 (0.007)	Loss 0.6072 (0.6758)	Prec@1 80.000 (77.137)	Prec@5 99.000 (98.686)
2019-05-03 16:37:45 - INFO - TRAINING - Epoch: [55][100/500]	Time 0.018 (0.020)	Data 0.000 (0.003)	Loss 0.6956 (0.6764)	Prec@1 77.000 (77.366)	Prec@5 97.000 (98.564)
2019-05-03 16:37:46 - INFO - TRAINING - Epoch: [55][150/500]	Time 0.016 (0.019)	Data 0.000 (0.002)	Loss 0.7124 (0.6681)	Prec@1 76.000 (77.728)	Prec@5 98.000 (98.669)
2019-05-03 16:37:47 - INFO - TRAINING - Epoch: [55][200/500]	Time 0.013 (0.018)	Data 0.000 (0.002)	Loss 0.8812 (0.6748)	Prec@1 68.000 (77.552)	Prec@5 98.000 (98.632)
2019-05-03 16:37:48 - INFO - TRAINING - Epoch: [55][250/500]	Time 0.013 (0.018)	Data 0.000 (0.001)	Loss 0.6791 (0.6785)	Prec@1 75.000 (77.363)	Prec@5 98.000 (98.657)
2019-05-03 16:37:49 - INFO - TRAINING - Epoch: [55][300/500]	Time 0.021 (0.018)	Data 0.000 (0.001)	Loss 0.9239 (0.6822)	Prec@1 69.000 (77.183)	Prec@5 97.000 (98.638)
2019-05-03 16:37:50 - INFO - TRAINING - Epoch: [55][350/500]	Time 0.014 (0.018)	Data 0.000 (0.001)	Loss 0.5907 (0.6823)	Prec@1 80.000 (77.134)	Prec@5 99.000 (98.641)
2019-05-03 16:37:51 - INFO - TRAINING - Epoch: [55][400/500]	Time 0.022 (0.018)	Data 0.000 (0.001)	Loss 0.6252 (0.6774)	Prec@1 80.000 (77.349)	Prec@5 98.000 (98.626)
2019-05-03 16:37:52 - INFO - TRAINING - Epoch: [55][450/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.8481 (0.6781)	Prec@1 69.000 (77.319)	Prec@5 97.000 (98.627)
2019-05-03 16:37:53 - INFO - EVALUATING - Epoch: [55][0/100]	Time 0.344 (0.344)	Data 0.336 (0.336)	Loss 0.7708 (0.7708)	Prec@1 76.000 (76.000)	Prec@5 98.000 (98.000)
2019-05-03 16:37:53 - INFO - EVALUATING - Epoch: [55][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.8685 (0.9060)	Prec@1 70.000 (70.843)	Prec@5 97.000 (97.000)
2019-05-03 16:37:54 - INFO - 
 Epoch: 56	Training Loss 0.6793 	Training Prec@1 77.326 	Training Prec@5 98.616 	Validation Loss 0.8995 	Validation Prec@1 70.440 	Validation Prec@5 97.200 	
2019-05-03 16:37:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:37:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:37:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:37:54 - INFO - TRAINING - Epoch: [56][0/500]	Time 0.247 (0.247)	Data 0.220 (0.220)	Loss 0.8036 (0.8036)	Prec@1 68.000 (68.000)	Prec@5 100.000 (100.000)
2019-05-03 16:37:55 - INFO - TRAINING - Epoch: [56][50/500]	Time 0.015 (0.022)	Data 0.000 (0.004)	Loss 0.5942 (0.6517)	Prec@1 77.000 (78.451)	Prec@5 99.000 (98.686)
2019-05-03 16:37:56 - INFO - TRAINING - Epoch: [56][100/500]	Time 0.026 (0.020)	Data 0.000 (0.002)	Loss 0.7892 (0.6586)	Prec@1 71.000 (77.871)	Prec@5 99.000 (98.663)
2019-05-03 16:37:57 - INFO - TRAINING - Epoch: [56][150/500]	Time 0.021 (0.020)	Data 0.000 (0.002)	Loss 0.7361 (0.6627)	Prec@1 77.000 (77.854)	Prec@5 98.000 (98.589)
2019-05-03 16:37:58 - INFO - TRAINING - Epoch: [56][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7263 (0.6644)	Prec@1 73.000 (77.756)	Prec@5 97.000 (98.582)
2019-05-03 16:37:59 - INFO - TRAINING - Epoch: [56][250/500]	Time 0.030 (0.019)	Data 0.000 (0.001)	Loss 0.7627 (0.6631)	Prec@1 73.000 (77.797)	Prec@5 100.000 (98.653)
2019-05-03 16:38:00 - INFO - TRAINING - Epoch: [56][300/500]	Time 0.018 (0.019)	Data 0.000 (0.001)	Loss 0.6711 (0.6646)	Prec@1 80.000 (77.681)	Prec@5 96.000 (98.638)
2019-05-03 16:38:01 - INFO - TRAINING - Epoch: [56][350/500]	Time 0.018 (0.019)	Data 0.000 (0.001)	Loss 0.5991 (0.6661)	Prec@1 80.000 (77.744)	Prec@5 98.000 (98.601)
2019-05-03 16:38:02 - INFO - TRAINING - Epoch: [56][400/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.5880 (0.6688)	Prec@1 81.000 (77.723)	Prec@5 98.000 (98.581)
2019-05-03 16:38:03 - INFO - TRAINING - Epoch: [56][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.7593 (0.6695)	Prec@1 76.000 (77.683)	Prec@5 97.000 (98.585)
2019-05-03 16:38:04 - INFO - EVALUATING - Epoch: [56][0/100]	Time 0.368 (0.368)	Data 0.360 (0.360)	Loss 0.7100 (0.7100)	Prec@1 75.000 (75.000)	Prec@5 97.000 (97.000)
2019-05-03 16:38:04 - INFO - EVALUATING - Epoch: [56][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.6128 (0.7288)	Prec@1 82.000 (76.137)	Prec@5 95.000 (98.078)
2019-05-03 16:38:05 - INFO - 
 Epoch: 57	Training Loss 0.6698 	Training Prec@1 77.630 	Training Prec@5 98.606 	Validation Loss 0.7345 	Validation Prec@1 75.660 	Validation Prec@5 98.160 	
2019-05-03 16:38:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:38:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:38:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:38:05 - INFO - TRAINING - Epoch: [57][0/500]	Time 0.259 (0.259)	Data 0.230 (0.230)	Loss 0.6698 (0.6698)	Prec@1 77.000 (77.000)	Prec@5 97.000 (97.000)
2019-05-03 16:38:06 - INFO - TRAINING - Epoch: [57][50/500]	Time 0.016 (0.024)	Data 0.000 (0.005)	Loss 0.5109 (0.6531)	Prec@1 81.000 (77.980)	Prec@5 99.000 (98.412)
2019-05-03 16:38:07 - INFO - TRAINING - Epoch: [57][100/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.6224 (0.6728)	Prec@1 78.000 (77.703)	Prec@5 99.000 (98.515)
2019-05-03 16:38:08 - INFO - TRAINING - Epoch: [57][150/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.7721 (0.6707)	Prec@1 75.000 (77.596)	Prec@5 99.000 (98.616)
2019-05-03 16:38:09 - INFO - TRAINING - Epoch: [57][200/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7459 (0.6777)	Prec@1 79.000 (77.408)	Prec@5 97.000 (98.632)
2019-05-03 16:38:10 - INFO - TRAINING - Epoch: [57][250/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.7381 (0.6770)	Prec@1 77.000 (77.478)	Prec@5 98.000 (98.669)
2019-05-03 16:38:11 - INFO - TRAINING - Epoch: [57][300/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6065 (0.6772)	Prec@1 82.000 (77.515)	Prec@5 97.000 (98.681)
2019-05-03 16:38:12 - INFO - TRAINING - Epoch: [57][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.4398 (0.6755)	Prec@1 86.000 (77.564)	Prec@5 100.000 (98.675)
2019-05-03 16:38:13 - INFO - TRAINING - Epoch: [57][400/500]	Time 0.035 (0.020)	Data 0.000 (0.001)	Loss 0.6068 (0.6749)	Prec@1 79.000 (77.529)	Prec@5 99.000 (98.668)
2019-05-03 16:38:13 - INFO - TRAINING - Epoch: [57][450/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.7966 (0.6738)	Prec@1 76.000 (77.561)	Prec@5 97.000 (98.647)
2019-05-03 16:38:15 - INFO - EVALUATING - Epoch: [57][0/100]	Time 0.338 (0.338)	Data 0.328 (0.328)	Loss 0.7753 (0.7753)	Prec@1 74.000 (74.000)	Prec@5 100.000 (100.000)
2019-05-03 16:38:15 - INFO - EVALUATING - Epoch: [57][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.6832 (0.7159)	Prec@1 79.000 (76.000)	Prec@5 99.000 (98.353)
2019-05-03 16:38:15 - INFO - 
 Epoch: 58	Training Loss 0.6728 	Training Prec@1 77.568 	Training Prec@5 98.672 	Validation Loss 0.7199 	Validation Prec@1 75.600 	Validation Prec@5 98.450 	
2019-05-03 16:38:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:38:15 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:38:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:38:16 - INFO - TRAINING - Epoch: [58][0/500]	Time 0.339 (0.339)	Data 0.317 (0.317)	Loss 0.7411 (0.7411)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:38:17 - INFO - TRAINING - Epoch: [58][50/500]	Time 0.013 (0.027)	Data 0.000 (0.006)	Loss 0.8092 (0.6663)	Prec@1 73.000 (77.451)	Prec@5 99.000 (98.804)
2019-05-03 16:38:18 - INFO - TRAINING - Epoch: [58][100/500]	Time 0.016 (0.022)	Data 0.000 (0.003)	Loss 0.6865 (0.6620)	Prec@1 74.000 (78.059)	Prec@5 99.000 (98.693)
2019-05-03 16:38:19 - INFO - TRAINING - Epoch: [58][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.5913 (0.6585)	Prec@1 77.000 (78.066)	Prec@5 99.000 (98.695)
2019-05-03 16:38:20 - INFO - TRAINING - Epoch: [58][200/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 0.6475 (0.6603)	Prec@1 79.000 (78.035)	Prec@5 100.000 (98.677)
2019-05-03 16:38:21 - INFO - TRAINING - Epoch: [58][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6960 (0.6627)	Prec@1 79.000 (77.873)	Prec@5 98.000 (98.689)
2019-05-03 16:38:22 - INFO - TRAINING - Epoch: [58][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6351 (0.6620)	Prec@1 75.000 (77.857)	Prec@5 99.000 (98.661)
2019-05-03 16:38:23 - INFO - TRAINING - Epoch: [58][350/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.7749 (0.6638)	Prec@1 69.000 (77.789)	Prec@5 99.000 (98.647)
2019-05-03 16:38:24 - INFO - TRAINING - Epoch: [58][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7490 (0.6616)	Prec@1 76.000 (77.845)	Prec@5 97.000 (98.648)
2019-05-03 16:38:25 - INFO - TRAINING - Epoch: [58][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5426 (0.6629)	Prec@1 81.000 (77.847)	Prec@5 99.000 (98.654)
2019-05-03 16:38:26 - INFO - EVALUATING - Epoch: [58][0/100]	Time 0.219 (0.219)	Data 0.211 (0.211)	Loss 0.6889 (0.6889)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:38:26 - INFO - EVALUATING - Epoch: [58][50/100]	Time 0.004 (0.010)	Data 0.000 (0.005)	Loss 0.7630 (0.7835)	Prec@1 77.000 (73.784)	Prec@5 99.000 (98.176)
2019-05-03 16:38:27 - INFO - 
 Epoch: 59	Training Loss 0.6616 	Training Prec@1 77.816 	Training Prec@5 98.674 	Validation Loss 0.7815 	Validation Prec@1 73.310 	Validation Prec@5 98.430 	
2019-05-03 16:38:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:38:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:38:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:38:27 - INFO - TRAINING - Epoch: [59][0/500]	Time 0.273 (0.273)	Data 0.245 (0.245)	Loss 0.5142 (0.5142)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:38:28 - INFO - TRAINING - Epoch: [59][50/500]	Time 0.022 (0.024)	Data 0.000 (0.005)	Loss 0.6478 (0.6816)	Prec@1 78.000 (77.059)	Prec@5 96.000 (98.373)
2019-05-03 16:38:29 - INFO - TRAINING - Epoch: [59][100/500]	Time 0.013 (0.022)	Data 0.000 (0.003)	Loss 0.6648 (0.6857)	Prec@1 79.000 (77.139)	Prec@5 99.000 (98.386)
2019-05-03 16:38:30 - INFO - TRAINING - Epoch: [59][150/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 0.4937 (0.6719)	Prec@1 83.000 (77.589)	Prec@5 100.000 (98.556)
2019-05-03 16:38:31 - INFO - TRAINING - Epoch: [59][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4560 (0.6702)	Prec@1 84.000 (77.597)	Prec@5 98.000 (98.572)
2019-05-03 16:38:32 - INFO - TRAINING - Epoch: [59][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5271 (0.6691)	Prec@1 81.000 (77.498)	Prec@5 98.000 (98.586)
2019-05-03 16:38:33 - INFO - TRAINING - Epoch: [59][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6955 (0.6692)	Prec@1 78.000 (77.498)	Prec@5 97.000 (98.571)
2019-05-03 16:38:34 - INFO - TRAINING - Epoch: [59][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6689 (0.6704)	Prec@1 73.000 (77.473)	Prec@5 100.000 (98.573)
2019-05-03 16:38:35 - INFO - TRAINING - Epoch: [59][400/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.7759 (0.6687)	Prec@1 75.000 (77.574)	Prec@5 98.000 (98.581)
2019-05-03 16:38:36 - INFO - TRAINING - Epoch: [59][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5138 (0.6700)	Prec@1 82.000 (77.585)	Prec@5 99.000 (98.552)
2019-05-03 16:38:37 - INFO - EVALUATING - Epoch: [59][0/100]	Time 0.256 (0.256)	Data 0.246 (0.246)	Loss 0.6383 (0.6383)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 16:38:37 - INFO - EVALUATING - Epoch: [59][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 0.7094 (0.7504)	Prec@1 77.000 (74.824)	Prec@5 96.000 (98.157)
2019-05-03 16:38:38 - INFO - 
 Epoch: 60	Training Loss 0.6673 	Training Prec@1 77.654 	Training Prec@5 98.568 	Validation Loss 0.7558 	Validation Prec@1 74.490 	Validation Prec@5 98.260 	
2019-05-03 16:38:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:38:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:38:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:38:38 - INFO - TRAINING - Epoch: [60][0/500]	Time 0.243 (0.243)	Data 0.225 (0.225)	Loss 0.5840 (0.5840)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 16:38:39 - INFO - TRAINING - Epoch: [60][50/500]	Time 0.015 (0.024)	Data 0.000 (0.005)	Loss 0.5710 (0.6464)	Prec@1 79.000 (78.216)	Prec@5 100.000 (98.647)
2019-05-03 16:38:40 - INFO - TRAINING - Epoch: [60][100/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.6604 (0.6581)	Prec@1 80.000 (77.970)	Prec@5 99.000 (98.604)
2019-05-03 16:38:41 - INFO - TRAINING - Epoch: [60][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.6108 (0.6539)	Prec@1 76.000 (78.073)	Prec@5 99.000 (98.623)
2019-05-03 16:38:42 - INFO - TRAINING - Epoch: [60][200/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.9115 (0.6465)	Prec@1 67.000 (78.348)	Prec@5 99.000 (98.672)
2019-05-03 16:38:43 - INFO - TRAINING - Epoch: [60][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7500 (0.6487)	Prec@1 72.000 (78.179)	Prec@5 98.000 (98.701)
2019-05-03 16:38:44 - INFO - TRAINING - Epoch: [60][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5548 (0.6549)	Prec@1 82.000 (78.010)	Prec@5 99.000 (98.651)
2019-05-03 16:38:45 - INFO - TRAINING - Epoch: [60][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7247 (0.6570)	Prec@1 79.000 (77.909)	Prec@5 96.000 (98.644)
2019-05-03 16:38:46 - INFO - TRAINING - Epoch: [60][400/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.7628 (0.6587)	Prec@1 74.000 (77.870)	Prec@5 99.000 (98.668)
2019-05-03 16:38:47 - INFO - TRAINING - Epoch: [60][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.5044 (0.6594)	Prec@1 81.000 (77.865)	Prec@5 100.000 (98.681)
2019-05-03 16:38:48 - INFO - EVALUATING - Epoch: [60][0/100]	Time 0.348 (0.348)	Data 0.335 (0.335)	Loss 0.9264 (0.9264)	Prec@1 75.000 (75.000)	Prec@5 96.000 (96.000)
2019-05-03 16:38:49 - INFO - EVALUATING - Epoch: [60][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.9067 (0.8786)	Prec@1 76.000 (71.667)	Prec@5 94.000 (97.490)
2019-05-03 16:38:49 - INFO - 
 Epoch: 61	Training Loss 0.6611 	Training Prec@1 77.854 	Training Prec@5 98.676 	Validation Loss 0.8773 	Validation Prec@1 71.540 	Validation Prec@5 97.420 	
2019-05-03 16:38:49 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:38:49 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:38:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:38:49 - INFO - TRAINING - Epoch: [61][0/500]	Time 0.258 (0.258)	Data 0.236 (0.236)	Loss 0.6068 (0.6068)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:38:50 - INFO - TRAINING - Epoch: [61][50/500]	Time 0.012 (0.023)	Data 0.000 (0.005)	Loss 0.7801 (0.6449)	Prec@1 75.000 (78.275)	Prec@5 100.000 (98.843)
2019-05-03 16:38:51 - INFO - TRAINING - Epoch: [61][100/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.6370 (0.6444)	Prec@1 82.000 (78.406)	Prec@5 98.000 (98.772)
2019-05-03 16:38:52 - INFO - TRAINING - Epoch: [61][150/500]	Time 0.030 (0.021)	Data 0.000 (0.002)	Loss 0.6344 (0.6550)	Prec@1 79.000 (78.013)	Prec@5 100.000 (98.762)
2019-05-03 16:38:53 - INFO - TRAINING - Epoch: [61][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7394 (0.6540)	Prec@1 77.000 (78.114)	Prec@5 97.000 (98.771)
2019-05-03 16:38:54 - INFO - TRAINING - Epoch: [61][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5899 (0.6489)	Prec@1 81.000 (78.187)	Prec@5 100.000 (98.773)
2019-05-03 16:38:55 - INFO - TRAINING - Epoch: [61][300/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.7544 (0.6504)	Prec@1 80.000 (78.183)	Prec@5 96.000 (98.754)
2019-05-03 16:38:56 - INFO - TRAINING - Epoch: [61][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5944 (0.6464)	Prec@1 80.000 (78.236)	Prec@5 99.000 (98.766)
2019-05-03 16:38:57 - INFO - TRAINING - Epoch: [61][400/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7565 (0.6449)	Prec@1 77.000 (78.327)	Prec@5 96.000 (98.763)
2019-05-03 16:38:58 - INFO - TRAINING - Epoch: [61][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6259 (0.6469)	Prec@1 78.000 (78.255)	Prec@5 99.000 (98.749)
2019-05-03 16:38:59 - INFO - EVALUATING - Epoch: [61][0/100]	Time 0.320 (0.320)	Data 0.313 (0.313)	Loss 0.7978 (0.7978)	Prec@1 71.000 (71.000)	Prec@5 98.000 (98.000)
2019-05-03 16:38:59 - INFO - EVALUATING - Epoch: [61][50/100]	Time 0.007 (0.012)	Data 0.000 (0.006)	Loss 0.7238 (0.7828)	Prec@1 76.000 (74.647)	Prec@5 96.000 (97.392)
2019-05-03 16:39:00 - INFO - 
 Epoch: 62	Training Loss 0.6457 	Training Prec@1 78.304 	Training Prec@5 98.750 	Validation Loss 0.7792 	Validation Prec@1 74.230 	Validation Prec@5 97.720 	
2019-05-03 16:39:00 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:00 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:00 - INFO - TRAINING - Epoch: [62][0/500]	Time 0.275 (0.275)	Data 0.245 (0.245)	Loss 0.7185 (0.7185)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:01 - INFO - TRAINING - Epoch: [62][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.5350 (0.6376)	Prec@1 82.000 (77.843)	Prec@5 99.000 (98.961)
2019-05-03 16:39:02 - INFO - TRAINING - Epoch: [62][100/500]	Time 0.022 (0.022)	Data 0.000 (0.003)	Loss 0.7924 (0.6411)	Prec@1 73.000 (78.178)	Prec@5 99.000 (98.861)
2019-05-03 16:39:03 - INFO - TRAINING - Epoch: [62][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.7369 (0.6442)	Prec@1 76.000 (78.258)	Prec@5 100.000 (98.815)
2019-05-03 16:39:04 - INFO - TRAINING - Epoch: [62][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5503 (0.6476)	Prec@1 83.000 (78.154)	Prec@5 100.000 (98.771)
2019-05-03 16:39:05 - INFO - TRAINING - Epoch: [62][250/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.8271 (0.6434)	Prec@1 76.000 (78.378)	Prec@5 99.000 (98.821)
2019-05-03 16:39:06 - INFO - TRAINING - Epoch: [62][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6713 (0.6424)	Prec@1 79.000 (78.445)	Prec@5 99.000 (98.850)
2019-05-03 16:39:07 - INFO - TRAINING - Epoch: [62][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7045 (0.6457)	Prec@1 74.000 (78.330)	Prec@5 99.000 (98.826)
2019-05-03 16:39:08 - INFO - TRAINING - Epoch: [62][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5261 (0.6459)	Prec@1 83.000 (78.424)	Prec@5 99.000 (98.783)
2019-05-03 16:39:09 - INFO - TRAINING - Epoch: [62][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7592 (0.6478)	Prec@1 75.000 (78.417)	Prec@5 97.000 (98.741)
2019-05-03 16:39:10 - INFO - EVALUATING - Epoch: [62][0/100]	Time 0.342 (0.342)	Data 0.333 (0.333)	Loss 0.7507 (0.7507)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:11 - INFO - EVALUATING - Epoch: [62][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.8045 (0.7946)	Prec@1 79.000 (74.314)	Prec@5 96.000 (97.314)
2019-05-03 16:39:11 - INFO - 
 Epoch: 63	Training Loss 0.6498 	Training Prec@1 78.364 	Training Prec@5 98.766 	Validation Loss 0.7963 	Validation Prec@1 73.940 	Validation Prec@5 97.410 	
2019-05-03 16:39:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:11 - INFO - TRAINING - Epoch: [63][0/500]	Time 0.278 (0.278)	Data 0.253 (0.253)	Loss 0.6286 (0.6286)	Prec@1 82.000 (82.000)	Prec@5 97.000 (97.000)
2019-05-03 16:39:12 - INFO - TRAINING - Epoch: [63][50/500]	Time 0.021 (0.024)	Data 0.000 (0.005)	Loss 0.6464 (0.6340)	Prec@1 79.000 (78.529)	Prec@5 96.000 (98.667)
2019-05-03 16:39:13 - INFO - TRAINING - Epoch: [63][100/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.6644 (0.6353)	Prec@1 79.000 (78.822)	Prec@5 97.000 (98.624)
2019-05-03 16:39:14 - INFO - TRAINING - Epoch: [63][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.6381 (0.6366)	Prec@1 78.000 (78.808)	Prec@5 100.000 (98.629)
2019-05-03 16:39:15 - INFO - TRAINING - Epoch: [63][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5706 (0.6357)	Prec@1 77.000 (78.771)	Prec@5 100.000 (98.692)
2019-05-03 16:39:16 - INFO - TRAINING - Epoch: [63][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6060 (0.6346)	Prec@1 76.000 (78.785)	Prec@5 99.000 (98.689)
2019-05-03 16:39:17 - INFO - TRAINING - Epoch: [63][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6025 (0.6360)	Prec@1 80.000 (78.631)	Prec@5 98.000 (98.691)
2019-05-03 16:39:18 - INFO - TRAINING - Epoch: [63][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8044 (0.6345)	Prec@1 74.000 (78.618)	Prec@5 98.000 (98.732)
2019-05-03 16:39:19 - INFO - TRAINING - Epoch: [63][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5478 (0.6342)	Prec@1 83.000 (78.673)	Prec@5 100.000 (98.723)
2019-05-03 16:39:20 - INFO - TRAINING - Epoch: [63][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7987 (0.6371)	Prec@1 73.000 (78.603)	Prec@5 98.000 (98.725)
2019-05-03 16:39:22 - INFO - EVALUATING - Epoch: [63][0/100]	Time 0.347 (0.347)	Data 0.339 (0.339)	Loss 0.5288 (0.5288)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:22 - INFO - EVALUATING - Epoch: [63][50/100]	Time 0.009 (0.013)	Data 0.000 (0.007)	Loss 0.5834 (0.7011)	Prec@1 87.000 (77.294)	Prec@5 98.000 (98.078)
2019-05-03 16:39:22 - INFO - 
 Epoch: 64	Training Loss 0.6380 	Training Prec@1 78.576 	Training Prec@5 98.728 	Validation Loss 0.6975 	Validation Prec@1 76.850 	Validation Prec@5 98.290 	
2019-05-03 16:39:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:23 - INFO - TRAINING - Epoch: [64][0/500]	Time 0.264 (0.264)	Data 0.243 (0.243)	Loss 0.6219 (0.6219)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:24 - INFO - TRAINING - Epoch: [64][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.4645 (0.6481)	Prec@1 83.000 (77.706)	Prec@5 100.000 (98.686)
2019-05-03 16:39:25 - INFO - TRAINING - Epoch: [64][100/500]	Time 0.026 (0.022)	Data 0.000 (0.003)	Loss 0.6735 (0.6518)	Prec@1 77.000 (77.693)	Prec@5 100.000 (98.723)
2019-05-03 16:39:26 - INFO - TRAINING - Epoch: [64][150/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.8244 (0.6505)	Prec@1 74.000 (78.020)	Prec@5 99.000 (98.748)
2019-05-03 16:39:27 - INFO - TRAINING - Epoch: [64][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6874 (0.6414)	Prec@1 83.000 (78.458)	Prec@5 97.000 (98.781)
2019-05-03 16:39:28 - INFO - TRAINING - Epoch: [64][250/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.5628 (0.6464)	Prec@1 83.000 (78.255)	Prec@5 100.000 (98.797)
2019-05-03 16:39:28 - INFO - TRAINING - Epoch: [64][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.8089 (0.6441)	Prec@1 72.000 (78.392)	Prec@5 98.000 (98.774)
2019-05-03 16:39:29 - INFO - TRAINING - Epoch: [64][350/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6558 (0.6481)	Prec@1 77.000 (78.293)	Prec@5 100.000 (98.726)
2019-05-03 16:39:30 - INFO - TRAINING - Epoch: [64][400/500]	Time 0.011 (0.020)	Data 0.000 (0.001)	Loss 0.7022 (0.6475)	Prec@1 79.000 (78.349)	Prec@5 99.000 (98.718)
2019-05-03 16:39:32 - INFO - TRAINING - Epoch: [64][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6754 (0.6454)	Prec@1 78.000 (78.406)	Prec@5 99.000 (98.710)
2019-05-03 16:39:33 - INFO - EVALUATING - Epoch: [64][0/100]	Time 0.346 (0.346)	Data 0.330 (0.330)	Loss 0.7967 (0.7967)	Prec@1 71.000 (71.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:33 - INFO - EVALUATING - Epoch: [64][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.8380 (0.8273)	Prec@1 72.000 (72.627)	Prec@5 98.000 (97.667)
2019-05-03 16:39:33 - INFO - 
 Epoch: 65	Training Loss 0.6459 	Training Prec@1 78.400 	Training Prec@5 98.730 	Validation Loss 0.8274 	Validation Prec@1 72.390 	Validation Prec@5 97.750 	
2019-05-03 16:39:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:34 - INFO - TRAINING - Epoch: [65][0/500]	Time 0.272 (0.272)	Data 0.255 (0.255)	Loss 0.5786 (0.5786)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:35 - INFO - TRAINING - Epoch: [65][50/500]	Time 0.021 (0.024)	Data 0.000 (0.005)	Loss 0.7085 (0.6625)	Prec@1 78.000 (77.412)	Prec@5 98.000 (98.608)
2019-05-03 16:39:36 - INFO - TRAINING - Epoch: [65][100/500]	Time 0.023 (0.022)	Data 0.000 (0.003)	Loss 0.7668 (0.6550)	Prec@1 76.000 (77.634)	Prec@5 98.000 (98.653)
2019-05-03 16:39:37 - INFO - TRAINING - Epoch: [65][150/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.6595 (0.6475)	Prec@1 78.000 (78.079)	Prec@5 97.000 (98.702)
2019-05-03 16:39:38 - INFO - TRAINING - Epoch: [65][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5671 (0.6411)	Prec@1 84.000 (78.413)	Prec@5 100.000 (98.751)
2019-05-03 16:39:39 - INFO - TRAINING - Epoch: [65][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6878 (0.6410)	Prec@1 76.000 (78.426)	Prec@5 100.000 (98.725)
2019-05-03 16:39:40 - INFO - TRAINING - Epoch: [65][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5566 (0.6448)	Prec@1 80.000 (78.159)	Prec@5 99.000 (98.764)
2019-05-03 16:39:41 - INFO - TRAINING - Epoch: [65][350/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.7818 (0.6443)	Prec@1 75.000 (78.268)	Prec@5 97.000 (98.761)
2019-05-03 16:39:42 - INFO - TRAINING - Epoch: [65][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6211 (0.6443)	Prec@1 81.000 (78.314)	Prec@5 99.000 (98.781)
2019-05-03 16:39:43 - INFO - TRAINING - Epoch: [65][450/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.7127 (0.6433)	Prec@1 79.000 (78.373)	Prec@5 96.000 (98.772)
2019-05-03 16:39:44 - INFO - EVALUATING - Epoch: [65][0/100]	Time 0.325 (0.325)	Data 0.316 (0.316)	Loss 0.6799 (0.6799)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:44 - INFO - EVALUATING - Epoch: [65][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.6923 (0.6735)	Prec@1 75.000 (77.255)	Prec@5 97.000 (98.510)
2019-05-03 16:39:45 - INFO - 
 Epoch: 66	Training Loss 0.6417 	Training Prec@1 78.498 	Training Prec@5 98.772 	Validation Loss 0.6653 	Validation Prec@1 77.460 	Validation Prec@5 98.660 	
2019-05-03 16:39:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:45 - INFO - TRAINING - Epoch: [66][0/500]	Time 0.281 (0.281)	Data 0.250 (0.250)	Loss 0.6208 (0.6208)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:39:46 - INFO - TRAINING - Epoch: [66][50/500]	Time 0.025 (0.026)	Data 0.000 (0.005)	Loss 0.5243 (0.6343)	Prec@1 82.000 (78.608)	Prec@5 100.000 (98.882)
2019-05-03 16:39:47 - INFO - TRAINING - Epoch: [66][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.5869 (0.6273)	Prec@1 80.000 (78.911)	Prec@5 99.000 (98.881)
2019-05-03 16:39:48 - INFO - TRAINING - Epoch: [66][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.5459 (0.6220)	Prec@1 81.000 (79.020)	Prec@5 99.000 (98.834)
2019-05-03 16:39:49 - INFO - TRAINING - Epoch: [66][200/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5644 (0.6179)	Prec@1 82.000 (79.194)	Prec@5 97.000 (98.866)
2019-05-03 16:39:50 - INFO - TRAINING - Epoch: [66][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6867 (0.6283)	Prec@1 73.000 (78.900)	Prec@5 98.000 (98.817)
2019-05-03 16:39:51 - INFO - TRAINING - Epoch: [66][300/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.5140 (0.6308)	Prec@1 83.000 (78.814)	Prec@5 100.000 (98.787)
2019-05-03 16:39:52 - INFO - TRAINING - Epoch: [66][350/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.7011 (0.6358)	Prec@1 76.000 (78.635)	Prec@5 98.000 (98.769)
2019-05-03 16:39:53 - INFO - TRAINING - Epoch: [66][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5688 (0.6359)	Prec@1 85.000 (78.701)	Prec@5 99.000 (98.773)
2019-05-03 16:39:54 - INFO - TRAINING - Epoch: [66][450/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.5342 (0.6358)	Prec@1 80.000 (78.672)	Prec@5 99.000 (98.796)
2019-05-03 16:39:55 - INFO - EVALUATING - Epoch: [66][0/100]	Time 0.334 (0.334)	Data 0.328 (0.328)	Loss 0.6424 (0.6424)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:39:55 - INFO - EVALUATING - Epoch: [66][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.6398 (0.6693)	Prec@1 85.000 (77.647)	Prec@5 96.000 (98.431)
2019-05-03 16:39:55 - INFO - 
 Epoch: 67	Training Loss 0.6377 	Training Prec@1 78.604 	Training Prec@5 98.784 	Validation Loss 0.6731 	Validation Prec@1 77.480 	Validation Prec@5 98.570 	
2019-05-03 16:39:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:39:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:39:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:39:56 - INFO - TRAINING - Epoch: [67][0/500]	Time 0.276 (0.276)	Data 0.251 (0.251)	Loss 0.7352 (0.7352)	Prec@1 76.000 (76.000)	Prec@5 96.000 (96.000)
2019-05-03 16:39:57 - INFO - TRAINING - Epoch: [67][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.6374 (0.6251)	Prec@1 78.000 (78.941)	Prec@5 99.000 (98.922)
2019-05-03 16:39:58 - INFO - TRAINING - Epoch: [67][100/500]	Time 0.025 (0.023)	Data 0.000 (0.003)	Loss 0.6542 (0.6325)	Prec@1 81.000 (78.564)	Prec@5 99.000 (98.921)
2019-05-03 16:39:59 - INFO - TRAINING - Epoch: [67][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.7403 (0.6273)	Prec@1 78.000 (78.993)	Prec@5 100.000 (98.874)
2019-05-03 16:40:00 - INFO - TRAINING - Epoch: [67][200/500]	Time 0.013 (0.022)	Data 0.000 (0.001)	Loss 0.6160 (0.6243)	Prec@1 81.000 (79.055)	Prec@5 98.000 (98.930)
2019-05-03 16:40:01 - INFO - TRAINING - Epoch: [67][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6768 (0.6265)	Prec@1 79.000 (78.956)	Prec@5 98.000 (98.916)
2019-05-03 16:40:02 - INFO - TRAINING - Epoch: [67][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6536 (0.6246)	Prec@1 80.000 (79.063)	Prec@5 99.000 (98.910)
2019-05-03 16:40:03 - INFO - TRAINING - Epoch: [67][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6705 (0.6304)	Prec@1 78.000 (78.872)	Prec@5 99.000 (98.875)
2019-05-03 16:40:04 - INFO - TRAINING - Epoch: [67][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5608 (0.6316)	Prec@1 83.000 (78.880)	Prec@5 99.000 (98.865)
2019-05-03 16:40:05 - INFO - TRAINING - Epoch: [67][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6156 (0.6291)	Prec@1 77.000 (78.945)	Prec@5 98.000 (98.874)
2019-05-03 16:40:06 - INFO - EVALUATING - Epoch: [67][0/100]	Time 0.346 (0.346)	Data 0.332 (0.332)	Loss 0.6833 (0.6833)	Prec@1 72.000 (72.000)	Prec@5 98.000 (98.000)
2019-05-03 16:40:07 - INFO - EVALUATING - Epoch: [67][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.5638 (0.6868)	Prec@1 82.000 (76.745)	Prec@5 99.000 (98.255)
2019-05-03 16:40:07 - INFO - 
 Epoch: 68	Training Loss 0.6307 	Training Prec@1 78.864 	Training Prec@5 98.846 	Validation Loss 0.6909 	Validation Prec@1 76.930 	Validation Prec@5 98.300 	
2019-05-03 16:40:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:40:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:40:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:40:07 - INFO - TRAINING - Epoch: [68][0/500]	Time 0.270 (0.270)	Data 0.247 (0.247)	Loss 0.4761 (0.4761)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:40:08 - INFO - TRAINING - Epoch: [68][50/500]	Time 0.022 (0.025)	Data 0.000 (0.005)	Loss 0.7268 (0.6281)	Prec@1 76.000 (79.020)	Prec@5 100.000 (98.824)
2019-05-03 16:40:09 - INFO - TRAINING - Epoch: [68][100/500]	Time 0.028 (0.023)	Data 0.000 (0.003)	Loss 0.6206 (0.6184)	Prec@1 81.000 (79.525)	Prec@5 100.000 (98.861)
2019-05-03 16:40:10 - INFO - TRAINING - Epoch: [68][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.5727 (0.6191)	Prec@1 80.000 (79.377)	Prec@5 96.000 (98.914)
2019-05-03 16:40:11 - INFO - TRAINING - Epoch: [68][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6086 (0.6186)	Prec@1 77.000 (79.403)	Prec@5 98.000 (98.905)
2019-05-03 16:40:12 - INFO - TRAINING - Epoch: [68][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.8430 (0.6235)	Prec@1 70.000 (79.319)	Prec@5 100.000 (98.821)
2019-05-03 16:40:13 - INFO - TRAINING - Epoch: [68][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.6824 (0.6258)	Prec@1 74.000 (79.243)	Prec@5 100.000 (98.844)
2019-05-03 16:40:14 - INFO - TRAINING - Epoch: [68][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6800 (0.6278)	Prec@1 77.000 (79.157)	Prec@5 99.000 (98.832)
2019-05-03 16:40:15 - INFO - TRAINING - Epoch: [68][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5790 (0.6246)	Prec@1 77.000 (79.314)	Prec@5 99.000 (98.830)
2019-05-03 16:40:16 - INFO - TRAINING - Epoch: [68][450/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.4507 (0.6260)	Prec@1 85.000 (79.255)	Prec@5 99.000 (98.816)
2019-05-03 16:40:17 - INFO - EVALUATING - Epoch: [68][0/100]	Time 0.361 (0.361)	Data 0.355 (0.355)	Loss 0.6092 (0.6092)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:40:18 - INFO - EVALUATING - Epoch: [68][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5864 (0.6563)	Prec@1 85.000 (78.353)	Prec@5 96.000 (98.431)
2019-05-03 16:40:18 - INFO - 
 Epoch: 69	Training Loss 0.6254 	Training Prec@1 79.246 	Training Prec@5 98.818 	Validation Loss 0.6587 	Validation Prec@1 78.030 	Validation Prec@5 98.620 	
2019-05-03 16:40:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:40:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:40:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:40:18 - INFO - TRAINING - Epoch: [69][0/500]	Time 0.252 (0.252)	Data 0.230 (0.230)	Loss 0.5021 (0.5021)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:40:19 - INFO - TRAINING - Epoch: [69][50/500]	Time 0.023 (0.026)	Data 0.000 (0.005)	Loss 0.6079 (0.6127)	Prec@1 77.000 (79.412)	Prec@5 99.000 (98.784)
2019-05-03 16:40:20 - INFO - TRAINING - Epoch: [69][100/500]	Time 0.017 (0.023)	Data 0.000 (0.002)	Loss 0.5131 (0.6089)	Prec@1 81.000 (79.446)	Prec@5 99.000 (98.861)
2019-05-03 16:40:21 - INFO - TRAINING - Epoch: [69][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.5184 (0.6088)	Prec@1 83.000 (79.411)	Prec@5 99.000 (98.980)
2019-05-03 16:40:22 - INFO - TRAINING - Epoch: [69][200/500]	Time 0.012 (0.022)	Data 0.000 (0.001)	Loss 0.6402 (0.6161)	Prec@1 74.000 (79.174)	Prec@5 100.000 (98.980)
2019-05-03 16:40:23 - INFO - TRAINING - Epoch: [69][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.8111 (0.6225)	Prec@1 71.000 (78.908)	Prec@5 97.000 (98.896)
2019-05-03 16:40:24 - INFO - TRAINING - Epoch: [69][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6184 (0.6244)	Prec@1 81.000 (78.884)	Prec@5 99.000 (98.900)
2019-05-03 16:40:25 - INFO - TRAINING - Epoch: [69][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.8104 (0.6258)	Prec@1 73.000 (78.826)	Prec@5 97.000 (98.869)
2019-05-03 16:40:26 - INFO - TRAINING - Epoch: [69][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4556 (0.6268)	Prec@1 86.000 (78.885)	Prec@5 100.000 (98.858)
2019-05-03 16:40:27 - INFO - TRAINING - Epoch: [69][450/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6697 (0.6268)	Prec@1 76.000 (78.949)	Prec@5 99.000 (98.849)
2019-05-03 16:40:29 - INFO - EVALUATING - Epoch: [69][0/100]	Time 0.317 (0.317)	Data 0.305 (0.305)	Loss 0.7154 (0.7154)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-03 16:40:29 - INFO - EVALUATING - Epoch: [69][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.7126 (0.7429)	Prec@1 80.000 (75.490)	Prec@5 97.000 (98.255)
2019-05-03 16:40:29 - INFO - 
 Epoch: 70	Training Loss 0.6275 	Training Prec@1 78.950 	Training Prec@5 98.832 	Validation Loss 0.7424 	Validation Prec@1 75.190 	Validation Prec@5 98.390 	
2019-05-03 16:40:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:40:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:40:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:40:30 - INFO - TRAINING - Epoch: [70][0/500]	Time 0.263 (0.263)	Data 0.235 (0.235)	Loss 0.5870 (0.5870)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:40:31 - INFO - TRAINING - Epoch: [70][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.6651 (0.6277)	Prec@1 77.000 (78.961)	Prec@5 99.000 (98.843)
2019-05-03 16:40:32 - INFO - TRAINING - Epoch: [70][100/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.5367 (0.6209)	Prec@1 80.000 (79.386)	Prec@5 100.000 (98.822)
2019-05-03 16:40:33 - INFO - TRAINING - Epoch: [70][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.6190 (0.6178)	Prec@1 78.000 (79.450)	Prec@5 99.000 (98.755)
2019-05-03 16:40:34 - INFO - TRAINING - Epoch: [70][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6236 (0.6138)	Prec@1 79.000 (79.468)	Prec@5 99.000 (98.766)
2019-05-03 16:40:35 - INFO - TRAINING - Epoch: [70][250/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.6898 (0.6147)	Prec@1 78.000 (79.327)	Prec@5 98.000 (98.793)
2019-05-03 16:40:36 - INFO - TRAINING - Epoch: [70][300/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5993 (0.6155)	Prec@1 82.000 (79.316)	Prec@5 97.000 (98.774)
2019-05-03 16:40:37 - INFO - TRAINING - Epoch: [70][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6295 (0.6144)	Prec@1 82.000 (79.387)	Prec@5 97.000 (98.789)
2019-05-03 16:40:38 - INFO - TRAINING - Epoch: [70][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5366 (0.6142)	Prec@1 82.000 (79.401)	Prec@5 99.000 (98.800)
2019-05-03 16:40:39 - INFO - TRAINING - Epoch: [70][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5883 (0.6185)	Prec@1 81.000 (79.288)	Prec@5 100.000 (98.796)
2019-05-03 16:40:40 - INFO - EVALUATING - Epoch: [70][0/100]	Time 0.349 (0.349)	Data 0.334 (0.334)	Loss 0.6641 (0.6641)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 16:40:40 - INFO - EVALUATING - Epoch: [70][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.5686 (0.7456)	Prec@1 80.000 (75.137)	Prec@5 97.000 (98.235)
2019-05-03 16:40:40 - INFO - 
 Epoch: 71	Training Loss 0.6208 	Training Prec@1 79.226 	Training Prec@5 98.810 	Validation Loss 0.7483 	Validation Prec@1 74.850 	Validation Prec@5 98.370 	
2019-05-03 16:40:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:40:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:40:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:40:41 - INFO - TRAINING - Epoch: [71][0/500]	Time 0.259 (0.259)	Data 0.235 (0.235)	Loss 0.5803 (0.5803)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:40:42 - INFO - TRAINING - Epoch: [71][50/500]	Time 0.014 (0.023)	Data 0.000 (0.005)	Loss 0.6861 (0.6151)	Prec@1 79.000 (79.608)	Prec@5 97.000 (98.725)
2019-05-03 16:40:43 - INFO - TRAINING - Epoch: [71][100/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.6751 (0.6190)	Prec@1 78.000 (79.545)	Prec@5 99.000 (98.772)
2019-05-03 16:40:44 - INFO - TRAINING - Epoch: [71][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.5773 (0.6195)	Prec@1 78.000 (79.742)	Prec@5 100.000 (98.788)
2019-05-03 16:40:45 - INFO - TRAINING - Epoch: [71][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5750 (0.6146)	Prec@1 81.000 (79.811)	Prec@5 100.000 (98.856)
2019-05-03 16:40:46 - INFO - TRAINING - Epoch: [71][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7536 (0.6163)	Prec@1 75.000 (79.709)	Prec@5 98.000 (98.857)
2019-05-03 16:40:47 - INFO - TRAINING - Epoch: [71][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5972 (0.6190)	Prec@1 80.000 (79.618)	Prec@5 99.000 (98.860)
2019-05-03 16:40:48 - INFO - TRAINING - Epoch: [71][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7611 (0.6217)	Prec@1 76.000 (79.541)	Prec@5 99.000 (98.829)
2019-05-03 16:40:49 - INFO - TRAINING - Epoch: [71][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6367 (0.6253)	Prec@1 78.000 (79.367)	Prec@5 97.000 (98.810)
2019-05-03 16:40:50 - INFO - TRAINING - Epoch: [71][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.7019 (0.6249)	Prec@1 78.000 (79.366)	Prec@5 97.000 (98.818)
2019-05-03 16:40:51 - INFO - EVALUATING - Epoch: [71][0/100]	Time 0.330 (0.330)	Data 0.317 (0.317)	Loss 0.6671 (0.6671)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:40:51 - INFO - EVALUATING - Epoch: [71][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.6930 (0.6847)	Prec@1 78.000 (76.863)	Prec@5 96.000 (98.333)
2019-05-03 16:40:52 - INFO - 
 Epoch: 72	Training Loss 0.6255 	Training Prec@1 79.270 	Training Prec@5 98.840 	Validation Loss 0.6742 	Validation Prec@1 77.400 	Validation Prec@5 98.530 	
2019-05-03 16:40:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:40:52 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:40:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:40:52 - INFO - TRAINING - Epoch: [72][0/500]	Time 0.287 (0.287)	Data 0.262 (0.262)	Loss 0.5497 (0.5497)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:40:53 - INFO - TRAINING - Epoch: [72][50/500]	Time 0.027 (0.025)	Data 0.000 (0.005)	Loss 0.6400 (0.6069)	Prec@1 76.000 (80.353)	Prec@5 100.000 (98.863)
2019-05-03 16:40:54 - INFO - TRAINING - Epoch: [72][100/500]	Time 0.017 (0.022)	Data 0.000 (0.003)	Loss 0.6462 (0.6083)	Prec@1 73.000 (79.990)	Prec@5 100.000 (98.901)
2019-05-03 16:40:55 - INFO - TRAINING - Epoch: [72][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.6500 (0.6048)	Prec@1 76.000 (79.921)	Prec@5 100.000 (98.960)
2019-05-03 16:40:56 - INFO - TRAINING - Epoch: [72][200/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.5460 (0.6056)	Prec@1 81.000 (79.950)	Prec@5 100.000 (98.950)
2019-05-03 16:40:57 - INFO - TRAINING - Epoch: [72][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6239 (0.6047)	Prec@1 77.000 (79.892)	Prec@5 100.000 (98.916)
2019-05-03 16:40:58 - INFO - TRAINING - Epoch: [72][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5347 (0.6099)	Prec@1 84.000 (79.774)	Prec@5 98.000 (98.887)
2019-05-03 16:40:59 - INFO - TRAINING - Epoch: [72][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5338 (0.6104)	Prec@1 77.000 (79.741)	Prec@5 100.000 (98.860)
2019-05-03 16:41:00 - INFO - TRAINING - Epoch: [72][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5794 (0.6114)	Prec@1 78.000 (79.633)	Prec@5 100.000 (98.863)
2019-05-03 16:41:01 - INFO - TRAINING - Epoch: [72][450/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7136 (0.6143)	Prec@1 77.000 (79.599)	Prec@5 98.000 (98.860)
2019-05-03 16:41:02 - INFO - EVALUATING - Epoch: [72][0/100]	Time 0.353 (0.353)	Data 0.339 (0.339)	Loss 0.7558 (0.7558)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 16:41:02 - INFO - EVALUATING - Epoch: [72][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.7047 (0.7623)	Prec@1 75.000 (74.647)	Prec@5 98.000 (98.255)
2019-05-03 16:41:03 - INFO - 
 Epoch: 73	Training Loss 0.6155 	Training Prec@1 79.540 	Training Prec@5 98.872 	Validation Loss 0.7414 	Validation Prec@1 74.900 	Validation Prec@5 98.440 	
2019-05-03 16:41:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:03 - INFO - TRAINING - Epoch: [73][0/500]	Time 0.244 (0.244)	Data 0.216 (0.216)	Loss 0.8245 (0.8245)	Prec@1 76.000 (76.000)	Prec@5 98.000 (98.000)
2019-05-03 16:41:04 - INFO - TRAINING - Epoch: [73][50/500]	Time 0.017 (0.025)	Data 0.000 (0.004)	Loss 0.6044 (0.6176)	Prec@1 80.000 (78.784)	Prec@5 100.000 (98.980)
2019-05-03 16:41:05 - INFO - TRAINING - Epoch: [73][100/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.6248 (0.6122)	Prec@1 79.000 (79.515)	Prec@5 99.000 (98.871)
2019-05-03 16:41:06 - INFO - TRAINING - Epoch: [73][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.7455 (0.6150)	Prec@1 75.000 (79.371)	Prec@5 99.000 (98.874)
2019-05-03 16:41:07 - INFO - TRAINING - Epoch: [73][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7372 (0.6108)	Prec@1 75.000 (79.517)	Prec@5 99.000 (98.910)
2019-05-03 16:41:08 - INFO - TRAINING - Epoch: [73][250/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4293 (0.6099)	Prec@1 84.000 (79.454)	Prec@5 100.000 (98.952)
2019-05-03 16:41:09 - INFO - TRAINING - Epoch: [73][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4647 (0.6129)	Prec@1 86.000 (79.415)	Prec@5 99.000 (98.900)
2019-05-03 16:41:10 - INFO - TRAINING - Epoch: [73][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6253 (0.6112)	Prec@1 79.000 (79.578)	Prec@5 99.000 (98.906)
2019-05-03 16:41:11 - INFO - TRAINING - Epoch: [73][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6849 (0.6120)	Prec@1 80.000 (79.658)	Prec@5 99.000 (98.895)
2019-05-03 16:41:12 - INFO - TRAINING - Epoch: [73][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.9157 (0.6151)	Prec@1 71.000 (79.572)	Prec@5 97.000 (98.858)
2019-05-03 16:41:14 - INFO - EVALUATING - Epoch: [73][0/100]	Time 0.348 (0.348)	Data 0.335 (0.335)	Loss 0.6625 (0.6625)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:41:14 - INFO - EVALUATING - Epoch: [73][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.6161 (0.6569)	Prec@1 83.000 (78.059)	Prec@5 98.000 (98.549)
2019-05-03 16:41:14 - INFO - 
 Epoch: 74	Training Loss 0.6147 	Training Prec@1 79.528 	Training Prec@5 98.878 	Validation Loss 0.6641 	Validation Prec@1 77.810 	Validation Prec@5 98.650 	
2019-05-03 16:41:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:14 - INFO - TRAINING - Epoch: [74][0/500]	Time 0.251 (0.251)	Data 0.221 (0.221)	Loss 0.5738 (0.5738)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:41:15 - INFO - TRAINING - Epoch: [74][50/500]	Time 0.026 (0.024)	Data 0.000 (0.004)	Loss 0.7488 (0.5949)	Prec@1 73.000 (80.157)	Prec@5 99.000 (98.804)
2019-05-03 16:41:16 - INFO - TRAINING - Epoch: [74][100/500]	Time 0.027 (0.023)	Data 0.000 (0.002)	Loss 0.7103 (0.6090)	Prec@1 74.000 (79.515)	Prec@5 98.000 (98.782)
2019-05-03 16:41:17 - INFO - TRAINING - Epoch: [74][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.6714 (0.6136)	Prec@1 79.000 (79.556)	Prec@5 98.000 (98.841)
2019-05-03 16:41:18 - INFO - TRAINING - Epoch: [74][200/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.6788 (0.6176)	Prec@1 75.000 (79.393)	Prec@5 99.000 (98.836)
2019-05-03 16:41:19 - INFO - TRAINING - Epoch: [74][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6002 (0.6163)	Prec@1 77.000 (79.386)	Prec@5 99.000 (98.884)
2019-05-03 16:41:20 - INFO - TRAINING - Epoch: [74][300/500]	Time 0.011 (0.021)	Data 0.000 (0.001)	Loss 0.6643 (0.6159)	Prec@1 78.000 (79.432)	Prec@5 97.000 (98.900)
2019-05-03 16:41:22 - INFO - TRAINING - Epoch: [74][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5548 (0.6178)	Prec@1 75.000 (79.339)	Prec@5 100.000 (98.897)
2019-05-03 16:41:23 - INFO - TRAINING - Epoch: [74][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7568 (0.6170)	Prec@1 71.000 (79.416)	Prec@5 96.000 (98.863)
2019-05-03 16:41:24 - INFO - TRAINING - Epoch: [74][450/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7368 (0.6193)	Prec@1 79.000 (79.410)	Prec@5 99.000 (98.834)
2019-05-03 16:41:25 - INFO - EVALUATING - Epoch: [74][0/100]	Time 0.332 (0.332)	Data 0.325 (0.325)	Loss 0.7156 (0.7156)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-05-03 16:41:25 - INFO - EVALUATING - Epoch: [74][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.7783 (0.7194)	Prec@1 75.000 (76.353)	Prec@5 95.000 (98.098)
2019-05-03 16:41:26 - INFO - 
 Epoch: 75	Training Loss 0.6193 	Training Prec@1 79.412 	Training Prec@5 98.834 	Validation Loss 0.7177 	Validation Prec@1 76.170 	Validation Prec@5 98.290 	
2019-05-03 16:41:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:26 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:26 - INFO - TRAINING - Epoch: [75][0/500]	Time 0.264 (0.264)	Data 0.233 (0.233)	Loss 0.5780 (0.5780)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:41:27 - INFO - TRAINING - Epoch: [75][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.5924 (0.6029)	Prec@1 83.000 (80.157)	Prec@5 98.000 (98.667)
2019-05-03 16:41:28 - INFO - TRAINING - Epoch: [75][100/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.4608 (0.6025)	Prec@1 86.000 (80.030)	Prec@5 100.000 (98.782)
2019-05-03 16:41:29 - INFO - TRAINING - Epoch: [75][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7346 (0.6092)	Prec@1 71.000 (79.689)	Prec@5 99.000 (98.841)
2019-05-03 16:41:30 - INFO - TRAINING - Epoch: [75][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6186 (0.6129)	Prec@1 81.000 (79.632)	Prec@5 97.000 (98.761)
2019-05-03 16:41:31 - INFO - TRAINING - Epoch: [75][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8471 (0.6124)	Prec@1 71.000 (79.614)	Prec@5 97.000 (98.717)
2019-05-03 16:41:32 - INFO - TRAINING - Epoch: [75][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6833 (0.6103)	Prec@1 78.000 (79.698)	Prec@5 100.000 (98.757)
2019-05-03 16:41:33 - INFO - TRAINING - Epoch: [75][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4724 (0.6061)	Prec@1 79.000 (79.849)	Prec@5 100.000 (98.786)
2019-05-03 16:41:34 - INFO - TRAINING - Epoch: [75][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5477 (0.6077)	Prec@1 82.000 (79.835)	Prec@5 99.000 (98.786)
2019-05-03 16:41:35 - INFO - TRAINING - Epoch: [75][450/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5951 (0.6077)	Prec@1 77.000 (79.845)	Prec@5 100.000 (98.800)
2019-05-03 16:41:36 - INFO - EVALUATING - Epoch: [75][0/100]	Time 0.336 (0.336)	Data 0.328 (0.328)	Loss 0.7312 (0.7312)	Prec@1 73.000 (73.000)	Prec@5 100.000 (100.000)
2019-05-03 16:41:37 - INFO - EVALUATING - Epoch: [75][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 0.7185 (0.7908)	Prec@1 77.000 (73.784)	Prec@5 99.000 (97.745)
2019-05-03 16:41:37 - INFO - 
 Epoch: 76	Training Loss 0.6102 	Training Prec@1 79.764 	Training Prec@5 98.796 	Validation Loss 0.7978 	Validation Prec@1 73.510 	Validation Prec@5 97.970 	
2019-05-03 16:41:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:37 - INFO - TRAINING - Epoch: [76][0/500]	Time 0.261 (0.261)	Data 0.241 (0.241)	Loss 0.6264 (0.6264)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:41:38 - INFO - TRAINING - Epoch: [76][50/500]	Time 0.024 (0.023)	Data 0.000 (0.005)	Loss 0.6053 (0.5969)	Prec@1 75.000 (80.569)	Prec@5 100.000 (99.039)
2019-05-03 16:41:39 - INFO - TRAINING - Epoch: [76][100/500]	Time 0.030 (0.022)	Data 0.000 (0.002)	Loss 0.5737 (0.6034)	Prec@1 79.000 (80.198)	Prec@5 100.000 (99.030)
2019-05-03 16:41:40 - INFO - TRAINING - Epoch: [76][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.7304 (0.6152)	Prec@1 78.000 (79.781)	Prec@5 99.000 (98.927)
2019-05-03 16:41:41 - INFO - TRAINING - Epoch: [76][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5470 (0.6224)	Prec@1 83.000 (79.537)	Prec@5 100.000 (98.866)
2019-05-03 16:41:42 - INFO - TRAINING - Epoch: [76][250/500]	Time 0.032 (0.021)	Data 0.000 (0.001)	Loss 0.6724 (0.6183)	Prec@1 80.000 (79.661)	Prec@5 99.000 (98.865)
2019-05-03 16:41:43 - INFO - TRAINING - Epoch: [76][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6033 (0.6137)	Prec@1 78.000 (79.807)	Prec@5 99.000 (98.884)
2019-05-03 16:41:44 - INFO - TRAINING - Epoch: [76][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5596 (0.6154)	Prec@1 82.000 (79.652)	Prec@5 100.000 (98.880)
2019-05-03 16:41:45 - INFO - TRAINING - Epoch: [76][400/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.4322 (0.6155)	Prec@1 84.000 (79.571)	Prec@5 100.000 (98.903)
2019-05-03 16:41:46 - INFO - TRAINING - Epoch: [76][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.7370 (0.6180)	Prec@1 78.000 (79.519)	Prec@5 98.000 (98.849)
2019-05-03 16:41:47 - INFO - EVALUATING - Epoch: [76][0/100]	Time 0.336 (0.336)	Data 0.324 (0.324)	Loss 0.8844 (0.8844)	Prec@1 70.000 (70.000)	Prec@5 97.000 (97.000)
2019-05-03 16:41:48 - INFO - EVALUATING - Epoch: [76][50/100]	Time 0.010 (0.012)	Data 0.000 (0.006)	Loss 0.7263 (0.9005)	Prec@1 74.000 (70.804)	Prec@5 100.000 (96.922)
2019-05-03 16:41:48 - INFO - 
 Epoch: 77	Training Loss 0.6177 	Training Prec@1 79.490 	Training Prec@5 98.864 	Validation Loss 0.9016 	Validation Prec@1 70.300 	Validation Prec@5 96.840 	
2019-05-03 16:41:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:48 - INFO - TRAINING - Epoch: [77][0/500]	Time 0.260 (0.260)	Data 0.237 (0.237)	Loss 0.5557 (0.5557)	Prec@1 83.000 (83.000)	Prec@5 98.000 (98.000)
2019-05-03 16:41:49 - INFO - TRAINING - Epoch: [77][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.4766 (0.6083)	Prec@1 85.000 (79.510)	Prec@5 100.000 (98.784)
2019-05-03 16:41:50 - INFO - TRAINING - Epoch: [77][100/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.5930 (0.6142)	Prec@1 77.000 (79.376)	Prec@5 99.000 (98.792)
2019-05-03 16:41:51 - INFO - TRAINING - Epoch: [77][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.5161 (0.6077)	Prec@1 79.000 (79.709)	Prec@5 99.000 (98.861)
2019-05-03 16:41:52 - INFO - TRAINING - Epoch: [77][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7283 (0.6131)	Prec@1 81.000 (79.468)	Prec@5 95.000 (98.846)
2019-05-03 16:41:53 - INFO - TRAINING - Epoch: [77][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7816 (0.6162)	Prec@1 73.000 (79.466)	Prec@5 98.000 (98.821)
2019-05-03 16:41:54 - INFO - TRAINING - Epoch: [77][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5198 (0.6144)	Prec@1 83.000 (79.605)	Prec@5 99.000 (98.817)
2019-05-03 16:41:55 - INFO - TRAINING - Epoch: [77][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6508 (0.6099)	Prec@1 74.000 (79.704)	Prec@5 99.000 (98.855)
2019-05-03 16:41:56 - INFO - TRAINING - Epoch: [77][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5966 (0.6078)	Prec@1 86.000 (79.805)	Prec@5 99.000 (98.850)
2019-05-03 16:41:57 - INFO - TRAINING - Epoch: [77][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.4640 (0.6048)	Prec@1 83.000 (79.856)	Prec@5 100.000 (98.887)
2019-05-03 16:41:59 - INFO - EVALUATING - Epoch: [77][0/100]	Time 0.270 (0.270)	Data 0.263 (0.263)	Loss 0.5856 (0.5856)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:41:59 - INFO - EVALUATING - Epoch: [77][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.6767 (0.6991)	Prec@1 79.000 (77.235)	Prec@5 96.000 (98.020)
2019-05-03 16:41:59 - INFO - 
 Epoch: 78	Training Loss 0.6045 	Training Prec@1 79.876 	Training Prec@5 98.894 	Validation Loss 0.6985 	Validation Prec@1 76.980 	Validation Prec@5 98.260 	
2019-05-03 16:41:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:41:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:41:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:41:59 - INFO - TRAINING - Epoch: [78][0/500]	Time 0.261 (0.261)	Data 0.233 (0.233)	Loss 0.4760 (0.4760)	Prec@1 85.000 (85.000)	Prec@5 98.000 (98.000)
2019-05-03 16:42:00 - INFO - TRAINING - Epoch: [78][50/500]	Time 0.017 (0.026)	Data 0.000 (0.005)	Loss 0.6579 (0.6005)	Prec@1 79.000 (80.078)	Prec@5 98.000 (98.902)
2019-05-03 16:42:02 - INFO - TRAINING - Epoch: [78][100/500]	Time 0.016 (0.023)	Data 0.000 (0.002)	Loss 0.7119 (0.5938)	Prec@1 75.000 (79.931)	Prec@5 98.000 (98.901)
2019-05-03 16:42:03 - INFO - TRAINING - Epoch: [78][150/500]	Time 0.012 (0.022)	Data 0.000 (0.002)	Loss 0.6716 (0.5923)	Prec@1 78.000 (80.192)	Prec@5 99.000 (98.947)
2019-05-03 16:42:03 - INFO - TRAINING - Epoch: [78][200/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7080 (0.5991)	Prec@1 72.000 (80.050)	Prec@5 99.000 (98.915)
2019-05-03 16:42:04 - INFO - TRAINING - Epoch: [78][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6945 (0.6020)	Prec@1 77.000 (80.088)	Prec@5 99.000 (98.900)
2019-05-03 16:42:06 - INFO - TRAINING - Epoch: [78][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5120 (0.6026)	Prec@1 86.000 (80.053)	Prec@5 99.000 (98.900)
2019-05-03 16:42:06 - INFO - TRAINING - Epoch: [78][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.8279 (0.6042)	Prec@1 72.000 (79.980)	Prec@5 96.000 (98.897)
2019-05-03 16:42:07 - INFO - TRAINING - Epoch: [78][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5613 (0.6024)	Prec@1 85.000 (80.052)	Prec@5 99.000 (98.898)
2019-05-03 16:42:08 - INFO - TRAINING - Epoch: [78][450/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.5410 (0.6034)	Prec@1 84.000 (79.971)	Prec@5 98.000 (98.905)
2019-05-03 16:42:10 - INFO - EVALUATING - Epoch: [78][0/100]	Time 0.362 (0.362)	Data 0.353 (0.353)	Loss 0.6749 (0.6749)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:42:10 - INFO - EVALUATING - Epoch: [78][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.5738 (0.6858)	Prec@1 81.000 (77.235)	Prec@5 96.000 (98.412)
2019-05-03 16:42:10 - INFO - 
 Epoch: 79	Training Loss 0.6068 	Training Prec@1 79.826 	Training Prec@5 98.882 	Validation Loss 0.6781 	Validation Prec@1 77.300 	Validation Prec@5 98.590 	
2019-05-03 16:42:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:42:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:42:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:42:11 - INFO - TRAINING - Epoch: [79][0/500]	Time 0.247 (0.247)	Data 0.229 (0.229)	Loss 0.5285 (0.5285)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 16:42:12 - INFO - TRAINING - Epoch: [79][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.6227 (0.6089)	Prec@1 81.000 (79.373)	Prec@5 99.000 (99.059)
2019-05-03 16:42:13 - INFO - TRAINING - Epoch: [79][100/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6874 (0.5942)	Prec@1 78.000 (80.188)	Prec@5 99.000 (99.040)
2019-05-03 16:42:14 - INFO - TRAINING - Epoch: [79][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.6422 (0.5955)	Prec@1 81.000 (80.225)	Prec@5 99.000 (99.020)
2019-05-03 16:42:15 - INFO - TRAINING - Epoch: [79][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6383 (0.6088)	Prec@1 77.000 (79.741)	Prec@5 97.000 (98.905)
2019-05-03 16:42:16 - INFO - TRAINING - Epoch: [79][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5625 (0.6041)	Prec@1 81.000 (79.769)	Prec@5 99.000 (98.956)
2019-05-03 16:42:17 - INFO - TRAINING - Epoch: [79][300/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5530 (0.6018)	Prec@1 81.000 (79.924)	Prec@5 99.000 (98.944)
2019-05-03 16:42:18 - INFO - TRAINING - Epoch: [79][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5121 (0.6006)	Prec@1 82.000 (79.969)	Prec@5 100.000 (98.923)
2019-05-03 16:42:19 - INFO - TRAINING - Epoch: [79][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5466 (0.5996)	Prec@1 86.000 (80.055)	Prec@5 100.000 (98.898)
2019-05-03 16:42:19 - INFO - TRAINING - Epoch: [79][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.4502 (0.5993)	Prec@1 86.000 (80.062)	Prec@5 99.000 (98.907)
2019-05-03 16:42:21 - INFO - EVALUATING - Epoch: [79][0/100]	Time 0.349 (0.349)	Data 0.334 (0.334)	Loss 0.6537 (0.6537)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:42:21 - INFO - EVALUATING - Epoch: [79][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.8060 (0.8205)	Prec@1 77.000 (72.863)	Prec@5 94.000 (97.510)
2019-05-03 16:42:21 - INFO - 
 Epoch: 80	Training Loss 0.6001 	Training Prec@1 79.990 	Training Prec@5 98.920 	Validation Loss 0.8126 	Validation Prec@1 73.200 	Validation Prec@5 97.820 	
2019-05-03 16:42:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:42:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:42:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:42:22 - INFO - TRAINING - Epoch: [80][0/500]	Time 0.269 (0.269)	Data 0.240 (0.240)	Loss 0.8187 (0.8187)	Prec@1 73.000 (73.000)	Prec@5 98.000 (98.000)
2019-05-03 16:42:23 - INFO - TRAINING - Epoch: [80][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.4638 (0.5963)	Prec@1 84.000 (79.706)	Prec@5 99.000 (99.137)
2019-05-03 16:42:24 - INFO - TRAINING - Epoch: [80][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.6169 (0.5951)	Prec@1 80.000 (79.911)	Prec@5 99.000 (98.960)
2019-05-03 16:42:25 - INFO - TRAINING - Epoch: [80][150/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.3255 (0.5948)	Prec@1 90.000 (79.940)	Prec@5 100.000 (98.940)
2019-05-03 16:42:26 - INFO - TRAINING - Epoch: [80][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4677 (0.5980)	Prec@1 87.000 (80.020)	Prec@5 100.000 (98.905)
2019-05-03 16:42:27 - INFO - TRAINING - Epoch: [80][250/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.5867 (0.6030)	Prec@1 83.000 (79.749)	Prec@5 100.000 (98.880)
2019-05-03 16:42:28 - INFO - TRAINING - Epoch: [80][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.6432 (0.5996)	Prec@1 79.000 (80.007)	Prec@5 97.000 (98.877)
2019-05-03 16:42:29 - INFO - TRAINING - Epoch: [80][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.6017 (0.5989)	Prec@1 81.000 (80.048)	Prec@5 97.000 (98.877)
2019-05-03 16:42:30 - INFO - TRAINING - Epoch: [80][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.5660 (0.6000)	Prec@1 79.000 (79.970)	Prec@5 100.000 (98.855)
2019-05-03 16:42:31 - INFO - TRAINING - Epoch: [80][450/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.6088 (0.6012)	Prec@1 84.000 (79.958)	Prec@5 96.000 (98.847)
2019-05-03 16:42:32 - INFO - EVALUATING - Epoch: [80][0/100]	Time 0.323 (0.323)	Data 0.311 (0.311)	Loss 0.6164 (0.6164)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:42:32 - INFO - EVALUATING - Epoch: [80][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6093 (0.6882)	Prec@1 81.000 (77.647)	Prec@5 96.000 (98.255)
2019-05-03 16:42:32 - INFO - 
 Epoch: 81	Training Loss 0.6003 	Training Prec@1 79.976 	Training Prec@5 98.884 	Validation Loss 0.6938 	Validation Prec@1 77.240 	Validation Prec@5 98.400 	
2019-05-03 16:42:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:42:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:42:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:42:33 - INFO - TRAINING - Epoch: [81][0/500]	Time 0.261 (0.261)	Data 0.235 (0.235)	Loss 0.4930 (0.4930)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:42:34 - INFO - TRAINING - Epoch: [81][50/500]	Time 0.028 (0.023)	Data 0.000 (0.005)	Loss 0.6286 (0.6068)	Prec@1 80.000 (79.490)	Prec@5 99.000 (98.745)
2019-05-03 16:42:35 - INFO - TRAINING - Epoch: [81][100/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.7196 (0.5952)	Prec@1 76.000 (79.762)	Prec@5 98.000 (98.950)
2019-05-03 16:42:36 - INFO - TRAINING - Epoch: [81][150/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.7186 (0.5950)	Prec@1 76.000 (79.934)	Prec@5 95.000 (98.901)
2019-05-03 16:42:37 - INFO - TRAINING - Epoch: [81][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6271 (0.6019)	Prec@1 76.000 (79.667)	Prec@5 100.000 (98.905)
2019-05-03 16:42:38 - INFO - TRAINING - Epoch: [81][250/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.6751 (0.5972)	Prec@1 80.000 (79.936)	Prec@5 97.000 (98.920)
2019-05-03 16:42:39 - INFO - TRAINING - Epoch: [81][300/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5562 (0.5965)	Prec@1 82.000 (79.977)	Prec@5 99.000 (98.934)
2019-05-03 16:42:40 - INFO - TRAINING - Epoch: [81][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.5365 (0.5946)	Prec@1 86.000 (80.105)	Prec@5 99.000 (98.923)
2019-05-03 16:42:41 - INFO - TRAINING - Epoch: [81][400/500]	Time 0.032 (0.020)	Data 0.000 (0.001)	Loss 0.7676 (0.5983)	Prec@1 78.000 (79.943)	Prec@5 97.000 (98.910)
2019-05-03 16:42:42 - INFO - TRAINING - Epoch: [81][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.7267 (0.6013)	Prec@1 79.000 (79.896)	Prec@5 96.000 (98.902)
2019-05-03 16:42:43 - INFO - EVALUATING - Epoch: [81][0/100]	Time 0.335 (0.335)	Data 0.328 (0.328)	Loss 0.6408 (0.6408)	Prec@1 73.000 (73.000)	Prec@5 100.000 (100.000)
2019-05-03 16:42:43 - INFO - EVALUATING - Epoch: [81][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6012 (0.6783)	Prec@1 83.000 (77.451)	Prec@5 97.000 (98.686)
2019-05-03 16:42:43 - INFO - 
 Epoch: 82	Training Loss 0.5994 	Training Prec@1 79.954 	Training Prec@5 98.896 	Validation Loss 0.6747 	Validation Prec@1 77.550 	Validation Prec@5 98.710 	
2019-05-03 16:42:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:42:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:42:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:42:44 - INFO - TRAINING - Epoch: [82][0/500]	Time 0.282 (0.282)	Data 0.252 (0.252)	Loss 0.5416 (0.5416)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:42:45 - INFO - TRAINING - Epoch: [82][50/500]	Time 0.021 (0.025)	Data 0.000 (0.005)	Loss 0.5692 (0.6067)	Prec@1 79.000 (79.804)	Prec@5 99.000 (98.961)
2019-05-03 16:42:46 - INFO - TRAINING - Epoch: [82][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.4329 (0.5980)	Prec@1 87.000 (79.842)	Prec@5 99.000 (98.891)
2019-05-03 16:42:47 - INFO - TRAINING - Epoch: [82][150/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.5580 (0.5989)	Prec@1 82.000 (80.159)	Prec@5 100.000 (98.848)
2019-05-03 16:42:48 - INFO - TRAINING - Epoch: [82][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4865 (0.5926)	Prec@1 87.000 (80.458)	Prec@5 98.000 (98.915)
2019-05-03 16:42:49 - INFO - TRAINING - Epoch: [82][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6165 (0.5933)	Prec@1 82.000 (80.375)	Prec@5 97.000 (98.960)
2019-05-03 16:42:50 - INFO - TRAINING - Epoch: [82][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.4620 (0.5930)	Prec@1 83.000 (80.262)	Prec@5 100.000 (98.953)
2019-05-03 16:42:51 - INFO - TRAINING - Epoch: [82][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6362 (0.5954)	Prec@1 79.000 (80.225)	Prec@5 99.000 (98.929)
2019-05-03 16:42:52 - INFO - TRAINING - Epoch: [82][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6724 (0.5988)	Prec@1 77.000 (80.187)	Prec@5 99.000 (98.930)
2019-05-03 16:42:53 - INFO - TRAINING - Epoch: [82][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6704 (0.5980)	Prec@1 76.000 (80.188)	Prec@5 97.000 (98.931)
2019-05-03 16:42:54 - INFO - EVALUATING - Epoch: [82][0/100]	Time 0.352 (0.352)	Data 0.341 (0.341)	Loss 0.6657 (0.6657)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:42:55 - INFO - EVALUATING - Epoch: [82][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6675 (0.7204)	Prec@1 83.000 (76.294)	Prec@5 97.000 (98.078)
2019-05-03 16:42:55 - INFO - 
 Epoch: 83	Training Loss 0.5970 	Training Prec@1 80.232 	Training Prec@5 98.926 	Validation Loss 0.7258 	Validation Prec@1 75.870 	Validation Prec@5 98.190 	
2019-05-03 16:42:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:42:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:42:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:42:55 - INFO - TRAINING - Epoch: [83][0/500]	Time 0.281 (0.281)	Data 0.249 (0.249)	Loss 0.6879 (0.6879)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:42:56 - INFO - TRAINING - Epoch: [83][50/500]	Time 0.022 (0.025)	Data 0.000 (0.005)	Loss 0.4941 (0.6055)	Prec@1 83.000 (79.627)	Prec@5 98.000 (98.941)
2019-05-03 16:42:57 - INFO - TRAINING - Epoch: [83][100/500]	Time 0.013 (0.022)	Data 0.000 (0.003)	Loss 0.6591 (0.6071)	Prec@1 77.000 (79.782)	Prec@5 99.000 (98.842)
2019-05-03 16:42:58 - INFO - TRAINING - Epoch: [83][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.7114 (0.6005)	Prec@1 76.000 (80.086)	Prec@5 99.000 (98.907)
2019-05-03 16:42:59 - INFO - TRAINING - Epoch: [83][200/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5147 (0.5974)	Prec@1 85.000 (80.109)	Prec@5 97.000 (98.925)
2019-05-03 16:43:00 - INFO - TRAINING - Epoch: [83][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7935 (0.5950)	Prec@1 76.000 (80.187)	Prec@5 97.000 (98.988)
2019-05-03 16:43:01 - INFO - TRAINING - Epoch: [83][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.4842 (0.5937)	Prec@1 81.000 (80.296)	Prec@5 100.000 (98.977)
2019-05-03 16:43:02 - INFO - TRAINING - Epoch: [83][350/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.4916 (0.5936)	Prec@1 83.000 (80.285)	Prec@5 100.000 (98.946)
2019-05-03 16:43:03 - INFO - TRAINING - Epoch: [83][400/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5783 (0.5955)	Prec@1 77.000 (80.284)	Prec@5 99.000 (98.910)
2019-05-03 16:43:04 - INFO - TRAINING - Epoch: [83][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5854 (0.5953)	Prec@1 81.000 (80.310)	Prec@5 100.000 (98.918)
2019-05-03 16:43:06 - INFO - EVALUATING - Epoch: [83][0/100]	Time 0.331 (0.331)	Data 0.323 (0.323)	Loss 0.6559 (0.6559)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:43:06 - INFO - EVALUATING - Epoch: [83][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 0.6823 (0.7354)	Prec@1 81.000 (76.569)	Prec@5 95.000 (97.745)
2019-05-03 16:43:06 - INFO - 
 Epoch: 84	Training Loss 0.5967 	Training Prec@1 80.262 	Training Prec@5 98.910 	Validation Loss 0.7322 	Validation Prec@1 76.420 	Validation Prec@5 97.840 	
2019-05-03 16:43:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:43:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:43:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:43:06 - INFO - TRAINING - Epoch: [84][0/500]	Time 0.244 (0.244)	Data 0.219 (0.219)	Loss 0.5920 (0.5920)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:43:07 - INFO - TRAINING - Epoch: [84][50/500]	Time 0.023 (0.025)	Data 0.000 (0.004)	Loss 0.4073 (0.6029)	Prec@1 90.000 (80.000)	Prec@5 99.000 (98.941)
2019-05-03 16:43:08 - INFO - TRAINING - Epoch: [84][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.5407 (0.5862)	Prec@1 80.000 (80.485)	Prec@5 100.000 (98.941)
2019-05-03 16:43:09 - INFO - TRAINING - Epoch: [84][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.5477 (0.5947)	Prec@1 84.000 (80.139)	Prec@5 100.000 (98.861)
2019-05-03 16:43:10 - INFO - TRAINING - Epoch: [84][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4422 (0.5878)	Prec@1 84.000 (80.413)	Prec@5 99.000 (98.886)
2019-05-03 16:43:11 - INFO - TRAINING - Epoch: [84][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6868 (0.5897)	Prec@1 79.000 (80.331)	Prec@5 99.000 (98.968)
2019-05-03 16:43:12 - INFO - TRAINING - Epoch: [84][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5157 (0.5887)	Prec@1 82.000 (80.462)	Prec@5 99.000 (98.927)
2019-05-03 16:43:14 - INFO - TRAINING - Epoch: [84][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6913 (0.5875)	Prec@1 77.000 (80.479)	Prec@5 96.000 (98.903)
2019-05-03 16:43:15 - INFO - TRAINING - Epoch: [84][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5020 (0.5865)	Prec@1 83.000 (80.559)	Prec@5 100.000 (98.935)
2019-05-03 16:43:16 - INFO - TRAINING - Epoch: [84][450/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.4978 (0.5894)	Prec@1 85.000 (80.424)	Prec@5 97.000 (98.918)
2019-05-03 16:43:17 - INFO - EVALUATING - Epoch: [84][0/100]	Time 0.333 (0.333)	Data 0.323 (0.323)	Loss 0.5532 (0.5532)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:43:17 - INFO - EVALUATING - Epoch: [84][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.6088 (0.7572)	Prec@1 84.000 (75.961)	Prec@5 96.000 (97.471)
2019-05-03 16:43:17 - INFO - 
 Epoch: 85	Training Loss 0.5901 	Training Prec@1 80.354 	Training Prec@5 98.912 	Validation Loss 0.7679 	Validation Prec@1 75.050 	Validation Prec@5 97.680 	
2019-05-03 16:43:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:43:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:43:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:43:18 - INFO - TRAINING - Epoch: [85][0/500]	Time 0.260 (0.260)	Data 0.239 (0.239)	Loss 0.7415 (0.7415)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 16:43:19 - INFO - TRAINING - Epoch: [85][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.6829 (0.5927)	Prec@1 73.000 (79.843)	Prec@5 100.000 (99.020)
2019-05-03 16:43:20 - INFO - TRAINING - Epoch: [85][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.4800 (0.5746)	Prec@1 80.000 (80.495)	Prec@5 99.000 (99.158)
2019-05-03 16:43:21 - INFO - TRAINING - Epoch: [85][150/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 0.5863 (0.5727)	Prec@1 82.000 (80.848)	Prec@5 100.000 (99.099)
2019-05-03 16:43:22 - INFO - TRAINING - Epoch: [85][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4859 (0.5818)	Prec@1 85.000 (80.627)	Prec@5 100.000 (99.045)
2019-05-03 16:43:23 - INFO - TRAINING - Epoch: [85][250/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.6298 (0.5848)	Prec@1 80.000 (80.538)	Prec@5 99.000 (99.012)
2019-05-03 16:43:24 - INFO - TRAINING - Epoch: [85][300/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.7189 (0.5868)	Prec@1 78.000 (80.492)	Prec@5 94.000 (98.997)
2019-05-03 16:43:25 - INFO - TRAINING - Epoch: [85][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6367 (0.5897)	Prec@1 84.000 (80.444)	Prec@5 99.000 (98.989)
2019-05-03 16:43:26 - INFO - TRAINING - Epoch: [85][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6688 (0.5914)	Prec@1 80.000 (80.367)	Prec@5 98.000 (98.990)
2019-05-03 16:43:27 - INFO - TRAINING - Epoch: [85][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.4734 (0.5904)	Prec@1 84.000 (80.395)	Prec@5 99.000 (99.000)
2019-05-03 16:43:28 - INFO - EVALUATING - Epoch: [85][0/100]	Time 0.336 (0.336)	Data 0.327 (0.327)	Loss 0.8732 (0.8732)	Prec@1 73.000 (73.000)	Prec@5 98.000 (98.000)
2019-05-03 16:43:28 - INFO - EVALUATING - Epoch: [85][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.8431 (0.8480)	Prec@1 76.000 (72.275)	Prec@5 95.000 (97.608)
2019-05-03 16:43:28 - INFO - 
 Epoch: 86	Training Loss 0.5908 	Training Prec@1 80.378 	Training Prec@5 98.994 	Validation Loss 0.8390 	Validation Prec@1 72.420 	Validation Prec@5 97.760 	
2019-05-03 16:43:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:43:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:43:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:43:29 - INFO - TRAINING - Epoch: [86][0/500]	Time 0.253 (0.253)	Data 0.234 (0.234)	Loss 0.6937 (0.6937)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 16:43:30 - INFO - TRAINING - Epoch: [86][50/500]	Time 0.023 (0.022)	Data 0.000 (0.005)	Loss 0.5924 (0.5644)	Prec@1 82.000 (80.882)	Prec@5 99.000 (98.922)
2019-05-03 16:43:31 - INFO - TRAINING - Epoch: [86][100/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.5055 (0.5719)	Prec@1 82.000 (80.644)	Prec@5 100.000 (99.030)
2019-05-03 16:43:32 - INFO - TRAINING - Epoch: [86][150/500]	Time 0.014 (0.020)	Data 0.000 (0.002)	Loss 0.7589 (0.5747)	Prec@1 77.000 (80.788)	Prec@5 99.000 (98.987)
2019-05-03 16:43:33 - INFO - TRAINING - Epoch: [86][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.4807 (0.5749)	Prec@1 83.000 (80.856)	Prec@5 100.000 (98.980)
2019-05-03 16:43:33 - INFO - TRAINING - Epoch: [86][250/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5926 (0.5794)	Prec@1 78.000 (80.717)	Prec@5 99.000 (98.980)
2019-05-03 16:43:34 - INFO - TRAINING - Epoch: [86][300/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.7251 (0.5811)	Prec@1 74.000 (80.658)	Prec@5 97.000 (98.970)
2019-05-03 16:43:35 - INFO - TRAINING - Epoch: [86][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5866 (0.5824)	Prec@1 81.000 (80.698)	Prec@5 99.000 (98.943)
2019-05-03 16:43:36 - INFO - TRAINING - Epoch: [86][400/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.4904 (0.5848)	Prec@1 85.000 (80.564)	Prec@5 100.000 (98.953)
2019-05-03 16:43:37 - INFO - TRAINING - Epoch: [86][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5846 (0.5867)	Prec@1 82.000 (80.488)	Prec@5 96.000 (98.916)
2019-05-03 16:43:39 - INFO - EVALUATING - Epoch: [86][0/100]	Time 0.344 (0.344)	Data 0.326 (0.326)	Loss 0.5540 (0.5540)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 16:43:39 - INFO - EVALUATING - Epoch: [86][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6219 (0.6905)	Prec@1 79.000 (77.176)	Prec@5 97.000 (98.431)
2019-05-03 16:43:39 - INFO - 
 Epoch: 87	Training Loss 0.5891 	Training Prec@1 80.384 	Training Prec@5 98.930 	Validation Loss 0.6877 	Validation Prec@1 76.870 	Validation Prec@5 98.630 	
2019-05-03 16:43:39 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:43:39 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:43:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:43:40 - INFO - TRAINING - Epoch: [87][0/500]	Time 0.257 (0.257)	Data 0.236 (0.236)	Loss 0.5145 (0.5145)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 16:43:41 - INFO - TRAINING - Epoch: [87][50/500]	Time 0.028 (0.025)	Data 0.000 (0.005)	Loss 0.7220 (0.5942)	Prec@1 81.000 (80.569)	Prec@5 98.000 (98.863)
2019-05-03 16:43:42 - INFO - TRAINING - Epoch: [87][100/500]	Time 0.016 (0.023)	Data 0.000 (0.002)	Loss 0.4770 (0.5803)	Prec@1 82.000 (80.792)	Prec@5 99.000 (98.960)
2019-05-03 16:43:42 - INFO - TRAINING - Epoch: [87][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.4741 (0.5770)	Prec@1 85.000 (80.887)	Prec@5 100.000 (99.026)
2019-05-03 16:43:43 - INFO - TRAINING - Epoch: [87][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6226 (0.5794)	Prec@1 83.000 (80.811)	Prec@5 97.000 (99.010)
2019-05-03 16:43:44 - INFO - TRAINING - Epoch: [87][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.8078 (0.5826)	Prec@1 76.000 (80.717)	Prec@5 100.000 (99.028)
2019-05-03 16:43:45 - INFO - TRAINING - Epoch: [87][300/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5571 (0.5821)	Prec@1 83.000 (80.681)	Prec@5 99.000 (99.033)
2019-05-03 16:43:46 - INFO - TRAINING - Epoch: [87][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.4880 (0.5832)	Prec@1 87.000 (80.635)	Prec@5 96.000 (99.046)
2019-05-03 16:43:47 - INFO - TRAINING - Epoch: [87][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.7093 (0.5829)	Prec@1 71.000 (80.633)	Prec@5 100.000 (98.998)
2019-05-03 16:43:48 - INFO - TRAINING - Epoch: [87][450/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.7404 (0.5826)	Prec@1 73.000 (80.636)	Prec@5 100.000 (99.016)
2019-05-03 16:43:49 - INFO - EVALUATING - Epoch: [87][0/100]	Time 0.255 (0.255)	Data 0.247 (0.247)	Loss 0.5796 (0.5796)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:43:50 - INFO - EVALUATING - Epoch: [87][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.4446 (0.6728)	Prec@1 86.000 (77.608)	Prec@5 97.000 (98.569)
2019-05-03 16:43:50 - INFO - 
 Epoch: 88	Training Loss 0.5831 	Training Prec@1 80.630 	Training Prec@5 99.010 	Validation Loss 0.6778 	Validation Prec@1 77.530 	Validation Prec@5 98.630 	
2019-05-03 16:43:50 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:43:50 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:43:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:43:50 - INFO - TRAINING - Epoch: [88][0/500]	Time 0.277 (0.277)	Data 0.251 (0.251)	Loss 0.4707 (0.4707)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 16:43:51 - INFO - TRAINING - Epoch: [88][50/500]	Time 0.015 (0.026)	Data 0.000 (0.005)	Loss 0.4329 (0.5843)	Prec@1 87.000 (80.353)	Prec@5 100.000 (99.059)
2019-05-03 16:43:52 - INFO - TRAINING - Epoch: [88][100/500]	Time 0.023 (0.023)	Data 0.000 (0.003)	Loss 0.5715 (0.5915)	Prec@1 77.000 (80.079)	Prec@5 100.000 (99.030)
2019-05-03 16:43:53 - INFO - TRAINING - Epoch: [88][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.5385 (0.5882)	Prec@1 81.000 (80.325)	Prec@5 99.000 (99.066)
2019-05-03 16:43:54 - INFO - TRAINING - Epoch: [88][200/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5704 (0.5874)	Prec@1 79.000 (80.328)	Prec@5 100.000 (99.095)
2019-05-03 16:43:55 - INFO - TRAINING - Epoch: [88][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.6008 (0.5848)	Prec@1 80.000 (80.446)	Prec@5 100.000 (99.084)
2019-05-03 16:43:56 - INFO - TRAINING - Epoch: [88][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.7260 (0.5847)	Prec@1 80.000 (80.512)	Prec@5 99.000 (99.027)
2019-05-03 16:43:57 - INFO - TRAINING - Epoch: [88][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.4757 (0.5838)	Prec@1 86.000 (80.501)	Prec@5 97.000 (99.017)
2019-05-03 16:43:58 - INFO - TRAINING - Epoch: [88][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4556 (0.5885)	Prec@1 85.000 (80.344)	Prec@5 100.000 (99.002)
2019-05-03 16:43:59 - INFO - TRAINING - Epoch: [88][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5284 (0.5884)	Prec@1 83.000 (80.337)	Prec@5 100.000 (99.018)
2019-05-03 16:44:00 - INFO - EVALUATING - Epoch: [88][0/100]	Time 0.293 (0.293)	Data 0.283 (0.283)	Loss 0.6579 (0.6579)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 16:44:01 - INFO - EVALUATING - Epoch: [88][50/100]	Time 0.006 (0.011)	Data 0.000 (0.006)	Loss 0.5536 (0.6869)	Prec@1 85.000 (77.490)	Prec@5 97.000 (97.941)
2019-05-03 16:44:01 - INFO - 
 Epoch: 89	Training Loss 0.5856 	Training Prec@1 80.428 	Training Prec@5 99.036 	Validation Loss 0.6855 	Validation Prec@1 77.520 	Validation Prec@5 98.330 	
2019-05-03 16:44:01 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:01 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:01 - INFO - TRAINING - Epoch: [89][0/500]	Time 0.253 (0.253)	Data 0.221 (0.221)	Loss 0.5035 (0.5035)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:02 - INFO - TRAINING - Epoch: [89][50/500]	Time 0.023 (0.024)	Data 0.000 (0.004)	Loss 0.5445 (0.5927)	Prec@1 85.000 (80.059)	Prec@5 100.000 (99.039)
2019-05-03 16:44:03 - INFO - TRAINING - Epoch: [89][100/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.6098 (0.5846)	Prec@1 80.000 (80.515)	Prec@5 98.000 (99.030)
2019-05-03 16:44:04 - INFO - TRAINING - Epoch: [89][150/500]	Time 0.015 (0.019)	Data 0.000 (0.002)	Loss 0.4482 (0.5732)	Prec@1 86.000 (81.086)	Prec@5 100.000 (99.020)
2019-05-03 16:44:05 - INFO - TRAINING - Epoch: [89][200/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 0.7079 (0.5721)	Prec@1 82.000 (81.075)	Prec@5 99.000 (99.000)
2019-05-03 16:44:06 - INFO - TRAINING - Epoch: [89][250/500]	Time 0.028 (0.019)	Data 0.000 (0.001)	Loss 0.3927 (0.5739)	Prec@1 90.000 (80.988)	Prec@5 99.000 (98.964)
2019-05-03 16:44:07 - INFO - TRAINING - Epoch: [89][300/500]	Time 0.015 (0.019)	Data 0.000 (0.001)	Loss 0.6798 (0.5761)	Prec@1 77.000 (80.940)	Prec@5 99.000 (98.960)
2019-05-03 16:44:07 - INFO - TRAINING - Epoch: [89][350/500]	Time 0.029 (0.018)	Data 0.000 (0.001)	Loss 0.5587 (0.5811)	Prec@1 83.000 (80.821)	Prec@5 99.000 (98.940)
2019-05-03 16:44:08 - INFO - TRAINING - Epoch: [89][400/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 0.6161 (0.5822)	Prec@1 81.000 (80.773)	Prec@5 98.000 (98.948)
2019-05-03 16:44:09 - INFO - TRAINING - Epoch: [89][450/500]	Time 0.024 (0.019)	Data 0.000 (0.001)	Loss 0.4693 (0.5827)	Prec@1 83.000 (80.707)	Prec@5 99.000 (98.938)
2019-05-03 16:44:11 - INFO - EVALUATING - Epoch: [89][0/100]	Time 0.242 (0.242)	Data 0.230 (0.230)	Loss 0.6283 (0.6283)	Prec@1 77.000 (77.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:11 - INFO - EVALUATING - Epoch: [89][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.5589 (0.6715)	Prec@1 85.000 (77.176)	Prec@5 97.000 (98.529)
2019-05-03 16:44:11 - INFO - 
 Epoch: 90	Training Loss 0.5861 	Training Prec@1 80.602 	Training Prec@5 98.920 	Validation Loss 0.6711 	Validation Prec@1 77.430 	Validation Prec@5 98.710 	
2019-05-03 16:44:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:11 - INFO - TRAINING - Epoch: [90][0/500]	Time 0.262 (0.262)	Data 0.237 (0.237)	Loss 0.5128 (0.5128)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:12 - INFO - TRAINING - Epoch: [90][50/500]	Time 0.012 (0.023)	Data 0.000 (0.005)	Loss 0.4897 (0.5826)	Prec@1 85.000 (81.000)	Prec@5 100.000 (98.765)
2019-05-03 16:44:13 - INFO - TRAINING - Epoch: [90][100/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.5721 (0.5772)	Prec@1 79.000 (81.030)	Prec@5 99.000 (98.812)
2019-05-03 16:44:14 - INFO - TRAINING - Epoch: [90][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7061 (0.5777)	Prec@1 73.000 (80.993)	Prec@5 99.000 (98.874)
2019-05-03 16:44:15 - INFO - TRAINING - Epoch: [90][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4862 (0.5756)	Prec@1 82.000 (80.990)	Prec@5 100.000 (98.871)
2019-05-03 16:44:16 - INFO - TRAINING - Epoch: [90][250/500]	Time 0.032 (0.021)	Data 0.000 (0.001)	Loss 0.5334 (0.5764)	Prec@1 84.000 (80.940)	Prec@5 99.000 (98.900)
2019-05-03 16:44:17 - INFO - TRAINING - Epoch: [90][300/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5998 (0.5805)	Prec@1 80.000 (80.831)	Prec@5 99.000 (98.874)
2019-05-03 16:44:18 - INFO - TRAINING - Epoch: [90][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.4736 (0.5783)	Prec@1 85.000 (80.915)	Prec@5 98.000 (98.883)
2019-05-03 16:44:19 - INFO - TRAINING - Epoch: [90][400/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5787 (0.5782)	Prec@1 77.000 (80.885)	Prec@5 100.000 (98.885)
2019-05-03 16:44:20 - INFO - TRAINING - Epoch: [90][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7102 (0.5820)	Prec@1 78.000 (80.785)	Prec@5 99.000 (98.905)
2019-05-03 16:44:22 - INFO - EVALUATING - Epoch: [90][0/100]	Time 0.334 (0.334)	Data 0.327 (0.327)	Loss 0.5013 (0.5013)	Prec@1 84.000 (84.000)	Prec@5 98.000 (98.000)
2019-05-03 16:44:22 - INFO - EVALUATING - Epoch: [90][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.5414 (0.6745)	Prec@1 83.000 (77.824)	Prec@5 99.000 (98.549)
2019-05-03 16:44:22 - INFO - 
 Epoch: 91	Training Loss 0.5818 	Training Prec@1 80.784 	Training Prec@5 98.888 	Validation Loss 0.6622 	Validation Prec@1 78.180 	Validation Prec@5 98.670 	
2019-05-03 16:44:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:23 - INFO - TRAINING - Epoch: [91][0/500]	Time 0.274 (0.274)	Data 0.251 (0.251)	Loss 0.5649 (0.5649)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:44:24 - INFO - TRAINING - Epoch: [91][50/500]	Time 0.016 (0.023)	Data 0.000 (0.005)	Loss 0.6076 (0.5599)	Prec@1 80.000 (81.137)	Prec@5 99.000 (98.902)
2019-05-03 16:44:24 - INFO - TRAINING - Epoch: [91][100/500]	Time 0.025 (0.022)	Data 0.000 (0.003)	Loss 0.7285 (0.5743)	Prec@1 74.000 (80.723)	Prec@5 97.000 (98.921)
2019-05-03 16:44:25 - INFO - TRAINING - Epoch: [91][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.7018 (0.5787)	Prec@1 80.000 (80.960)	Prec@5 99.000 (98.874)
2019-05-03 16:44:26 - INFO - TRAINING - Epoch: [91][200/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6333 (0.5835)	Prec@1 79.000 (80.711)	Prec@5 95.000 (98.841)
2019-05-03 16:44:27 - INFO - TRAINING - Epoch: [91][250/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.3877 (0.5837)	Prec@1 89.000 (80.721)	Prec@5 100.000 (98.880)
2019-05-03 16:44:28 - INFO - TRAINING - Epoch: [91][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5526 (0.5847)	Prec@1 77.000 (80.704)	Prec@5 100.000 (98.887)
2019-05-03 16:44:29 - INFO - TRAINING - Epoch: [91][350/500]	Time 0.032 (0.020)	Data 0.000 (0.001)	Loss 0.5765 (0.5834)	Prec@1 79.000 (80.712)	Prec@5 98.000 (98.886)
2019-05-03 16:44:30 - INFO - TRAINING - Epoch: [91][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6609 (0.5844)	Prec@1 78.000 (80.623)	Prec@5 100.000 (98.925)
2019-05-03 16:44:31 - INFO - TRAINING - Epoch: [91][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4448 (0.5833)	Prec@1 85.000 (80.647)	Prec@5 100.000 (98.938)
2019-05-03 16:44:32 - INFO - EVALUATING - Epoch: [91][0/100]	Time 0.261 (0.261)	Data 0.247 (0.247)	Loss 0.5897 (0.5897)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:44:33 - INFO - EVALUATING - Epoch: [91][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.6552 (0.6620)	Prec@1 80.000 (78.804)	Prec@5 98.000 (98.471)
2019-05-03 16:44:33 - INFO - 
 Epoch: 92	Training Loss 0.5836 	Training Prec@1 80.672 	Training Prec@5 98.938 	Validation Loss 0.6617 	Validation Prec@1 78.440 	Validation Prec@5 98.520 	
2019-05-03 16:44:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:33 - INFO - TRAINING - Epoch: [92][0/500]	Time 0.278 (0.278)	Data 0.247 (0.247)	Loss 0.4760 (0.4760)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:34 - INFO - TRAINING - Epoch: [92][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.3542 (0.5677)	Prec@1 90.000 (81.588)	Prec@5 100.000 (98.941)
2019-05-03 16:44:35 - INFO - TRAINING - Epoch: [92][100/500]	Time 0.017 (0.023)	Data 0.000 (0.003)	Loss 0.4819 (0.5676)	Prec@1 83.000 (81.287)	Prec@5 100.000 (98.980)
2019-05-03 16:44:36 - INFO - TRAINING - Epoch: [92][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.5291 (0.5691)	Prec@1 82.000 (81.245)	Prec@5 100.000 (99.000)
2019-05-03 16:44:37 - INFO - TRAINING - Epoch: [92][200/500]	Time 0.032 (0.021)	Data 0.000 (0.001)	Loss 0.4296 (0.5692)	Prec@1 88.000 (81.194)	Prec@5 98.000 (99.025)
2019-05-03 16:44:38 - INFO - TRAINING - Epoch: [92][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5814 (0.5658)	Prec@1 77.000 (81.211)	Prec@5 99.000 (99.012)
2019-05-03 16:44:39 - INFO - TRAINING - Epoch: [92][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.6352 (0.5685)	Prec@1 77.000 (81.140)	Prec@5 98.000 (99.007)
2019-05-03 16:44:40 - INFO - TRAINING - Epoch: [92][350/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7044 (0.5703)	Prec@1 81.000 (81.068)	Prec@5 100.000 (99.023)
2019-05-03 16:44:41 - INFO - TRAINING - Epoch: [92][400/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.6298 (0.5719)	Prec@1 78.000 (80.913)	Prec@5 99.000 (99.035)
2019-05-03 16:44:42 - INFO - TRAINING - Epoch: [92][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6436 (0.5752)	Prec@1 78.000 (80.785)	Prec@5 99.000 (98.998)
2019-05-03 16:44:44 - INFO - EVALUATING - Epoch: [92][0/100]	Time 0.365 (0.365)	Data 0.359 (0.359)	Loss 0.8209 (0.8209)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:44 - INFO - EVALUATING - Epoch: [92][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.6605 (0.6650)	Prec@1 79.000 (77.980)	Prec@5 95.000 (98.353)
2019-05-03 16:44:44 - INFO - 
 Epoch: 93	Training Loss 0.5763 	Training Prec@1 80.760 	Training Prec@5 99.016 	Validation Loss 0.6661 	Validation Prec@1 77.700 	Validation Prec@5 98.600 	
2019-05-03 16:44:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:45 - INFO - TRAINING - Epoch: [93][0/500]	Time 0.259 (0.259)	Data 0.232 (0.232)	Loss 0.5796 (0.5796)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:44:46 - INFO - TRAINING - Epoch: [93][50/500]	Time 0.030 (0.025)	Data 0.000 (0.005)	Loss 0.5416 (0.6118)	Prec@1 83.000 (79.451)	Prec@5 98.000 (98.941)
2019-05-03 16:44:47 - INFO - TRAINING - Epoch: [93][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.5202 (0.5964)	Prec@1 82.000 (80.020)	Prec@5 100.000 (98.970)
2019-05-03 16:44:48 - INFO - TRAINING - Epoch: [93][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.7084 (0.5908)	Prec@1 75.000 (80.199)	Prec@5 98.000 (98.927)
2019-05-03 16:44:49 - INFO - TRAINING - Epoch: [93][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5718 (0.5847)	Prec@1 81.000 (80.398)	Prec@5 99.000 (99.025)
2019-05-03 16:44:50 - INFO - TRAINING - Epoch: [93][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4457 (0.5783)	Prec@1 88.000 (80.669)	Prec@5 99.000 (99.056)
2019-05-03 16:44:51 - INFO - TRAINING - Epoch: [93][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6171 (0.5783)	Prec@1 81.000 (80.704)	Prec@5 97.000 (99.033)
2019-05-03 16:44:51 - INFO - TRAINING - Epoch: [93][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5919 (0.5763)	Prec@1 82.000 (80.775)	Prec@5 98.000 (99.051)
2019-05-03 16:44:52 - INFO - TRAINING - Epoch: [93][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7225 (0.5789)	Prec@1 76.000 (80.741)	Prec@5 97.000 (99.012)
2019-05-03 16:44:53 - INFO - TRAINING - Epoch: [93][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5570 (0.5800)	Prec@1 84.000 (80.698)	Prec@5 99.000 (99.011)
2019-05-03 16:44:55 - INFO - EVALUATING - Epoch: [93][0/100]	Time 0.338 (0.338)	Data 0.323 (0.323)	Loss 0.5913 (0.5913)	Prec@1 78.000 (78.000)	Prec@5 98.000 (98.000)
2019-05-03 16:44:55 - INFO - EVALUATING - Epoch: [93][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.6857 (0.7064)	Prec@1 78.000 (76.922)	Prec@5 96.000 (98.059)
2019-05-03 16:44:55 - INFO - 
 Epoch: 94	Training Loss 0.5807 	Training Prec@1 80.682 	Training Prec@5 98.994 	Validation Loss 0.7015 	Validation Prec@1 76.580 	Validation Prec@5 98.240 	
2019-05-03 16:44:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:44:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:44:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:44:56 - INFO - TRAINING - Epoch: [94][0/500]	Time 0.265 (0.265)	Data 0.235 (0.235)	Loss 0.4860 (0.4860)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:44:57 - INFO - TRAINING - Epoch: [94][50/500]	Time 0.021 (0.025)	Data 0.000 (0.005)	Loss 0.4442 (0.5732)	Prec@1 84.000 (81.157)	Prec@5 100.000 (99.059)
2019-05-03 16:44:58 - INFO - TRAINING - Epoch: [94][100/500]	Time 0.020 (0.023)	Data 0.000 (0.002)	Loss 0.4779 (0.5716)	Prec@1 81.000 (81.059)	Prec@5 100.000 (99.099)
2019-05-03 16:44:59 - INFO - TRAINING - Epoch: [94][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.4974 (0.5723)	Prec@1 84.000 (80.940)	Prec@5 98.000 (99.093)
2019-05-03 16:45:00 - INFO - TRAINING - Epoch: [94][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.4653 (0.5773)	Prec@1 84.000 (80.771)	Prec@5 100.000 (99.114)
2019-05-03 16:45:01 - INFO - TRAINING - Epoch: [94][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6349 (0.5750)	Prec@1 80.000 (80.809)	Prec@5 98.000 (99.076)
2019-05-03 16:45:02 - INFO - TRAINING - Epoch: [94][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.4845 (0.5746)	Prec@1 86.000 (80.801)	Prec@5 100.000 (99.103)
2019-05-03 16:45:03 - INFO - TRAINING - Epoch: [94][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7142 (0.5800)	Prec@1 78.000 (80.567)	Prec@5 97.000 (99.071)
2019-05-03 16:45:04 - INFO - TRAINING - Epoch: [94][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6293 (0.5794)	Prec@1 81.000 (80.666)	Prec@5 99.000 (99.025)
2019-05-03 16:45:05 - INFO - TRAINING - Epoch: [94][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5189 (0.5808)	Prec@1 84.000 (80.650)	Prec@5 99.000 (99.020)
2019-05-03 16:45:06 - INFO - EVALUATING - Epoch: [94][0/100]	Time 0.356 (0.356)	Data 0.345 (0.345)	Loss 0.6409 (0.6409)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:45:06 - INFO - EVALUATING - Epoch: [94][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.6409 (0.6624)	Prec@1 82.000 (78.627)	Prec@5 97.000 (98.471)
2019-05-03 16:45:07 - INFO - 
 Epoch: 95	Training Loss 0.5792 	Training Prec@1 80.656 	Training Prec@5 99.026 	Validation Loss 0.6628 	Validation Prec@1 78.390 	Validation Prec@5 98.530 	
2019-05-03 16:45:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:45:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:45:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:45:07 - INFO - TRAINING - Epoch: [95][0/500]	Time 0.261 (0.261)	Data 0.238 (0.238)	Loss 0.4317 (0.4317)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:45:08 - INFO - TRAINING - Epoch: [95][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.4873 (0.5494)	Prec@1 83.000 (81.490)	Prec@5 100.000 (98.941)
2019-05-03 16:45:09 - INFO - TRAINING - Epoch: [95][100/500]	Time 0.019 (0.023)	Data 0.000 (0.002)	Loss 0.6502 (0.5562)	Prec@1 80.000 (81.475)	Prec@5 99.000 (98.970)
2019-05-03 16:45:10 - INFO - TRAINING - Epoch: [95][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.6351 (0.5605)	Prec@1 77.000 (81.252)	Prec@5 97.000 (98.901)
2019-05-03 16:45:11 - INFO - TRAINING - Epoch: [95][200/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.6349 (0.5720)	Prec@1 74.000 (80.786)	Prec@5 100.000 (98.925)
2019-05-03 16:45:12 - INFO - TRAINING - Epoch: [95][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4520 (0.5725)	Prec@1 84.000 (80.801)	Prec@5 100.000 (98.952)
2019-05-03 16:45:13 - INFO - TRAINING - Epoch: [95][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4841 (0.5725)	Prec@1 86.000 (80.764)	Prec@5 97.000 (98.953)
2019-05-03 16:45:14 - INFO - TRAINING - Epoch: [95][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7010 (0.5716)	Prec@1 74.000 (80.875)	Prec@5 99.000 (98.926)
2019-05-03 16:45:15 - INFO - TRAINING - Epoch: [95][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7102 (0.5729)	Prec@1 73.000 (80.968)	Prec@5 99.000 (98.913)
2019-05-03 16:45:16 - INFO - TRAINING - Epoch: [95][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4144 (0.5731)	Prec@1 86.000 (80.958)	Prec@5 99.000 (98.938)
2019-05-03 16:45:17 - INFO - EVALUATING - Epoch: [95][0/100]	Time 0.356 (0.356)	Data 0.347 (0.347)	Loss 0.5730 (0.5730)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:45:18 - INFO - EVALUATING - Epoch: [95][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.6209 (0.6735)	Prec@1 83.000 (77.627)	Prec@5 97.000 (98.588)
2019-05-03 16:45:18 - INFO - 
 Epoch: 96	Training Loss 0.5736 	Training Prec@1 80.932 	Training Prec@5 98.944 	Validation Loss 0.6610 	Validation Prec@1 77.910 	Validation Prec@5 98.730 	
2019-05-03 16:45:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:45:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:45:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:45:18 - INFO - TRAINING - Epoch: [96][0/500]	Time 0.269 (0.269)	Data 0.242 (0.242)	Loss 0.7603 (0.7603)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:45:19 - INFO - TRAINING - Epoch: [96][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.5668 (0.5753)	Prec@1 78.000 (81.098)	Prec@5 100.000 (99.020)
2019-05-03 16:45:20 - INFO - TRAINING - Epoch: [96][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.6222 (0.5756)	Prec@1 79.000 (81.099)	Prec@5 99.000 (99.119)
2019-05-03 16:45:21 - INFO - TRAINING - Epoch: [96][150/500]	Time 0.025 (0.021)	Data 0.000 (0.002)	Loss 0.4911 (0.5740)	Prec@1 83.000 (81.093)	Prec@5 100.000 (99.166)
2019-05-03 16:45:22 - INFO - TRAINING - Epoch: [96][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6313 (0.5770)	Prec@1 84.000 (81.035)	Prec@5 99.000 (99.109)
2019-05-03 16:45:23 - INFO - TRAINING - Epoch: [96][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.7439 (0.5721)	Prec@1 73.000 (81.135)	Prec@5 99.000 (99.112)
2019-05-03 16:45:24 - INFO - TRAINING - Epoch: [96][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5591 (0.5707)	Prec@1 83.000 (81.136)	Prec@5 100.000 (99.090)
2019-05-03 16:45:25 - INFO - TRAINING - Epoch: [96][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5248 (0.5729)	Prec@1 86.000 (81.091)	Prec@5 99.000 (99.060)
2019-05-03 16:45:26 - INFO - TRAINING - Epoch: [96][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7108 (0.5717)	Prec@1 74.000 (81.162)	Prec@5 98.000 (99.055)
2019-05-03 16:45:27 - INFO - TRAINING - Epoch: [96][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.7182 (0.5731)	Prec@1 79.000 (81.075)	Prec@5 97.000 (99.071)
2019-05-03 16:45:29 - INFO - EVALUATING - Epoch: [96][0/100]	Time 0.282 (0.282)	Data 0.268 (0.268)	Loss 0.6014 (0.6014)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:45:29 - INFO - EVALUATING - Epoch: [96][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.7003 (0.6659)	Prec@1 78.000 (77.961)	Prec@5 97.000 (98.490)
2019-05-03 16:45:29 - INFO - 
 Epoch: 97	Training Loss 0.5753 	Training Prec@1 80.984 	Training Prec@5 99.058 	Validation Loss 0.6770 	Validation Prec@1 77.310 	Validation Prec@5 98.470 	
2019-05-03 16:45:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:45:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:45:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:45:30 - INFO - TRAINING - Epoch: [97][0/500]	Time 0.265 (0.265)	Data 0.240 (0.240)	Loss 0.6904 (0.6904)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:45:31 - INFO - TRAINING - Epoch: [97][50/500]	Time 0.016 (0.026)	Data 0.000 (0.005)	Loss 0.4281 (0.5586)	Prec@1 87.000 (81.314)	Prec@5 100.000 (99.118)
2019-05-03 16:45:32 - INFO - TRAINING - Epoch: [97][100/500]	Time 0.015 (0.024)	Data 0.000 (0.002)	Loss 0.7499 (0.5624)	Prec@1 74.000 (81.347)	Prec@5 98.000 (99.059)
2019-05-03 16:45:33 - INFO - TRAINING - Epoch: [97][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.6401 (0.5622)	Prec@1 81.000 (81.391)	Prec@5 97.000 (99.046)
2019-05-03 16:45:34 - INFO - TRAINING - Epoch: [97][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.5484 (0.5664)	Prec@1 81.000 (81.194)	Prec@5 99.000 (99.075)
2019-05-03 16:45:35 - INFO - TRAINING - Epoch: [97][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6889 (0.5673)	Prec@1 75.000 (81.219)	Prec@5 99.000 (99.100)
2019-05-03 16:45:36 - INFO - TRAINING - Epoch: [97][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6837 (0.5695)	Prec@1 79.000 (81.183)	Prec@5 96.000 (99.076)
2019-05-03 16:45:37 - INFO - TRAINING - Epoch: [97][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.4948 (0.5709)	Prec@1 87.000 (81.080)	Prec@5 100.000 (99.051)
2019-05-03 16:45:38 - INFO - TRAINING - Epoch: [97][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4871 (0.5716)	Prec@1 83.000 (81.042)	Prec@5 98.000 (99.040)
2019-05-03 16:45:39 - INFO - TRAINING - Epoch: [97][450/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.6543 (0.5723)	Prec@1 79.000 (81.013)	Prec@5 99.000 (99.042)
2019-05-03 16:45:40 - INFO - EVALUATING - Epoch: [97][0/100]	Time 0.347 (0.347)	Data 0.335 (0.335)	Loss 0.5195 (0.5195)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:45:40 - INFO - EVALUATING - Epoch: [97][50/100]	Time 0.009 (0.013)	Data 0.000 (0.007)	Loss 0.4646 (0.6693)	Prec@1 88.000 (78.196)	Prec@5 98.000 (98.667)
2019-05-03 16:45:41 - INFO - 
 Epoch: 98	Training Loss 0.5716 	Training Prec@1 81.014 	Training Prec@5 99.044 	Validation Loss 0.6688 	Validation Prec@1 78.090 	Validation Prec@5 98.670 	
2019-05-03 16:45:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:45:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:45:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:45:41 - INFO - TRAINING - Epoch: [98][0/500]	Time 0.283 (0.283)	Data 0.259 (0.259)	Loss 0.4746 (0.4746)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 16:45:42 - INFO - TRAINING - Epoch: [98][50/500]	Time 0.019 (0.024)	Data 0.000 (0.005)	Loss 0.6310 (0.5436)	Prec@1 78.000 (81.980)	Prec@5 99.000 (98.922)
2019-05-03 16:45:43 - INFO - TRAINING - Epoch: [98][100/500]	Time 0.016 (0.021)	Data 0.000 (0.003)	Loss 0.6986 (0.5520)	Prec@1 76.000 (81.307)	Prec@5 97.000 (99.030)
2019-05-03 16:45:44 - INFO - TRAINING - Epoch: [98][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.5430 (0.5599)	Prec@1 83.000 (81.126)	Prec@5 99.000 (98.960)
2019-05-03 16:45:45 - INFO - TRAINING - Epoch: [98][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5894 (0.5668)	Prec@1 78.000 (81.104)	Prec@5 100.000 (98.990)
2019-05-03 16:45:46 - INFO - TRAINING - Epoch: [98][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5173 (0.5650)	Prec@1 80.000 (81.139)	Prec@5 100.000 (98.988)
2019-05-03 16:45:47 - INFO - TRAINING - Epoch: [98][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5110 (0.5667)	Prec@1 83.000 (81.149)	Prec@5 99.000 (98.993)
2019-05-03 16:45:48 - INFO - TRAINING - Epoch: [98][350/500]	Time 0.035 (0.021)	Data 0.000 (0.001)	Loss 0.5030 (0.5658)	Prec@1 82.000 (81.105)	Prec@5 100.000 (99.009)
2019-05-03 16:45:49 - INFO - TRAINING - Epoch: [98][400/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5464 (0.5667)	Prec@1 79.000 (81.070)	Prec@5 100.000 (99.025)
2019-05-03 16:45:50 - INFO - TRAINING - Epoch: [98][450/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6797 (0.5660)	Prec@1 83.000 (81.086)	Prec@5 100.000 (99.038)
2019-05-03 16:45:51 - INFO - EVALUATING - Epoch: [98][0/100]	Time 0.350 (0.350)	Data 0.336 (0.336)	Loss 0.6414 (0.6414)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:45:52 - INFO - EVALUATING - Epoch: [98][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5808 (0.6392)	Prec@1 81.000 (79.020)	Prec@5 98.000 (98.647)
2019-05-03 16:45:52 - INFO - 
 Epoch: 99	Training Loss 0.5664 	Training Prec@1 81.066 	Training Prec@5 99.056 	Validation Loss 0.6348 	Validation Prec@1 79.130 	Validation Prec@5 98.800 	
2019-05-03 16:45:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:45:52 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:45:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:45:52 - INFO - TRAINING - Epoch: [99][0/500]	Time 0.251 (0.251)	Data 0.231 (0.231)	Loss 0.6071 (0.6071)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:45:53 - INFO - TRAINING - Epoch: [99][50/500]	Time 0.026 (0.025)	Data 0.000 (0.005)	Loss 0.7015 (0.5738)	Prec@1 78.000 (80.392)	Prec@5 97.000 (98.961)
2019-05-03 16:45:54 - INFO - TRAINING - Epoch: [99][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.4251 (0.5732)	Prec@1 83.000 (80.762)	Prec@5 100.000 (98.950)
2019-05-03 16:45:55 - INFO - TRAINING - Epoch: [99][150/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.4880 (0.5774)	Prec@1 87.000 (80.689)	Prec@5 97.000 (98.940)
2019-05-03 16:45:56 - INFO - TRAINING - Epoch: [99][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4410 (0.5672)	Prec@1 83.000 (81.050)	Prec@5 100.000 (99.035)
2019-05-03 16:45:57 - INFO - TRAINING - Epoch: [99][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5349 (0.5664)	Prec@1 85.000 (81.104)	Prec@5 99.000 (99.056)
2019-05-03 16:45:58 - INFO - TRAINING - Epoch: [99][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.4746 (0.5708)	Prec@1 85.000 (81.010)	Prec@5 99.000 (99.060)
2019-05-03 16:45:59 - INFO - TRAINING - Epoch: [99][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4383 (0.5711)	Prec@1 87.000 (80.969)	Prec@5 100.000 (99.048)
2019-05-03 16:46:00 - INFO - TRAINING - Epoch: [99][400/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.6519 (0.5705)	Prec@1 79.000 (81.025)	Prec@5 98.000 (99.075)
2019-05-03 16:46:01 - INFO - TRAINING - Epoch: [99][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6884 (0.5716)	Prec@1 79.000 (81.009)	Prec@5 98.000 (99.049)
2019-05-03 16:46:02 - INFO - EVALUATING - Epoch: [99][0/100]	Time 0.259 (0.259)	Data 0.247 (0.247)	Loss 0.7341 (0.7341)	Prec@1 73.000 (73.000)	Prec@5 100.000 (100.000)
2019-05-03 16:46:03 - INFO - EVALUATING - Epoch: [99][50/100]	Time 0.005 (0.010)	Data 0.000 (0.005)	Loss 0.6300 (0.6444)	Prec@1 80.000 (78.608)	Prec@5 96.000 (98.765)
2019-05-03 16:46:03 - INFO - 
 Epoch: 100	Training Loss 0.5705 	Training Prec@1 81.058 	Training Prec@5 99.032 	Validation Loss 0.6444 	Validation Prec@1 78.760 	Validation Prec@5 98.870 	
2019-05-03 16:46:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:03 - INFO - TRAINING - Epoch: [100][0/500]	Time 0.252 (0.252)	Data 0.231 (0.231)	Loss 0.5379 (0.5379)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:46:04 - INFO - TRAINING - Epoch: [100][50/500]	Time 0.016 (0.024)	Data 0.000 (0.005)	Loss 0.5208 (0.5544)	Prec@1 84.000 (81.784)	Prec@5 100.000 (98.902)
2019-05-03 16:46:05 - INFO - TRAINING - Epoch: [100][100/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.6085 (0.5533)	Prec@1 80.000 (81.861)	Prec@5 99.000 (98.980)
2019-05-03 16:46:06 - INFO - TRAINING - Epoch: [100][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.5975 (0.5516)	Prec@1 82.000 (81.728)	Prec@5 99.000 (99.040)
2019-05-03 16:46:07 - INFO - TRAINING - Epoch: [100][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.4658 (0.5533)	Prec@1 84.000 (81.682)	Prec@5 100.000 (99.085)
2019-05-03 16:46:08 - INFO - TRAINING - Epoch: [100][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.9034 (0.5557)	Prec@1 69.000 (81.661)	Prec@5 98.000 (99.016)
2019-05-03 16:46:09 - INFO - TRAINING - Epoch: [100][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6454 (0.5614)	Prec@1 75.000 (81.405)	Prec@5 99.000 (99.030)
2019-05-03 16:46:10 - INFO - TRAINING - Epoch: [100][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.5485 (0.5599)	Prec@1 83.000 (81.430)	Prec@5 100.000 (99.071)
2019-05-03 16:46:11 - INFO - TRAINING - Epoch: [100][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4836 (0.5594)	Prec@1 84.000 (81.484)	Prec@5 100.000 (99.095)
2019-05-03 16:46:12 - INFO - TRAINING - Epoch: [100][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6214 (0.5602)	Prec@1 80.000 (81.461)	Prec@5 100.000 (99.104)
2019-05-03 16:46:14 - INFO - EVALUATING - Epoch: [100][0/100]	Time 0.347 (0.347)	Data 0.337 (0.337)	Loss 0.5870 (0.5870)	Prec@1 82.000 (82.000)	Prec@5 98.000 (98.000)
2019-05-03 16:46:14 - INFO - EVALUATING - Epoch: [100][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5620 (0.6718)	Prec@1 84.000 (77.980)	Prec@5 96.000 (98.510)
2019-05-03 16:46:14 - INFO - 
 Epoch: 101	Training Loss 0.5621 	Training Prec@1 81.458 	Training Prec@5 99.088 	Validation Loss 0.6670 	Validation Prec@1 78.200 	Validation Prec@5 98.690 	
2019-05-03 16:46:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:15 - INFO - TRAINING - Epoch: [101][0/500]	Time 0.265 (0.265)	Data 0.236 (0.236)	Loss 0.7005 (0.7005)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 16:46:16 - INFO - TRAINING - Epoch: [101][50/500]	Time 0.027 (0.025)	Data 0.000 (0.005)	Loss 0.6810 (0.5624)	Prec@1 82.000 (80.882)	Prec@5 100.000 (99.176)
2019-05-03 16:46:17 - INFO - TRAINING - Epoch: [101][100/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.4656 (0.5589)	Prec@1 83.000 (81.168)	Prec@5 98.000 (99.099)
2019-05-03 16:46:18 - INFO - TRAINING - Epoch: [101][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7031 (0.5630)	Prec@1 78.000 (80.993)	Prec@5 98.000 (99.053)
2019-05-03 16:46:19 - INFO - TRAINING - Epoch: [101][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5041 (0.5669)	Prec@1 85.000 (80.970)	Prec@5 100.000 (99.080)
2019-05-03 16:46:20 - INFO - TRAINING - Epoch: [101][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7594 (0.5672)	Prec@1 75.000 (81.024)	Prec@5 99.000 (99.080)
2019-05-03 16:46:21 - INFO - TRAINING - Epoch: [101][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5538 (0.5658)	Prec@1 79.000 (81.017)	Prec@5 99.000 (99.113)
2019-05-03 16:46:22 - INFO - TRAINING - Epoch: [101][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6793 (0.5693)	Prec@1 77.000 (81.017)	Prec@5 99.000 (99.080)
2019-05-03 16:46:23 - INFO - TRAINING - Epoch: [101][400/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6503 (0.5675)	Prec@1 74.000 (81.127)	Prec@5 99.000 (99.090)
2019-05-03 16:46:24 - INFO - TRAINING - Epoch: [101][450/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5791 (0.5701)	Prec@1 80.000 (81.033)	Prec@5 98.000 (99.051)
2019-05-03 16:46:25 - INFO - EVALUATING - Epoch: [101][0/100]	Time 0.256 (0.256)	Data 0.248 (0.248)	Loss 0.7020 (0.7020)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-03 16:46:25 - INFO - EVALUATING - Epoch: [101][50/100]	Time 0.006 (0.010)	Data 0.000 (0.005)	Loss 0.7349 (0.8115)	Prec@1 74.000 (73.353)	Prec@5 97.000 (97.510)
2019-05-03 16:46:25 - INFO - 
 Epoch: 102	Training Loss 0.5721 	Training Prec@1 80.970 	Training Prec@5 99.052 	Validation Loss 0.8011 	Validation Prec@1 73.620 	Validation Prec@5 97.740 	
2019-05-03 16:46:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:26 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:26 - INFO - TRAINING - Epoch: [102][0/500]	Time 0.272 (0.272)	Data 0.250 (0.250)	Loss 0.4854 (0.4854)	Prec@1 86.000 (86.000)	Prec@5 97.000 (97.000)
2019-05-03 16:46:27 - INFO - TRAINING - Epoch: [102][50/500]	Time 0.027 (0.025)	Data 0.000 (0.005)	Loss 0.6552 (0.5558)	Prec@1 78.000 (81.431)	Prec@5 98.000 (98.863)
2019-05-03 16:46:28 - INFO - TRAINING - Epoch: [102][100/500]	Time 0.021 (0.022)	Data 0.000 (0.003)	Loss 0.6037 (0.5496)	Prec@1 79.000 (81.465)	Prec@5 100.000 (98.990)
2019-05-03 16:46:29 - INFO - TRAINING - Epoch: [102][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6569 (0.5603)	Prec@1 80.000 (81.232)	Prec@5 99.000 (98.960)
2019-05-03 16:46:30 - INFO - TRAINING - Epoch: [102][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5780 (0.5618)	Prec@1 78.000 (81.179)	Prec@5 99.000 (98.965)
2019-05-03 16:46:31 - INFO - TRAINING - Epoch: [102][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7193 (0.5588)	Prec@1 78.000 (81.271)	Prec@5 99.000 (98.996)
2019-05-03 16:46:32 - INFO - TRAINING - Epoch: [102][300/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.5221 (0.5556)	Prec@1 81.000 (81.395)	Prec@5 100.000 (99.023)
2019-05-03 16:46:33 - INFO - TRAINING - Epoch: [102][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5721 (0.5560)	Prec@1 83.000 (81.433)	Prec@5 99.000 (99.009)
2019-05-03 16:46:34 - INFO - TRAINING - Epoch: [102][400/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6105 (0.5586)	Prec@1 81.000 (81.406)	Prec@5 98.000 (98.990)
2019-05-03 16:46:35 - INFO - TRAINING - Epoch: [102][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6556 (0.5617)	Prec@1 77.000 (81.317)	Prec@5 98.000 (99.011)
2019-05-03 16:46:36 - INFO - EVALUATING - Epoch: [102][0/100]	Time 0.330 (0.330)	Data 0.315 (0.315)	Loss 0.5824 (0.5824)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:46:36 - INFO - EVALUATING - Epoch: [102][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.4796 (0.6518)	Prec@1 87.000 (78.392)	Prec@5 97.000 (98.588)
2019-05-03 16:46:37 - INFO - 
 Epoch: 103	Training Loss 0.5657 	Training Prec@1 81.194 	Training Prec@5 98.994 	Validation Loss 0.6386 	Validation Prec@1 78.820 	Validation Prec@5 98.830 	
2019-05-03 16:46:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:37 - INFO - TRAINING - Epoch: [103][0/500]	Time 0.260 (0.260)	Data 0.239 (0.239)	Loss 0.5299 (0.5299)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:46:38 - INFO - TRAINING - Epoch: [103][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.5509 (0.5787)	Prec@1 81.000 (81.157)	Prec@5 98.000 (98.824)
2019-05-03 16:46:39 - INFO - TRAINING - Epoch: [103][100/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.7388 (0.5651)	Prec@1 79.000 (81.347)	Prec@5 98.000 (99.059)
2019-05-03 16:46:40 - INFO - TRAINING - Epoch: [103][150/500]	Time 0.031 (0.021)	Data 0.000 (0.002)	Loss 0.3096 (0.5778)	Prec@1 90.000 (80.715)	Prec@5 100.000 (99.060)
2019-05-03 16:46:41 - INFO - TRAINING - Epoch: [103][200/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6334 (0.5747)	Prec@1 80.000 (80.766)	Prec@5 97.000 (99.085)
2019-05-03 16:46:42 - INFO - TRAINING - Epoch: [103][250/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.4290 (0.5717)	Prec@1 85.000 (80.912)	Prec@5 99.000 (99.124)
2019-05-03 16:46:43 - INFO - TRAINING - Epoch: [103][300/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.5124 (0.5673)	Prec@1 82.000 (81.076)	Prec@5 100.000 (99.166)
2019-05-03 16:46:44 - INFO - TRAINING - Epoch: [103][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4885 (0.5692)	Prec@1 84.000 (81.023)	Prec@5 100.000 (99.177)
2019-05-03 16:46:45 - INFO - TRAINING - Epoch: [103][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6113 (0.5684)	Prec@1 79.000 (81.120)	Prec@5 99.000 (99.137)
2019-05-03 16:46:46 - INFO - TRAINING - Epoch: [103][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6398 (0.5668)	Prec@1 80.000 (81.151)	Prec@5 99.000 (99.118)
2019-05-03 16:46:47 - INFO - EVALUATING - Epoch: [103][0/100]	Time 0.351 (0.351)	Data 0.345 (0.345)	Loss 0.6308 (0.6308)	Prec@1 78.000 (78.000)	Prec@5 98.000 (98.000)
2019-05-03 16:46:48 - INFO - EVALUATING - Epoch: [103][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.5481 (0.6489)	Prec@1 82.000 (78.745)	Prec@5 98.000 (98.373)
2019-05-03 16:46:48 - INFO - 
 Epoch: 104	Training Loss 0.5682 	Training Prec@1 81.110 	Training Prec@5 99.120 	Validation Loss 0.6511 	Validation Prec@1 78.340 	Validation Prec@5 98.520 	
2019-05-03 16:46:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:48 - INFO - TRAINING - Epoch: [104][0/500]	Time 0.278 (0.278)	Data 0.249 (0.249)	Loss 0.5595 (0.5595)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:46:49 - INFO - TRAINING - Epoch: [104][50/500]	Time 0.022 (0.025)	Data 0.000 (0.005)	Loss 0.2863 (0.5801)	Prec@1 92.000 (80.765)	Prec@5 100.000 (98.980)
2019-05-03 16:46:50 - INFO - TRAINING - Epoch: [104][100/500]	Time 0.027 (0.022)	Data 0.000 (0.003)	Loss 0.5794 (0.5908)	Prec@1 82.000 (80.673)	Prec@5 97.000 (98.911)
2019-05-03 16:46:51 - INFO - TRAINING - Epoch: [104][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.4198 (0.5751)	Prec@1 83.000 (81.179)	Prec@5 99.000 (99.026)
2019-05-03 16:46:52 - INFO - TRAINING - Epoch: [104][200/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.4055 (0.5706)	Prec@1 86.000 (81.214)	Prec@5 99.000 (99.035)
2019-05-03 16:46:53 - INFO - TRAINING - Epoch: [104][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6099 (0.5690)	Prec@1 79.000 (81.315)	Prec@5 99.000 (99.044)
2019-05-03 16:46:54 - INFO - TRAINING - Epoch: [104][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5014 (0.5695)	Prec@1 81.000 (81.279)	Prec@5 100.000 (99.056)
2019-05-03 16:46:55 - INFO - TRAINING - Epoch: [104][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.3054 (0.5687)	Prec@1 89.000 (81.245)	Prec@5 100.000 (99.057)
2019-05-03 16:46:56 - INFO - TRAINING - Epoch: [104][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4907 (0.5686)	Prec@1 80.000 (81.214)	Prec@5 100.000 (99.040)
2019-05-03 16:46:57 - INFO - TRAINING - Epoch: [104][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5031 (0.5664)	Prec@1 83.000 (81.310)	Prec@5 99.000 (99.038)
2019-05-03 16:46:58 - INFO - EVALUATING - Epoch: [104][0/100]	Time 0.257 (0.257)	Data 0.244 (0.244)	Loss 0.6225 (0.6225)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 16:46:59 - INFO - EVALUATING - Epoch: [104][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 0.6063 (0.6620)	Prec@1 82.000 (78.451)	Prec@5 97.000 (98.373)
2019-05-03 16:46:59 - INFO - 
 Epoch: 105	Training Loss 0.5633 	Training Prec@1 81.396 	Training Prec@5 99.050 	Validation Loss 0.6658 	Validation Prec@1 78.160 	Validation Prec@5 98.350 	
2019-05-03 16:46:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:46:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:46:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:46:59 - INFO - TRAINING - Epoch: [105][0/500]	Time 0.262 (0.262)	Data 0.232 (0.232)	Loss 0.7064 (0.7064)	Prec@1 78.000 (78.000)	Prec@5 97.000 (97.000)
2019-05-03 16:47:00 - INFO - TRAINING - Epoch: [105][50/500]	Time 0.027 (0.025)	Data 0.000 (0.005)	Loss 0.6147 (0.5647)	Prec@1 79.000 (81.039)	Prec@5 98.000 (99.020)
2019-05-03 16:47:01 - INFO - TRAINING - Epoch: [105][100/500]	Time 0.023 (0.024)	Data 0.000 (0.002)	Loss 0.4547 (0.5621)	Prec@1 83.000 (81.129)	Prec@5 99.000 (98.950)
2019-05-03 16:47:02 - INFO - TRAINING - Epoch: [105][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.5614 (0.5545)	Prec@1 83.000 (81.503)	Prec@5 98.000 (99.026)
2019-05-03 16:47:03 - INFO - TRAINING - Epoch: [105][200/500]	Time 0.022 (0.022)	Data 0.000 (0.001)	Loss 0.7508 (0.5581)	Prec@1 80.000 (81.522)	Prec@5 100.000 (98.995)
2019-05-03 16:47:04 - INFO - TRAINING - Epoch: [105][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6672 (0.5602)	Prec@1 76.000 (81.406)	Prec@5 97.000 (98.956)
2019-05-03 16:47:05 - INFO - TRAINING - Epoch: [105][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.4331 (0.5578)	Prec@1 87.000 (81.548)	Prec@5 100.000 (98.944)
2019-05-03 16:47:06 - INFO - TRAINING - Epoch: [105][350/500]	Time 0.032 (0.021)	Data 0.000 (0.001)	Loss 0.5622 (0.5576)	Prec@1 84.000 (81.573)	Prec@5 98.000 (98.957)
2019-05-03 16:47:08 - INFO - TRAINING - Epoch: [105][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6229 (0.5604)	Prec@1 78.000 (81.436)	Prec@5 100.000 (98.965)
2019-05-03 16:47:09 - INFO - TRAINING - Epoch: [105][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7183 (0.5595)	Prec@1 76.000 (81.468)	Prec@5 100.000 (99.004)
2019-05-03 16:47:10 - INFO - EVALUATING - Epoch: [105][0/100]	Time 0.348 (0.348)	Data 0.342 (0.342)	Loss 0.6936 (0.6936)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:10 - INFO - EVALUATING - Epoch: [105][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6286 (0.6430)	Prec@1 83.000 (78.725)	Prec@5 97.000 (98.725)
2019-05-03 16:47:10 - INFO - 
 Epoch: 106	Training Loss 0.5595 	Training Prec@1 81.490 	Training Prec@5 98.992 	Validation Loss 0.6551 	Validation Prec@1 78.300 	Validation Prec@5 98.720 	
2019-05-03 16:47:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:47:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:47:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:47:11 - INFO - TRAINING - Epoch: [106][0/500]	Time 0.251 (0.251)	Data 0.220 (0.220)	Loss 0.5750 (0.5750)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:47:12 - INFO - TRAINING - Epoch: [106][50/500]	Time 0.016 (0.023)	Data 0.000 (0.004)	Loss 0.4855 (0.5467)	Prec@1 79.000 (82.118)	Prec@5 99.000 (98.980)
2019-05-03 16:47:13 - INFO - TRAINING - Epoch: [106][100/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.4206 (0.5513)	Prec@1 83.000 (81.851)	Prec@5 99.000 (99.040)
2019-05-03 16:47:14 - INFO - TRAINING - Epoch: [106][150/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.6424 (0.5485)	Prec@1 80.000 (81.980)	Prec@5 96.000 (99.093)
2019-05-03 16:47:15 - INFO - TRAINING - Epoch: [106][200/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5296 (0.5542)	Prec@1 84.000 (81.612)	Prec@5 98.000 (99.090)
2019-05-03 16:47:16 - INFO - TRAINING - Epoch: [106][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4715 (0.5538)	Prec@1 84.000 (81.594)	Prec@5 99.000 (99.112)
2019-05-03 16:47:17 - INFO - TRAINING - Epoch: [106][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.6054 (0.5539)	Prec@1 81.000 (81.611)	Prec@5 98.000 (99.106)
2019-05-03 16:47:18 - INFO - TRAINING - Epoch: [106][350/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5440 (0.5575)	Prec@1 85.000 (81.493)	Prec@5 100.000 (99.097)
2019-05-03 16:47:19 - INFO - TRAINING - Epoch: [106][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.6246 (0.5618)	Prec@1 77.000 (81.302)	Prec@5 99.000 (99.070)
2019-05-03 16:47:20 - INFO - TRAINING - Epoch: [106][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5306 (0.5622)	Prec@1 80.000 (81.317)	Prec@5 100.000 (99.055)
2019-05-03 16:47:21 - INFO - EVALUATING - Epoch: [106][0/100]	Time 0.337 (0.337)	Data 0.331 (0.331)	Loss 0.5854 (0.5854)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:21 - INFO - EVALUATING - Epoch: [106][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.5181 (0.6245)	Prec@1 86.000 (79.686)	Prec@5 98.000 (98.804)
2019-05-03 16:47:22 - INFO - 
 Epoch: 107	Training Loss 0.5595 	Training Prec@1 81.430 	Training Prec@5 99.050 	Validation Loss 0.6243 	Validation Prec@1 79.690 	Validation Prec@5 98.860 	
2019-05-03 16:47:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:47:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:47:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:47:22 - INFO - TRAINING - Epoch: [107][0/500]	Time 0.278 (0.278)	Data 0.253 (0.253)	Loss 0.3003 (0.3003)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 16:47:23 - INFO - TRAINING - Epoch: [107][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.5007 (0.5685)	Prec@1 81.000 (80.980)	Prec@5 99.000 (99.039)
2019-05-03 16:47:24 - INFO - TRAINING - Epoch: [107][100/500]	Time 0.016 (0.021)	Data 0.000 (0.003)	Loss 0.5637 (0.5565)	Prec@1 80.000 (81.356)	Prec@5 100.000 (99.109)
2019-05-03 16:47:25 - INFO - TRAINING - Epoch: [107][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.4811 (0.5543)	Prec@1 87.000 (81.543)	Prec@5 99.000 (99.053)
2019-05-03 16:47:26 - INFO - TRAINING - Epoch: [107][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.7356 (0.5576)	Prec@1 76.000 (81.418)	Prec@5 97.000 (99.055)
2019-05-03 16:47:27 - INFO - TRAINING - Epoch: [107][250/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5936 (0.5572)	Prec@1 74.000 (81.351)	Prec@5 100.000 (99.064)
2019-05-03 16:47:28 - INFO - TRAINING - Epoch: [107][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.7705 (0.5548)	Prec@1 74.000 (81.522)	Prec@5 100.000 (99.050)
2019-05-03 16:47:29 - INFO - TRAINING - Epoch: [107][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.8373 (0.5567)	Prec@1 75.000 (81.444)	Prec@5 97.000 (99.057)
2019-05-03 16:47:30 - INFO - TRAINING - Epoch: [107][400/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.8288 (0.5578)	Prec@1 72.000 (81.444)	Prec@5 98.000 (99.052)
2019-05-03 16:47:31 - INFO - TRAINING - Epoch: [107][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.3657 (0.5547)	Prec@1 88.000 (81.605)	Prec@5 100.000 (99.049)
2019-05-03 16:47:32 - INFO - EVALUATING - Epoch: [107][0/100]	Time 0.325 (0.325)	Data 0.317 (0.317)	Loss 0.5728 (0.5728)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:32 - INFO - EVALUATING - Epoch: [107][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.5651 (0.6503)	Prec@1 83.000 (78.843)	Prec@5 96.000 (98.451)
2019-05-03 16:47:32 - INFO - 
 Epoch: 108	Training Loss 0.5566 	Training Prec@1 81.474 	Training Prec@5 99.058 	Validation Loss 0.6563 	Validation Prec@1 78.650 	Validation Prec@5 98.600 	
2019-05-03 16:47:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:47:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:47:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:47:33 - INFO - TRAINING - Epoch: [108][0/500]	Time 0.274 (0.274)	Data 0.250 (0.250)	Loss 0.4886 (0.4886)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:34 - INFO - TRAINING - Epoch: [108][50/500]	Time 0.018 (0.024)	Data 0.000 (0.005)	Loss 0.5322 (0.5654)	Prec@1 81.000 (81.039)	Prec@5 100.000 (98.980)
2019-05-03 16:47:35 - INFO - TRAINING - Epoch: [108][100/500]	Time 0.029 (0.022)	Data 0.000 (0.003)	Loss 0.6508 (0.5731)	Prec@1 83.000 (80.733)	Prec@5 99.000 (99.000)
2019-05-03 16:47:36 - INFO - TRAINING - Epoch: [108][150/500]	Time 0.024 (0.021)	Data 0.000 (0.002)	Loss 0.3960 (0.5665)	Prec@1 89.000 (81.232)	Prec@5 99.000 (98.993)
2019-05-03 16:47:37 - INFO - TRAINING - Epoch: [108][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5330 (0.5683)	Prec@1 82.000 (81.149)	Prec@5 98.000 (99.010)
2019-05-03 16:47:38 - INFO - TRAINING - Epoch: [108][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5493 (0.5648)	Prec@1 82.000 (81.295)	Prec@5 100.000 (98.988)
2019-05-03 16:47:39 - INFO - TRAINING - Epoch: [108][300/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.4894 (0.5601)	Prec@1 77.000 (81.332)	Prec@5 100.000 (99.010)
2019-05-03 16:47:40 - INFO - TRAINING - Epoch: [108][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5602 (0.5584)	Prec@1 83.000 (81.339)	Prec@5 98.000 (99.017)
2019-05-03 16:47:41 - INFO - TRAINING - Epoch: [108][400/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5493 (0.5547)	Prec@1 79.000 (81.434)	Prec@5 100.000 (99.060)
2019-05-03 16:47:42 - INFO - TRAINING - Epoch: [108][450/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.4656 (0.5544)	Prec@1 86.000 (81.448)	Prec@5 100.000 (99.062)
2019-05-03 16:47:43 - INFO - EVALUATING - Epoch: [108][0/100]	Time 0.351 (0.351)	Data 0.333 (0.333)	Loss 0.6682 (0.6682)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:47:43 - INFO - EVALUATING - Epoch: [108][50/100]	Time 0.007 (0.014)	Data 0.000 (0.008)	Loss 0.7308 (0.6925)	Prec@1 75.000 (78.020)	Prec@5 97.000 (98.353)
2019-05-03 16:47:44 - INFO - 
 Epoch: 109	Training Loss 0.5555 	Training Prec@1 81.430 	Training Prec@5 99.068 	Validation Loss 0.6721 	Validation Prec@1 78.220 	Validation Prec@5 98.520 	
2019-05-03 16:47:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:47:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:47:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:47:44 - INFO - TRAINING - Epoch: [109][0/500]	Time 0.255 (0.255)	Data 0.228 (0.228)	Loss 0.5615 (0.5615)	Prec@1 87.000 (87.000)	Prec@5 98.000 (98.000)
2019-05-03 16:47:45 - INFO - TRAINING - Epoch: [109][50/500]	Time 0.021 (0.025)	Data 0.000 (0.005)	Loss 0.4778 (0.5686)	Prec@1 83.000 (81.235)	Prec@5 99.000 (98.941)
2019-05-03 16:47:46 - INFO - TRAINING - Epoch: [109][100/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.5843 (0.5703)	Prec@1 80.000 (81.257)	Prec@5 98.000 (99.010)
2019-05-03 16:47:47 - INFO - TRAINING - Epoch: [109][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.5086 (0.5691)	Prec@1 81.000 (81.252)	Prec@5 100.000 (98.980)
2019-05-03 16:47:48 - INFO - TRAINING - Epoch: [109][200/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5775 (0.5702)	Prec@1 85.000 (81.363)	Prec@5 99.000 (98.990)
2019-05-03 16:47:49 - INFO - TRAINING - Epoch: [109][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.8802 (0.5650)	Prec@1 66.000 (81.462)	Prec@5 97.000 (98.988)
2019-05-03 16:47:50 - INFO - TRAINING - Epoch: [109][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6164 (0.5621)	Prec@1 77.000 (81.525)	Prec@5 100.000 (99.020)
2019-05-03 16:47:51 - INFO - TRAINING - Epoch: [109][350/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.4918 (0.5613)	Prec@1 83.000 (81.564)	Prec@5 99.000 (99.031)
2019-05-03 16:47:52 - INFO - TRAINING - Epoch: [109][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.5348 (0.5635)	Prec@1 82.000 (81.431)	Prec@5 100.000 (99.037)
2019-05-03 16:47:53 - INFO - TRAINING - Epoch: [109][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5359 (0.5635)	Prec@1 79.000 (81.419)	Prec@5 98.000 (99.033)
2019-05-03 16:47:54 - INFO - EVALUATING - Epoch: [109][0/100]	Time 0.250 (0.250)	Data 0.244 (0.244)	Loss 0.5998 (0.5998)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:54 - INFO - EVALUATING - Epoch: [109][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6046 (0.6933)	Prec@1 83.000 (77.059)	Prec@5 97.000 (98.373)
2019-05-03 16:47:55 - INFO - 
 Epoch: 110	Training Loss 0.5609 	Training Prec@1 81.444 	Training Prec@5 99.040 	Validation Loss 0.6894 	Validation Prec@1 76.760 	Validation Prec@5 98.590 	
2019-05-03 16:47:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:47:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:47:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:47:55 - INFO - TRAINING - Epoch: [110][0/500]	Time 0.246 (0.246)	Data 0.221 (0.221)	Loss 0.6096 (0.6096)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:47:56 - INFO - TRAINING - Epoch: [110][50/500]	Time 0.025 (0.024)	Data 0.000 (0.004)	Loss 0.6579 (0.5596)	Prec@1 78.000 (81.216)	Prec@5 98.000 (99.098)
2019-05-03 16:47:57 - INFO - TRAINING - Epoch: [110][100/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.5343 (0.5463)	Prec@1 81.000 (81.644)	Prec@5 100.000 (99.178)
2019-05-03 16:47:58 - INFO - TRAINING - Epoch: [110][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.6859 (0.5444)	Prec@1 73.000 (81.848)	Prec@5 99.000 (99.099)
2019-05-03 16:47:59 - INFO - TRAINING - Epoch: [110][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5051 (0.5475)	Prec@1 83.000 (81.811)	Prec@5 99.000 (99.090)
2019-05-03 16:48:00 - INFO - TRAINING - Epoch: [110][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5391 (0.5501)	Prec@1 79.000 (81.785)	Prec@5 99.000 (99.040)
2019-05-03 16:48:01 - INFO - TRAINING - Epoch: [110][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6627 (0.5509)	Prec@1 80.000 (81.754)	Prec@5 98.000 (99.076)
2019-05-03 16:48:02 - INFO - TRAINING - Epoch: [110][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5857 (0.5528)	Prec@1 80.000 (81.704)	Prec@5 96.000 (99.060)
2019-05-03 16:48:03 - INFO - TRAINING - Epoch: [110][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6289 (0.5525)	Prec@1 79.000 (81.736)	Prec@5 98.000 (99.072)
2019-05-03 16:48:04 - INFO - TRAINING - Epoch: [110][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5383 (0.5523)	Prec@1 83.000 (81.707)	Prec@5 99.000 (99.095)
2019-05-03 16:48:06 - INFO - EVALUATING - Epoch: [110][0/100]	Time 0.347 (0.347)	Data 0.335 (0.335)	Loss 0.6366 (0.6366)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-03 16:48:06 - INFO - EVALUATING - Epoch: [110][50/100]	Time 0.005 (0.014)	Data 0.000 (0.008)	Loss 0.5651 (0.6422)	Prec@1 83.000 (78.745)	Prec@5 96.000 (98.412)
2019-05-03 16:48:06 - INFO - 
 Epoch: 111	Training Loss 0.5540 	Training Prec@1 81.674 	Training Prec@5 99.080 	Validation Loss 0.6456 	Validation Prec@1 78.540 	Validation Prec@5 98.590 	
2019-05-03 16:48:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:48:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:48:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:48:07 - INFO - TRAINING - Epoch: [111][0/500]	Time 0.299 (0.299)	Data 0.262 (0.262)	Loss 0.5475 (0.5475)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:48:08 - INFO - TRAINING - Epoch: [111][50/500]	Time 0.022 (0.024)	Data 0.000 (0.005)	Loss 0.4864 (0.5413)	Prec@1 86.000 (81.902)	Prec@5 98.000 (99.196)
2019-05-03 16:48:09 - INFO - TRAINING - Epoch: [111][100/500]	Time 0.024 (0.023)	Data 0.000 (0.003)	Loss 0.5552 (0.5631)	Prec@1 82.000 (80.950)	Prec@5 100.000 (99.069)
2019-05-03 16:48:10 - INFO - TRAINING - Epoch: [111][150/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.5145 (0.5563)	Prec@1 80.000 (81.179)	Prec@5 99.000 (99.106)
2019-05-03 16:48:11 - INFO - TRAINING - Epoch: [111][200/500]	Time 0.032 (0.021)	Data 0.000 (0.001)	Loss 0.4404 (0.5549)	Prec@1 89.000 (81.378)	Prec@5 99.000 (99.040)
2019-05-03 16:48:12 - INFO - TRAINING - Epoch: [111][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7544 (0.5564)	Prec@1 74.000 (81.398)	Prec@5 99.000 (99.036)
2019-05-03 16:48:13 - INFO - TRAINING - Epoch: [111][300/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4974 (0.5553)	Prec@1 81.000 (81.442)	Prec@5 99.000 (99.040)
2019-05-03 16:48:14 - INFO - TRAINING - Epoch: [111][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6797 (0.5552)	Prec@1 72.000 (81.433)	Prec@5 100.000 (99.068)
2019-05-03 16:48:15 - INFO - TRAINING - Epoch: [111][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5735 (0.5573)	Prec@1 81.000 (81.387)	Prec@5 99.000 (99.100)
2019-05-03 16:48:16 - INFO - TRAINING - Epoch: [111][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5790 (0.5566)	Prec@1 78.000 (81.386)	Prec@5 100.000 (99.093)
2019-05-03 16:48:17 - INFO - EVALUATING - Epoch: [111][0/100]	Time 0.417 (0.417)	Data 0.409 (0.409)	Loss 0.5442 (0.5442)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:48:17 - INFO - EVALUATING - Epoch: [111][50/100]	Time 0.007 (0.014)	Data 0.000 (0.008)	Loss 0.4897 (0.6302)	Prec@1 89.000 (78.863)	Prec@5 98.000 (98.725)
2019-05-03 16:48:18 - INFO - 
 Epoch: 112	Training Loss 0.5550 	Training Prec@1 81.432 	Training Prec@5 99.114 	Validation Loss 0.6161 	Validation Prec@1 79.340 	Validation Prec@5 98.890 	
2019-05-03 16:48:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:48:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:48:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:48:18 - INFO - TRAINING - Epoch: [112][0/500]	Time 0.254 (0.254)	Data 0.231 (0.231)	Loss 0.4850 (0.4850)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 16:48:19 - INFO - TRAINING - Epoch: [112][50/500]	Time 0.026 (0.023)	Data 0.000 (0.005)	Loss 0.4163 (0.5469)	Prec@1 85.000 (81.353)	Prec@5 100.000 (99.373)
2019-05-03 16:48:20 - INFO - TRAINING - Epoch: [112][100/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.5483 (0.5638)	Prec@1 82.000 (81.099)	Prec@5 100.000 (99.129)
2019-05-03 16:48:21 - INFO - TRAINING - Epoch: [112][150/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.6126 (0.5576)	Prec@1 82.000 (81.305)	Prec@5 98.000 (99.166)
2019-05-03 16:48:22 - INFO - TRAINING - Epoch: [112][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5164 (0.5561)	Prec@1 82.000 (81.279)	Prec@5 100.000 (99.174)
2019-05-03 16:48:23 - INFO - TRAINING - Epoch: [112][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5561 (0.5547)	Prec@1 84.000 (81.343)	Prec@5 98.000 (99.131)
2019-05-03 16:48:24 - INFO - TRAINING - Epoch: [112][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.4868 (0.5552)	Prec@1 84.000 (81.319)	Prec@5 99.000 (99.136)
2019-05-03 16:48:25 - INFO - TRAINING - Epoch: [112][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4834 (0.5561)	Prec@1 86.000 (81.319)	Prec@5 100.000 (99.137)
2019-05-03 16:48:26 - INFO - TRAINING - Epoch: [112][400/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5554 (0.5576)	Prec@1 82.000 (81.314)	Prec@5 100.000 (99.147)
2019-05-03 16:48:27 - INFO - TRAINING - Epoch: [112][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.4507 (0.5549)	Prec@1 87.000 (81.437)	Prec@5 100.000 (99.153)
2019-05-03 16:48:28 - INFO - EVALUATING - Epoch: [112][0/100]	Time 0.241 (0.241)	Data 0.235 (0.235)	Loss 0.4911 (0.4911)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:48:28 - INFO - EVALUATING - Epoch: [112][50/100]	Time 0.005 (0.010)	Data 0.000 (0.005)	Loss 0.6725 (0.6911)	Prec@1 79.000 (77.333)	Prec@5 97.000 (98.275)
2019-05-03 16:48:29 - INFO - 
 Epoch: 113	Training Loss 0.5549 	Training Prec@1 81.432 	Training Prec@5 99.144 	Validation Loss 0.6779 	Validation Prec@1 77.570 	Validation Prec@5 98.460 	
2019-05-03 16:48:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:48:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:48:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:48:29 - INFO - TRAINING - Epoch: [113][0/500]	Time 0.292 (0.292)	Data 0.259 (0.259)	Loss 0.2660 (0.2660)	Prec@1 95.000 (95.000)	Prec@5 100.000 (100.000)
2019-05-03 16:48:30 - INFO - TRAINING - Epoch: [113][50/500]	Time 0.023 (0.026)	Data 0.000 (0.005)	Loss 0.4117 (0.5417)	Prec@1 88.000 (82.490)	Prec@5 100.000 (99.157)
2019-05-03 16:48:31 - INFO - TRAINING - Epoch: [113][100/500]	Time 0.016 (0.023)	Data 0.000 (0.003)	Loss 0.4857 (0.5510)	Prec@1 82.000 (81.861)	Prec@5 99.000 (99.168)
2019-05-03 16:48:32 - INFO - TRAINING - Epoch: [113][150/500]	Time 0.011 (0.022)	Data 0.000 (0.002)	Loss 0.4825 (0.5549)	Prec@1 82.000 (81.642)	Prec@5 100.000 (99.146)
2019-05-03 16:48:33 - INFO - TRAINING - Epoch: [113][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5508 (0.5531)	Prec@1 78.000 (81.632)	Prec@5 100.000 (99.174)
2019-05-03 16:48:34 - INFO - TRAINING - Epoch: [113][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7501 (0.5588)	Prec@1 75.000 (81.518)	Prec@5 99.000 (99.163)
2019-05-03 16:48:35 - INFO - TRAINING - Epoch: [113][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6377 (0.5587)	Prec@1 76.000 (81.472)	Prec@5 100.000 (99.140)
2019-05-03 16:48:36 - INFO - TRAINING - Epoch: [113][350/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5803 (0.5543)	Prec@1 82.000 (81.644)	Prec@5 99.000 (99.145)
2019-05-03 16:48:37 - INFO - TRAINING - Epoch: [113][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5647 (0.5542)	Prec@1 84.000 (81.653)	Prec@5 100.000 (99.130)
2019-05-03 16:48:38 - INFO - TRAINING - Epoch: [113][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4973 (0.5521)	Prec@1 83.000 (81.665)	Prec@5 100.000 (99.151)
2019-05-03 16:48:39 - INFO - EVALUATING - Epoch: [113][0/100]	Time 0.246 (0.246)	Data 0.231 (0.231)	Loss 0.5137 (0.5137)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:48:39 - INFO - EVALUATING - Epoch: [113][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 0.6548 (0.6602)	Prec@1 78.000 (78.549)	Prec@5 97.000 (98.412)
2019-05-03 16:48:40 - INFO - 
 Epoch: 114	Training Loss 0.5518 	Training Prec@1 81.664 	Training Prec@5 99.150 	Validation Loss 0.6579 	Validation Prec@1 78.570 	Validation Prec@5 98.600 	
2019-05-03 16:48:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:48:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:48:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:48:40 - INFO - TRAINING - Epoch: [114][0/500]	Time 0.268 (0.268)	Data 0.243 (0.243)	Loss 0.5627 (0.5627)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:48:41 - INFO - TRAINING - Epoch: [114][50/500]	Time 0.014 (0.025)	Data 0.000 (0.005)	Loss 0.5986 (0.5765)	Prec@1 82.000 (81.216)	Prec@5 98.000 (98.980)
2019-05-03 16:48:42 - INFO - TRAINING - Epoch: [114][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.7845 (0.5568)	Prec@1 78.000 (81.782)	Prec@5 98.000 (99.119)
2019-05-03 16:48:43 - INFO - TRAINING - Epoch: [114][150/500]	Time 0.028 (0.021)	Data 0.000 (0.002)	Loss 0.4582 (0.5472)	Prec@1 83.000 (81.834)	Prec@5 100.000 (99.219)
2019-05-03 16:48:44 - INFO - TRAINING - Epoch: [114][200/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6931 (0.5463)	Prec@1 75.000 (81.716)	Prec@5 100.000 (99.234)
2019-05-03 16:48:45 - INFO - TRAINING - Epoch: [114][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4902 (0.5457)	Prec@1 85.000 (81.713)	Prec@5 99.000 (99.227)
2019-05-03 16:48:46 - INFO - TRAINING - Epoch: [114][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7654 (0.5471)	Prec@1 78.000 (81.671)	Prec@5 97.000 (99.223)
2019-05-03 16:48:47 - INFO - TRAINING - Epoch: [114][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5919 (0.5496)	Prec@1 81.000 (81.647)	Prec@5 99.000 (99.168)
2019-05-03 16:48:48 - INFO - TRAINING - Epoch: [114][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6312 (0.5503)	Prec@1 78.000 (81.603)	Prec@5 100.000 (99.152)
2019-05-03 16:48:49 - INFO - TRAINING - Epoch: [114][450/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5880 (0.5491)	Prec@1 82.000 (81.652)	Prec@5 99.000 (99.157)
2019-05-03 16:48:50 - INFO - EVALUATING - Epoch: [114][0/100]	Time 0.312 (0.312)	Data 0.296 (0.296)	Loss 0.6181 (0.6181)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:48:51 - INFO - EVALUATING - Epoch: [114][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.6739 (0.6688)	Prec@1 81.000 (78.451)	Prec@5 96.000 (98.294)
2019-05-03 16:48:51 - INFO - 
 Epoch: 115	Training Loss 0.5496 	Training Prec@1 81.658 	Training Prec@5 99.158 	Validation Loss 0.6579 	Validation Prec@1 78.780 	Validation Prec@5 98.440 	
2019-05-03 16:48:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:48:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:48:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:48:51 - INFO - TRAINING - Epoch: [115][0/500]	Time 0.276 (0.276)	Data 0.248 (0.248)	Loss 0.4692 (0.4692)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:48:52 - INFO - TRAINING - Epoch: [115][50/500]	Time 0.013 (0.024)	Data 0.000 (0.005)	Loss 0.6196 (0.5457)	Prec@1 80.000 (81.863)	Prec@5 98.000 (99.314)
2019-05-03 16:48:53 - INFO - TRAINING - Epoch: [115][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.5099 (0.5510)	Prec@1 84.000 (81.802)	Prec@5 99.000 (99.059)
2019-05-03 16:48:54 - INFO - TRAINING - Epoch: [115][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.5744 (0.5599)	Prec@1 80.000 (81.536)	Prec@5 100.000 (99.026)
2019-05-03 16:48:56 - INFO - TRAINING - Epoch: [115][200/500]	Time 0.024 (0.022)	Data 0.000 (0.001)	Loss 0.4852 (0.5571)	Prec@1 85.000 (81.716)	Prec@5 99.000 (99.040)
2019-05-03 16:48:57 - INFO - TRAINING - Epoch: [115][250/500]	Time 0.016 (0.022)	Data 0.000 (0.001)	Loss 0.4834 (0.5579)	Prec@1 83.000 (81.709)	Prec@5 99.000 (98.992)
2019-05-03 16:48:58 - INFO - TRAINING - Epoch: [115][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5768 (0.5587)	Prec@1 81.000 (81.654)	Prec@5 97.000 (99.013)
2019-05-03 16:48:59 - INFO - TRAINING - Epoch: [115][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5085 (0.5538)	Prec@1 82.000 (81.806)	Prec@5 100.000 (99.031)
2019-05-03 16:49:00 - INFO - TRAINING - Epoch: [115][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4480 (0.5552)	Prec@1 82.000 (81.733)	Prec@5 100.000 (99.022)
2019-05-03 16:49:01 - INFO - TRAINING - Epoch: [115][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5063 (0.5571)	Prec@1 81.000 (81.639)	Prec@5 100.000 (99.024)
2019-05-03 16:49:02 - INFO - EVALUATING - Epoch: [115][0/100]	Time 0.346 (0.346)	Data 0.336 (0.336)	Loss 0.6424 (0.6424)	Prec@1 78.000 (78.000)	Prec@5 98.000 (98.000)
2019-05-03 16:49:02 - INFO - EVALUATING - Epoch: [115][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.5194 (0.6353)	Prec@1 86.000 (79.353)	Prec@5 98.000 (98.765)
2019-05-03 16:49:02 - INFO - 
 Epoch: 116	Training Loss 0.5574 	Training Prec@1 81.612 	Training Prec@5 99.034 	Validation Loss 0.6256 	Validation Prec@1 79.290 	Validation Prec@5 98.870 	
2019-05-03 16:49:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:03 - INFO - TRAINING - Epoch: [116][0/500]	Time 0.281 (0.281)	Data 0.256 (0.256)	Loss 0.4540 (0.4540)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:04 - INFO - TRAINING - Epoch: [116][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.4907 (0.5642)	Prec@1 84.000 (81.980)	Prec@5 100.000 (99.059)
2019-05-03 16:49:05 - INFO - TRAINING - Epoch: [116][100/500]	Time 0.026 (0.022)	Data 0.000 (0.003)	Loss 0.5808 (0.5652)	Prec@1 79.000 (81.446)	Prec@5 100.000 (99.010)
2019-05-03 16:49:06 - INFO - TRAINING - Epoch: [116][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.4744 (0.5681)	Prec@1 84.000 (81.543)	Prec@5 99.000 (98.967)
2019-05-03 16:49:07 - INFO - TRAINING - Epoch: [116][200/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5184 (0.5600)	Prec@1 82.000 (81.662)	Prec@5 100.000 (99.025)
2019-05-03 16:49:08 - INFO - TRAINING - Epoch: [116][250/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.5742 (0.5560)	Prec@1 75.000 (81.681)	Prec@5 99.000 (99.008)
2019-05-03 16:49:09 - INFO - TRAINING - Epoch: [116][300/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.7000 (0.5576)	Prec@1 74.000 (81.548)	Prec@5 100.000 (99.013)
2019-05-03 16:49:10 - INFO - TRAINING - Epoch: [116][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6350 (0.5564)	Prec@1 81.000 (81.541)	Prec@5 98.000 (99.031)
2019-05-03 16:49:11 - INFO - TRAINING - Epoch: [116][400/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.6021 (0.5544)	Prec@1 80.000 (81.584)	Prec@5 97.000 (99.030)
2019-05-03 16:49:12 - INFO - TRAINING - Epoch: [116][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4812 (0.5538)	Prec@1 81.000 (81.612)	Prec@5 100.000 (99.044)
2019-05-03 16:49:13 - INFO - EVALUATING - Epoch: [116][0/100]	Time 0.256 (0.256)	Data 0.250 (0.250)	Loss 0.5509 (0.5509)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:14 - INFO - EVALUATING - Epoch: [116][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.4936 (0.6313)	Prec@1 86.000 (79.275)	Prec@5 98.000 (98.529)
2019-05-03 16:49:14 - INFO - 
 Epoch: 117	Training Loss 0.5540 	Training Prec@1 81.574 	Training Prec@5 99.076 	Validation Loss 0.6278 	Validation Prec@1 79.340 	Validation Prec@5 98.690 	
2019-05-03 16:49:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:14 - INFO - TRAINING - Epoch: [117][0/500]	Time 0.286 (0.286)	Data 0.263 (0.263)	Loss 0.5894 (0.5894)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:15 - INFO - TRAINING - Epoch: [117][50/500]	Time 0.025 (0.027)	Data 0.000 (0.005)	Loss 0.4919 (0.5740)	Prec@1 83.000 (81.039)	Prec@5 100.000 (99.137)
2019-05-03 16:49:16 - INFO - TRAINING - Epoch: [117][100/500]	Time 0.025 (0.024)	Data 0.000 (0.003)	Loss 0.4765 (0.5513)	Prec@1 83.000 (81.683)	Prec@5 100.000 (99.069)
2019-05-03 16:49:17 - INFO - TRAINING - Epoch: [117][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.7240 (0.5467)	Prec@1 79.000 (82.060)	Prec@5 97.000 (99.066)
2019-05-03 16:49:18 - INFO - TRAINING - Epoch: [117][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.6653 (0.5481)	Prec@1 77.000 (81.935)	Prec@5 99.000 (99.095)
2019-05-03 16:49:19 - INFO - TRAINING - Epoch: [117][250/500]	Time 0.023 (0.022)	Data 0.000 (0.001)	Loss 0.5761 (0.5500)	Prec@1 79.000 (81.845)	Prec@5 100.000 (99.092)
2019-05-03 16:49:20 - INFO - TRAINING - Epoch: [117][300/500]	Time 0.026 (0.022)	Data 0.000 (0.001)	Loss 0.6465 (0.5496)	Prec@1 75.000 (81.801)	Prec@5 100.000 (99.100)
2019-05-03 16:49:21 - INFO - TRAINING - Epoch: [117][350/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.6162 (0.5497)	Prec@1 80.000 (81.858)	Prec@5 97.000 (99.068)
2019-05-03 16:49:22 - INFO - TRAINING - Epoch: [117][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7090 (0.5510)	Prec@1 77.000 (81.838)	Prec@5 97.000 (99.040)
2019-05-03 16:49:23 - INFO - TRAINING - Epoch: [117][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5194 (0.5516)	Prec@1 83.000 (81.820)	Prec@5 98.000 (99.038)
2019-05-03 16:49:25 - INFO - EVALUATING - Epoch: [117][0/100]	Time 0.270 (0.270)	Data 0.260 (0.260)	Loss 0.6100 (0.6100)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:25 - INFO - EVALUATING - Epoch: [117][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 0.6881 (0.7066)	Prec@1 80.000 (77.157)	Prec@5 95.000 (98.216)
2019-05-03 16:49:25 - INFO - 
 Epoch: 118	Training Loss 0.5515 	Training Prec@1 81.822 	Training Prec@5 99.066 	Validation Loss 0.6992 	Validation Prec@1 77.160 	Validation Prec@5 98.560 	
2019-05-03 16:49:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:26 - INFO - TRAINING - Epoch: [118][0/500]	Time 0.261 (0.261)	Data 0.235 (0.235)	Loss 0.4877 (0.4877)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 16:49:26 - INFO - TRAINING - Epoch: [118][50/500]	Time 0.020 (0.023)	Data 0.000 (0.005)	Loss 0.5830 (0.5264)	Prec@1 84.000 (82.510)	Prec@5 97.000 (99.157)
2019-05-03 16:49:27 - INFO - TRAINING - Epoch: [118][100/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.5899 (0.5289)	Prec@1 78.000 (82.545)	Prec@5 99.000 (99.119)
2019-05-03 16:49:28 - INFO - TRAINING - Epoch: [118][150/500]	Time 0.028 (0.020)	Data 0.000 (0.002)	Loss 0.5932 (0.5370)	Prec@1 82.000 (82.305)	Prec@5 100.000 (99.119)
2019-05-03 16:49:29 - INFO - TRAINING - Epoch: [118][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6164 (0.5491)	Prec@1 80.000 (81.925)	Prec@5 100.000 (99.100)
2019-05-03 16:49:30 - INFO - TRAINING - Epoch: [118][250/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5433 (0.5491)	Prec@1 81.000 (81.924)	Prec@5 98.000 (99.108)
2019-05-03 16:49:31 - INFO - TRAINING - Epoch: [118][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7100 (0.5470)	Prec@1 77.000 (81.987)	Prec@5 98.000 (99.130)
2019-05-03 16:49:32 - INFO - TRAINING - Epoch: [118][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.5297 (0.5510)	Prec@1 84.000 (81.906)	Prec@5 99.000 (99.077)
2019-05-03 16:49:33 - INFO - TRAINING - Epoch: [118][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.3870 (0.5560)	Prec@1 88.000 (81.741)	Prec@5 100.000 (99.050)
2019-05-03 16:49:35 - INFO - TRAINING - Epoch: [118][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.4788 (0.5523)	Prec@1 89.000 (81.920)	Prec@5 99.000 (99.060)
2019-05-03 16:49:36 - INFO - EVALUATING - Epoch: [118][0/100]	Time 0.345 (0.345)	Data 0.335 (0.335)	Loss 0.5794 (0.5794)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:36 - INFO - EVALUATING - Epoch: [118][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.6573 (0.6810)	Prec@1 80.000 (77.922)	Prec@5 97.000 (98.333)
2019-05-03 16:49:36 - INFO - 
 Epoch: 119	Training Loss 0.5505 	Training Prec@1 81.978 	Training Prec@5 99.060 	Validation Loss 0.6886 	Validation Prec@1 77.460 	Validation Prec@5 98.440 	
2019-05-03 16:49:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:37 - INFO - TRAINING - Epoch: [119][0/500]	Time 0.261 (0.261)	Data 0.230 (0.230)	Loss 0.5274 (0.5274)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 16:49:38 - INFO - TRAINING - Epoch: [119][50/500]	Time 0.025 (0.025)	Data 0.000 (0.005)	Loss 0.5245 (0.5574)	Prec@1 79.000 (81.549)	Prec@5 99.000 (99.196)
2019-05-03 16:49:39 - INFO - TRAINING - Epoch: [119][100/500]	Time 0.029 (0.023)	Data 0.000 (0.002)	Loss 0.4528 (0.5435)	Prec@1 82.000 (82.030)	Prec@5 99.000 (99.228)
2019-05-03 16:49:40 - INFO - TRAINING - Epoch: [119][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.6187 (0.5411)	Prec@1 77.000 (82.199)	Prec@5 99.000 (99.205)
2019-05-03 16:49:41 - INFO - TRAINING - Epoch: [119][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7234 (0.5424)	Prec@1 78.000 (82.154)	Prec@5 98.000 (99.124)
2019-05-03 16:49:42 - INFO - TRAINING - Epoch: [119][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6283 (0.5459)	Prec@1 79.000 (82.000)	Prec@5 99.000 (99.096)
2019-05-03 16:49:43 - INFO - TRAINING - Epoch: [119][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6525 (0.5504)	Prec@1 79.000 (81.940)	Prec@5 98.000 (99.050)
2019-05-03 16:49:44 - INFO - TRAINING - Epoch: [119][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5122 (0.5495)	Prec@1 85.000 (81.983)	Prec@5 98.000 (99.077)
2019-05-03 16:49:45 - INFO - TRAINING - Epoch: [119][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.6541 (0.5532)	Prec@1 80.000 (81.890)	Prec@5 100.000 (99.075)
2019-05-03 16:49:46 - INFO - TRAINING - Epoch: [119][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.3908 (0.5511)	Prec@1 85.000 (81.894)	Prec@5 100.000 (99.073)
2019-05-03 16:49:47 - INFO - EVALUATING - Epoch: [119][0/100]	Time 0.334 (0.334)	Data 0.324 (0.324)	Loss 0.5328 (0.5328)	Prec@1 84.000 (84.000)	Prec@5 97.000 (97.000)
2019-05-03 16:49:47 - INFO - EVALUATING - Epoch: [119][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.5184 (0.6184)	Prec@1 84.000 (80.000)	Prec@5 99.000 (98.510)
2019-05-03 16:49:47 - INFO - 
 Epoch: 120	Training Loss 0.5501 	Training Prec@1 81.960 	Training Prec@5 99.092 	Validation Loss 0.6127 	Validation Prec@1 80.130 	Validation Prec@5 98.680 	
2019-05-03 16:49:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:48 - INFO - TRAINING - Epoch: [120][0/500]	Time 0.257 (0.257)	Data 0.222 (0.222)	Loss 0.6786 (0.6786)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:49:49 - INFO - TRAINING - Epoch: [120][50/500]	Time 0.015 (0.023)	Data 0.000 (0.004)	Loss 0.6056 (0.5409)	Prec@1 80.000 (82.431)	Prec@5 99.000 (99.216)
2019-05-03 16:49:50 - INFO - TRAINING - Epoch: [120][100/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.7819 (0.5377)	Prec@1 73.000 (82.168)	Prec@5 99.000 (99.267)
2019-05-03 16:49:51 - INFO - TRAINING - Epoch: [120][150/500]	Time 0.029 (0.022)	Data 0.000 (0.002)	Loss 0.5245 (0.5396)	Prec@1 82.000 (82.106)	Prec@5 100.000 (99.192)
2019-05-03 16:49:52 - INFO - TRAINING - Epoch: [120][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5852 (0.5394)	Prec@1 82.000 (82.149)	Prec@5 98.000 (99.194)
2019-05-03 16:49:53 - INFO - TRAINING - Epoch: [120][250/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.4683 (0.5363)	Prec@1 83.000 (82.223)	Prec@5 99.000 (99.199)
2019-05-03 16:49:54 - INFO - TRAINING - Epoch: [120][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4169 (0.5398)	Prec@1 85.000 (82.073)	Prec@5 100.000 (99.130)
2019-05-03 16:49:55 - INFO - TRAINING - Epoch: [120][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5029 (0.5409)	Prec@1 84.000 (82.100)	Prec@5 99.000 (99.137)
2019-05-03 16:49:56 - INFO - TRAINING - Epoch: [120][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7064 (0.5445)	Prec@1 79.000 (82.062)	Prec@5 99.000 (99.137)
2019-05-03 16:49:57 - INFO - TRAINING - Epoch: [120][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5679 (0.5461)	Prec@1 86.000 (81.976)	Prec@5 99.000 (99.149)
2019-05-03 16:49:58 - INFO - EVALUATING - Epoch: [120][0/100]	Time 0.260 (0.260)	Data 0.253 (0.253)	Loss 0.4761 (0.4761)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 16:49:58 - INFO - EVALUATING - Epoch: [120][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.4968 (0.6092)	Prec@1 84.000 (79.804)	Prec@5 98.000 (98.725)
2019-05-03 16:49:59 - INFO - 
 Epoch: 121	Training Loss 0.5467 	Training Prec@1 81.980 	Training Prec@5 99.138 	Validation Loss 0.6040 	Validation Prec@1 79.910 	Validation Prec@5 98.860 	
2019-05-03 16:49:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:49:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:49:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:49:59 - INFO - TRAINING - Epoch: [121][0/500]	Time 0.245 (0.245)	Data 0.223 (0.223)	Loss 0.6892 (0.6892)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:00 - INFO - TRAINING - Epoch: [121][50/500]	Time 0.021 (0.026)	Data 0.000 (0.005)	Loss 0.7037 (0.5631)	Prec@1 80.000 (81.392)	Prec@5 98.000 (99.078)
2019-05-03 16:50:01 - INFO - TRAINING - Epoch: [121][100/500]	Time 0.017 (0.023)	Data 0.000 (0.002)	Loss 0.6804 (0.5670)	Prec@1 74.000 (81.386)	Prec@5 99.000 (98.941)
2019-05-03 16:50:02 - INFO - TRAINING - Epoch: [121][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.5092 (0.5574)	Prec@1 81.000 (81.576)	Prec@5 100.000 (99.086)
2019-05-03 16:50:03 - INFO - TRAINING - Epoch: [121][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5292 (0.5535)	Prec@1 80.000 (81.662)	Prec@5 100.000 (99.139)
2019-05-03 16:50:04 - INFO - TRAINING - Epoch: [121][250/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.8241 (0.5549)	Prec@1 75.000 (81.625)	Prec@5 99.000 (99.100)
2019-05-03 16:50:05 - INFO - TRAINING - Epoch: [121][300/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.4450 (0.5507)	Prec@1 86.000 (81.807)	Prec@5 100.000 (99.113)
2019-05-03 16:50:06 - INFO - TRAINING - Epoch: [121][350/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.6044 (0.5494)	Prec@1 80.000 (81.855)	Prec@5 100.000 (99.108)
2019-05-03 16:50:07 - INFO - TRAINING - Epoch: [121][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5358 (0.5469)	Prec@1 82.000 (81.835)	Prec@5 99.000 (99.125)
2019-05-03 16:50:08 - INFO - TRAINING - Epoch: [121][450/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.5991 (0.5462)	Prec@1 79.000 (81.847)	Prec@5 100.000 (99.111)
2019-05-03 16:50:09 - INFO - EVALUATING - Epoch: [121][0/100]	Time 0.318 (0.318)	Data 0.311 (0.311)	Loss 0.6221 (0.6221)	Prec@1 78.000 (78.000)	Prec@5 97.000 (97.000)
2019-05-03 16:50:10 - INFO - EVALUATING - Epoch: [121][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.5480 (0.6365)	Prec@1 80.000 (78.725)	Prec@5 98.000 (98.765)
2019-05-03 16:50:10 - INFO - 
 Epoch: 122	Training Loss 0.5467 	Training Prec@1 81.816 	Training Prec@5 99.104 	Validation Loss 0.6292 	Validation Prec@1 79.160 	Validation Prec@5 98.950 	
2019-05-03 16:50:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:50:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:50:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:50:10 - INFO - TRAINING - Epoch: [122][0/500]	Time 0.256 (0.256)	Data 0.235 (0.235)	Loss 0.6531 (0.6531)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:50:11 - INFO - TRAINING - Epoch: [122][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.6687 (0.5448)	Prec@1 77.000 (82.549)	Prec@5 98.000 (99.000)
2019-05-03 16:50:12 - INFO - TRAINING - Epoch: [122][100/500]	Time 0.029 (0.022)	Data 0.000 (0.002)	Loss 0.6186 (0.5382)	Prec@1 83.000 (82.733)	Prec@5 99.000 (99.010)
2019-05-03 16:50:13 - INFO - TRAINING - Epoch: [122][150/500]	Time 0.011 (0.022)	Data 0.000 (0.002)	Loss 0.5452 (0.5397)	Prec@1 85.000 (82.536)	Prec@5 98.000 (99.060)
2019-05-03 16:50:14 - INFO - TRAINING - Epoch: [122][200/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.5417 (0.5368)	Prec@1 84.000 (82.512)	Prec@5 98.000 (99.149)
2019-05-03 16:50:15 - INFO - TRAINING - Epoch: [122][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6355 (0.5359)	Prec@1 85.000 (82.550)	Prec@5 98.000 (99.163)
2019-05-03 16:50:16 - INFO - TRAINING - Epoch: [122][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6374 (0.5390)	Prec@1 78.000 (82.349)	Prec@5 100.000 (99.166)
2019-05-03 16:50:17 - INFO - TRAINING - Epoch: [122][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5669 (0.5430)	Prec@1 80.000 (82.225)	Prec@5 100.000 (99.117)
2019-05-03 16:50:18 - INFO - TRAINING - Epoch: [122][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6825 (0.5417)	Prec@1 80.000 (82.259)	Prec@5 98.000 (99.115)
2019-05-03 16:50:19 - INFO - TRAINING - Epoch: [122][450/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.4582 (0.5433)	Prec@1 86.000 (82.180)	Prec@5 100.000 (99.102)
2019-05-03 16:50:21 - INFO - EVALUATING - Epoch: [122][0/100]	Time 0.373 (0.373)	Data 0.356 (0.356)	Loss 0.6129 (0.6129)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 16:50:21 - INFO - EVALUATING - Epoch: [122][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.6227 (0.6079)	Prec@1 78.000 (80.510)	Prec@5 96.000 (98.784)
2019-05-03 16:50:21 - INFO - 
 Epoch: 123	Training Loss 0.5464 	Training Prec@1 82.074 	Training Prec@5 99.104 	Validation Loss 0.5970 	Validation Prec@1 80.320 	Validation Prec@5 98.940 	
2019-05-03 16:50:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:50:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:50:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:50:22 - INFO - TRAINING - Epoch: [123][0/500]	Time 0.255 (0.255)	Data 0.231 (0.231)	Loss 0.5629 (0.5629)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:23 - INFO - TRAINING - Epoch: [123][50/500]	Time 0.015 (0.023)	Data 0.000 (0.005)	Loss 0.6207 (0.5278)	Prec@1 77.000 (82.824)	Prec@5 100.000 (99.235)
2019-05-03 16:50:24 - INFO - TRAINING - Epoch: [123][100/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.4779 (0.5299)	Prec@1 86.000 (82.891)	Prec@5 100.000 (99.178)
2019-05-03 16:50:25 - INFO - TRAINING - Epoch: [123][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.6557 (0.5413)	Prec@1 78.000 (82.298)	Prec@5 99.000 (99.199)
2019-05-03 16:50:26 - INFO - TRAINING - Epoch: [123][200/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.7016 (0.5456)	Prec@1 73.000 (82.035)	Prec@5 99.000 (99.189)
2019-05-03 16:50:27 - INFO - TRAINING - Epoch: [123][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4399 (0.5440)	Prec@1 86.000 (82.096)	Prec@5 98.000 (99.227)
2019-05-03 16:50:28 - INFO - TRAINING - Epoch: [123][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5003 (0.5454)	Prec@1 84.000 (82.050)	Prec@5 99.000 (99.206)
2019-05-03 16:50:29 - INFO - TRAINING - Epoch: [123][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4950 (0.5458)	Prec@1 85.000 (81.946)	Prec@5 97.000 (99.179)
2019-05-03 16:50:30 - INFO - TRAINING - Epoch: [123][400/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5529 (0.5453)	Prec@1 84.000 (81.955)	Prec@5 99.000 (99.162)
2019-05-03 16:50:31 - INFO - TRAINING - Epoch: [123][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6470 (0.5453)	Prec@1 82.000 (81.971)	Prec@5 99.000 (99.140)
2019-05-03 16:50:32 - INFO - EVALUATING - Epoch: [123][0/100]	Time 0.355 (0.355)	Data 0.339 (0.339)	Loss 0.6539 (0.6539)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:32 - INFO - EVALUATING - Epoch: [123][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.6137 (0.6825)	Prec@1 80.000 (77.824)	Prec@5 97.000 (98.490)
2019-05-03 16:50:33 - INFO - 
 Epoch: 124	Training Loss 0.5454 	Training Prec@1 81.904 	Training Prec@5 99.162 	Validation Loss 0.6745 	Validation Prec@1 77.910 	Validation Prec@5 98.670 	
2019-05-03 16:50:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:50:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:50:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:50:33 - INFO - TRAINING - Epoch: [124][0/500]	Time 0.267 (0.267)	Data 0.246 (0.246)	Loss 0.2864 (0.2864)	Prec@1 94.000 (94.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:34 - INFO - TRAINING - Epoch: [124][50/500]	Time 0.018 (0.024)	Data 0.000 (0.005)	Loss 0.5762 (0.5457)	Prec@1 83.000 (81.863)	Prec@5 99.000 (99.216)
2019-05-03 16:50:35 - INFO - TRAINING - Epoch: [124][100/500]	Time 0.026 (0.022)	Data 0.000 (0.003)	Loss 0.5707 (0.5593)	Prec@1 80.000 (81.624)	Prec@5 100.000 (99.139)
2019-05-03 16:50:36 - INFO - TRAINING - Epoch: [124][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.6395 (0.5552)	Prec@1 80.000 (81.656)	Prec@5 99.000 (99.185)
2019-05-03 16:50:37 - INFO - TRAINING - Epoch: [124][200/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6904 (0.5521)	Prec@1 76.000 (81.657)	Prec@5 100.000 (99.184)
2019-05-03 16:50:38 - INFO - TRAINING - Epoch: [124][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6767 (0.5509)	Prec@1 75.000 (81.590)	Prec@5 100.000 (99.163)
2019-05-03 16:50:39 - INFO - TRAINING - Epoch: [124][300/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.3518 (0.5477)	Prec@1 89.000 (81.791)	Prec@5 100.000 (99.183)
2019-05-03 16:50:40 - INFO - TRAINING - Epoch: [124][350/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.4861 (0.5468)	Prec@1 81.000 (81.872)	Prec@5 100.000 (99.179)
2019-05-03 16:50:41 - INFO - TRAINING - Epoch: [124][400/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.5725 (0.5457)	Prec@1 78.000 (81.960)	Prec@5 99.000 (99.145)
2019-05-03 16:50:42 - INFO - TRAINING - Epoch: [124][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7157 (0.5474)	Prec@1 75.000 (81.869)	Prec@5 100.000 (99.109)
2019-05-03 16:50:43 - INFO - EVALUATING - Epoch: [124][0/100]	Time 0.333 (0.333)	Data 0.325 (0.325)	Loss 0.5640 (0.5640)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:43 - INFO - EVALUATING - Epoch: [124][50/100]	Time 0.007 (0.012)	Data 0.000 (0.006)	Loss 0.7352 (0.7199)	Prec@1 76.000 (76.667)	Prec@5 96.000 (98.333)
2019-05-03 16:50:44 - INFO - 
 Epoch: 125	Training Loss 0.5481 	Training Prec@1 81.858 	Training Prec@5 99.094 	Validation Loss 0.7188 	Validation Prec@1 76.150 	Validation Prec@5 98.490 	
2019-05-03 16:50:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:50:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:50:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:50:44 - INFO - TRAINING - Epoch: [125][0/500]	Time 0.259 (0.259)	Data 0.237 (0.237)	Loss 0.4959 (0.4959)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:50:45 - INFO - TRAINING - Epoch: [125][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.5574 (0.5498)	Prec@1 83.000 (81.863)	Prec@5 100.000 (99.000)
2019-05-03 16:50:46 - INFO - TRAINING - Epoch: [125][100/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.4281 (0.5486)	Prec@1 84.000 (82.059)	Prec@5 100.000 (99.040)
2019-05-03 16:50:47 - INFO - TRAINING - Epoch: [125][150/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.4964 (0.5494)	Prec@1 81.000 (81.762)	Prec@5 99.000 (99.046)
2019-05-03 16:50:48 - INFO - TRAINING - Epoch: [125][200/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.4282 (0.5520)	Prec@1 85.000 (81.642)	Prec@5 98.000 (99.040)
2019-05-03 16:50:49 - INFO - TRAINING - Epoch: [125][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6170 (0.5511)	Prec@1 79.000 (81.653)	Prec@5 99.000 (99.060)
2019-05-03 16:50:50 - INFO - TRAINING - Epoch: [125][300/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.6792 (0.5508)	Prec@1 82.000 (81.638)	Prec@5 100.000 (99.080)
2019-05-03 16:50:51 - INFO - TRAINING - Epoch: [125][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.4915 (0.5501)	Prec@1 84.000 (81.630)	Prec@5 99.000 (99.085)
2019-05-03 16:50:52 - INFO - TRAINING - Epoch: [125][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6492 (0.5486)	Prec@1 79.000 (81.673)	Prec@5 98.000 (99.102)
2019-05-03 16:50:53 - INFO - TRAINING - Epoch: [125][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.3401 (0.5480)	Prec@1 90.000 (81.667)	Prec@5 100.000 (99.100)
2019-05-03 16:50:54 - INFO - EVALUATING - Epoch: [125][0/100]	Time 0.346 (0.346)	Data 0.336 (0.336)	Loss 0.6278 (0.6278)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:50:55 - INFO - EVALUATING - Epoch: [125][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.6714 (0.7650)	Prec@1 82.000 (75.373)	Prec@5 97.000 (98.314)
2019-05-03 16:50:55 - INFO - 
 Epoch: 126	Training Loss 0.5487 	Training Prec@1 81.722 	Training Prec@5 99.088 	Validation Loss 0.7615 	Validation Prec@1 75.120 	Validation Prec@5 98.510 	
2019-05-03 16:50:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:50:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:50:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:50:55 - INFO - TRAINING - Epoch: [126][0/500]	Time 0.261 (0.261)	Data 0.240 (0.240)	Loss 0.5450 (0.5450)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:50:56 - INFO - TRAINING - Epoch: [126][50/500]	Time 0.032 (0.025)	Data 0.000 (0.005)	Loss 0.4626 (0.5199)	Prec@1 82.000 (82.980)	Prec@5 100.000 (99.137)
2019-05-03 16:50:57 - INFO - TRAINING - Epoch: [126][100/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.5715 (0.5378)	Prec@1 84.000 (82.356)	Prec@5 98.000 (99.168)
2019-05-03 16:50:58 - INFO - TRAINING - Epoch: [126][150/500]	Time 0.013 (0.021)	Data 0.000 (0.002)	Loss 0.5003 (0.5297)	Prec@1 84.000 (82.735)	Prec@5 100.000 (99.192)
2019-05-03 16:50:59 - INFO - TRAINING - Epoch: [126][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4060 (0.5340)	Prec@1 85.000 (82.468)	Prec@5 100.000 (99.194)
2019-05-03 16:51:00 - INFO - TRAINING - Epoch: [126][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4647 (0.5403)	Prec@1 85.000 (82.275)	Prec@5 98.000 (99.163)
2019-05-03 16:51:01 - INFO - TRAINING - Epoch: [126][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5992 (0.5401)	Prec@1 80.000 (82.252)	Prec@5 99.000 (99.110)
2019-05-03 16:51:02 - INFO - TRAINING - Epoch: [126][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.4527 (0.5380)	Prec@1 87.000 (82.296)	Prec@5 99.000 (99.108)
2019-05-03 16:51:03 - INFO - TRAINING - Epoch: [126][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4786 (0.5402)	Prec@1 83.000 (82.192)	Prec@5 100.000 (99.115)
2019-05-03 16:51:04 - INFO - TRAINING - Epoch: [126][450/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.5097 (0.5428)	Prec@1 82.000 (82.060)	Prec@5 99.000 (99.113)
2019-05-03 16:51:06 - INFO - EVALUATING - Epoch: [126][0/100]	Time 0.341 (0.341)	Data 0.329 (0.329)	Loss 0.6718 (0.6718)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:06 - INFO - EVALUATING - Epoch: [126][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.6695 (0.6670)	Prec@1 78.000 (78.157)	Prec@5 97.000 (98.392)
2019-05-03 16:51:06 - INFO - 
 Epoch: 127	Training Loss 0.5448 	Training Prec@1 81.964 	Training Prec@5 99.104 	Validation Loss 0.6654 	Validation Prec@1 78.470 	Validation Prec@5 98.420 	
2019-05-03 16:51:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:51:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:51:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:51:06 - INFO - TRAINING - Epoch: [127][0/500]	Time 0.276 (0.276)	Data 0.253 (0.253)	Loss 0.5775 (0.5775)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:07 - INFO - TRAINING - Epoch: [127][50/500]	Time 0.024 (0.023)	Data 0.000 (0.005)	Loss 0.3683 (0.5462)	Prec@1 88.000 (82.275)	Prec@5 100.000 (99.039)
2019-05-03 16:51:08 - INFO - TRAINING - Epoch: [127][100/500]	Time 0.016 (0.021)	Data 0.000 (0.003)	Loss 0.4967 (0.5339)	Prec@1 84.000 (82.564)	Prec@5 99.000 (99.228)
2019-05-03 16:51:09 - INFO - TRAINING - Epoch: [127][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.5731 (0.5385)	Prec@1 82.000 (82.159)	Prec@5 100.000 (99.179)
2019-05-03 16:51:10 - INFO - TRAINING - Epoch: [127][200/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.7905 (0.5437)	Prec@1 70.000 (82.100)	Prec@5 99.000 (99.114)
2019-05-03 16:51:11 - INFO - TRAINING - Epoch: [127][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6293 (0.5388)	Prec@1 80.000 (82.147)	Prec@5 99.000 (99.163)
2019-05-03 16:51:12 - INFO - TRAINING - Epoch: [127][300/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.5275 (0.5406)	Prec@1 81.000 (82.110)	Prec@5 99.000 (99.149)
2019-05-03 16:51:13 - INFO - TRAINING - Epoch: [127][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.6995 (0.5478)	Prec@1 74.000 (81.843)	Prec@5 100.000 (99.105)
2019-05-03 16:51:14 - INFO - TRAINING - Epoch: [127][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.6100 (0.5457)	Prec@1 77.000 (81.903)	Prec@5 99.000 (99.122)
2019-05-03 16:51:15 - INFO - TRAINING - Epoch: [127][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.4973 (0.5444)	Prec@1 86.000 (81.949)	Prec@5 100.000 (99.149)
2019-05-03 16:51:17 - INFO - EVALUATING - Epoch: [127][0/100]	Time 0.361 (0.361)	Data 0.346 (0.346)	Loss 0.6181 (0.6181)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:17 - INFO - EVALUATING - Epoch: [127][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5519 (0.6210)	Prec@1 83.000 (79.941)	Prec@5 98.000 (98.627)
2019-05-03 16:51:17 - INFO - 
 Epoch: 128	Training Loss 0.5440 	Training Prec@1 81.922 	Training Prec@5 99.168 	Validation Loss 0.6102 	Validation Prec@1 79.840 	Validation Prec@5 98.800 	
2019-05-03 16:51:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:51:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:51:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:51:17 - INFO - TRAINING - Epoch: [128][0/500]	Time 0.267 (0.267)	Data 0.236 (0.236)	Loss 0.6553 (0.6553)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 16:51:18 - INFO - TRAINING - Epoch: [128][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.4456 (0.5296)	Prec@1 87.000 (82.235)	Prec@5 99.000 (99.059)
2019-05-03 16:51:19 - INFO - TRAINING - Epoch: [128][100/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.4296 (0.5373)	Prec@1 88.000 (81.950)	Prec@5 99.000 (99.139)
2019-05-03 16:51:20 - INFO - TRAINING - Epoch: [128][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7135 (0.5387)	Prec@1 74.000 (81.788)	Prec@5 97.000 (99.179)
2019-05-03 16:51:21 - INFO - TRAINING - Epoch: [128][200/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5087 (0.5348)	Prec@1 85.000 (81.995)	Prec@5 97.000 (99.209)
2019-05-03 16:51:22 - INFO - TRAINING - Epoch: [128][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5350 (0.5363)	Prec@1 81.000 (81.996)	Prec@5 99.000 (99.187)
2019-05-03 16:51:23 - INFO - TRAINING - Epoch: [128][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5074 (0.5331)	Prec@1 82.000 (82.199)	Prec@5 99.000 (99.179)
2019-05-03 16:51:24 - INFO - TRAINING - Epoch: [128][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5788 (0.5355)	Prec@1 82.000 (82.105)	Prec@5 100.000 (99.185)
2019-05-03 16:51:25 - INFO - TRAINING - Epoch: [128][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.4964 (0.5374)	Prec@1 84.000 (82.032)	Prec@5 99.000 (99.187)
2019-05-03 16:51:27 - INFO - TRAINING - Epoch: [128][450/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6780 (0.5363)	Prec@1 80.000 (82.035)	Prec@5 98.000 (99.197)
2019-05-03 16:51:28 - INFO - EVALUATING - Epoch: [128][0/100]	Time 0.267 (0.267)	Data 0.256 (0.256)	Loss 0.7243 (0.7243)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:28 - INFO - EVALUATING - Epoch: [128][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 0.6260 (0.6660)	Prec@1 84.000 (78.314)	Prec@5 95.000 (98.686)
2019-05-03 16:51:28 - INFO - 
 Epoch: 129	Training Loss 0.5399 	Training Prec@1 81.998 	Training Prec@5 99.166 	Validation Loss 0.6539 	Validation Prec@1 78.300 	Validation Prec@5 98.820 	
2019-05-03 16:51:28 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:51:28 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:51:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:51:29 - INFO - TRAINING - Epoch: [129][0/500]	Time 0.244 (0.244)	Data 0.225 (0.225)	Loss 0.4601 (0.4601)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:30 - INFO - TRAINING - Epoch: [129][50/500]	Time 0.025 (0.025)	Data 0.000 (0.005)	Loss 0.6031 (0.5671)	Prec@1 80.000 (81.765)	Prec@5 98.000 (99.000)
2019-05-03 16:51:31 - INFO - TRAINING - Epoch: [129][100/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.5231 (0.5609)	Prec@1 82.000 (81.792)	Prec@5 100.000 (98.970)
2019-05-03 16:51:32 - INFO - TRAINING - Epoch: [129][150/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.4946 (0.5482)	Prec@1 86.000 (82.159)	Prec@5 99.000 (99.053)
2019-05-03 16:51:33 - INFO - TRAINING - Epoch: [129][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5012 (0.5467)	Prec@1 87.000 (82.179)	Prec@5 98.000 (99.055)
2019-05-03 16:51:34 - INFO - TRAINING - Epoch: [129][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4579 (0.5424)	Prec@1 83.000 (82.203)	Prec@5 100.000 (99.100)
2019-05-03 16:51:35 - INFO - TRAINING - Epoch: [129][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6504 (0.5436)	Prec@1 73.000 (82.007)	Prec@5 100.000 (99.113)
2019-05-03 16:51:36 - INFO - TRAINING - Epoch: [129][350/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6231 (0.5464)	Prec@1 81.000 (81.872)	Prec@5 100.000 (99.103)
2019-05-03 16:51:37 - INFO - TRAINING - Epoch: [129][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6932 (0.5483)	Prec@1 75.000 (81.818)	Prec@5 99.000 (99.112)
2019-05-03 16:51:38 - INFO - TRAINING - Epoch: [129][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.7269 (0.5467)	Prec@1 75.000 (81.860)	Prec@5 98.000 (99.106)
2019-05-03 16:51:39 - INFO - EVALUATING - Epoch: [129][0/100]	Time 0.360 (0.360)	Data 0.353 (0.353)	Loss 0.7221 (0.7221)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 16:51:39 - INFO - EVALUATING - Epoch: [129][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.6534 (0.7358)	Prec@1 79.000 (75.804)	Prec@5 98.000 (97.686)
2019-05-03 16:51:39 - INFO - 
 Epoch: 130	Training Loss 0.5453 	Training Prec@1 81.894 	Training Prec@5 99.124 	Validation Loss 0.7277 	Validation Prec@1 76.220 	Validation Prec@5 97.880 	
2019-05-03 16:51:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:51:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:51:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:51:40 - INFO - TRAINING - Epoch: [130][0/500]	Time 0.272 (0.272)	Data 0.247 (0.247)	Loss 0.4467 (0.4467)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:41 - INFO - TRAINING - Epoch: [130][50/500]	Time 0.020 (0.025)	Data 0.000 (0.005)	Loss 0.5309 (0.5469)	Prec@1 83.000 (82.078)	Prec@5 99.000 (99.098)
2019-05-03 16:51:42 - INFO - TRAINING - Epoch: [130][100/500]	Time 0.011 (0.023)	Data 0.000 (0.003)	Loss 0.6220 (0.5310)	Prec@1 78.000 (82.376)	Prec@5 97.000 (99.188)
2019-05-03 16:51:43 - INFO - TRAINING - Epoch: [130][150/500]	Time 0.031 (0.022)	Data 0.000 (0.002)	Loss 0.3853 (0.5354)	Prec@1 88.000 (82.265)	Prec@5 100.000 (99.166)
2019-05-03 16:51:44 - INFO - TRAINING - Epoch: [130][200/500]	Time 0.014 (0.022)	Data 0.000 (0.001)	Loss 0.5319 (0.5378)	Prec@1 81.000 (82.313)	Prec@5 99.000 (99.134)
2019-05-03 16:51:45 - INFO - TRAINING - Epoch: [130][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5500 (0.5429)	Prec@1 84.000 (82.171)	Prec@5 97.000 (99.127)
2019-05-03 16:51:46 - INFO - TRAINING - Epoch: [130][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5169 (0.5414)	Prec@1 82.000 (82.176)	Prec@5 100.000 (99.176)
2019-05-03 16:51:47 - INFO - TRAINING - Epoch: [130][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4678 (0.5432)	Prec@1 83.000 (82.125)	Prec@5 100.000 (99.165)
2019-05-03 16:51:48 - INFO - TRAINING - Epoch: [130][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6330 (0.5440)	Prec@1 80.000 (82.107)	Prec@5 100.000 (99.172)
2019-05-03 16:51:49 - INFO - TRAINING - Epoch: [130][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.6479 (0.5459)	Prec@1 81.000 (82.089)	Prec@5 98.000 (99.153)
2019-05-03 16:51:50 - INFO - EVALUATING - Epoch: [130][0/100]	Time 0.337 (0.337)	Data 0.329 (0.329)	Loss 0.6166 (0.6166)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 16:51:50 - INFO - EVALUATING - Epoch: [130][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.5258 (0.6992)	Prec@1 84.000 (76.725)	Prec@5 97.000 (98.314)
2019-05-03 16:51:51 - INFO - 
 Epoch: 131	Training Loss 0.5483 	Training Prec@1 82.040 	Training Prec@5 99.150 	Validation Loss 0.6930 	Validation Prec@1 76.880 	Validation Prec@5 98.440 	
2019-05-03 16:51:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:51:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:51:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:51:51 - INFO - TRAINING - Epoch: [131][0/500]	Time 0.287 (0.287)	Data 0.254 (0.254)	Loss 0.7020 (0.7020)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 16:51:52 - INFO - TRAINING - Epoch: [131][50/500]	Time 0.033 (0.024)	Data 0.000 (0.005)	Loss 0.8503 (0.5554)	Prec@1 75.000 (81.588)	Prec@5 98.000 (99.098)
2019-05-03 16:51:53 - INFO - TRAINING - Epoch: [131][100/500]	Time 0.014 (0.023)	Data 0.000 (0.003)	Loss 0.6120 (0.5569)	Prec@1 78.000 (81.465)	Prec@5 100.000 (99.119)
2019-05-03 16:51:54 - INFO - TRAINING - Epoch: [131][150/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.4373 (0.5518)	Prec@1 85.000 (81.629)	Prec@5 100.000 (99.066)
2019-05-03 16:51:55 - INFO - TRAINING - Epoch: [131][200/500]	Time 0.025 (0.022)	Data 0.000 (0.001)	Loss 0.3741 (0.5484)	Prec@1 89.000 (81.781)	Prec@5 100.000 (99.070)
2019-05-03 16:51:56 - INFO - TRAINING - Epoch: [131][250/500]	Time 0.031 (0.022)	Data 0.000 (0.001)	Loss 0.5534 (0.5435)	Prec@1 83.000 (81.869)	Prec@5 98.000 (99.100)
2019-05-03 16:51:57 - INFO - TRAINING - Epoch: [131][300/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.7389 (0.5455)	Prec@1 80.000 (81.817)	Prec@5 97.000 (99.116)
2019-05-03 16:51:58 - INFO - TRAINING - Epoch: [131][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6628 (0.5444)	Prec@1 74.000 (81.866)	Prec@5 99.000 (99.128)
2019-05-03 16:51:59 - INFO - TRAINING - Epoch: [131][400/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.7148 (0.5479)	Prec@1 78.000 (81.810)	Prec@5 97.000 (99.100)
2019-05-03 16:52:00 - INFO - TRAINING - Epoch: [131][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5283 (0.5487)	Prec@1 77.000 (81.787)	Prec@5 99.000 (99.098)
2019-05-03 16:52:02 - INFO - EVALUATING - Epoch: [131][0/100]	Time 0.331 (0.331)	Data 0.322 (0.322)	Loss 0.5804 (0.5804)	Prec@1 83.000 (83.000)	Prec@5 96.000 (96.000)
2019-05-03 16:52:02 - INFO - EVALUATING - Epoch: [131][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.7750 (0.7225)	Prec@1 76.000 (76.706)	Prec@5 97.000 (98.137)
2019-05-03 16:52:02 - INFO - 
 Epoch: 132	Training Loss 0.5466 	Training Prec@1 81.814 	Training Prec@5 99.116 	Validation Loss 0.7084 	Validation Prec@1 77.070 	Validation Prec@5 98.340 	
2019-05-03 16:52:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:03 - INFO - TRAINING - Epoch: [132][0/500]	Time 0.266 (0.266)	Data 0.237 (0.237)	Loss 0.4675 (0.4675)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:52:04 - INFO - TRAINING - Epoch: [132][50/500]	Time 0.026 (0.025)	Data 0.000 (0.005)	Loss 0.5431 (0.5451)	Prec@1 80.000 (81.922)	Prec@5 100.000 (99.157)
2019-05-03 16:52:05 - INFO - TRAINING - Epoch: [132][100/500]	Time 0.025 (0.023)	Data 0.000 (0.002)	Loss 0.7008 (0.5471)	Prec@1 77.000 (81.851)	Prec@5 99.000 (99.109)
2019-05-03 16:52:06 - INFO - TRAINING - Epoch: [132][150/500]	Time 0.019 (0.021)	Data 0.000 (0.002)	Loss 0.4883 (0.5394)	Prec@1 83.000 (82.238)	Prec@5 100.000 (99.113)
2019-05-03 16:52:07 - INFO - TRAINING - Epoch: [132][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6323 (0.5412)	Prec@1 78.000 (82.164)	Prec@5 98.000 (99.085)
2019-05-03 16:52:08 - INFO - TRAINING - Epoch: [132][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6085 (0.5402)	Prec@1 79.000 (82.251)	Prec@5 100.000 (99.108)
2019-05-03 16:52:09 - INFO - TRAINING - Epoch: [132][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.6621 (0.5415)	Prec@1 81.000 (82.209)	Prec@5 97.000 (99.070)
2019-05-03 16:52:10 - INFO - TRAINING - Epoch: [132][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7218 (0.5413)	Prec@1 79.000 (82.154)	Prec@5 98.000 (99.085)
2019-05-03 16:52:11 - INFO - TRAINING - Epoch: [132][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.7425 (0.5428)	Prec@1 76.000 (82.100)	Prec@5 97.000 (99.072)
2019-05-03 16:52:12 - INFO - TRAINING - Epoch: [132][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5930 (0.5438)	Prec@1 75.000 (82.038)	Prec@5 100.000 (99.078)
2019-05-03 16:52:13 - INFO - EVALUATING - Epoch: [132][0/100]	Time 0.340 (0.340)	Data 0.334 (0.334)	Loss 0.6311 (0.6311)	Prec@1 76.000 (76.000)	Prec@5 98.000 (98.000)
2019-05-03 16:52:13 - INFO - EVALUATING - Epoch: [132][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.6197 (0.6550)	Prec@1 78.000 (78.549)	Prec@5 97.000 (98.373)
2019-05-03 16:52:14 - INFO - 
 Epoch: 133	Training Loss 0.5461 	Training Prec@1 81.974 	Training Prec@5 99.080 	Validation Loss 0.6351 	Validation Prec@1 78.770 	Validation Prec@5 98.650 	
2019-05-03 16:52:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:14 - INFO - TRAINING - Epoch: [133][0/500]	Time 0.281 (0.281)	Data 0.248 (0.248)	Loss 0.5213 (0.5213)	Prec@1 84.000 (84.000)	Prec@5 98.000 (98.000)
2019-05-03 16:52:15 - INFO - TRAINING - Epoch: [133][50/500]	Time 0.019 (0.026)	Data 0.000 (0.005)	Loss 0.5034 (0.5445)	Prec@1 81.000 (81.824)	Prec@5 100.000 (99.235)
2019-05-03 16:52:16 - INFO - TRAINING - Epoch: [133][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.5362 (0.5480)	Prec@1 84.000 (81.782)	Prec@5 100.000 (99.129)
2019-05-03 16:52:17 - INFO - TRAINING - Epoch: [133][150/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.4913 (0.5437)	Prec@1 88.000 (81.987)	Prec@5 98.000 (99.199)
2019-05-03 16:52:18 - INFO - TRAINING - Epoch: [133][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4118 (0.5460)	Prec@1 88.000 (81.861)	Prec@5 100.000 (99.154)
2019-05-03 16:52:19 - INFO - TRAINING - Epoch: [133][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6576 (0.5507)	Prec@1 78.000 (81.717)	Prec@5 97.000 (99.151)
2019-05-03 16:52:20 - INFO - TRAINING - Epoch: [133][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5463 (0.5492)	Prec@1 84.000 (81.711)	Prec@5 99.000 (99.163)
2019-05-03 16:52:21 - INFO - TRAINING - Epoch: [133][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4427 (0.5465)	Prec@1 87.000 (81.803)	Prec@5 100.000 (99.148)
2019-05-03 16:52:22 - INFO - TRAINING - Epoch: [133][400/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.4343 (0.5460)	Prec@1 84.000 (81.781)	Prec@5 100.000 (99.132)
2019-05-03 16:52:23 - INFO - TRAINING - Epoch: [133][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5175 (0.5430)	Prec@1 83.000 (81.914)	Prec@5 98.000 (99.111)
2019-05-03 16:52:24 - INFO - EVALUATING - Epoch: [133][0/100]	Time 0.359 (0.359)	Data 0.347 (0.347)	Loss 0.5798 (0.5798)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:52:24 - INFO - EVALUATING - Epoch: [133][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.4565 (0.6060)	Prec@1 88.000 (80.157)	Prec@5 98.000 (98.510)
2019-05-03 16:52:25 - INFO - 
 Epoch: 134	Training Loss 0.5402 	Training Prec@1 82.008 	Training Prec@5 99.116 	Validation Loss 0.6057 	Validation Prec@1 79.820 	Validation Prec@5 98.650 	
2019-05-03 16:52:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:25 - INFO - TRAINING - Epoch: [134][0/500]	Time 0.268 (0.268)	Data 0.239 (0.239)	Loss 0.6710 (0.6710)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:52:26 - INFO - TRAINING - Epoch: [134][50/500]	Time 0.028 (0.024)	Data 0.000 (0.005)	Loss 0.5465 (0.5256)	Prec@1 79.000 (82.059)	Prec@5 100.000 (99.176)
2019-05-03 16:52:27 - INFO - TRAINING - Epoch: [134][100/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.5739 (0.5266)	Prec@1 86.000 (82.436)	Prec@5 99.000 (99.119)
2019-05-03 16:52:28 - INFO - TRAINING - Epoch: [134][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.4927 (0.5264)	Prec@1 85.000 (82.483)	Prec@5 99.000 (99.119)
2019-05-03 16:52:29 - INFO - TRAINING - Epoch: [134][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6809 (0.5325)	Prec@1 73.000 (82.398)	Prec@5 99.000 (99.109)
2019-05-03 16:52:30 - INFO - TRAINING - Epoch: [134][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.6396 (0.5358)	Prec@1 82.000 (82.283)	Prec@5 99.000 (99.143)
2019-05-03 16:52:31 - INFO - TRAINING - Epoch: [134][300/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.5972 (0.5356)	Prec@1 81.000 (82.279)	Prec@5 100.000 (99.153)
2019-05-03 16:52:32 - INFO - TRAINING - Epoch: [134][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6591 (0.5400)	Prec@1 80.000 (82.174)	Prec@5 99.000 (99.128)
2019-05-03 16:52:33 - INFO - TRAINING - Epoch: [134][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.5863 (0.5413)	Prec@1 79.000 (82.107)	Prec@5 99.000 (99.077)
2019-05-03 16:52:34 - INFO - TRAINING - Epoch: [134][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.6359 (0.5370)	Prec@1 78.000 (82.220)	Prec@5 98.000 (99.106)
2019-05-03 16:52:35 - INFO - EVALUATING - Epoch: [134][0/100]	Time 0.330 (0.330)	Data 0.324 (0.324)	Loss 0.4168 (0.4168)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 16:52:36 - INFO - EVALUATING - Epoch: [134][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5147 (0.6024)	Prec@1 82.000 (80.647)	Prec@5 98.000 (98.824)
2019-05-03 16:52:36 - INFO - 
 Epoch: 135	Training Loss 0.5389 	Training Prec@1 82.110 	Training Prec@5 99.088 	Validation Loss 0.5945 	Validation Prec@1 80.430 	Validation Prec@5 98.890 	
2019-05-03 16:52:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:36 - INFO - TRAINING - Epoch: [135][0/500]	Time 0.265 (0.265)	Data 0.244 (0.244)	Loss 0.4145 (0.4145)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-03 16:52:37 - INFO - TRAINING - Epoch: [135][50/500]	Time 0.015 (0.023)	Data 0.000 (0.005)	Loss 0.5887 (0.5125)	Prec@1 76.000 (82.608)	Prec@5 98.000 (99.235)
2019-05-03 16:52:38 - INFO - TRAINING - Epoch: [135][100/500]	Time 0.016 (0.021)	Data 0.000 (0.003)	Loss 0.5032 (0.5243)	Prec@1 88.000 (82.782)	Prec@5 99.000 (99.109)
2019-05-03 16:52:39 - INFO - TRAINING - Epoch: [135][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.4851 (0.5321)	Prec@1 87.000 (82.623)	Prec@5 99.000 (99.066)
2019-05-03 16:52:40 - INFO - TRAINING - Epoch: [135][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4467 (0.5371)	Prec@1 83.000 (82.418)	Prec@5 100.000 (99.045)
2019-05-03 16:52:41 - INFO - TRAINING - Epoch: [135][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5376 (0.5369)	Prec@1 86.000 (82.287)	Prec@5 100.000 (99.104)
2019-05-03 16:52:42 - INFO - TRAINING - Epoch: [135][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.3735 (0.5440)	Prec@1 87.000 (82.073)	Prec@5 100.000 (99.070)
2019-05-03 16:52:43 - INFO - TRAINING - Epoch: [135][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.4334 (0.5425)	Prec@1 87.000 (82.037)	Prec@5 100.000 (99.100)
2019-05-03 16:52:44 - INFO - TRAINING - Epoch: [135][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.5558 (0.5419)	Prec@1 84.000 (82.027)	Prec@5 100.000 (99.092)
2019-05-03 16:52:45 - INFO - TRAINING - Epoch: [135][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5167 (0.5424)	Prec@1 81.000 (82.055)	Prec@5 99.000 (99.091)
2019-05-03 16:52:46 - INFO - EVALUATING - Epoch: [135][0/100]	Time 0.352 (0.352)	Data 0.340 (0.340)	Loss 0.5779 (0.5779)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:52:47 - INFO - EVALUATING - Epoch: [135][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.4771 (0.6410)	Prec@1 87.000 (78.824)	Prec@5 97.000 (98.608)
2019-05-03 16:52:47 - INFO - 
 Epoch: 136	Training Loss 0.5426 	Training Prec@1 82.004 	Training Prec@5 99.116 	Validation Loss 0.6318 	Validation Prec@1 79.220 	Validation Prec@5 98.730 	
2019-05-03 16:52:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:47 - INFO - TRAINING - Epoch: [136][0/500]	Time 0.279 (0.279)	Data 0.252 (0.252)	Loss 0.5310 (0.5310)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 16:52:48 - INFO - TRAINING - Epoch: [136][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.5171 (0.5596)	Prec@1 82.000 (81.490)	Prec@5 97.000 (99.255)
2019-05-03 16:52:49 - INFO - TRAINING - Epoch: [136][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.5804 (0.5437)	Prec@1 81.000 (81.921)	Prec@5 98.000 (99.158)
2019-05-03 16:52:50 - INFO - TRAINING - Epoch: [136][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.4470 (0.5487)	Prec@1 85.000 (81.589)	Prec@5 100.000 (99.172)
2019-05-03 16:52:51 - INFO - TRAINING - Epoch: [136][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5887 (0.5458)	Prec@1 83.000 (81.721)	Prec@5 99.000 (99.179)
2019-05-03 16:52:52 - INFO - TRAINING - Epoch: [136][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6536 (0.5456)	Prec@1 81.000 (81.693)	Prec@5 98.000 (99.167)
2019-05-03 16:52:53 - INFO - TRAINING - Epoch: [136][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5632 (0.5463)	Prec@1 83.000 (81.661)	Prec@5 98.000 (99.159)
2019-05-03 16:52:54 - INFO - TRAINING - Epoch: [136][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6807 (0.5426)	Prec@1 79.000 (81.738)	Prec@5 99.000 (99.179)
2019-05-03 16:52:55 - INFO - TRAINING - Epoch: [136][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5035 (0.5408)	Prec@1 80.000 (81.803)	Prec@5 100.000 (99.182)
2019-05-03 16:52:56 - INFO - TRAINING - Epoch: [136][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6184 (0.5431)	Prec@1 81.000 (81.783)	Prec@5 98.000 (99.175)
2019-05-03 16:52:58 - INFO - EVALUATING - Epoch: [136][0/100]	Time 0.342 (0.342)	Data 0.333 (0.333)	Loss 0.6119 (0.6119)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:52:58 - INFO - EVALUATING - Epoch: [136][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.4524 (0.6039)	Prec@1 91.000 (80.333)	Prec@5 97.000 (98.667)
2019-05-03 16:52:58 - INFO - 
 Epoch: 137	Training Loss 0.5401 	Training Prec@1 81.856 	Training Prec@5 99.174 	Validation Loss 0.6055 	Validation Prec@1 80.150 	Validation Prec@5 98.880 	
2019-05-03 16:52:58 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:52:58 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:52:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:52:58 - INFO - TRAINING - Epoch: [137][0/500]	Time 0.257 (0.257)	Data 0.239 (0.239)	Loss 0.4199 (0.4199)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:00 - INFO - TRAINING - Epoch: [137][50/500]	Time 0.018 (0.026)	Data 0.000 (0.005)	Loss 0.5245 (0.5484)	Prec@1 85.000 (81.706)	Prec@5 99.000 (99.157)
2019-05-03 16:53:01 - INFO - TRAINING - Epoch: [137][100/500]	Time 0.022 (0.024)	Data 0.000 (0.002)	Loss 0.2674 (0.5424)	Prec@1 94.000 (82.010)	Prec@5 100.000 (99.158)
2019-05-03 16:53:02 - INFO - TRAINING - Epoch: [137][150/500]	Time 0.035 (0.023)	Data 0.000 (0.002)	Loss 0.3529 (0.5441)	Prec@1 89.000 (81.894)	Prec@5 99.000 (99.119)
2019-05-03 16:53:03 - INFO - TRAINING - Epoch: [137][200/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.7044 (0.5408)	Prec@1 74.000 (81.980)	Prec@5 99.000 (99.144)
2019-05-03 16:53:03 - INFO - TRAINING - Epoch: [137][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4958 (0.5458)	Prec@1 85.000 (81.849)	Prec@5 100.000 (99.167)
2019-05-03 16:53:04 - INFO - TRAINING - Epoch: [137][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5191 (0.5428)	Prec@1 86.000 (81.947)	Prec@5 99.000 (99.186)
2019-05-03 16:53:05 - INFO - TRAINING - Epoch: [137][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5245 (0.5439)	Prec@1 84.000 (81.934)	Prec@5 100.000 (99.165)
2019-05-03 16:53:06 - INFO - TRAINING - Epoch: [137][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.4223 (0.5441)	Prec@1 85.000 (81.953)	Prec@5 100.000 (99.150)
2019-05-03 16:53:07 - INFO - TRAINING - Epoch: [137][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.6364 (0.5452)	Prec@1 78.000 (81.914)	Prec@5 99.000 (99.122)
2019-05-03 16:53:09 - INFO - EVALUATING - Epoch: [137][0/100]	Time 0.353 (0.353)	Data 0.342 (0.342)	Loss 0.6044 (0.6044)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:09 - INFO - EVALUATING - Epoch: [137][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.4883 (0.6128)	Prec@1 87.000 (80.078)	Prec@5 97.000 (98.863)
2019-05-03 16:53:09 - INFO - 
 Epoch: 138	Training Loss 0.5440 	Training Prec@1 81.920 	Training Prec@5 99.118 	Validation Loss 0.6120 	Validation Prec@1 79.970 	Validation Prec@5 98.970 	
2019-05-03 16:53:09 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:53:09 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:53:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:53:10 - INFO - TRAINING - Epoch: [138][0/500]	Time 0.262 (0.262)	Data 0.240 (0.240)	Loss 0.5550 (0.5550)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:53:11 - INFO - TRAINING - Epoch: [138][50/500]	Time 0.020 (0.026)	Data 0.000 (0.005)	Loss 0.4786 (0.5141)	Prec@1 85.000 (82.824)	Prec@5 98.000 (99.294)
2019-05-03 16:53:12 - INFO - TRAINING - Epoch: [138][100/500]	Time 0.020 (0.024)	Data 0.000 (0.003)	Loss 0.5980 (0.5266)	Prec@1 81.000 (82.386)	Prec@5 100.000 (99.149)
2019-05-03 16:53:13 - INFO - TRAINING - Epoch: [138][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.4929 (0.5291)	Prec@1 84.000 (82.417)	Prec@5 100.000 (99.139)
2019-05-03 16:53:14 - INFO - TRAINING - Epoch: [138][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5236 (0.5291)	Prec@1 82.000 (82.463)	Prec@5 100.000 (99.114)
2019-05-03 16:53:15 - INFO - TRAINING - Epoch: [138][250/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.6054 (0.5298)	Prec@1 81.000 (82.255)	Prec@5 99.000 (99.159)
2019-05-03 16:53:16 - INFO - TRAINING - Epoch: [138][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4767 (0.5322)	Prec@1 86.000 (82.259)	Prec@5 98.000 (99.133)
2019-05-03 16:53:17 - INFO - TRAINING - Epoch: [138][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5533 (0.5320)	Prec@1 79.000 (82.254)	Prec@5 100.000 (99.134)
2019-05-03 16:53:18 - INFO - TRAINING - Epoch: [138][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4093 (0.5340)	Prec@1 85.000 (82.197)	Prec@5 100.000 (99.130)
2019-05-03 16:53:19 - INFO - TRAINING - Epoch: [138][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6077 (0.5346)	Prec@1 76.000 (82.177)	Prec@5 100.000 (99.135)
2019-05-03 16:53:20 - INFO - EVALUATING - Epoch: [138][0/100]	Time 0.371 (0.371)	Data 0.359 (0.359)	Loss 0.5413 (0.5413)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:20 - INFO - EVALUATING - Epoch: [138][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.5626 (0.6152)	Prec@1 84.000 (79.686)	Prec@5 97.000 (98.608)
2019-05-03 16:53:21 - INFO - 
 Epoch: 139	Training Loss 0.5391 	Training Prec@1 81.996 	Training Prec@5 99.140 	Validation Loss 0.6119 	Validation Prec@1 79.740 	Validation Prec@5 98.870 	
2019-05-03 16:53:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:53:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:53:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:53:21 - INFO - TRAINING - Epoch: [139][0/500]	Time 0.295 (0.295)	Data 0.266 (0.266)	Loss 0.5695 (0.5695)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:53:22 - INFO - TRAINING - Epoch: [139][50/500]	Time 0.016 (0.027)	Data 0.000 (0.005)	Loss 0.4572 (0.5276)	Prec@1 88.000 (83.020)	Prec@5 99.000 (99.196)
2019-05-03 16:53:23 - INFO - TRAINING - Epoch: [139][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.5761 (0.5253)	Prec@1 82.000 (82.772)	Prec@5 100.000 (99.218)
2019-05-03 16:53:24 - INFO - TRAINING - Epoch: [139][150/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.6207 (0.5385)	Prec@1 81.000 (82.212)	Prec@5 96.000 (99.192)
2019-05-03 16:53:25 - INFO - TRAINING - Epoch: [139][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4681 (0.5421)	Prec@1 81.000 (82.000)	Prec@5 99.000 (99.144)
2019-05-03 16:53:26 - INFO - TRAINING - Epoch: [139][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5863 (0.5417)	Prec@1 78.000 (82.052)	Prec@5 99.000 (99.116)
2019-05-03 16:53:27 - INFO - TRAINING - Epoch: [139][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5696 (0.5378)	Prec@1 79.000 (82.246)	Prec@5 99.000 (99.153)
2019-05-03 16:53:28 - INFO - TRAINING - Epoch: [139][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4096 (0.5310)	Prec@1 84.000 (82.439)	Prec@5 100.000 (99.191)
2019-05-03 16:53:29 - INFO - TRAINING - Epoch: [139][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4950 (0.5317)	Prec@1 83.000 (82.344)	Prec@5 100.000 (99.214)
2019-05-03 16:53:30 - INFO - TRAINING - Epoch: [139][450/500]	Time 0.033 (0.021)	Data 0.000 (0.001)	Loss 0.5339 (0.5349)	Prec@1 87.000 (82.255)	Prec@5 98.000 (99.162)
2019-05-03 16:53:32 - INFO - EVALUATING - Epoch: [139][0/100]	Time 0.331 (0.331)	Data 0.317 (0.317)	Loss 0.7406 (0.7406)	Prec@1 73.000 (73.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:32 - INFO - EVALUATING - Epoch: [139][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5681 (0.6159)	Prec@1 81.000 (79.804)	Prec@5 98.000 (98.608)
2019-05-03 16:53:32 - INFO - 
 Epoch: 140	Training Loss 0.5349 	Training Prec@1 82.254 	Training Prec@5 99.144 	Validation Loss 0.6072 	Validation Prec@1 79.550 	Validation Prec@5 98.820 	
2019-05-03 16:53:32 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:53:32 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:53:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:53:33 - INFO - TRAINING - Epoch: [140][0/500]	Time 0.266 (0.266)	Data 0.244 (0.244)	Loss 0.5146 (0.5146)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:34 - INFO - TRAINING - Epoch: [140][50/500]	Time 0.015 (0.025)	Data 0.000 (0.005)	Loss 0.5469 (0.5298)	Prec@1 83.000 (82.176)	Prec@5 99.000 (99.333)
2019-05-03 16:53:35 - INFO - TRAINING - Epoch: [140][100/500]	Time 0.021 (0.021)	Data 0.000 (0.003)	Loss 0.4503 (0.5273)	Prec@1 89.000 (82.109)	Prec@5 98.000 (99.307)
2019-05-03 16:53:35 - INFO - TRAINING - Epoch: [140][150/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.6513 (0.5270)	Prec@1 79.000 (82.225)	Prec@5 99.000 (99.258)
2019-05-03 16:53:36 - INFO - TRAINING - Epoch: [140][200/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5275 (0.5363)	Prec@1 81.000 (81.985)	Prec@5 99.000 (99.209)
2019-05-03 16:53:37 - INFO - TRAINING - Epoch: [140][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5480 (0.5352)	Prec@1 82.000 (81.944)	Prec@5 100.000 (99.223)
2019-05-03 16:53:38 - INFO - TRAINING - Epoch: [140][300/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.3896 (0.5334)	Prec@1 89.000 (82.030)	Prec@5 99.000 (99.219)
2019-05-03 16:53:39 - INFO - TRAINING - Epoch: [140][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5819 (0.5343)	Prec@1 81.000 (82.043)	Prec@5 100.000 (99.217)
2019-05-03 16:53:40 - INFO - TRAINING - Epoch: [140][400/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.5131 (0.5392)	Prec@1 85.000 (81.940)	Prec@5 100.000 (99.175)
2019-05-03 16:53:41 - INFO - TRAINING - Epoch: [140][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5041 (0.5389)	Prec@1 80.000 (81.965)	Prec@5 100.000 (99.151)
2019-05-03 16:53:43 - INFO - EVALUATING - Epoch: [140][0/100]	Time 0.322 (0.322)	Data 0.311 (0.311)	Loss 0.6102 (0.6102)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:53:43 - INFO - EVALUATING - Epoch: [140][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.5506 (0.6280)	Prec@1 85.000 (79.471)	Prec@5 97.000 (98.510)
2019-05-03 16:53:43 - INFO - 
 Epoch: 141	Training Loss 0.5401 	Training Prec@1 81.946 	Training Prec@5 99.140 	Validation Loss 0.6287 	Validation Prec@1 79.550 	Validation Prec@5 98.660 	
2019-05-03 16:53:43 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:53:43 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:53:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:53:44 - INFO - TRAINING - Epoch: [141][0/500]	Time 0.266 (0.266)	Data 0.238 (0.238)	Loss 0.6113 (0.6113)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:53:45 - INFO - TRAINING - Epoch: [141][50/500]	Time 0.013 (0.023)	Data 0.000 (0.005)	Loss 0.5284 (0.5278)	Prec@1 84.000 (82.275)	Prec@5 99.000 (99.078)
2019-05-03 16:53:46 - INFO - TRAINING - Epoch: [141][100/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.3902 (0.5297)	Prec@1 85.000 (82.307)	Prec@5 100.000 (99.139)
2019-05-03 16:53:47 - INFO - TRAINING - Epoch: [141][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.5864 (0.5266)	Prec@1 82.000 (82.404)	Prec@5 98.000 (99.132)
2019-05-03 16:53:48 - INFO - TRAINING - Epoch: [141][200/500]	Time 0.014 (0.022)	Data 0.000 (0.001)	Loss 0.4472 (0.5315)	Prec@1 86.000 (82.294)	Prec@5 100.000 (99.100)
2019-05-03 16:53:49 - INFO - TRAINING - Epoch: [141][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5350 (0.5340)	Prec@1 82.000 (82.235)	Prec@5 100.000 (99.159)
2019-05-03 16:53:50 - INFO - TRAINING - Epoch: [141][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.6824 (0.5360)	Prec@1 79.000 (82.209)	Prec@5 100.000 (99.146)
2019-05-03 16:53:51 - INFO - TRAINING - Epoch: [141][350/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6360 (0.5372)	Prec@1 81.000 (82.248)	Prec@5 100.000 (99.154)
2019-05-03 16:53:52 - INFO - TRAINING - Epoch: [141][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.3457 (0.5371)	Prec@1 88.000 (82.232)	Prec@5 99.000 (99.157)
2019-05-03 16:53:53 - INFO - TRAINING - Epoch: [141][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4001 (0.5360)	Prec@1 89.000 (82.237)	Prec@5 100.000 (99.175)
2019-05-03 16:53:54 - INFO - EVALUATING - Epoch: [141][0/100]	Time 0.345 (0.345)	Data 0.331 (0.331)	Loss 0.6758 (0.6758)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:53:54 - INFO - EVALUATING - Epoch: [141][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.6166 (0.7028)	Prec@1 86.000 (77.078)	Prec@5 96.000 (98.490)
2019-05-03 16:53:55 - INFO - 
 Epoch: 142	Training Loss 0.5359 	Training Prec@1 82.202 	Training Prec@5 99.170 	Validation Loss 0.7032 	Validation Prec@1 77.070 	Validation Prec@5 98.630 	
2019-05-03 16:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:53:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:53:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:53:55 - INFO - TRAINING - Epoch: [142][0/500]	Time 0.255 (0.255)	Data 0.222 (0.222)	Loss 0.4906 (0.4906)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:53:56 - INFO - TRAINING - Epoch: [142][50/500]	Time 0.017 (0.024)	Data 0.000 (0.004)	Loss 0.4521 (0.5395)	Prec@1 83.000 (82.196)	Prec@5 100.000 (98.961)
2019-05-03 16:53:57 - INFO - TRAINING - Epoch: [142][100/500]	Time 0.019 (0.023)	Data 0.000 (0.002)	Loss 0.4754 (0.5421)	Prec@1 85.000 (82.158)	Prec@5 99.000 (99.020)
2019-05-03 16:53:58 - INFO - TRAINING - Epoch: [142][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.4638 (0.5294)	Prec@1 86.000 (82.609)	Prec@5 99.000 (99.079)
2019-05-03 16:53:59 - INFO - TRAINING - Epoch: [142][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5795 (0.5310)	Prec@1 82.000 (82.458)	Prec@5 97.000 (99.109)
2019-05-03 16:54:00 - INFO - TRAINING - Epoch: [142][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.4505 (0.5334)	Prec@1 84.000 (82.351)	Prec@5 100.000 (99.120)
2019-05-03 16:54:01 - INFO - TRAINING - Epoch: [142][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5864 (0.5325)	Prec@1 78.000 (82.362)	Prec@5 99.000 (99.120)
2019-05-03 16:54:02 - INFO - TRAINING - Epoch: [142][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5264 (0.5319)	Prec@1 84.000 (82.359)	Prec@5 98.000 (99.114)
2019-05-03 16:54:03 - INFO - TRAINING - Epoch: [142][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.3675 (0.5345)	Prec@1 88.000 (82.289)	Prec@5 100.000 (99.087)
2019-05-03 16:54:04 - INFO - TRAINING - Epoch: [142][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.3721 (0.5336)	Prec@1 90.000 (82.262)	Prec@5 100.000 (99.078)
2019-05-03 16:54:05 - INFO - EVALUATING - Epoch: [142][0/100]	Time 0.327 (0.327)	Data 0.313 (0.313)	Loss 0.5747 (0.5747)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:54:06 - INFO - EVALUATING - Epoch: [142][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5630 (0.6189)	Prec@1 83.000 (80.725)	Prec@5 97.000 (98.627)
2019-05-03 16:54:06 - INFO - 
 Epoch: 143	Training Loss 0.5342 	Training Prec@1 82.242 	Training Prec@5 99.078 	Validation Loss 0.6172 	Validation Prec@1 80.250 	Validation Prec@5 98.810 	
2019-05-03 16:54:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:54:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:54:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:54:06 - INFO - TRAINING - Epoch: [143][0/500]	Time 0.278 (0.278)	Data 0.253 (0.253)	Loss 0.4571 (0.4571)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:54:07 - INFO - TRAINING - Epoch: [143][50/500]	Time 0.016 (0.024)	Data 0.000 (0.005)	Loss 0.5129 (0.5230)	Prec@1 80.000 (82.882)	Prec@5 100.000 (98.961)
2019-05-03 16:54:08 - INFO - TRAINING - Epoch: [143][100/500]	Time 0.022 (0.022)	Data 0.000 (0.003)	Loss 0.5757 (0.5341)	Prec@1 78.000 (82.297)	Prec@5 100.000 (99.099)
2019-05-03 16:54:09 - INFO - TRAINING - Epoch: [143][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.5997 (0.5360)	Prec@1 79.000 (82.219)	Prec@5 99.000 (99.099)
2019-05-03 16:54:10 - INFO - TRAINING - Epoch: [143][200/500]	Time 0.013 (0.022)	Data 0.000 (0.001)	Loss 0.5254 (0.5351)	Prec@1 81.000 (82.244)	Prec@5 98.000 (99.065)
2019-05-03 16:54:11 - INFO - TRAINING - Epoch: [143][250/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.5334 (0.5354)	Prec@1 81.000 (82.131)	Prec@5 100.000 (99.092)
2019-05-03 16:54:12 - INFO - TRAINING - Epoch: [143][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5500 (0.5305)	Prec@1 78.000 (82.302)	Prec@5 100.000 (99.103)
2019-05-03 16:54:13 - INFO - TRAINING - Epoch: [143][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7123 (0.5283)	Prec@1 78.000 (82.370)	Prec@5 96.000 (99.111)
2019-05-03 16:54:14 - INFO - TRAINING - Epoch: [143][400/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5021 (0.5305)	Prec@1 82.000 (82.282)	Prec@5 99.000 (99.110)
2019-05-03 16:54:15 - INFO - TRAINING - Epoch: [143][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4821 (0.5324)	Prec@1 81.000 (82.242)	Prec@5 100.000 (99.111)
2019-05-03 16:54:16 - INFO - EVALUATING - Epoch: [143][0/100]	Time 0.339 (0.339)	Data 0.326 (0.326)	Loss 0.5918 (0.5918)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:54:17 - INFO - EVALUATING - Epoch: [143][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5386 (0.6282)	Prec@1 82.000 (79.882)	Prec@5 98.000 (98.863)
2019-05-03 16:54:17 - INFO - 
 Epoch: 144	Training Loss 0.5332 	Training Prec@1 82.180 	Training Prec@5 99.126 	Validation Loss 0.6230 	Validation Prec@1 79.780 	Validation Prec@5 98.950 	
2019-05-03 16:54:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:54:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:54:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:54:17 - INFO - TRAINING - Epoch: [144][0/500]	Time 0.269 (0.269)	Data 0.232 (0.232)	Loss 0.5611 (0.5611)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:54:18 - INFO - TRAINING - Epoch: [144][50/500]	Time 0.029 (0.025)	Data 0.000 (0.005)	Loss 0.4656 (0.5288)	Prec@1 83.000 (82.941)	Prec@5 100.000 (99.176)
2019-05-03 16:54:19 - INFO - TRAINING - Epoch: [144][100/500]	Time 0.028 (0.022)	Data 0.000 (0.002)	Loss 0.5935 (0.5332)	Prec@1 79.000 (82.446)	Prec@5 99.000 (99.158)
2019-05-03 16:54:21 - INFO - TRAINING - Epoch: [144][150/500]	Time 0.022 (0.022)	Data 0.000 (0.002)	Loss 0.6037 (0.5314)	Prec@1 75.000 (82.311)	Prec@5 99.000 (99.199)
2019-05-03 16:54:22 - INFO - TRAINING - Epoch: [144][200/500]	Time 0.022 (0.022)	Data 0.000 (0.001)	Loss 0.4336 (0.5341)	Prec@1 85.000 (82.234)	Prec@5 99.000 (99.174)
2019-05-03 16:54:23 - INFO - TRAINING - Epoch: [144][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5718 (0.5336)	Prec@1 77.000 (82.135)	Prec@5 100.000 (99.139)
2019-05-03 16:54:24 - INFO - TRAINING - Epoch: [144][300/500]	Time 0.029 (0.022)	Data 0.000 (0.001)	Loss 0.3747 (0.5322)	Prec@1 92.000 (82.233)	Prec@5 100.000 (99.173)
2019-05-03 16:54:25 - INFO - TRAINING - Epoch: [144][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.5130 (0.5374)	Prec@1 84.000 (82.068)	Prec@5 99.000 (99.157)
2019-05-03 16:54:26 - INFO - TRAINING - Epoch: [144][400/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.3695 (0.5385)	Prec@1 88.000 (82.065)	Prec@5 100.000 (99.155)
2019-05-03 16:54:27 - INFO - TRAINING - Epoch: [144][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6955 (0.5385)	Prec@1 79.000 (82.069)	Prec@5 99.000 (99.146)
2019-05-03 16:54:28 - INFO - EVALUATING - Epoch: [144][0/100]	Time 0.354 (0.354)	Data 0.346 (0.346)	Loss 0.5395 (0.5395)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:54:28 - INFO - EVALUATING - Epoch: [144][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6038 (0.6362)	Prec@1 80.000 (79.392)	Prec@5 97.000 (98.745)
2019-05-03 16:54:29 - INFO - 
 Epoch: 145	Training Loss 0.5375 	Training Prec@1 82.066 	Training Prec@5 99.160 	Validation Loss 0.6286 	Validation Prec@1 79.500 	Validation Prec@5 98.910 	
2019-05-03 16:54:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:54:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:54:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:54:29 - INFO - TRAINING - Epoch: [145][0/500]	Time 0.288 (0.288)	Data 0.264 (0.264)	Loss 0.7812 (0.7812)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 16:54:30 - INFO - TRAINING - Epoch: [145][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.5621 (0.5356)	Prec@1 80.000 (82.588)	Prec@5 100.000 (99.137)
2019-05-03 16:54:31 - INFO - TRAINING - Epoch: [145][100/500]	Time 0.016 (0.023)	Data 0.000 (0.003)	Loss 0.5450 (0.5441)	Prec@1 79.000 (82.000)	Prec@5 98.000 (99.079)
2019-05-03 16:54:32 - INFO - TRAINING - Epoch: [145][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.5807 (0.5378)	Prec@1 80.000 (82.046)	Prec@5 100.000 (99.152)
2019-05-03 16:54:33 - INFO - TRAINING - Epoch: [145][200/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.6134 (0.5385)	Prec@1 79.000 (82.194)	Prec@5 98.000 (99.139)
2019-05-03 16:54:34 - INFO - TRAINING - Epoch: [145][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5248 (0.5343)	Prec@1 82.000 (82.355)	Prec@5 97.000 (99.151)
2019-05-03 16:54:35 - INFO - TRAINING - Epoch: [145][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5678 (0.5343)	Prec@1 81.000 (82.326)	Prec@5 99.000 (99.159)
2019-05-03 16:54:36 - INFO - TRAINING - Epoch: [145][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5352 (0.5331)	Prec@1 82.000 (82.370)	Prec@5 98.000 (99.177)
2019-05-03 16:54:37 - INFO - TRAINING - Epoch: [145][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7420 (0.5369)	Prec@1 76.000 (82.172)	Prec@5 99.000 (99.162)
2019-05-03 16:54:38 - INFO - TRAINING - Epoch: [145][450/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6062 (0.5363)	Prec@1 78.000 (82.175)	Prec@5 100.000 (99.166)
2019-05-03 16:54:39 - INFO - EVALUATING - Epoch: [145][0/100]	Time 0.337 (0.337)	Data 0.325 (0.325)	Loss 0.7175 (0.7175)	Prec@1 74.000 (74.000)	Prec@5 98.000 (98.000)
2019-05-03 16:54:40 - INFO - EVALUATING - Epoch: [145][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.6090 (0.6321)	Prec@1 81.000 (79.118)	Prec@5 97.000 (98.647)
2019-05-03 16:54:40 - INFO - 
 Epoch: 146	Training Loss 0.5379 	Training Prec@1 82.134 	Training Prec@5 99.136 	Validation Loss 0.6271 	Validation Prec@1 79.080 	Validation Prec@5 98.780 	
2019-05-03 16:54:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:54:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:54:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:54:40 - INFO - TRAINING - Epoch: [146][0/500]	Time 0.262 (0.262)	Data 0.240 (0.240)	Loss 0.4123 (0.4123)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 16:54:41 - INFO - TRAINING - Epoch: [146][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.6608 (0.5385)	Prec@1 77.000 (81.882)	Prec@5 97.000 (99.118)
2019-05-03 16:54:42 - INFO - TRAINING - Epoch: [146][100/500]	Time 0.026 (0.023)	Data 0.000 (0.002)	Loss 0.5558 (0.5422)	Prec@1 80.000 (81.752)	Prec@5 99.000 (99.079)
2019-05-03 16:54:43 - INFO - TRAINING - Epoch: [146][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.5501 (0.5355)	Prec@1 83.000 (82.099)	Prec@5 99.000 (99.099)
2019-05-03 16:54:44 - INFO - TRAINING - Epoch: [146][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.3218 (0.5327)	Prec@1 90.000 (82.303)	Prec@5 100.000 (99.134)
2019-05-03 16:54:45 - INFO - TRAINING - Epoch: [146][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5082 (0.5294)	Prec@1 79.000 (82.394)	Prec@5 99.000 (99.120)
2019-05-03 16:54:46 - INFO - TRAINING - Epoch: [146][300/500]	Time 0.011 (0.020)	Data 0.000 (0.001)	Loss 0.4941 (0.5320)	Prec@1 84.000 (82.336)	Prec@5 98.000 (99.153)
2019-05-03 16:54:47 - INFO - TRAINING - Epoch: [146][350/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.4746 (0.5320)	Prec@1 81.000 (82.293)	Prec@5 99.000 (99.171)
2019-05-03 16:54:48 - INFO - TRAINING - Epoch: [146][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5851 (0.5309)	Prec@1 83.000 (82.289)	Prec@5 99.000 (99.192)
2019-05-03 16:54:49 - INFO - TRAINING - Epoch: [146][450/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.5822 (0.5303)	Prec@1 82.000 (82.310)	Prec@5 99.000 (99.202)
2019-05-03 16:54:50 - INFO - EVALUATING - Epoch: [146][0/100]	Time 0.311 (0.311)	Data 0.303 (0.303)	Loss 0.4961 (0.4961)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 16:54:51 - INFO - EVALUATING - Epoch: [146][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.6634 (0.6212)	Prec@1 78.000 (79.863)	Prec@5 98.000 (98.765)
2019-05-03 16:54:51 - INFO - 
 Epoch: 147	Training Loss 0.5308 	Training Prec@1 82.280 	Training Prec@5 99.188 	Validation Loss 0.6149 	Validation Prec@1 79.890 	Validation Prec@5 98.910 	
2019-05-03 16:54:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:54:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:54:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:54:51 - INFO - TRAINING - Epoch: [147][0/500]	Time 0.285 (0.285)	Data 0.255 (0.255)	Loss 0.4465 (0.4465)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 16:54:52 - INFO - TRAINING - Epoch: [147][50/500]	Time 0.016 (0.024)	Data 0.000 (0.005)	Loss 0.6106 (0.5341)	Prec@1 83.000 (82.196)	Prec@5 98.000 (98.961)
2019-05-03 16:54:53 - INFO - TRAINING - Epoch: [147][100/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.5854 (0.5334)	Prec@1 80.000 (82.069)	Prec@5 100.000 (99.099)
2019-05-03 16:54:54 - INFO - TRAINING - Epoch: [147][150/500]	Time 0.025 (0.021)	Data 0.000 (0.002)	Loss 0.5999 (0.5366)	Prec@1 76.000 (82.060)	Prec@5 98.000 (99.040)
2019-05-03 16:54:55 - INFO - TRAINING - Epoch: [147][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6564 (0.5389)	Prec@1 77.000 (81.940)	Prec@5 99.000 (99.080)
2019-05-03 16:54:56 - INFO - TRAINING - Epoch: [147][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5820 (0.5372)	Prec@1 79.000 (82.143)	Prec@5 100.000 (99.088)
2019-05-03 16:54:57 - INFO - TRAINING - Epoch: [147][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5400 (0.5373)	Prec@1 84.000 (82.063)	Prec@5 99.000 (99.070)
2019-05-03 16:54:58 - INFO - TRAINING - Epoch: [147][350/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5749 (0.5377)	Prec@1 78.000 (82.077)	Prec@5 100.000 (99.094)
2019-05-03 16:54:59 - INFO - TRAINING - Epoch: [147][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6725 (0.5376)	Prec@1 78.000 (82.105)	Prec@5 99.000 (99.102)
2019-05-03 16:55:00 - INFO - TRAINING - Epoch: [147][450/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.4464 (0.5356)	Prec@1 83.000 (82.169)	Prec@5 100.000 (99.133)
2019-05-03 16:55:01 - INFO - EVALUATING - Epoch: [147][0/100]	Time 0.257 (0.257)	Data 0.248 (0.248)	Loss 0.6287 (0.6287)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:02 - INFO - EVALUATING - Epoch: [147][50/100]	Time 0.007 (0.011)	Data 0.000 (0.005)	Loss 0.5960 (0.6316)	Prec@1 84.000 (79.627)	Prec@5 98.000 (98.706)
2019-05-03 16:55:02 - INFO - 
 Epoch: 148	Training Loss 0.5363 	Training Prec@1 82.186 	Training Prec@5 99.122 	Validation Loss 0.6302 	Validation Prec@1 79.360 	Validation Prec@5 98.850 	
2019-05-03 16:55:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:02 - INFO - TRAINING - Epoch: [148][0/500]	Time 0.270 (0.270)	Data 0.243 (0.243)	Loss 0.5145 (0.5145)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:55:03 - INFO - TRAINING - Epoch: [148][50/500]	Time 0.019 (0.026)	Data 0.000 (0.005)	Loss 0.7161 (0.5311)	Prec@1 77.000 (81.725)	Prec@5 96.000 (98.961)
2019-05-03 16:55:05 - INFO - TRAINING - Epoch: [148][100/500]	Time 0.024 (0.024)	Data 0.000 (0.003)	Loss 0.5639 (0.5241)	Prec@1 77.000 (82.564)	Prec@5 100.000 (99.079)
2019-05-03 16:55:05 - INFO - TRAINING - Epoch: [148][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.6195 (0.5203)	Prec@1 83.000 (82.536)	Prec@5 99.000 (99.146)
2019-05-03 16:55:07 - INFO - TRAINING - Epoch: [148][200/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.3499 (0.5300)	Prec@1 91.000 (82.363)	Prec@5 100.000 (99.134)
2019-05-03 16:55:08 - INFO - TRAINING - Epoch: [148][250/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4611 (0.5337)	Prec@1 87.000 (82.279)	Prec@5 99.000 (99.080)
2019-05-03 16:55:08 - INFO - TRAINING - Epoch: [148][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6280 (0.5341)	Prec@1 81.000 (82.193)	Prec@5 99.000 (99.076)
2019-05-03 16:55:09 - INFO - TRAINING - Epoch: [148][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4933 (0.5354)	Prec@1 80.000 (82.228)	Prec@5 100.000 (99.071)
2019-05-03 16:55:10 - INFO - TRAINING - Epoch: [148][400/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6814 (0.5341)	Prec@1 80.000 (82.239)	Prec@5 97.000 (99.087)
2019-05-03 16:55:11 - INFO - TRAINING - Epoch: [148][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5019 (0.5339)	Prec@1 80.000 (82.215)	Prec@5 100.000 (99.106)
2019-05-03 16:55:13 - INFO - EVALUATING - Epoch: [148][0/100]	Time 0.330 (0.330)	Data 0.320 (0.320)	Loss 0.6285 (0.6285)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-05-03 16:55:13 - INFO - EVALUATING - Epoch: [148][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5294 (0.6651)	Prec@1 85.000 (78.627)	Prec@5 97.000 (98.412)
2019-05-03 16:55:13 - INFO - 
 Epoch: 149	Training Loss 0.5335 	Training Prec@1 82.290 	Training Prec@5 99.108 	Validation Loss 0.6531 	Validation Prec@1 78.480 	Validation Prec@5 98.660 	
2019-05-03 16:55:13 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:13 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:14 - INFO - TRAINING - Epoch: [149][0/500]	Time 0.246 (0.246)	Data 0.226 (0.226)	Loss 0.6539 (0.6539)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:15 - INFO - TRAINING - Epoch: [149][50/500]	Time 0.030 (0.024)	Data 0.000 (0.005)	Loss 0.6049 (0.5221)	Prec@1 83.000 (82.255)	Prec@5 100.000 (99.098)
2019-05-03 16:55:16 - INFO - TRAINING - Epoch: [149][100/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.4258 (0.5213)	Prec@1 85.000 (82.505)	Prec@5 99.000 (99.168)
2019-05-03 16:55:16 - INFO - TRAINING - Epoch: [149][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.5546 (0.5231)	Prec@1 78.000 (82.424)	Prec@5 99.000 (99.185)
2019-05-03 16:55:17 - INFO - TRAINING - Epoch: [149][200/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4779 (0.5199)	Prec@1 80.000 (82.607)	Prec@5 100.000 (99.179)
2019-05-03 16:55:18 - INFO - TRAINING - Epoch: [149][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6500 (0.5251)	Prec@1 81.000 (82.335)	Prec@5 98.000 (99.195)
2019-05-03 16:55:19 - INFO - TRAINING - Epoch: [149][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.4640 (0.5281)	Prec@1 88.000 (82.226)	Prec@5 98.000 (99.186)
2019-05-03 16:55:21 - INFO - TRAINING - Epoch: [149][350/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4426 (0.5294)	Prec@1 85.000 (82.214)	Prec@5 100.000 (99.168)
2019-05-03 16:55:22 - INFO - TRAINING - Epoch: [149][400/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.5521 (0.5285)	Prec@1 80.000 (82.252)	Prec@5 100.000 (99.175)
2019-05-03 16:55:22 - INFO - TRAINING - Epoch: [149][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5295 (0.5305)	Prec@1 80.000 (82.206)	Prec@5 100.000 (99.160)
2019-05-03 16:55:24 - INFO - EVALUATING - Epoch: [149][0/100]	Time 0.350 (0.350)	Data 0.338 (0.338)	Loss 0.6431 (0.6431)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:24 - INFO - EVALUATING - Epoch: [149][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.5949 (0.6755)	Prec@1 83.000 (78.275)	Prec@5 97.000 (98.627)
2019-05-03 16:55:24 - INFO - 
 Epoch: 150	Training Loss 0.5321 	Training Prec@1 82.194 	Training Prec@5 99.144 	Validation Loss 0.6562 	Validation Prec@1 78.710 	Validation Prec@5 98.790 	
2019-05-03 16:55:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:25 - INFO - TRAINING - Epoch: [150][0/500]	Time 0.288 (0.288)	Data 0.263 (0.263)	Loss 0.7386 (0.7386)	Prec@1 75.000 (75.000)	Prec@5 98.000 (98.000)
2019-05-03 16:55:26 - INFO - TRAINING - Epoch: [150][50/500]	Time 0.025 (0.024)	Data 0.000 (0.005)	Loss 0.5039 (0.5514)	Prec@1 84.000 (81.725)	Prec@5 100.000 (99.157)
2019-05-03 16:55:27 - INFO - TRAINING - Epoch: [150][100/500]	Time 0.015 (0.023)	Data 0.000 (0.003)	Loss 0.6777 (0.5387)	Prec@1 77.000 (82.158)	Prec@5 100.000 (99.168)
2019-05-03 16:55:28 - INFO - TRAINING - Epoch: [150][150/500]	Time 0.016 (0.022)	Data 0.000 (0.002)	Loss 0.6457 (0.5313)	Prec@1 79.000 (82.417)	Prec@5 99.000 (99.132)
2019-05-03 16:55:29 - INFO - TRAINING - Epoch: [150][200/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5570 (0.5283)	Prec@1 82.000 (82.567)	Prec@5 99.000 (99.159)
2019-05-03 16:55:30 - INFO - TRAINING - Epoch: [150][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4897 (0.5345)	Prec@1 85.000 (82.554)	Prec@5 98.000 (99.120)
2019-05-03 16:55:31 - INFO - TRAINING - Epoch: [150][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4098 (0.5302)	Prec@1 84.000 (82.681)	Prec@5 99.000 (99.146)
2019-05-03 16:55:32 - INFO - TRAINING - Epoch: [150][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6328 (0.5335)	Prec@1 78.000 (82.541)	Prec@5 99.000 (99.131)
2019-05-03 16:55:33 - INFO - TRAINING - Epoch: [150][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5416 (0.5330)	Prec@1 79.000 (82.434)	Prec@5 100.000 (99.167)
2019-05-03 16:55:34 - INFO - TRAINING - Epoch: [150][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5251 (0.5300)	Prec@1 84.000 (82.559)	Prec@5 98.000 (99.173)
2019-05-03 16:55:35 - INFO - EVALUATING - Epoch: [150][0/100]	Time 0.341 (0.341)	Data 0.334 (0.334)	Loss 0.5389 (0.5389)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:35 - INFO - EVALUATING - Epoch: [150][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.4892 (0.5956)	Prec@1 89.000 (80.902)	Prec@5 96.000 (98.804)
2019-05-03 16:55:36 - INFO - 
 Epoch: 151	Training Loss 0.5324 	Training Prec@1 82.448 	Training Prec@5 99.156 	Validation Loss 0.5964 	Validation Prec@1 80.580 	Validation Prec@5 99.000 	
2019-05-03 16:55:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:36 - INFO - TRAINING - Epoch: [151][0/500]	Time 0.280 (0.280)	Data 0.256 (0.256)	Loss 0.4292 (0.4292)	Prec@1 88.000 (88.000)	Prec@5 100.000 (100.000)
2019-05-03 16:55:37 - INFO - TRAINING - Epoch: [151][50/500]	Time 0.019 (0.027)	Data 0.000 (0.005)	Loss 0.5280 (0.5265)	Prec@1 83.000 (82.667)	Prec@5 98.000 (99.137)
2019-05-03 16:55:38 - INFO - TRAINING - Epoch: [151][100/500]	Time 0.021 (0.024)	Data 0.000 (0.003)	Loss 0.4712 (0.5252)	Prec@1 85.000 (82.802)	Prec@5 100.000 (99.050)
2019-05-03 16:55:39 - INFO - TRAINING - Epoch: [151][150/500]	Time 0.021 (0.023)	Data 0.000 (0.002)	Loss 0.5902 (0.5260)	Prec@1 81.000 (82.795)	Prec@5 99.000 (99.146)
2019-05-03 16:55:40 - INFO - TRAINING - Epoch: [151][200/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.6500 (0.5320)	Prec@1 78.000 (82.522)	Prec@5 100.000 (99.169)
2019-05-03 16:55:41 - INFO - TRAINING - Epoch: [151][250/500]	Time 0.029 (0.022)	Data 0.000 (0.001)	Loss 0.4063 (0.5317)	Prec@1 86.000 (82.434)	Prec@5 99.000 (99.139)
2019-05-03 16:55:42 - INFO - TRAINING - Epoch: [151][300/500]	Time 0.021 (0.022)	Data 0.000 (0.001)	Loss 0.3633 (0.5311)	Prec@1 90.000 (82.538)	Prec@5 99.000 (99.143)
2019-05-03 16:55:43 - INFO - TRAINING - Epoch: [151][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4260 (0.5332)	Prec@1 86.000 (82.427)	Prec@5 100.000 (99.134)
2019-05-03 16:55:44 - INFO - TRAINING - Epoch: [151][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5147 (0.5301)	Prec@1 85.000 (82.449)	Prec@5 99.000 (99.147)
2019-05-03 16:55:45 - INFO - TRAINING - Epoch: [151][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6087 (0.5304)	Prec@1 78.000 (82.426)	Prec@5 100.000 (99.175)
2019-05-03 16:55:47 - INFO - EVALUATING - Epoch: [151][0/100]	Time 0.343 (0.343)	Data 0.330 (0.330)	Loss 0.7212 (0.7212)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:47 - INFO - EVALUATING - Epoch: [151][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.4784 (0.6071)	Prec@1 86.000 (80.569)	Prec@5 97.000 (98.588)
2019-05-03 16:55:47 - INFO - 
 Epoch: 152	Training Loss 0.5307 	Training Prec@1 82.422 	Training Prec@5 99.160 	Validation Loss 0.6074 	Validation Prec@1 80.390 	Validation Prec@5 98.730 	
2019-05-03 16:55:47 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:47 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:48 - INFO - TRAINING - Epoch: [152][0/500]	Time 0.260 (0.260)	Data 0.238 (0.238)	Loss 0.6150 (0.6150)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:55:49 - INFO - TRAINING - Epoch: [152][50/500]	Time 0.028 (0.024)	Data 0.000 (0.005)	Loss 0.4519 (0.5110)	Prec@1 85.000 (82.843)	Prec@5 99.000 (99.157)
2019-05-03 16:55:50 - INFO - TRAINING - Epoch: [152][100/500]	Time 0.027 (0.023)	Data 0.000 (0.002)	Loss 0.5206 (0.5229)	Prec@1 83.000 (82.465)	Prec@5 99.000 (99.188)
2019-05-03 16:55:51 - INFO - TRAINING - Epoch: [152][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.4546 (0.5240)	Prec@1 84.000 (82.649)	Prec@5 99.000 (99.126)
2019-05-03 16:55:52 - INFO - TRAINING - Epoch: [152][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5308 (0.5194)	Prec@1 85.000 (82.836)	Prec@5 98.000 (99.159)
2019-05-03 16:55:53 - INFO - TRAINING - Epoch: [152][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5344 (0.5239)	Prec@1 84.000 (82.673)	Prec@5 99.000 (99.116)
2019-05-03 16:55:54 - INFO - TRAINING - Epoch: [152][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5770 (0.5260)	Prec@1 82.000 (82.555)	Prec@5 99.000 (99.136)
2019-05-03 16:55:55 - INFO - TRAINING - Epoch: [152][350/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.4564 (0.5286)	Prec@1 86.000 (82.501)	Prec@5 100.000 (99.094)
2019-05-03 16:55:56 - INFO - TRAINING - Epoch: [152][400/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.6281 (0.5287)	Prec@1 75.000 (82.429)	Prec@5 99.000 (99.135)
2019-05-03 16:55:57 - INFO - TRAINING - Epoch: [152][450/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.5110 (0.5330)	Prec@1 84.000 (82.313)	Prec@5 99.000 (99.120)
2019-05-03 16:55:58 - INFO - EVALUATING - Epoch: [152][0/100]	Time 0.346 (0.346)	Data 0.340 (0.340)	Loss 0.6144 (0.6144)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:55:58 - INFO - EVALUATING - Epoch: [152][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6157 (0.6725)	Prec@1 82.000 (77.843)	Prec@5 97.000 (98.373)
2019-05-03 16:55:58 - INFO - 
 Epoch: 153	Training Loss 0.5344 	Training Prec@1 82.310 	Training Prec@5 99.096 	Validation Loss 0.6760 	Validation Prec@1 77.750 	Validation Prec@5 98.580 	
2019-05-03 16:55:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:55:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:55:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:55:59 - INFO - TRAINING - Epoch: [153][0/500]	Time 0.271 (0.271)	Data 0.248 (0.248)	Loss 0.5884 (0.5884)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 16:56:00 - INFO - TRAINING - Epoch: [153][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.5620 (0.5084)	Prec@1 81.000 (83.235)	Prec@5 100.000 (99.294)
2019-05-03 16:56:01 - INFO - TRAINING - Epoch: [153][100/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.6079 (0.5316)	Prec@1 81.000 (82.505)	Prec@5 100.000 (99.158)
2019-05-03 16:56:02 - INFO - TRAINING - Epoch: [153][150/500]	Time 0.017 (0.021)	Data 0.000 (0.002)	Loss 0.3728 (0.5260)	Prec@1 89.000 (82.709)	Prec@5 99.000 (99.199)
2019-05-03 16:56:03 - INFO - TRAINING - Epoch: [153][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5938 (0.5268)	Prec@1 82.000 (82.746)	Prec@5 99.000 (99.169)
2019-05-03 16:56:04 - INFO - TRAINING - Epoch: [153][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4599 (0.5243)	Prec@1 84.000 (82.737)	Prec@5 100.000 (99.187)
2019-05-03 16:56:05 - INFO - TRAINING - Epoch: [153][300/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.7406 (0.5262)	Prec@1 74.000 (82.625)	Prec@5 99.000 (99.163)
2019-05-03 16:56:06 - INFO - TRAINING - Epoch: [153][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6111 (0.5308)	Prec@1 82.000 (82.533)	Prec@5 97.000 (99.120)
2019-05-03 16:56:07 - INFO - TRAINING - Epoch: [153][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4701 (0.5326)	Prec@1 84.000 (82.459)	Prec@5 100.000 (99.132)
2019-05-03 16:56:08 - INFO - TRAINING - Epoch: [153][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5808 (0.5328)	Prec@1 82.000 (82.424)	Prec@5 98.000 (99.142)
2019-05-03 16:56:09 - INFO - EVALUATING - Epoch: [153][0/100]	Time 0.330 (0.330)	Data 0.319 (0.319)	Loss 0.5432 (0.5432)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:56:09 - INFO - EVALUATING - Epoch: [153][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 0.6252 (0.6022)	Prec@1 80.000 (80.020)	Prec@5 97.000 (98.765)
2019-05-03 16:56:10 - INFO - 
 Epoch: 154	Training Loss 0.5345 	Training Prec@1 82.368 	Training Prec@5 99.126 	Validation Loss 0.6103 	Validation Prec@1 79.780 	Validation Prec@5 98.770 	
2019-05-03 16:56:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:56:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:56:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:56:10 - INFO - TRAINING - Epoch: [154][0/500]	Time 0.280 (0.280)	Data 0.259 (0.259)	Loss 0.5629 (0.5629)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:56:11 - INFO - TRAINING - Epoch: [154][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.5320 (0.5303)	Prec@1 81.000 (82.745)	Prec@5 99.000 (99.255)
2019-05-03 16:56:12 - INFO - TRAINING - Epoch: [154][100/500]	Time 0.016 (0.023)	Data 0.000 (0.003)	Loss 0.5503 (0.5329)	Prec@1 80.000 (82.267)	Prec@5 100.000 (99.198)
2019-05-03 16:56:13 - INFO - TRAINING - Epoch: [154][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.6177 (0.5328)	Prec@1 80.000 (82.126)	Prec@5 99.000 (99.146)
2019-05-03 16:56:14 - INFO - TRAINING - Epoch: [154][200/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.5241 (0.5312)	Prec@1 82.000 (82.323)	Prec@5 99.000 (99.164)
2019-05-03 16:56:15 - INFO - TRAINING - Epoch: [154][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.6132 (0.5318)	Prec@1 80.000 (82.442)	Prec@5 99.000 (99.171)
2019-05-03 16:56:16 - INFO - TRAINING - Epoch: [154][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5154 (0.5304)	Prec@1 79.000 (82.475)	Prec@5 100.000 (99.140)
2019-05-03 16:56:17 - INFO - TRAINING - Epoch: [154][350/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6097 (0.5299)	Prec@1 81.000 (82.476)	Prec@5 98.000 (99.114)
2019-05-03 16:56:18 - INFO - TRAINING - Epoch: [154][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5036 (0.5348)	Prec@1 80.000 (82.292)	Prec@5 98.000 (99.092)
2019-05-03 16:56:19 - INFO - TRAINING - Epoch: [154][450/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5064 (0.5329)	Prec@1 77.000 (82.330)	Prec@5 100.000 (99.095)
2019-05-03 16:56:21 - INFO - EVALUATING - Epoch: [154][0/100]	Time 0.353 (0.353)	Data 0.342 (0.342)	Loss 0.5013 (0.5013)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 16:56:21 - INFO - EVALUATING - Epoch: [154][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.4613 (0.6258)	Prec@1 85.000 (80.529)	Prec@5 99.000 (98.549)
2019-05-03 16:56:21 - INFO - 
 Epoch: 155	Training Loss 0.5327 	Training Prec@1 82.316 	Training Prec@5 99.110 	Validation Loss 0.6150 	Validation Prec@1 80.410 	Validation Prec@5 98.870 	
2019-05-03 16:56:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:56:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:56:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:56:21 - INFO - TRAINING - Epoch: [155][0/500]	Time 0.259 (0.259)	Data 0.234 (0.234)	Loss 0.5420 (0.5420)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:56:22 - INFO - TRAINING - Epoch: [155][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.5514 (0.5332)	Prec@1 83.000 (82.255)	Prec@5 99.000 (99.098)
2019-05-03 16:56:24 - INFO - TRAINING - Epoch: [155][100/500]	Time 0.033 (0.023)	Data 0.000 (0.002)	Loss 0.5265 (0.5336)	Prec@1 85.000 (82.356)	Prec@5 98.000 (99.119)
2019-05-03 16:56:24 - INFO - TRAINING - Epoch: [155][150/500]	Time 0.011 (0.021)	Data 0.000 (0.002)	Loss 0.6892 (0.5267)	Prec@1 80.000 (82.570)	Prec@5 98.000 (99.126)
2019-05-03 16:56:25 - INFO - TRAINING - Epoch: [155][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4625 (0.5244)	Prec@1 86.000 (82.766)	Prec@5 99.000 (99.139)
2019-05-03 16:56:26 - INFO - TRAINING - Epoch: [155][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4672 (0.5241)	Prec@1 83.000 (82.629)	Prec@5 100.000 (99.175)
2019-05-03 16:56:27 - INFO - TRAINING - Epoch: [155][300/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.4554 (0.5228)	Prec@1 85.000 (82.684)	Prec@5 99.000 (99.179)
2019-05-03 16:56:29 - INFO - TRAINING - Epoch: [155][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5344 (0.5232)	Prec@1 82.000 (82.650)	Prec@5 100.000 (99.171)
2019-05-03 16:56:29 - INFO - TRAINING - Epoch: [155][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5067 (0.5237)	Prec@1 85.000 (82.621)	Prec@5 100.000 (99.157)
2019-05-03 16:56:31 - INFO - TRAINING - Epoch: [155][450/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5941 (0.5247)	Prec@1 74.000 (82.528)	Prec@5 100.000 (99.180)
2019-05-03 16:56:32 - INFO - EVALUATING - Epoch: [155][0/100]	Time 0.366 (0.366)	Data 0.351 (0.351)	Loss 0.7040 (0.7040)	Prec@1 78.000 (78.000)	Prec@5 96.000 (96.000)
2019-05-03 16:56:32 - INFO - EVALUATING - Epoch: [155][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.6477 (0.6711)	Prec@1 83.000 (78.431)	Prec@5 97.000 (97.980)
2019-05-03 16:56:32 - INFO - 
 Epoch: 156	Training Loss 0.5247 	Training Prec@1 82.566 	Training Prec@5 99.180 	Validation Loss 0.6726 	Validation Prec@1 78.200 	Validation Prec@5 98.170 	
2019-05-03 16:56:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:56:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:56:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:56:33 - INFO - TRAINING - Epoch: [156][0/500]	Time 0.277 (0.277)	Data 0.250 (0.250)	Loss 0.5014 (0.5014)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:56:34 - INFO - TRAINING - Epoch: [156][50/500]	Time 0.022 (0.024)	Data 0.000 (0.005)	Loss 0.6179 (0.5448)	Prec@1 79.000 (82.255)	Prec@5 99.000 (99.118)
2019-05-03 16:56:35 - INFO - TRAINING - Epoch: [156][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.5700 (0.5458)	Prec@1 86.000 (81.990)	Prec@5 99.000 (99.119)
2019-05-03 16:56:36 - INFO - TRAINING - Epoch: [156][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.6540 (0.5448)	Prec@1 81.000 (82.020)	Prec@5 99.000 (99.146)
2019-05-03 16:56:37 - INFO - TRAINING - Epoch: [156][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.7106 (0.5431)	Prec@1 79.000 (82.100)	Prec@5 99.000 (99.124)
2019-05-03 16:56:38 - INFO - TRAINING - Epoch: [156][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.7820 (0.5383)	Prec@1 76.000 (82.207)	Prec@5 97.000 (99.120)
2019-05-03 16:56:39 - INFO - TRAINING - Epoch: [156][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5298 (0.5328)	Prec@1 83.000 (82.372)	Prec@5 100.000 (99.169)
2019-05-03 16:56:40 - INFO - TRAINING - Epoch: [156][350/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.7056 (0.5320)	Prec@1 75.000 (82.353)	Prec@5 99.000 (99.185)
2019-05-03 16:56:41 - INFO - TRAINING - Epoch: [156][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5737 (0.5338)	Prec@1 79.000 (82.319)	Prec@5 100.000 (99.177)
2019-05-03 16:56:42 - INFO - TRAINING - Epoch: [156][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.4647 (0.5338)	Prec@1 84.000 (82.306)	Prec@5 100.000 (99.191)
2019-05-03 16:56:43 - INFO - EVALUATING - Epoch: [156][0/100]	Time 0.319 (0.319)	Data 0.305 (0.305)	Loss 0.4882 (0.4882)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 16:56:43 - INFO - EVALUATING - Epoch: [156][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.5070 (0.5964)	Prec@1 86.000 (80.412)	Prec@5 97.000 (98.902)
2019-05-03 16:56:43 - INFO - 
 Epoch: 157	Training Loss 0.5331 	Training Prec@1 82.348 	Training Prec@5 99.172 	Validation Loss 0.6005 	Validation Prec@1 79.980 	Validation Prec@5 98.960 	
2019-05-03 16:56:44 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:56:44 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:56:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:56:44 - INFO - TRAINING - Epoch: [157][0/500]	Time 0.248 (0.248)	Data 0.227 (0.227)	Loss 0.5187 (0.5187)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 16:56:45 - INFO - TRAINING - Epoch: [157][50/500]	Time 0.027 (0.023)	Data 0.000 (0.005)	Loss 0.4303 (0.5159)	Prec@1 84.000 (82.431)	Prec@5 100.000 (99.314)
2019-05-03 16:56:46 - INFO - TRAINING - Epoch: [157][100/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.4674 (0.5182)	Prec@1 84.000 (82.297)	Prec@5 100.000 (99.307)
2019-05-03 16:56:47 - INFO - TRAINING - Epoch: [157][150/500]	Time 0.018 (0.021)	Data 0.000 (0.002)	Loss 0.6116 (0.5171)	Prec@1 82.000 (82.470)	Prec@5 98.000 (99.311)
2019-05-03 16:56:48 - INFO - TRAINING - Epoch: [157][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7009 (0.5217)	Prec@1 77.000 (82.488)	Prec@5 99.000 (99.209)
2019-05-03 16:56:49 - INFO - TRAINING - Epoch: [157][250/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6710 (0.5249)	Prec@1 74.000 (82.347)	Prec@5 100.000 (99.223)
2019-05-03 16:56:50 - INFO - TRAINING - Epoch: [157][300/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5289 (0.5250)	Prec@1 81.000 (82.415)	Prec@5 98.000 (99.219)
2019-05-03 16:56:51 - INFO - TRAINING - Epoch: [157][350/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.8174 (0.5250)	Prec@1 73.000 (82.442)	Prec@5 98.000 (99.242)
2019-05-03 16:56:52 - INFO - TRAINING - Epoch: [157][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.4156 (0.5222)	Prec@1 84.000 (82.606)	Prec@5 100.000 (99.234)
2019-05-03 16:56:53 - INFO - TRAINING - Epoch: [157][450/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5489 (0.5248)	Prec@1 82.000 (82.506)	Prec@5 98.000 (99.215)
2019-05-03 16:56:54 - INFO - EVALUATING - Epoch: [157][0/100]	Time 0.339 (0.339)	Data 0.333 (0.333)	Loss 0.6250 (0.6250)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 16:56:54 - INFO - EVALUATING - Epoch: [157][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.4817 (0.5888)	Prec@1 87.000 (80.588)	Prec@5 98.000 (98.784)
2019-05-03 16:56:54 - INFO - 
 Epoch: 158	Training Loss 0.5257 	Training Prec@1 82.412 	Training Prec@5 99.212 	Validation Loss 0.5814 	Validation Prec@1 80.740 	Validation Prec@5 99.000 	
2019-05-03 16:56:55 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:56:55 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:56:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:56:55 - INFO - TRAINING - Epoch: [158][0/500]	Time 0.295 (0.295)	Data 0.267 (0.267)	Loss 0.7126 (0.7126)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:56:56 - INFO - TRAINING - Epoch: [158][50/500]	Time 0.014 (0.025)	Data 0.000 (0.005)	Loss 0.8017 (0.5626)	Prec@1 75.000 (81.275)	Prec@5 100.000 (99.059)
2019-05-03 16:56:57 - INFO - TRAINING - Epoch: [158][100/500]	Time 0.023 (0.022)	Data 0.000 (0.003)	Loss 0.5193 (0.5497)	Prec@1 80.000 (81.871)	Prec@5 100.000 (99.248)
2019-05-03 16:56:58 - INFO - TRAINING - Epoch: [158][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.4433 (0.5444)	Prec@1 84.000 (81.967)	Prec@5 100.000 (99.205)
2019-05-03 16:56:59 - INFO - TRAINING - Epoch: [158][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.4336 (0.5401)	Prec@1 87.000 (82.189)	Prec@5 99.000 (99.194)
2019-05-03 16:57:00 - INFO - TRAINING - Epoch: [158][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4475 (0.5404)	Prec@1 88.000 (82.092)	Prec@5 100.000 (99.235)
2019-05-03 16:57:01 - INFO - TRAINING - Epoch: [158][300/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.4102 (0.5337)	Prec@1 87.000 (82.322)	Prec@5 99.000 (99.259)
2019-05-03 16:57:02 - INFO - TRAINING - Epoch: [158][350/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5634 (0.5323)	Prec@1 82.000 (82.385)	Prec@5 100.000 (99.254)
2019-05-03 16:57:03 - INFO - TRAINING - Epoch: [158][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.5032 (0.5339)	Prec@1 84.000 (82.299)	Prec@5 100.000 (99.214)
2019-05-03 16:57:04 - INFO - TRAINING - Epoch: [158][450/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.4669 (0.5333)	Prec@1 83.000 (82.353)	Prec@5 97.000 (99.213)
2019-05-03 16:57:05 - INFO - EVALUATING - Epoch: [158][0/100]	Time 0.284 (0.284)	Data 0.275 (0.275)	Loss 0.6592 (0.6592)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 16:57:05 - INFO - EVALUATING - Epoch: [158][50/100]	Time 0.005 (0.011)	Data 0.000 (0.006)	Loss 0.5901 (0.6322)	Prec@1 85.000 (79.627)	Prec@5 97.000 (98.863)
2019-05-03 16:57:06 - INFO - 
 Epoch: 159	Training Loss 0.5346 	Training Prec@1 82.308 	Training Prec@5 99.178 	Validation Loss 0.6377 	Validation Prec@1 79.330 	Validation Prec@5 98.850 	
2019-05-03 16:57:06 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:57:06 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:57:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:57:06 - INFO - TRAINING - Epoch: [159][0/500]	Time 0.263 (0.263)	Data 0.243 (0.243)	Loss 0.6673 (0.6673)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:57:07 - INFO - TRAINING - Epoch: [159][50/500]	Time 0.017 (0.024)	Data 0.000 (0.005)	Loss 0.5133 (0.5458)	Prec@1 83.000 (82.373)	Prec@5 100.000 (99.059)
2019-05-03 16:57:08 - INFO - TRAINING - Epoch: [159][100/500]	Time 0.014 (0.022)	Data 0.000 (0.003)	Loss 0.5483 (0.5381)	Prec@1 81.000 (82.208)	Prec@5 100.000 (99.208)
2019-05-03 16:57:09 - INFO - TRAINING - Epoch: [159][150/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.5010 (0.5309)	Prec@1 81.000 (82.490)	Prec@5 100.000 (99.179)
2019-05-03 16:57:10 - INFO - TRAINING - Epoch: [159][200/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.5529 (0.5241)	Prec@1 83.000 (82.731)	Prec@5 97.000 (99.209)
2019-05-03 16:57:11 - INFO - TRAINING - Epoch: [159][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4979 (0.5263)	Prec@1 81.000 (82.633)	Prec@5 100.000 (99.199)
2019-05-03 16:57:12 - INFO - TRAINING - Epoch: [159][300/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5681 (0.5321)	Prec@1 82.000 (82.452)	Prec@5 100.000 (99.146)
2019-05-03 16:57:13 - INFO - TRAINING - Epoch: [159][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.3484 (0.5290)	Prec@1 88.000 (82.581)	Prec@5 100.000 (99.140)
2019-05-03 16:57:14 - INFO - TRAINING - Epoch: [159][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7422 (0.5276)	Prec@1 75.000 (82.651)	Prec@5 100.000 (99.160)
2019-05-03 16:57:15 - INFO - TRAINING - Epoch: [159][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6938 (0.5303)	Prec@1 73.000 (82.590)	Prec@5 100.000 (99.151)
2019-05-03 16:57:17 - INFO - EVALUATING - Epoch: [159][0/100]	Time 0.352 (0.352)	Data 0.340 (0.340)	Loss 0.5652 (0.5652)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 16:57:17 - INFO - EVALUATING - Epoch: [159][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.3928 (0.6250)	Prec@1 90.000 (79.314)	Prec@5 98.000 (98.824)
2019-05-03 16:57:17 - INFO - 
 Epoch: 160	Training Loss 0.5297 	Training Prec@1 82.580 	Training Prec@5 99.160 	Validation Loss 0.6075 	Validation Prec@1 79.920 	Validation Prec@5 98.910 	
2019-05-03 16:57:17 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:57:17 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:57:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:57:18 - INFO - TRAINING - Epoch: [160][0/500]	Time 0.276 (0.276)	Data 0.248 (0.248)	Loss 0.5088 (0.5088)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:57:19 - INFO - TRAINING - Epoch: [160][50/500]	Time 0.021 (0.026)	Data 0.000 (0.005)	Loss 0.4834 (0.5079)	Prec@1 81.000 (83.137)	Prec@5 100.000 (99.314)
2019-05-03 16:57:20 - INFO - TRAINING - Epoch: [160][100/500]	Time 0.023 (0.023)	Data 0.000 (0.003)	Loss 0.4437 (0.5263)	Prec@1 83.000 (82.446)	Prec@5 100.000 (99.178)
2019-05-03 16:57:21 - INFO - TRAINING - Epoch: [160][150/500]	Time 0.018 (0.022)	Data 0.000 (0.002)	Loss 0.6618 (0.5317)	Prec@1 77.000 (82.119)	Prec@5 99.000 (99.179)
2019-05-03 16:57:22 - INFO - TRAINING - Epoch: [160][200/500]	Time 0.027 (0.022)	Data 0.000 (0.001)	Loss 0.2885 (0.5238)	Prec@1 88.000 (82.398)	Prec@5 99.000 (99.194)
2019-05-03 16:57:23 - INFO - TRAINING - Epoch: [160][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5382 (0.5282)	Prec@1 82.000 (82.275)	Prec@5 100.000 (99.183)
2019-05-03 16:57:24 - INFO - TRAINING - Epoch: [160][300/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.5343 (0.5282)	Prec@1 83.000 (82.262)	Prec@5 99.000 (99.140)
2019-05-03 16:57:25 - INFO - TRAINING - Epoch: [160][350/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.3230 (0.5281)	Prec@1 91.000 (82.308)	Prec@5 100.000 (99.154)
2019-05-03 16:57:26 - INFO - TRAINING - Epoch: [160][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.4115 (0.5276)	Prec@1 83.000 (82.294)	Prec@5 100.000 (99.177)
2019-05-03 16:57:27 - INFO - TRAINING - Epoch: [160][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5519 (0.5290)	Prec@1 80.000 (82.275)	Prec@5 98.000 (99.166)
2019-05-03 16:57:28 - INFO - EVALUATING - Epoch: [160][0/100]	Time 0.317 (0.317)	Data 0.304 (0.304)	Loss 0.6590 (0.6590)	Prec@1 77.000 (77.000)	Prec@5 97.000 (97.000)
2019-05-03 16:57:28 - INFO - EVALUATING - Epoch: [160][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.6066 (0.6251)	Prec@1 83.000 (79.765)	Prec@5 98.000 (98.647)
2019-05-03 16:57:29 - INFO - 
 Epoch: 161	Training Loss 0.5286 	Training Prec@1 82.342 	Training Prec@5 99.170 	Validation Loss 0.6218 	Validation Prec@1 79.600 	Validation Prec@5 98.770 	
2019-05-03 16:57:29 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:57:29 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:57:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:57:29 - INFO - TRAINING - Epoch: [161][0/500]	Time 0.271 (0.271)	Data 0.245 (0.245)	Loss 0.5981 (0.5981)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:57:30 - INFO - TRAINING - Epoch: [161][50/500]	Time 0.017 (0.026)	Data 0.000 (0.005)	Loss 0.4839 (0.5089)	Prec@1 83.000 (83.020)	Prec@5 99.000 (99.294)
2019-05-03 16:57:31 - INFO - TRAINING - Epoch: [161][100/500]	Time 0.014 (0.023)	Data 0.000 (0.003)	Loss 0.5805 (0.5234)	Prec@1 78.000 (82.475)	Prec@5 99.000 (99.277)
2019-05-03 16:57:32 - INFO - TRAINING - Epoch: [161][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.4659 (0.5283)	Prec@1 83.000 (82.470)	Prec@5 100.000 (99.192)
2019-05-03 16:57:33 - INFO - TRAINING - Epoch: [161][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.6721 (0.5276)	Prec@1 75.000 (82.577)	Prec@5 100.000 (99.224)
2019-05-03 16:57:34 - INFO - TRAINING - Epoch: [161][250/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5179 (0.5287)	Prec@1 80.000 (82.586)	Prec@5 99.000 (99.199)
2019-05-03 16:57:35 - INFO - TRAINING - Epoch: [161][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.5318 (0.5298)	Prec@1 79.000 (82.535)	Prec@5 98.000 (99.176)
2019-05-03 16:57:36 - INFO - TRAINING - Epoch: [161][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5169 (0.5294)	Prec@1 83.000 (82.484)	Prec@5 100.000 (99.165)
2019-05-03 16:57:37 - INFO - TRAINING - Epoch: [161][400/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4376 (0.5284)	Prec@1 82.000 (82.521)	Prec@5 100.000 (99.175)
2019-05-03 16:57:38 - INFO - TRAINING - Epoch: [161][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5951 (0.5293)	Prec@1 85.000 (82.435)	Prec@5 98.000 (99.160)
2019-05-03 16:57:39 - INFO - EVALUATING - Epoch: [161][0/100]	Time 0.289 (0.289)	Data 0.277 (0.277)	Loss 0.6732 (0.6732)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 16:57:40 - INFO - EVALUATING - Epoch: [161][50/100]	Time 0.007 (0.011)	Data 0.000 (0.006)	Loss 0.5178 (0.6950)	Prec@1 89.000 (78.529)	Prec@5 97.000 (97.608)
2019-05-03 16:57:40 - INFO - 
 Epoch: 162	Training Loss 0.5303 	Training Prec@1 82.404 	Training Prec@5 99.146 	Validation Loss 0.6855 	Validation Prec@1 78.630 	Validation Prec@5 97.930 	
2019-05-03 16:57:40 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:57:40 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:57:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:57:40 - INFO - TRAINING - Epoch: [162][0/500]	Time 0.255 (0.255)	Data 0.224 (0.224)	Loss 0.5994 (0.5994)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:57:41 - INFO - TRAINING - Epoch: [162][50/500]	Time 0.018 (0.026)	Data 0.000 (0.005)	Loss 0.5080 (0.5295)	Prec@1 85.000 (82.588)	Prec@5 97.000 (99.078)
2019-05-03 16:57:42 - INFO - TRAINING - Epoch: [162][100/500]	Time 0.017 (0.024)	Data 0.000 (0.002)	Loss 0.6227 (0.5385)	Prec@1 80.000 (81.871)	Prec@5 98.000 (99.168)
2019-05-03 16:57:43 - INFO - TRAINING - Epoch: [162][150/500]	Time 0.022 (0.023)	Data 0.000 (0.002)	Loss 0.5126 (0.5358)	Prec@1 83.000 (82.132)	Prec@5 98.000 (99.238)
2019-05-03 16:57:44 - INFO - TRAINING - Epoch: [162][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.5755 (0.5388)	Prec@1 84.000 (82.229)	Prec@5 99.000 (99.189)
2019-05-03 16:57:45 - INFO - TRAINING - Epoch: [162][250/500]	Time 0.025 (0.022)	Data 0.000 (0.001)	Loss 0.4731 (0.5371)	Prec@1 83.000 (82.219)	Prec@5 100.000 (99.199)
2019-05-03 16:57:46 - INFO - TRAINING - Epoch: [162][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4981 (0.5354)	Prec@1 80.000 (82.223)	Prec@5 100.000 (99.196)
2019-05-03 16:57:47 - INFO - TRAINING - Epoch: [162][350/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4649 (0.5358)	Prec@1 85.000 (82.219)	Prec@5 100.000 (99.205)
2019-05-03 16:57:48 - INFO - TRAINING - Epoch: [162][400/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6562 (0.5344)	Prec@1 81.000 (82.277)	Prec@5 98.000 (99.185)
2019-05-03 16:57:49 - INFO - TRAINING - Epoch: [162][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.4306 (0.5324)	Prec@1 86.000 (82.357)	Prec@5 100.000 (99.188)
2019-05-03 16:57:51 - INFO - EVALUATING - Epoch: [162][0/100]	Time 0.350 (0.350)	Data 0.337 (0.337)	Loss 0.4413 (0.4413)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 16:57:51 - INFO - EVALUATING - Epoch: [162][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.4642 (0.5721)	Prec@1 88.000 (81.314)	Prec@5 97.000 (98.882)
2019-05-03 16:57:51 - INFO - 
 Epoch: 163	Training Loss 0.5319 	Training Prec@1 82.336 	Training Prec@5 99.168 	Validation Loss 0.5658 	Validation Prec@1 81.380 	Validation Prec@5 99.040 	
2019-05-03 16:57:51 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:57:51 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:57:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:57:52 - INFO - TRAINING - Epoch: [163][0/500]	Time 0.273 (0.273)	Data 0.235 (0.235)	Loss 0.4963 (0.4963)	Prec@1 83.000 (83.000)	Prec@5 100.000 (100.000)
2019-05-03 16:57:53 - INFO - TRAINING - Epoch: [163][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.5096 (0.5270)	Prec@1 84.000 (82.157)	Prec@5 99.000 (99.235)
2019-05-03 16:57:54 - INFO - TRAINING - Epoch: [163][100/500]	Time 0.033 (0.023)	Data 0.000 (0.002)	Loss 0.4729 (0.5246)	Prec@1 85.000 (82.505)	Prec@5 100.000 (99.248)
2019-05-03 16:57:55 - INFO - TRAINING - Epoch: [163][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.6559 (0.5200)	Prec@1 78.000 (82.722)	Prec@5 99.000 (99.212)
2019-05-03 16:57:56 - INFO - TRAINING - Epoch: [163][200/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.4787 (0.5221)	Prec@1 86.000 (82.602)	Prec@5 99.000 (99.234)
2019-05-03 16:57:57 - INFO - TRAINING - Epoch: [163][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4505 (0.5301)	Prec@1 88.000 (82.359)	Prec@5 100.000 (99.211)
2019-05-03 16:57:58 - INFO - TRAINING - Epoch: [163][300/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5806 (0.5274)	Prec@1 83.000 (82.326)	Prec@5 100.000 (99.233)
2019-05-03 16:57:59 - INFO - TRAINING - Epoch: [163][350/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.6629 (0.5311)	Prec@1 81.000 (82.239)	Prec@5 100.000 (99.222)
2019-05-03 16:58:00 - INFO - TRAINING - Epoch: [163][400/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.5346 (0.5298)	Prec@1 80.000 (82.344)	Prec@5 99.000 (99.219)
2019-05-03 16:58:01 - INFO - TRAINING - Epoch: [163][450/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.6180 (0.5296)	Prec@1 78.000 (82.377)	Prec@5 99.000 (99.213)
2019-05-03 16:58:02 - INFO - EVALUATING - Epoch: [163][0/100]	Time 0.311 (0.311)	Data 0.302 (0.302)	Loss 0.5369 (0.5369)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 16:58:02 - INFO - EVALUATING - Epoch: [163][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5615 (0.6710)	Prec@1 87.000 (78.235)	Prec@5 97.000 (98.627)
2019-05-03 16:58:02 - INFO - 
 Epoch: 164	Training Loss 0.5285 	Training Prec@1 82.386 	Training Prec@5 99.220 	Validation Loss 0.6642 	Validation Prec@1 78.420 	Validation Prec@5 98.700 	
2019-05-03 16:58:02 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:02 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:03 - INFO - TRAINING - Epoch: [164][0/500]	Time 0.253 (0.253)	Data 0.227 (0.227)	Loss 0.4628 (0.4628)	Prec@1 88.000 (88.000)	Prec@5 99.000 (99.000)
2019-05-03 16:58:04 - INFO - TRAINING - Epoch: [164][50/500]	Time 0.015 (0.024)	Data 0.000 (0.005)	Loss 0.3881 (0.5158)	Prec@1 87.000 (83.078)	Prec@5 99.000 (99.235)
2019-05-03 16:58:05 - INFO - TRAINING - Epoch: [164][100/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.4010 (0.5184)	Prec@1 89.000 (83.010)	Prec@5 98.000 (99.238)
2019-05-03 16:58:06 - INFO - TRAINING - Epoch: [164][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.4808 (0.5236)	Prec@1 83.000 (82.801)	Prec@5 100.000 (99.252)
2019-05-03 16:58:07 - INFO - TRAINING - Epoch: [164][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.3855 (0.5186)	Prec@1 85.000 (82.766)	Prec@5 99.000 (99.249)
2019-05-03 16:58:08 - INFO - TRAINING - Epoch: [164][250/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.4773 (0.5195)	Prec@1 85.000 (82.789)	Prec@5 100.000 (99.223)
2019-05-03 16:58:09 - INFO - TRAINING - Epoch: [164][300/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.3835 (0.5226)	Prec@1 87.000 (82.684)	Prec@5 100.000 (99.176)
2019-05-03 16:58:10 - INFO - TRAINING - Epoch: [164][350/500]	Time 0.011 (0.021)	Data 0.000 (0.001)	Loss 0.5619 (0.5241)	Prec@1 81.000 (82.598)	Prec@5 99.000 (99.174)
2019-05-03 16:58:11 - INFO - TRAINING - Epoch: [164][400/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6701 (0.5247)	Prec@1 79.000 (82.653)	Prec@5 98.000 (99.172)
2019-05-03 16:58:12 - INFO - TRAINING - Epoch: [164][450/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4481 (0.5267)	Prec@1 85.000 (82.643)	Prec@5 98.000 (99.149)
2019-05-03 16:58:13 - INFO - EVALUATING - Epoch: [164][0/100]	Time 0.343 (0.343)	Data 0.328 (0.328)	Loss 0.6195 (0.6195)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 16:58:13 - INFO - EVALUATING - Epoch: [164][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.5512 (0.5976)	Prec@1 81.000 (80.196)	Prec@5 99.000 (98.882)
2019-05-03 16:58:14 - INFO - 
 Epoch: 165	Training Loss 0.5245 	Training Prec@1 82.718 	Training Prec@5 99.182 	Validation Loss 0.5893 	Validation Prec@1 80.760 	Validation Prec@5 98.960 	
2019-05-03 16:58:14 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:14 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:14 - INFO - TRAINING - Epoch: [165][0/500]	Time 0.266 (0.266)	Data 0.241 (0.241)	Loss 0.4378 (0.4378)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 16:58:15 - INFO - TRAINING - Epoch: [165][50/500]	Time 0.024 (0.026)	Data 0.000 (0.005)	Loss 0.5745 (0.5291)	Prec@1 82.000 (83.098)	Prec@5 100.000 (99.039)
2019-05-03 16:58:16 - INFO - TRAINING - Epoch: [165][100/500]	Time 0.018 (0.023)	Data 0.000 (0.003)	Loss 0.5846 (0.5225)	Prec@1 78.000 (83.099)	Prec@5 100.000 (99.139)
2019-05-03 16:58:17 - INFO - TRAINING - Epoch: [165][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.3679 (0.5233)	Prec@1 87.000 (82.874)	Prec@5 99.000 (99.093)
2019-05-03 16:58:18 - INFO - TRAINING - Epoch: [165][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5083 (0.5272)	Prec@1 82.000 (82.587)	Prec@5 100.000 (99.100)
2019-05-03 16:58:19 - INFO - TRAINING - Epoch: [165][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6756 (0.5272)	Prec@1 79.000 (82.610)	Prec@5 99.000 (99.116)
2019-05-03 16:58:20 - INFO - TRAINING - Epoch: [165][300/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5581 (0.5237)	Prec@1 81.000 (82.678)	Prec@5 98.000 (99.113)
2019-05-03 16:58:21 - INFO - TRAINING - Epoch: [165][350/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.6455 (0.5299)	Prec@1 78.000 (82.442)	Prec@5 100.000 (99.097)
2019-05-03 16:58:22 - INFO - TRAINING - Epoch: [165][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.4733 (0.5304)	Prec@1 85.000 (82.379)	Prec@5 98.000 (99.095)
2019-05-03 16:58:23 - INFO - TRAINING - Epoch: [165][450/500]	Time 0.030 (0.020)	Data 0.000 (0.001)	Loss 0.4312 (0.5313)	Prec@1 86.000 (82.297)	Prec@5 99.000 (99.100)
2019-05-03 16:58:24 - INFO - EVALUATING - Epoch: [165][0/100]	Time 0.345 (0.345)	Data 0.331 (0.331)	Loss 0.5839 (0.5839)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:58:25 - INFO - EVALUATING - Epoch: [165][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.4727 (0.5889)	Prec@1 86.000 (80.549)	Prec@5 98.000 (98.843)
2019-05-03 16:58:25 - INFO - 
 Epoch: 166	Training Loss 0.5283 	Training Prec@1 82.348 	Training Prec@5 99.120 	Validation Loss 0.5901 	Validation Prec@1 80.640 	Validation Prec@5 99.000 	
2019-05-03 16:58:25 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:25 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:25 - INFO - TRAINING - Epoch: [166][0/500]	Time 0.272 (0.272)	Data 0.247 (0.247)	Loss 0.5784 (0.5784)	Prec@1 83.000 (83.000)	Prec@5 98.000 (98.000)
2019-05-03 16:58:26 - INFO - TRAINING - Epoch: [166][50/500]	Time 0.017 (0.023)	Data 0.000 (0.005)	Loss 0.4413 (0.5305)	Prec@1 83.000 (82.490)	Prec@5 98.000 (99.157)
2019-05-03 16:58:27 - INFO - TRAINING - Epoch: [166][100/500]	Time 0.016 (0.022)	Data 0.000 (0.003)	Loss 0.3739 (0.5152)	Prec@1 86.000 (82.822)	Prec@5 100.000 (99.228)
2019-05-03 16:58:28 - INFO - TRAINING - Epoch: [166][150/500]	Time 0.020 (0.021)	Data 0.000 (0.002)	Loss 0.5842 (0.5174)	Prec@1 82.000 (82.781)	Prec@5 98.000 (99.245)
2019-05-03 16:58:29 - INFO - TRAINING - Epoch: [166][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6909 (0.5265)	Prec@1 78.000 (82.413)	Prec@5 100.000 (99.224)
2019-05-03 16:58:30 - INFO - TRAINING - Epoch: [166][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4380 (0.5210)	Prec@1 84.000 (82.606)	Prec@5 99.000 (99.227)
2019-05-03 16:58:31 - INFO - TRAINING - Epoch: [166][300/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6765 (0.5240)	Prec@1 78.000 (82.561)	Prec@5 99.000 (99.243)
2019-05-03 16:58:32 - INFO - TRAINING - Epoch: [166][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5074 (0.5238)	Prec@1 85.000 (82.607)	Prec@5 100.000 (99.239)
2019-05-03 16:58:33 - INFO - TRAINING - Epoch: [166][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4921 (0.5246)	Prec@1 83.000 (82.601)	Prec@5 100.000 (99.219)
2019-05-03 16:58:34 - INFO - TRAINING - Epoch: [166][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.3652 (0.5273)	Prec@1 89.000 (82.508)	Prec@5 100.000 (99.197)
2019-05-03 16:58:35 - INFO - EVALUATING - Epoch: [166][0/100]	Time 0.371 (0.371)	Data 0.360 (0.360)	Loss 0.5834 (0.5834)	Prec@1 83.000 (83.000)	Prec@5 98.000 (98.000)
2019-05-03 16:58:36 - INFO - EVALUATING - Epoch: [166][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5386 (0.6059)	Prec@1 85.000 (79.843)	Prec@5 97.000 (98.745)
2019-05-03 16:58:36 - INFO - 
 Epoch: 167	Training Loss 0.5248 	Training Prec@1 82.556 	Training Prec@5 99.208 	Validation Loss 0.6026 	Validation Prec@1 80.020 	Validation Prec@5 98.850 	
2019-05-03 16:58:36 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:36 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:36 - INFO - TRAINING - Epoch: [167][0/500]	Time 0.279 (0.279)	Data 0.253 (0.253)	Loss 0.4817 (0.4817)	Prec@1 86.000 (86.000)	Prec@5 99.000 (99.000)
2019-05-03 16:58:37 - INFO - TRAINING - Epoch: [167][50/500]	Time 0.022 (0.025)	Data 0.000 (0.005)	Loss 0.5903 (0.5432)	Prec@1 81.000 (81.843)	Prec@5 98.000 (99.176)
2019-05-03 16:58:38 - INFO - TRAINING - Epoch: [167][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.7048 (0.5365)	Prec@1 74.000 (82.158)	Prec@5 100.000 (99.198)
2019-05-03 16:58:40 - INFO - TRAINING - Epoch: [167][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.4180 (0.5356)	Prec@1 84.000 (82.358)	Prec@5 100.000 (99.219)
2019-05-03 16:58:41 - INFO - TRAINING - Epoch: [167][200/500]	Time 0.015 (0.022)	Data 0.000 (0.001)	Loss 0.4995 (0.5300)	Prec@1 84.000 (82.532)	Prec@5 100.000 (99.269)
2019-05-03 16:58:42 - INFO - TRAINING - Epoch: [167][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5027 (0.5291)	Prec@1 80.000 (82.546)	Prec@5 100.000 (99.287)
2019-05-03 16:58:43 - INFO - TRAINING - Epoch: [167][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6829 (0.5315)	Prec@1 77.000 (82.312)	Prec@5 100.000 (99.223)
2019-05-03 16:58:44 - INFO - TRAINING - Epoch: [167][350/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.3727 (0.5250)	Prec@1 86.000 (82.487)	Prec@5 100.000 (99.236)
2019-05-03 16:58:45 - INFO - TRAINING - Epoch: [167][400/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4893 (0.5296)	Prec@1 84.000 (82.327)	Prec@5 100.000 (99.200)
2019-05-03 16:58:46 - INFO - TRAINING - Epoch: [167][450/500]	Time 0.030 (0.021)	Data 0.000 (0.001)	Loss 0.3179 (0.5264)	Prec@1 91.000 (82.421)	Prec@5 99.000 (99.213)
2019-05-03 16:58:47 - INFO - EVALUATING - Epoch: [167][0/100]	Time 0.355 (0.355)	Data 0.340 (0.340)	Loss 0.6343 (0.6343)	Prec@1 78.000 (78.000)	Prec@5 99.000 (99.000)
2019-05-03 16:58:47 - INFO - EVALUATING - Epoch: [167][50/100]	Time 0.010 (0.013)	Data 0.000 (0.007)	Loss 0.4962 (0.6189)	Prec@1 87.000 (79.333)	Prec@5 97.000 (98.745)
2019-05-03 16:58:48 - INFO - 
 Epoch: 168	Training Loss 0.5259 	Training Prec@1 82.442 	Training Prec@5 99.212 	Validation Loss 0.6131 	Validation Prec@1 79.650 	Validation Prec@5 98.940 	
2019-05-03 16:58:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:48 - INFO - TRAINING - Epoch: [168][0/500]	Time 0.277 (0.277)	Data 0.253 (0.253)	Loss 0.7862 (0.7862)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 16:58:49 - INFO - TRAINING - Epoch: [168][50/500]	Time 0.018 (0.024)	Data 0.000 (0.005)	Loss 0.4908 (0.5370)	Prec@1 88.000 (82.922)	Prec@5 100.000 (99.039)
2019-05-03 16:58:50 - INFO - TRAINING - Epoch: [168][100/500]	Time 0.027 (0.022)	Data 0.000 (0.003)	Loss 0.5064 (0.5397)	Prec@1 82.000 (82.376)	Prec@5 100.000 (99.040)
2019-05-03 16:58:51 - INFO - TRAINING - Epoch: [168][150/500]	Time 0.013 (0.022)	Data 0.000 (0.002)	Loss 0.6987 (0.5346)	Prec@1 78.000 (82.556)	Prec@5 97.000 (99.033)
2019-05-03 16:58:52 - INFO - TRAINING - Epoch: [168][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5097 (0.5327)	Prec@1 83.000 (82.517)	Prec@5 97.000 (99.045)
2019-05-03 16:58:53 - INFO - TRAINING - Epoch: [168][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6601 (0.5355)	Prec@1 79.000 (82.434)	Prec@5 98.000 (99.072)
2019-05-03 16:58:54 - INFO - TRAINING - Epoch: [168][300/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.5587 (0.5301)	Prec@1 82.000 (82.575)	Prec@5 99.000 (99.113)
2019-05-03 16:58:55 - INFO - TRAINING - Epoch: [168][350/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5098 (0.5292)	Prec@1 80.000 (82.544)	Prec@5 99.000 (99.131)
2019-05-03 16:58:56 - INFO - TRAINING - Epoch: [168][400/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.3943 (0.5307)	Prec@1 87.000 (82.421)	Prec@5 100.000 (99.135)
2019-05-03 16:58:57 - INFO - TRAINING - Epoch: [168][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.7009 (0.5289)	Prec@1 78.000 (82.463)	Prec@5 98.000 (99.144)
2019-05-03 16:58:58 - INFO - EVALUATING - Epoch: [168][0/100]	Time 0.347 (0.347)	Data 0.337 (0.337)	Loss 0.6605 (0.6605)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 16:58:58 - INFO - EVALUATING - Epoch: [168][50/100]	Time 0.006 (0.012)	Data 0.000 (0.007)	Loss 0.4475 (0.6424)	Prec@1 85.000 (79.235)	Prec@5 98.000 (98.627)
2019-05-03 16:58:59 - INFO - 
 Epoch: 169	Training Loss 0.5287 	Training Prec@1 82.448 	Training Prec@5 99.152 	Validation Loss 0.6431 	Validation Prec@1 79.190 	Validation Prec@5 98.700 	
2019-05-03 16:58:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:58:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:58:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:58:59 - INFO - TRAINING - Epoch: [169][0/500]	Time 0.293 (0.293)	Data 0.263 (0.263)	Loss 0.5122 (0.5122)	Prec@1 82.000 (82.000)	Prec@5 99.000 (99.000)
2019-05-03 16:59:00 - INFO - TRAINING - Epoch: [169][50/500]	Time 0.014 (0.027)	Data 0.000 (0.005)	Loss 0.5456 (0.5414)	Prec@1 84.000 (82.196)	Prec@5 97.000 (99.118)
2019-05-03 16:59:01 - INFO - TRAINING - Epoch: [169][100/500]	Time 0.028 (0.024)	Data 0.000 (0.003)	Loss 0.5057 (0.5407)	Prec@1 85.000 (82.366)	Prec@5 99.000 (99.000)
2019-05-03 16:59:02 - INFO - TRAINING - Epoch: [169][150/500]	Time 0.021 (0.023)	Data 0.000 (0.002)	Loss 0.5958 (0.5387)	Prec@1 85.000 (82.358)	Prec@5 99.000 (99.086)
2019-05-03 16:59:03 - INFO - TRAINING - Epoch: [169][200/500]	Time 0.023 (0.022)	Data 0.000 (0.001)	Loss 0.5423 (0.5311)	Prec@1 83.000 (82.781)	Prec@5 99.000 (99.109)
2019-05-03 16:59:04 - INFO - TRAINING - Epoch: [169][250/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.4680 (0.5329)	Prec@1 85.000 (82.645)	Prec@5 98.000 (99.143)
2019-05-03 16:59:05 - INFO - TRAINING - Epoch: [169][300/500]	Time 0.019 (0.022)	Data 0.000 (0.001)	Loss 0.4473 (0.5332)	Prec@1 86.000 (82.535)	Prec@5 98.000 (99.140)
2019-05-03 16:59:06 - INFO - TRAINING - Epoch: [169][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6003 (0.5368)	Prec@1 75.000 (82.299)	Prec@5 99.000 (99.134)
2019-05-03 16:59:07 - INFO - TRAINING - Epoch: [169][400/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4408 (0.5344)	Prec@1 90.000 (82.384)	Prec@5 98.000 (99.130)
2019-05-03 16:59:09 - INFO - TRAINING - Epoch: [169][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.7374 (0.5337)	Prec@1 79.000 (82.424)	Prec@5 99.000 (99.142)
2019-05-03 16:59:10 - INFO - EVALUATING - Epoch: [169][0/100]	Time 0.356 (0.356)	Data 0.349 (0.349)	Loss 0.6563 (0.6563)	Prec@1 76.000 (76.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:10 - INFO - EVALUATING - Epoch: [169][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5353 (0.6073)	Prec@1 85.000 (80.137)	Prec@5 98.000 (98.451)
2019-05-03 16:59:10 - INFO - 
 Epoch: 170	Training Loss 0.5318 	Training Prec@1 82.502 	Training Prec@5 99.142 	Validation Loss 0.6101 	Validation Prec@1 79.890 	Validation Prec@5 98.690 	
2019-05-03 16:59:11 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:59:11 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:59:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:59:11 - INFO - TRAINING - Epoch: [170][0/500]	Time 0.257 (0.257)	Data 0.231 (0.231)	Loss 0.4039 (0.4039)	Prec@1 87.000 (87.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:12 - INFO - TRAINING - Epoch: [170][50/500]	Time 0.014 (0.024)	Data 0.000 (0.005)	Loss 0.4848 (0.5119)	Prec@1 82.000 (83.157)	Prec@5 100.000 (99.333)
2019-05-03 16:59:13 - INFO - TRAINING - Epoch: [170][100/500]	Time 0.023 (0.021)	Data 0.000 (0.002)	Loss 0.8076 (0.5095)	Prec@1 75.000 (83.327)	Prec@5 98.000 (99.257)
2019-05-03 16:59:14 - INFO - TRAINING - Epoch: [170][150/500]	Time 0.022 (0.021)	Data 0.000 (0.002)	Loss 0.4840 (0.5139)	Prec@1 83.000 (82.954)	Prec@5 100.000 (99.265)
2019-05-03 16:59:15 - INFO - TRAINING - Epoch: [170][200/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6548 (0.5158)	Prec@1 74.000 (83.015)	Prec@5 99.000 (99.234)
2019-05-03 16:59:16 - INFO - TRAINING - Epoch: [170][250/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.4645 (0.5121)	Prec@1 86.000 (83.096)	Prec@5 99.000 (99.235)
2019-05-03 16:59:17 - INFO - TRAINING - Epoch: [170][300/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.6205 (0.5136)	Prec@1 81.000 (83.070)	Prec@5 99.000 (99.246)
2019-05-03 16:59:18 - INFO - TRAINING - Epoch: [170][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.3527 (0.5189)	Prec@1 89.000 (82.926)	Prec@5 100.000 (99.239)
2019-05-03 16:59:19 - INFO - TRAINING - Epoch: [170][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.8471 (0.5229)	Prec@1 72.000 (82.763)	Prec@5 98.000 (99.227)
2019-05-03 16:59:20 - INFO - TRAINING - Epoch: [170][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5571 (0.5238)	Prec@1 81.000 (82.747)	Prec@5 99.000 (99.228)
2019-05-03 16:59:21 - INFO - EVALUATING - Epoch: [170][0/100]	Time 0.371 (0.371)	Data 0.361 (0.361)	Loss 0.6299 (0.6299)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:59:21 - INFO - EVALUATING - Epoch: [170][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5808 (0.5991)	Prec@1 87.000 (80.941)	Prec@5 95.000 (98.784)
2019-05-03 16:59:22 - INFO - 
 Epoch: 171	Training Loss 0.5254 	Training Prec@1 82.696 	Training Prec@5 99.232 	Validation Loss 0.5935 	Validation Prec@1 80.770 	Validation Prec@5 98.890 	
2019-05-03 16:59:22 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:59:22 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:59:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:59:22 - INFO - TRAINING - Epoch: [171][0/500]	Time 0.266 (0.266)	Data 0.244 (0.244)	Loss 0.5814 (0.5814)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:23 - INFO - TRAINING - Epoch: [171][50/500]	Time 0.025 (0.025)	Data 0.000 (0.005)	Loss 0.4756 (0.5301)	Prec@1 83.000 (81.804)	Prec@5 100.000 (99.196)
2019-05-03 16:59:24 - INFO - TRAINING - Epoch: [171][100/500]	Time 0.019 (0.023)	Data 0.000 (0.003)	Loss 0.4739 (0.5306)	Prec@1 85.000 (82.139)	Prec@5 100.000 (99.079)
2019-05-03 16:59:25 - INFO - TRAINING - Epoch: [171][150/500]	Time 0.027 (0.022)	Data 0.000 (0.002)	Loss 0.6111 (0.5365)	Prec@1 80.000 (82.099)	Prec@5 97.000 (99.046)
2019-05-03 16:59:26 - INFO - TRAINING - Epoch: [171][200/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.4534 (0.5342)	Prec@1 86.000 (82.209)	Prec@5 98.000 (99.090)
2019-05-03 16:59:27 - INFO - TRAINING - Epoch: [171][250/500]	Time 0.025 (0.022)	Data 0.000 (0.001)	Loss 0.5159 (0.5282)	Prec@1 82.000 (82.327)	Prec@5 98.000 (99.124)
2019-05-03 16:59:28 - INFO - TRAINING - Epoch: [171][300/500]	Time 0.024 (0.022)	Data 0.000 (0.001)	Loss 0.4573 (0.5260)	Prec@1 88.000 (82.379)	Prec@5 98.000 (99.153)
2019-05-03 16:59:29 - INFO - TRAINING - Epoch: [171][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.6525 (0.5249)	Prec@1 78.000 (82.467)	Prec@5 99.000 (99.148)
2019-05-03 16:59:30 - INFO - TRAINING - Epoch: [171][400/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5275 (0.5244)	Prec@1 82.000 (82.469)	Prec@5 98.000 (99.155)
2019-05-03 16:59:31 - INFO - TRAINING - Epoch: [171][450/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5554 (0.5289)	Prec@1 83.000 (82.375)	Prec@5 99.000 (99.162)
2019-05-03 16:59:32 - INFO - EVALUATING - Epoch: [171][0/100]	Time 0.268 (0.268)	Data 0.255 (0.255)	Loss 0.4643 (0.4643)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:33 - INFO - EVALUATING - Epoch: [171][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 0.6001 (0.5865)	Prec@1 83.000 (80.902)	Prec@5 96.000 (98.804)
2019-05-03 16:59:33 - INFO - 
 Epoch: 172	Training Loss 0.5277 	Training Prec@1 82.438 	Training Prec@5 99.166 	Validation Loss 0.5835 	Validation Prec@1 81.010 	Validation Prec@5 98.810 	
2019-05-03 16:59:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:59:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:59:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:59:33 - INFO - TRAINING - Epoch: [172][0/500]	Time 0.277 (0.277)	Data 0.254 (0.254)	Loss 0.4700 (0.4700)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:35 - INFO - TRAINING - Epoch: [172][50/500]	Time 0.023 (0.026)	Data 0.000 (0.005)	Loss 0.6180 (0.5353)	Prec@1 80.000 (82.373)	Prec@5 98.000 (99.098)
2019-05-03 16:59:36 - INFO - TRAINING - Epoch: [172][100/500]	Time 0.020 (0.023)	Data 0.000 (0.003)	Loss 0.6965 (0.5293)	Prec@1 74.000 (82.475)	Prec@5 100.000 (99.178)
2019-05-03 16:59:37 - INFO - TRAINING - Epoch: [172][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.5154 (0.5228)	Prec@1 83.000 (82.609)	Prec@5 99.000 (99.179)
2019-05-03 16:59:37 - INFO - TRAINING - Epoch: [172][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4343 (0.5258)	Prec@1 84.000 (82.458)	Prec@5 100.000 (99.209)
2019-05-03 16:59:38 - INFO - TRAINING - Epoch: [172][250/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.5238 (0.5268)	Prec@1 84.000 (82.474)	Prec@5 100.000 (99.219)
2019-05-03 16:59:39 - INFO - TRAINING - Epoch: [172][300/500]	Time 0.031 (0.021)	Data 0.000 (0.001)	Loss 0.5535 (0.5260)	Prec@1 84.000 (82.435)	Prec@5 99.000 (99.203)
2019-05-03 16:59:40 - INFO - TRAINING - Epoch: [172][350/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.6125 (0.5243)	Prec@1 83.000 (82.538)	Prec@5 100.000 (99.199)
2019-05-03 16:59:41 - INFO - TRAINING - Epoch: [172][400/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.3758 (0.5300)	Prec@1 86.000 (82.339)	Prec@5 100.000 (99.195)
2019-05-03 16:59:42 - INFO - TRAINING - Epoch: [172][450/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.4602 (0.5276)	Prec@1 86.000 (82.428)	Prec@5 100.000 (99.204)
2019-05-03 16:59:44 - INFO - EVALUATING - Epoch: [172][0/100]	Time 0.420 (0.420)	Data 0.412 (0.412)	Loss 0.4865 (0.4865)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 16:59:44 - INFO - EVALUATING - Epoch: [172][50/100]	Time 0.007 (0.014)	Data 0.000 (0.008)	Loss 0.5215 (0.5926)	Prec@1 84.000 (81.020)	Prec@5 97.000 (98.765)
2019-05-03 16:59:44 - INFO - 
 Epoch: 173	Training Loss 0.5271 	Training Prec@1 82.468 	Training Prec@5 99.210 	Validation Loss 0.5923 	Validation Prec@1 80.580 	Validation Prec@5 98.920 	
2019-05-03 16:59:45 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:59:45 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:59:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:59:45 - INFO - TRAINING - Epoch: [173][0/500]	Time 0.262 (0.262)	Data 0.232 (0.232)	Loss 0.4963 (0.4963)	Prec@1 87.000 (87.000)	Prec@5 97.000 (97.000)
2019-05-03 16:59:46 - INFO - TRAINING - Epoch: [173][50/500]	Time 0.019 (0.024)	Data 0.000 (0.005)	Loss 0.5324 (0.5443)	Prec@1 83.000 (82.118)	Prec@5 99.000 (99.255)
2019-05-03 16:59:47 - INFO - TRAINING - Epoch: [173][100/500]	Time 0.025 (0.023)	Data 0.000 (0.002)	Loss 0.4338 (0.5356)	Prec@1 83.000 (82.158)	Prec@5 100.000 (99.139)
2019-05-03 16:59:48 - INFO - TRAINING - Epoch: [173][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.4263 (0.5228)	Prec@1 89.000 (82.490)	Prec@5 100.000 (99.238)
2019-05-03 16:59:49 - INFO - TRAINING - Epoch: [173][200/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.7071 (0.5220)	Prec@1 75.000 (82.697)	Prec@5 98.000 (99.174)
2019-05-03 16:59:50 - INFO - TRAINING - Epoch: [173][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6352 (0.5244)	Prec@1 76.000 (82.629)	Prec@5 98.000 (99.151)
2019-05-03 16:59:51 - INFO - TRAINING - Epoch: [173][300/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5621 (0.5274)	Prec@1 81.000 (82.512)	Prec@5 98.000 (99.149)
2019-05-03 16:59:52 - INFO - TRAINING - Epoch: [173][350/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.6961 (0.5262)	Prec@1 81.000 (82.467)	Prec@5 99.000 (99.179)
2019-05-03 16:59:53 - INFO - TRAINING - Epoch: [173][400/500]	Time 0.033 (0.021)	Data 0.000 (0.001)	Loss 0.4873 (0.5254)	Prec@1 85.000 (82.559)	Prec@5 98.000 (99.162)
2019-05-03 16:59:54 - INFO - TRAINING - Epoch: [173][450/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5450 (0.5263)	Prec@1 80.000 (82.488)	Prec@5 100.000 (99.149)
2019-05-03 16:59:55 - INFO - EVALUATING - Epoch: [173][0/100]	Time 0.256 (0.256)	Data 0.250 (0.250)	Loss 0.5716 (0.5716)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 16:59:55 - INFO - EVALUATING - Epoch: [173][50/100]	Time 0.005 (0.011)	Data 0.000 (0.005)	Loss 0.4649 (0.5895)	Prec@1 84.000 (80.314)	Prec@5 97.000 (98.902)
2019-05-03 16:59:56 - INFO - 
 Epoch: 174	Training Loss 0.5264 	Training Prec@1 82.464 	Training Prec@5 99.128 	Validation Loss 0.5983 	Validation Prec@1 80.150 	Validation Prec@5 98.950 	
2019-05-03 16:59:56 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 16:59:56 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 16:59:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 16:59:56 - INFO - TRAINING - Epoch: [174][0/500]	Time 0.288 (0.288)	Data 0.264 (0.264)	Loss 0.5120 (0.5120)	Prec@1 79.000 (79.000)	Prec@5 100.000 (100.000)
2019-05-03 16:59:57 - INFO - TRAINING - Epoch: [174][50/500]	Time 0.025 (0.024)	Data 0.000 (0.005)	Loss 0.2853 (0.5303)	Prec@1 92.000 (82.000)	Prec@5 99.000 (99.118)
2019-05-03 16:59:58 - INFO - TRAINING - Epoch: [174][100/500]	Time 0.019 (0.022)	Data 0.000 (0.003)	Loss 0.3171 (0.5245)	Prec@1 91.000 (82.406)	Prec@5 100.000 (99.158)
2019-05-03 16:59:59 - INFO - TRAINING - Epoch: [174][150/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.6305 (0.5209)	Prec@1 80.000 (82.556)	Prec@5 99.000 (99.185)
2019-05-03 17:00:00 - INFO - TRAINING - Epoch: [174][200/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4684 (0.5236)	Prec@1 84.000 (82.612)	Prec@5 99.000 (99.184)
2019-05-03 17:00:01 - INFO - TRAINING - Epoch: [174][250/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.5537 (0.5214)	Prec@1 76.000 (82.641)	Prec@5 100.000 (99.235)
2019-05-03 17:00:02 - INFO - TRAINING - Epoch: [174][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6159 (0.5245)	Prec@1 76.000 (82.495)	Prec@5 98.000 (99.196)
2019-05-03 17:00:03 - INFO - TRAINING - Epoch: [174][350/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.4502 (0.5232)	Prec@1 84.000 (82.527)	Prec@5 99.000 (99.182)
2019-05-03 17:00:04 - INFO - TRAINING - Epoch: [174][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.7056 (0.5269)	Prec@1 80.000 (82.441)	Prec@5 98.000 (99.195)
2019-05-03 17:00:05 - INFO - TRAINING - Epoch: [174][450/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.4250 (0.5254)	Prec@1 86.000 (82.532)	Prec@5 100.000 (99.195)
2019-05-03 17:00:06 - INFO - EVALUATING - Epoch: [174][0/100]	Time 0.237 (0.237)	Data 0.228 (0.228)	Loss 0.8304 (0.8304)	Prec@1 73.000 (73.000)	Prec@5 99.000 (99.000)
2019-05-03 17:00:07 - INFO - EVALUATING - Epoch: [174][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 0.5193 (0.6611)	Prec@1 83.000 (78.235)	Prec@5 97.000 (98.686)
2019-05-03 17:00:07 - INFO - 
 Epoch: 175	Training Loss 0.5274 	Training Prec@1 82.494 	Training Prec@5 99.200 	Validation Loss 0.6571 	Validation Prec@1 78.550 	Validation Prec@5 98.810 	
2019-05-03 17:00:07 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:00:07 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:00:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:00:07 - INFO - TRAINING - Epoch: [175][0/500]	Time 0.272 (0.272)	Data 0.243 (0.243)	Loss 0.6096 (0.6096)	Prec@1 76.000 (76.000)	Prec@5 99.000 (99.000)
2019-05-03 17:00:08 - INFO - TRAINING - Epoch: [175][50/500]	Time 0.024 (0.024)	Data 0.000 (0.005)	Loss 0.4991 (0.5206)	Prec@1 85.000 (81.784)	Prec@5 98.000 (99.235)
2019-05-03 17:00:09 - INFO - TRAINING - Epoch: [175][100/500]	Time 0.024 (0.023)	Data 0.000 (0.003)	Loss 0.4540 (0.5248)	Prec@1 85.000 (82.099)	Prec@5 100.000 (99.287)
2019-05-03 17:00:10 - INFO - TRAINING - Epoch: [175][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.4835 (0.5203)	Prec@1 85.000 (82.417)	Prec@5 100.000 (99.225)
2019-05-03 17:00:11 - INFO - TRAINING - Epoch: [175][200/500]	Time 0.020 (0.022)	Data 0.000 (0.001)	Loss 0.4211 (0.5190)	Prec@1 84.000 (82.473)	Prec@5 100.000 (99.209)
2019-05-03 17:00:12 - INFO - TRAINING - Epoch: [175][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5710 (0.5229)	Prec@1 80.000 (82.371)	Prec@5 98.000 (99.171)
2019-05-03 17:00:13 - INFO - TRAINING - Epoch: [175][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5942 (0.5222)	Prec@1 83.000 (82.468)	Prec@5 100.000 (99.169)
2019-05-03 17:00:14 - INFO - TRAINING - Epoch: [175][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4974 (0.5205)	Prec@1 83.000 (82.584)	Prec@5 99.000 (99.162)
2019-05-03 17:00:15 - INFO - TRAINING - Epoch: [175][400/500]	Time 0.028 (0.021)	Data 0.000 (0.001)	Loss 0.4946 (0.5231)	Prec@1 84.000 (82.501)	Prec@5 99.000 (99.167)
2019-05-03 17:00:16 - INFO - TRAINING - Epoch: [175][450/500]	Time 0.011 (0.021)	Data 0.000 (0.001)	Loss 0.4219 (0.5231)	Prec@1 84.000 (82.550)	Prec@5 100.000 (99.184)
2019-05-03 17:00:18 - INFO - EVALUATING - Epoch: [175][0/100]	Time 0.340 (0.340)	Data 0.331 (0.331)	Loss 0.6977 (0.6977)	Prec@1 78.000 (78.000)	Prec@5 96.000 (96.000)
2019-05-03 17:00:18 - INFO - EVALUATING - Epoch: [175][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.7348 (0.7484)	Prec@1 76.000 (75.922)	Prec@5 96.000 (97.725)
2019-05-03 17:00:18 - INFO - 
 Epoch: 176	Training Loss 0.5243 	Training Prec@1 82.558 	Training Prec@5 99.176 	Validation Loss 0.7519 	Validation Prec@1 75.860 	Validation Prec@5 97.850 	
2019-05-03 17:00:18 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:00:18 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:00:18 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:00:19 - INFO - TRAINING - Epoch: [176][0/500]	Time 0.262 (0.262)	Data 0.234 (0.234)	Loss 0.3738 (0.3738)	Prec@1 91.000 (91.000)	Prec@5 100.000 (100.000)
2019-05-03 17:00:20 - INFO - TRAINING - Epoch: [176][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.4429 (0.5254)	Prec@1 86.000 (82.961)	Prec@5 100.000 (98.980)
2019-05-03 17:00:21 - INFO - TRAINING - Epoch: [176][100/500]	Time 0.014 (0.022)	Data 0.000 (0.002)	Loss 0.5173 (0.5393)	Prec@1 82.000 (82.188)	Prec@5 99.000 (98.871)
2019-05-03 17:00:22 - INFO - TRAINING - Epoch: [176][150/500]	Time 0.025 (0.021)	Data 0.000 (0.002)	Loss 0.5524 (0.5307)	Prec@1 79.000 (82.430)	Prec@5 98.000 (98.960)
2019-05-03 17:00:22 - INFO - TRAINING - Epoch: [176][200/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5022 (0.5284)	Prec@1 81.000 (82.537)	Prec@5 99.000 (98.980)
2019-05-03 17:00:24 - INFO - TRAINING - Epoch: [176][250/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6265 (0.5316)	Prec@1 78.000 (82.498)	Prec@5 99.000 (98.932)
2019-05-03 17:00:24 - INFO - TRAINING - Epoch: [176][300/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.5401 (0.5312)	Prec@1 82.000 (82.455)	Prec@5 98.000 (99.000)
2019-05-03 17:00:26 - INFO - TRAINING - Epoch: [176][350/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5531 (0.5328)	Prec@1 83.000 (82.396)	Prec@5 99.000 (99.031)
2019-05-03 17:00:27 - INFO - TRAINING - Epoch: [176][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4495 (0.5312)	Prec@1 86.000 (82.424)	Prec@5 100.000 (99.070)
2019-05-03 17:00:28 - INFO - TRAINING - Epoch: [176][450/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.6036 (0.5343)	Prec@1 82.000 (82.344)	Prec@5 97.000 (99.093)
2019-05-03 17:00:29 - INFO - EVALUATING - Epoch: [176][0/100]	Time 0.364 (0.364)	Data 0.352 (0.352)	Loss 0.6288 (0.6288)	Prec@1 76.000 (76.000)	Prec@5 97.000 (97.000)
2019-05-03 17:00:29 - INFO - EVALUATING - Epoch: [176][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.5723 (0.6587)	Prec@1 85.000 (78.647)	Prec@5 97.000 (98.431)
2019-05-03 17:00:29 - INFO - 
 Epoch: 177	Training Loss 0.5316 	Training Prec@1 82.446 	Training Prec@5 99.100 	Validation Loss 0.6590 	Validation Prec@1 78.440 	Validation Prec@5 98.560 	
2019-05-03 17:00:30 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:00:30 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:00:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:00:30 - INFO - TRAINING - Epoch: [177][0/500]	Time 0.266 (0.266)	Data 0.244 (0.244)	Loss 0.4997 (0.4997)	Prec@1 86.000 (86.000)	Prec@5 98.000 (98.000)
2019-05-03 17:00:31 - INFO - TRAINING - Epoch: [177][50/500]	Time 0.014 (0.025)	Data 0.000 (0.005)	Loss 0.6040 (0.5258)	Prec@1 82.000 (82.765)	Prec@5 99.000 (99.137)
2019-05-03 17:00:32 - INFO - TRAINING - Epoch: [177][100/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.5051 (0.5191)	Prec@1 84.000 (82.881)	Prec@5 100.000 (99.168)
2019-05-03 17:00:33 - INFO - TRAINING - Epoch: [177][150/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.4872 (0.5140)	Prec@1 85.000 (83.053)	Prec@5 100.000 (99.199)
2019-05-03 17:00:34 - INFO - TRAINING - Epoch: [177][200/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5257 (0.5115)	Prec@1 78.000 (82.935)	Prec@5 99.000 (99.224)
2019-05-03 17:00:35 - INFO - TRAINING - Epoch: [177][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4638 (0.5139)	Prec@1 84.000 (82.876)	Prec@5 100.000 (99.235)
2019-05-03 17:00:36 - INFO - TRAINING - Epoch: [177][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.6483 (0.5174)	Prec@1 81.000 (82.857)	Prec@5 100.000 (99.213)
2019-05-03 17:00:37 - INFO - TRAINING - Epoch: [177][350/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.4600 (0.5147)	Prec@1 85.000 (82.917)	Prec@5 100.000 (99.242)
2019-05-03 17:00:38 - INFO - TRAINING - Epoch: [177][400/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.4876 (0.5166)	Prec@1 83.000 (82.843)	Prec@5 100.000 (99.222)
2019-05-03 17:00:39 - INFO - TRAINING - Epoch: [177][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6324 (0.5161)	Prec@1 79.000 (82.856)	Prec@5 99.000 (99.215)
2019-05-03 17:00:40 - INFO - EVALUATING - Epoch: [177][0/100]	Time 0.270 (0.270)	Data 0.256 (0.256)	Loss 0.6088 (0.6088)	Prec@1 82.000 (82.000)	Prec@5 98.000 (98.000)
2019-05-03 17:00:40 - INFO - EVALUATING - Epoch: [177][50/100]	Time 0.004 (0.011)	Data 0.000 (0.005)	Loss 0.5895 (0.5833)	Prec@1 83.000 (81.118)	Prec@5 97.000 (98.784)
2019-05-03 17:00:41 - INFO - 
 Epoch: 178	Training Loss 0.5184 	Training Prec@1 82.802 	Training Prec@5 99.218 	Validation Loss 0.5812 	Validation Prec@1 81.200 	Validation Prec@5 98.910 	
2019-05-03 17:00:41 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:00:41 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:00:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:00:41 - INFO - TRAINING - Epoch: [178][0/500]	Time 0.268 (0.268)	Data 0.237 (0.237)	Loss 0.4632 (0.4632)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 17:00:42 - INFO - TRAINING - Epoch: [178][50/500]	Time 0.016 (0.023)	Data 0.000 (0.005)	Loss 0.4098 (0.5293)	Prec@1 86.000 (81.863)	Prec@5 99.000 (99.255)
2019-05-03 17:00:43 - INFO - TRAINING - Epoch: [178][100/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6583 (0.5333)	Prec@1 75.000 (82.079)	Prec@5 97.000 (99.149)
2019-05-03 17:00:44 - INFO - TRAINING - Epoch: [178][150/500]	Time 0.021 (0.022)	Data 0.000 (0.002)	Loss 0.6315 (0.5287)	Prec@1 77.000 (82.073)	Prec@5 99.000 (99.225)
2019-05-03 17:00:45 - INFO - TRAINING - Epoch: [178][200/500]	Time 0.018 (0.022)	Data 0.000 (0.001)	Loss 0.5781 (0.5251)	Prec@1 80.000 (82.299)	Prec@5 99.000 (99.204)
2019-05-03 17:00:46 - INFO - TRAINING - Epoch: [178][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4777 (0.5253)	Prec@1 79.000 (82.319)	Prec@5 100.000 (99.207)
2019-05-03 17:00:47 - INFO - TRAINING - Epoch: [178][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.5186 (0.5218)	Prec@1 82.000 (82.452)	Prec@5 98.000 (99.246)
2019-05-03 17:00:48 - INFO - TRAINING - Epoch: [178][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4085 (0.5214)	Prec@1 85.000 (82.576)	Prec@5 99.000 (99.231)
2019-05-03 17:00:49 - INFO - TRAINING - Epoch: [178][400/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5478 (0.5192)	Prec@1 78.000 (82.688)	Prec@5 99.000 (99.224)
2019-05-03 17:00:50 - INFO - TRAINING - Epoch: [178][450/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5116 (0.5165)	Prec@1 86.000 (82.818)	Prec@5 97.000 (99.226)
2019-05-03 17:00:51 - INFO - EVALUATING - Epoch: [178][0/100]	Time 0.327 (0.327)	Data 0.316 (0.316)	Loss 0.8040 (0.8040)	Prec@1 75.000 (75.000)	Prec@5 99.000 (99.000)
2019-05-03 17:00:52 - INFO - EVALUATING - Epoch: [178][50/100]	Time 0.004 (0.012)	Data 0.000 (0.006)	Loss 0.6084 (0.7129)	Prec@1 79.000 (77.196)	Prec@5 97.000 (98.451)
2019-05-03 17:00:52 - INFO - 
 Epoch: 179	Training Loss 0.5183 	Training Prec@1 82.798 	Training Prec@5 99.202 	Validation Loss 0.7000 	Validation Prec@1 77.730 	Validation Prec@5 98.610 	
2019-05-03 17:00:52 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:00:52 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:00:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:00:52 - INFO - TRAINING - Epoch: [179][0/500]	Time 0.246 (0.246)	Data 0.227 (0.227)	Loss 0.4904 (0.4904)	Prec@1 85.000 (85.000)	Prec@5 100.000 (100.000)
2019-05-03 17:00:53 - INFO - TRAINING - Epoch: [179][50/500]	Time 0.023 (0.024)	Data 0.000 (0.005)	Loss 0.7006 (0.5281)	Prec@1 78.000 (82.569)	Prec@5 99.000 (99.216)
2019-05-03 17:00:54 - INFO - TRAINING - Epoch: [179][100/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.7023 (0.5307)	Prec@1 78.000 (82.723)	Prec@5 100.000 (99.178)
2019-05-03 17:00:55 - INFO - TRAINING - Epoch: [179][150/500]	Time 0.026 (0.022)	Data 0.000 (0.002)	Loss 0.5366 (0.5340)	Prec@1 82.000 (82.437)	Prec@5 99.000 (99.139)
2019-05-03 17:00:56 - INFO - TRAINING - Epoch: [179][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.4441 (0.5308)	Prec@1 86.000 (82.557)	Prec@5 99.000 (99.134)
2019-05-03 17:00:57 - INFO - TRAINING - Epoch: [179][250/500]	Time 0.026 (0.021)	Data 0.000 (0.001)	Loss 0.5555 (0.5333)	Prec@1 84.000 (82.542)	Prec@5 97.000 (99.124)
2019-05-03 17:00:59 - INFO - TRAINING - Epoch: [179][300/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.4456 (0.5316)	Prec@1 85.000 (82.628)	Prec@5 99.000 (99.159)
2019-05-03 17:00:59 - INFO - TRAINING - Epoch: [179][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.3948 (0.5321)	Prec@1 87.000 (82.556)	Prec@5 100.000 (99.160)
2019-05-03 17:01:01 - INFO - TRAINING - Epoch: [179][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.4904 (0.5291)	Prec@1 85.000 (82.663)	Prec@5 100.000 (99.157)
2019-05-03 17:01:01 - INFO - TRAINING - Epoch: [179][450/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5467 (0.5251)	Prec@1 80.000 (82.763)	Prec@5 100.000 (99.171)
2019-05-03 17:01:03 - INFO - EVALUATING - Epoch: [179][0/100]	Time 0.358 (0.358)	Data 0.342 (0.342)	Loss 0.6117 (0.6117)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 17:01:03 - INFO - EVALUATING - Epoch: [179][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.5976 (0.6074)	Prec@1 83.000 (80.314)	Prec@5 97.000 (98.745)
2019-05-03 17:01:03 - INFO - 
 Epoch: 180	Training Loss 0.5272 	Training Prec@1 82.674 	Training Prec@5 99.166 	Validation Loss 0.6085 	Validation Prec@1 80.050 	Validation Prec@5 98.840 	
2019-05-03 17:01:03 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:03 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:04 - INFO - TRAINING - Epoch: [180][0/500]	Time 0.249 (0.249)	Data 0.225 (0.225)	Loss 0.6773 (0.6773)	Prec@1 74.000 (74.000)	Prec@5 100.000 (100.000)
2019-05-03 17:01:05 - INFO - TRAINING - Epoch: [180][50/500]	Time 0.027 (0.026)	Data 0.000 (0.005)	Loss 0.4356 (0.4998)	Prec@1 85.000 (83.314)	Prec@5 100.000 (99.314)
2019-05-03 17:01:06 - INFO - TRAINING - Epoch: [180][100/500]	Time 0.025 (0.023)	Data 0.000 (0.002)	Loss 0.4778 (0.5100)	Prec@1 86.000 (83.119)	Prec@5 99.000 (99.307)
2019-05-03 17:01:07 - INFO - TRAINING - Epoch: [180][150/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.5613 (0.5176)	Prec@1 82.000 (82.801)	Prec@5 98.000 (99.245)
2019-05-03 17:01:08 - INFO - TRAINING - Epoch: [180][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.7285 (0.5157)	Prec@1 77.000 (82.851)	Prec@5 99.000 (99.234)
2019-05-03 17:01:09 - INFO - TRAINING - Epoch: [180][250/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5367 (0.5191)	Prec@1 85.000 (82.829)	Prec@5 98.000 (99.191)
2019-05-03 17:01:10 - INFO - TRAINING - Epoch: [180][300/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4263 (0.5172)	Prec@1 86.000 (82.894)	Prec@5 100.000 (99.159)
2019-05-03 17:01:11 - INFO - TRAINING - Epoch: [180][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.4608 (0.5169)	Prec@1 87.000 (82.892)	Prec@5 99.000 (99.165)
2019-05-03 17:01:12 - INFO - TRAINING - Epoch: [180][400/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5108 (0.5194)	Prec@1 81.000 (82.810)	Prec@5 99.000 (99.162)
2019-05-03 17:01:13 - INFO - TRAINING - Epoch: [180][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.3342 (0.5184)	Prec@1 90.000 (82.840)	Prec@5 100.000 (99.173)
2019-05-03 17:01:14 - INFO - EVALUATING - Epoch: [180][0/100]	Time 0.357 (0.357)	Data 0.351 (0.351)	Loss 0.5531 (0.5531)	Prec@1 80.000 (80.000)	Prec@5 99.000 (99.000)
2019-05-03 17:01:14 - INFO - EVALUATING - Epoch: [180][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5370 (0.5840)	Prec@1 86.000 (80.843)	Prec@5 97.000 (98.588)
2019-05-03 17:01:15 - INFO - 
 Epoch: 181	Training Loss 0.5178 	Training Prec@1 82.854 	Training Prec@5 99.186 	Validation Loss 0.5841 	Validation Prec@1 80.920 	Validation Prec@5 98.750 	
2019-05-03 17:01:15 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:15 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:15 - INFO - TRAINING - Epoch: [181][0/500]	Time 0.261 (0.261)	Data 0.239 (0.239)	Loss 0.4435 (0.4435)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 17:01:16 - INFO - TRAINING - Epoch: [181][50/500]	Time 0.015 (0.024)	Data 0.000 (0.005)	Loss 0.4299 (0.5251)	Prec@1 87.000 (82.627)	Prec@5 100.000 (99.216)
2019-05-03 17:01:17 - INFO - TRAINING - Epoch: [181][100/500]	Time 0.015 (0.022)	Data 0.000 (0.002)	Loss 0.6243 (0.5335)	Prec@1 82.000 (82.287)	Prec@5 97.000 (99.119)
2019-05-03 17:01:18 - INFO - TRAINING - Epoch: [181][150/500]	Time 0.017 (0.022)	Data 0.000 (0.002)	Loss 0.4980 (0.5290)	Prec@1 83.000 (82.351)	Prec@5 99.000 (99.106)
2019-05-03 17:01:19 - INFO - TRAINING - Epoch: [181][200/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.4507 (0.5216)	Prec@1 82.000 (82.667)	Prec@5 100.000 (99.159)
2019-05-03 17:01:20 - INFO - TRAINING - Epoch: [181][250/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4494 (0.5186)	Prec@1 87.000 (82.709)	Prec@5 100.000 (99.187)
2019-05-03 17:01:21 - INFO - TRAINING - Epoch: [181][300/500]	Time 0.017 (0.021)	Data 0.000 (0.001)	Loss 0.5198 (0.5220)	Prec@1 85.000 (82.678)	Prec@5 98.000 (99.183)
2019-05-03 17:01:22 - INFO - TRAINING - Epoch: [181][350/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6038 (0.5239)	Prec@1 78.000 (82.570)	Prec@5 100.000 (99.185)
2019-05-03 17:01:23 - INFO - TRAINING - Epoch: [181][400/500]	Time 0.028 (0.020)	Data 0.000 (0.001)	Loss 0.4902 (0.5205)	Prec@1 84.000 (82.668)	Prec@5 100.000 (99.209)
2019-05-03 17:01:24 - INFO - TRAINING - Epoch: [181][450/500]	Time 0.012 (0.020)	Data 0.000 (0.001)	Loss 0.4753 (0.5190)	Prec@1 83.000 (82.712)	Prec@5 100.000 (99.217)
2019-05-03 17:01:25 - INFO - EVALUATING - Epoch: [181][0/100]	Time 0.272 (0.272)	Data 0.262 (0.262)	Loss 0.6229 (0.6229)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 17:01:25 - INFO - EVALUATING - Epoch: [181][50/100]	Time 0.006 (0.011)	Data 0.000 (0.005)	Loss 0.6051 (0.6612)	Prec@1 83.000 (78.569)	Prec@5 97.000 (98.627)
2019-05-03 17:01:26 - INFO - 
 Epoch: 182	Training Loss 0.5166 	Training Prec@1 82.774 	Training Prec@5 99.218 	Validation Loss 0.6608 	Validation Prec@1 78.440 	Validation Prec@5 98.740 	
2019-05-03 17:01:26 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:26 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:26 - INFO - TRAINING - Epoch: [182][0/500]	Time 0.280 (0.280)	Data 0.259 (0.259)	Loss 0.6677 (0.6677)	Prec@1 82.000 (82.000)	Prec@5 97.000 (97.000)
2019-05-03 17:01:27 - INFO - TRAINING - Epoch: [182][50/500]	Time 0.017 (0.025)	Data 0.000 (0.005)	Loss 0.3872 (0.5135)	Prec@1 84.000 (82.961)	Prec@5 100.000 (99.275)
2019-05-03 17:01:28 - INFO - TRAINING - Epoch: [182][100/500]	Time 0.018 (0.022)	Data 0.000 (0.003)	Loss 0.7337 (0.5267)	Prec@1 77.000 (82.634)	Prec@5 99.000 (99.158)
2019-05-03 17:01:29 - INFO - TRAINING - Epoch: [182][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.5177 (0.5301)	Prec@1 82.000 (82.417)	Prec@5 100.000 (99.159)
2019-05-03 17:01:30 - INFO - TRAINING - Epoch: [182][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5494 (0.5361)	Prec@1 83.000 (82.174)	Prec@5 99.000 (99.164)
2019-05-03 17:01:31 - INFO - TRAINING - Epoch: [182][250/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.5756 (0.5320)	Prec@1 83.000 (82.426)	Prec@5 99.000 (99.183)
2019-05-03 17:01:32 - INFO - TRAINING - Epoch: [182][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5274 (0.5268)	Prec@1 82.000 (82.565)	Prec@5 98.000 (99.186)
2019-05-03 17:01:33 - INFO - TRAINING - Epoch: [182][350/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4888 (0.5214)	Prec@1 85.000 (82.721)	Prec@5 100.000 (99.202)
2019-05-03 17:01:34 - INFO - TRAINING - Epoch: [182][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.4679 (0.5231)	Prec@1 80.000 (82.663)	Prec@5 100.000 (99.180)
2019-05-03 17:01:35 - INFO - TRAINING - Epoch: [182][450/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5358 (0.5249)	Prec@1 82.000 (82.616)	Prec@5 99.000 (99.166)
2019-05-03 17:01:36 - INFO - EVALUATING - Epoch: [182][0/100]	Time 0.314 (0.314)	Data 0.304 (0.304)	Loss 0.5791 (0.5791)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 17:01:37 - INFO - EVALUATING - Epoch: [182][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5179 (0.6201)	Prec@1 80.000 (79.608)	Prec@5 97.000 (98.529)
2019-05-03 17:01:37 - INFO - 
 Epoch: 183	Training Loss 0.5247 	Training Prec@1 82.602 	Training Prec@5 99.180 	Validation Loss 0.6196 	Validation Prec@1 79.500 	Validation Prec@5 98.730 	
2019-05-03 17:01:37 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:37 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:37 - INFO - TRAINING - Epoch: [183][0/500]	Time 0.259 (0.259)	Data 0.236 (0.236)	Loss 0.4890 (0.4890)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 17:01:38 - INFO - TRAINING - Epoch: [183][50/500]	Time 0.018 (0.023)	Data 0.000 (0.005)	Loss 0.6855 (0.5459)	Prec@1 75.000 (82.078)	Prec@5 100.000 (99.020)
2019-05-03 17:01:39 - INFO - TRAINING - Epoch: [183][100/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.5211 (0.5297)	Prec@1 80.000 (82.465)	Prec@5 99.000 (99.168)
2019-05-03 17:01:40 - INFO - TRAINING - Epoch: [183][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.5885 (0.5261)	Prec@1 79.000 (82.556)	Prec@5 99.000 (99.192)
2019-05-03 17:01:41 - INFO - TRAINING - Epoch: [183][200/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6420 (0.5229)	Prec@1 77.000 (82.592)	Prec@5 100.000 (99.204)
2019-05-03 17:01:42 - INFO - TRAINING - Epoch: [183][250/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.3325 (0.5183)	Prec@1 89.000 (82.761)	Prec@5 100.000 (99.215)
2019-05-03 17:01:43 - INFO - TRAINING - Epoch: [183][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4315 (0.5185)	Prec@1 85.000 (82.801)	Prec@5 100.000 (99.229)
2019-05-03 17:01:44 - INFO - TRAINING - Epoch: [183][350/500]	Time 0.027 (0.020)	Data 0.000 (0.001)	Loss 0.5886 (0.5214)	Prec@1 82.000 (82.772)	Prec@5 98.000 (99.214)
2019-05-03 17:01:45 - INFO - TRAINING - Epoch: [183][400/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.6848 (0.5201)	Prec@1 78.000 (82.838)	Prec@5 99.000 (99.200)
2019-05-03 17:01:46 - INFO - TRAINING - Epoch: [183][450/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.6157 (0.5206)	Prec@1 82.000 (82.803)	Prec@5 98.000 (99.193)
2019-05-03 17:01:47 - INFO - EVALUATING - Epoch: [183][0/100]	Time 0.315 (0.315)	Data 0.302 (0.302)	Loss 0.5881 (0.5881)	Prec@1 78.000 (78.000)	Prec@5 100.000 (100.000)
2019-05-03 17:01:48 - INFO - EVALUATING - Epoch: [183][50/100]	Time 0.008 (0.012)	Data 0.000 (0.006)	Loss 0.5007 (0.6004)	Prec@1 91.000 (80.412)	Prec@5 97.000 (98.843)
2019-05-03 17:01:48 - INFO - 
 Epoch: 184	Training Loss 0.5168 	Training Prec@1 82.944 	Training Prec@5 99.206 	Validation Loss 0.6007 	Validation Prec@1 80.480 	Validation Prec@5 98.890 	
2019-05-03 17:01:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:48 - INFO - TRAINING - Epoch: [184][0/500]	Time 0.272 (0.272)	Data 0.239 (0.239)	Loss 0.4842 (0.4842)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 17:01:50 - INFO - TRAINING - Epoch: [184][50/500]	Time 0.019 (0.026)	Data 0.000 (0.005)	Loss 0.5738 (0.5271)	Prec@1 82.000 (82.118)	Prec@5 99.000 (99.235)
2019-05-03 17:01:50 - INFO - TRAINING - Epoch: [184][100/500]	Time 0.023 (0.022)	Data 0.000 (0.002)	Loss 0.4265 (0.5243)	Prec@1 85.000 (82.356)	Prec@5 100.000 (99.208)
2019-05-03 17:01:51 - INFO - TRAINING - Epoch: [184][150/500]	Time 0.014 (0.021)	Data 0.000 (0.002)	Loss 0.4419 (0.5206)	Prec@1 81.000 (82.483)	Prec@5 100.000 (99.225)
2019-05-03 17:01:52 - INFO - TRAINING - Epoch: [184][200/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.5485 (0.5224)	Prec@1 85.000 (82.632)	Prec@5 97.000 (99.239)
2019-05-03 17:01:53 - INFO - TRAINING - Epoch: [184][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.4208 (0.5253)	Prec@1 89.000 (82.542)	Prec@5 99.000 (99.195)
2019-05-03 17:01:54 - INFO - TRAINING - Epoch: [184][300/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.6402 (0.5239)	Prec@1 75.000 (82.595)	Prec@5 100.000 (99.173)
2019-05-03 17:01:55 - INFO - TRAINING - Epoch: [184][350/500]	Time 0.024 (0.020)	Data 0.000 (0.001)	Loss 0.3219 (0.5236)	Prec@1 87.000 (82.615)	Prec@5 100.000 (99.182)
2019-05-03 17:01:56 - INFO - TRAINING - Epoch: [184][400/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.6219 (0.5237)	Prec@1 81.000 (82.626)	Prec@5 98.000 (99.177)
2019-05-03 17:01:57 - INFO - TRAINING - Epoch: [184][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5240 (0.5214)	Prec@1 83.000 (82.681)	Prec@5 100.000 (99.188)
2019-05-03 17:01:58 - INFO - EVALUATING - Epoch: [184][0/100]	Time 0.343 (0.343)	Data 0.331 (0.331)	Loss 0.5595 (0.5595)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 17:01:59 - INFO - EVALUATING - Epoch: [184][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6129 (0.5892)	Prec@1 82.000 (80.843)	Prec@5 98.000 (98.902)
2019-05-03 17:01:59 - INFO - 
 Epoch: 185	Training Loss 0.5223 	Training Prec@1 82.578 	Training Prec@5 99.180 	Validation Loss 0.5857 	Validation Prec@1 80.760 	Validation Prec@5 98.960 	
2019-05-03 17:01:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:01:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:01:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:01:59 - INFO - TRAINING - Epoch: [185][0/500]	Time 0.294 (0.294)	Data 0.263 (0.263)	Loss 0.5375 (0.5375)	Prec@1 85.000 (85.000)	Prec@5 99.000 (99.000)
2019-05-03 17:02:00 - INFO - TRAINING - Epoch: [185][50/500]	Time 0.020 (0.024)	Data 0.000 (0.005)	Loss 0.4607 (0.5031)	Prec@1 86.000 (83.157)	Prec@5 100.000 (99.373)
2019-05-03 17:02:01 - INFO - TRAINING - Epoch: [185][100/500]	Time 0.017 (0.021)	Data 0.000 (0.003)	Loss 0.5075 (0.5145)	Prec@1 83.000 (82.762)	Prec@5 100.000 (99.366)
2019-05-03 17:02:02 - INFO - TRAINING - Epoch: [185][150/500]	Time 0.016 (0.020)	Data 0.000 (0.002)	Loss 0.5833 (0.5130)	Prec@1 78.000 (82.834)	Prec@5 100.000 (99.338)
2019-05-03 17:02:03 - INFO - TRAINING - Epoch: [185][200/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 0.4774 (0.5181)	Prec@1 85.000 (82.736)	Prec@5 100.000 (99.274)
2019-05-03 17:02:04 - INFO - TRAINING - Epoch: [185][250/500]	Time 0.013 (0.019)	Data 0.000 (0.001)	Loss 0.6213 (0.5187)	Prec@1 81.000 (82.761)	Prec@5 97.000 (99.231)
2019-05-03 17:02:05 - INFO - TRAINING - Epoch: [185][300/500]	Time 0.028 (0.019)	Data 0.000 (0.001)	Loss 0.5415 (0.5154)	Prec@1 81.000 (82.864)	Prec@5 100.000 (99.282)
2019-05-03 17:02:06 - INFO - TRAINING - Epoch: [185][350/500]	Time 0.018 (0.019)	Data 0.000 (0.001)	Loss 0.5672 (0.5185)	Prec@1 80.000 (82.746)	Prec@5 100.000 (99.279)
2019-05-03 17:02:07 - INFO - TRAINING - Epoch: [185][400/500]	Time 0.016 (0.019)	Data 0.000 (0.001)	Loss 0.5117 (0.5184)	Prec@1 82.000 (82.756)	Prec@5 100.000 (99.272)
2019-05-03 17:02:08 - INFO - TRAINING - Epoch: [185][450/500]	Time 0.022 (0.019)	Data 0.000 (0.001)	Loss 0.5397 (0.5222)	Prec@1 84.000 (82.605)	Prec@5 98.000 (99.259)
2019-05-03 17:02:09 - INFO - EVALUATING - Epoch: [185][0/100]	Time 0.382 (0.382)	Data 0.372 (0.372)	Loss 0.6274 (0.6274)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 17:02:09 - INFO - EVALUATING - Epoch: [185][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.5950 (0.6384)	Prec@1 83.000 (79.961)	Prec@5 97.000 (98.667)
2019-05-03 17:02:09 - INFO - 
 Epoch: 186	Training Loss 0.5224 	Training Prec@1 82.618 	Training Prec@5 99.234 	Validation Loss 0.6293 	Validation Prec@1 79.710 	Validation Prec@5 98.750 	
2019-05-03 17:02:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:02:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:02:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:02:10 - INFO - TRAINING - Epoch: [186][0/500]	Time 0.274 (0.274)	Data 0.254 (0.254)	Loss 0.6915 (0.6915)	Prec@1 74.000 (74.000)	Prec@5 99.000 (99.000)
2019-05-03 17:02:11 - INFO - TRAINING - Epoch: [186][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.4907 (0.5356)	Prec@1 83.000 (82.314)	Prec@5 100.000 (98.941)
2019-05-03 17:02:12 - INFO - TRAINING - Epoch: [186][100/500]	Time 0.014 (0.021)	Data 0.000 (0.003)	Loss 0.3898 (0.5246)	Prec@1 85.000 (82.644)	Prec@5 100.000 (99.059)
2019-05-03 17:02:13 - INFO - TRAINING - Epoch: [186][150/500]	Time 0.021 (0.021)	Data 0.000 (0.002)	Loss 0.5552 (0.5244)	Prec@1 82.000 (82.775)	Prec@5 100.000 (99.126)
2019-05-03 17:02:14 - INFO - TRAINING - Epoch: [186][200/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.4945 (0.5240)	Prec@1 84.000 (82.711)	Prec@5 99.000 (99.164)
2019-05-03 17:02:15 - INFO - TRAINING - Epoch: [186][250/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.5644 (0.5204)	Prec@1 82.000 (82.689)	Prec@5 96.000 (99.207)
2019-05-03 17:02:16 - INFO - TRAINING - Epoch: [186][300/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5483 (0.5223)	Prec@1 85.000 (82.684)	Prec@5 99.000 (99.219)
2019-05-03 17:02:17 - INFO - TRAINING - Epoch: [186][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.6287 (0.5231)	Prec@1 81.000 (82.644)	Prec@5 100.000 (99.208)
2019-05-03 17:02:18 - INFO - TRAINING - Epoch: [186][400/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5448 (0.5220)	Prec@1 84.000 (82.636)	Prec@5 99.000 (99.197)
2019-05-03 17:02:19 - INFO - TRAINING - Epoch: [186][450/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.4395 (0.5210)	Prec@1 85.000 (82.661)	Prec@5 99.000 (99.186)
2019-05-03 17:02:20 - INFO - EVALUATING - Epoch: [186][0/100]	Time 0.329 (0.329)	Data 0.316 (0.316)	Loss 0.6529 (0.6529)	Prec@1 76.000 (76.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:20 - INFO - EVALUATING - Epoch: [186][50/100]	Time 0.003 (0.012)	Data 0.000 (0.006)	Loss 0.5441 (0.6312)	Prec@1 86.000 (79.471)	Prec@5 96.000 (98.373)
2019-05-03 17:02:21 - INFO - 
 Epoch: 187	Training Loss 0.5243 	Training Prec@1 82.562 	Training Prec@5 99.168 	Validation Loss 0.6238 	Validation Prec@1 79.670 	Validation Prec@5 98.580 	
2019-05-03 17:02:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:02:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:02:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:02:21 - INFO - TRAINING - Epoch: [187][0/500]	Time 0.281 (0.281)	Data 0.255 (0.255)	Loss 0.5762 (0.5762)	Prec@1 81.000 (81.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:22 - INFO - TRAINING - Epoch: [187][50/500]	Time 0.011 (0.026)	Data 0.000 (0.005)	Loss 0.4525 (0.5222)	Prec@1 84.000 (82.863)	Prec@5 100.000 (99.216)
2019-05-03 17:02:23 - INFO - TRAINING - Epoch: [187][100/500]	Time 0.016 (0.024)	Data 0.000 (0.003)	Loss 0.3905 (0.5226)	Prec@1 88.000 (82.762)	Prec@5 100.000 (99.218)
2019-05-03 17:02:24 - INFO - TRAINING - Epoch: [187][150/500]	Time 0.024 (0.022)	Data 0.000 (0.002)	Loss 0.5104 (0.5263)	Prec@1 81.000 (82.675)	Prec@5 99.000 (99.272)
2019-05-03 17:02:25 - INFO - TRAINING - Epoch: [187][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.7055 (0.5232)	Prec@1 76.000 (82.776)	Prec@5 99.000 (99.249)
2019-05-03 17:02:26 - INFO - TRAINING - Epoch: [187][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6008 (0.5274)	Prec@1 84.000 (82.637)	Prec@5 98.000 (99.263)
2019-05-03 17:02:27 - INFO - TRAINING - Epoch: [187][300/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.4522 (0.5291)	Prec@1 86.000 (82.598)	Prec@5 99.000 (99.216)
2019-05-03 17:02:28 - INFO - TRAINING - Epoch: [187][350/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.6316 (0.5281)	Prec@1 76.000 (82.644)	Prec@5 100.000 (99.185)
2019-05-03 17:02:29 - INFO - TRAINING - Epoch: [187][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.5230 (0.5261)	Prec@1 82.000 (82.686)	Prec@5 100.000 (99.177)
2019-05-03 17:02:29 - INFO - TRAINING - Epoch: [187][450/500]	Time 0.014 (0.019)	Data 0.000 (0.001)	Loss 0.3883 (0.5261)	Prec@1 90.000 (82.659)	Prec@5 99.000 (99.164)
2019-05-03 17:02:31 - INFO - EVALUATING - Epoch: [187][0/100]	Time 0.351 (0.351)	Data 0.342 (0.342)	Loss 0.5225 (0.5225)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 17:02:31 - INFO - EVALUATING - Epoch: [187][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.4519 (0.6318)	Prec@1 87.000 (78.745)	Prec@5 99.000 (98.686)
2019-05-03 17:02:31 - INFO - 
 Epoch: 188	Training Loss 0.5259 	Training Prec@1 82.692 	Training Prec@5 99.162 	Validation Loss 0.6266 	Validation Prec@1 78.980 	Validation Prec@5 98.780 	
2019-05-03 17:02:31 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:02:31 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:02:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:02:32 - INFO - TRAINING - Epoch: [188][0/500]	Time 0.267 (0.267)	Data 0.245 (0.245)	Loss 0.3498 (0.3498)	Prec@1 91.000 (91.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:32 - INFO - TRAINING - Epoch: [188][50/500]	Time 0.016 (0.021)	Data 0.000 (0.005)	Loss 0.6158 (0.5415)	Prec@1 80.000 (81.843)	Prec@5 100.000 (99.333)
2019-05-03 17:02:33 - INFO - TRAINING - Epoch: [188][100/500]	Time 0.020 (0.020)	Data 0.000 (0.003)	Loss 0.4696 (0.5216)	Prec@1 82.000 (82.911)	Prec@5 97.000 (99.109)
2019-05-03 17:02:34 - INFO - TRAINING - Epoch: [188][150/500]	Time 0.017 (0.020)	Data 0.000 (0.002)	Loss 0.3950 (0.5206)	Prec@1 87.000 (82.788)	Prec@5 100.000 (99.113)
2019-05-03 17:02:35 - INFO - TRAINING - Epoch: [188][200/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.5626 (0.5221)	Prec@1 82.000 (82.741)	Prec@5 99.000 (99.070)
2019-05-03 17:02:36 - INFO - TRAINING - Epoch: [188][250/500]	Time 0.021 (0.019)	Data 0.000 (0.001)	Loss 0.5471 (0.5180)	Prec@1 84.000 (82.876)	Prec@5 100.000 (99.127)
2019-05-03 17:02:37 - INFO - TRAINING - Epoch: [188][300/500]	Time 0.026 (0.019)	Data 0.000 (0.001)	Loss 0.5214 (0.5182)	Prec@1 81.000 (82.791)	Prec@5 99.000 (99.166)
2019-05-03 17:02:38 - INFO - TRAINING - Epoch: [188][350/500]	Time 0.013 (0.019)	Data 0.000 (0.001)	Loss 0.4711 (0.5181)	Prec@1 81.000 (82.712)	Prec@5 100.000 (99.179)
2019-05-03 17:02:39 - INFO - TRAINING - Epoch: [188][400/500]	Time 0.015 (0.020)	Data 0.000 (0.001)	Loss 0.3832 (0.5172)	Prec@1 84.000 (82.781)	Prec@5 100.000 (99.172)
2019-05-03 17:02:40 - INFO - TRAINING - Epoch: [188][450/500]	Time 0.014 (0.020)	Data 0.000 (0.001)	Loss 0.5264 (0.5197)	Prec@1 83.000 (82.650)	Prec@5 99.000 (99.166)
2019-05-03 17:02:42 - INFO - EVALUATING - Epoch: [188][0/100]	Time 0.350 (0.350)	Data 0.343 (0.343)	Loss 0.5576 (0.5576)	Prec@1 84.000 (84.000)	Prec@5 99.000 (99.000)
2019-05-03 17:02:42 - INFO - EVALUATING - Epoch: [188][50/100]	Time 0.007 (0.012)	Data 0.000 (0.007)	Loss 0.6637 (0.6322)	Prec@1 80.000 (79.412)	Prec@5 97.000 (98.627)
2019-05-03 17:02:42 - INFO - 
 Epoch: 189	Training Loss 0.5211 	Training Prec@1 82.598 	Training Prec@5 99.174 	Validation Loss 0.6251 	Validation Prec@1 79.210 	Validation Prec@5 98.840 	
2019-05-03 17:02:42 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:02:42 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:02:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:02:43 - INFO - TRAINING - Epoch: [189][0/500]	Time 0.265 (0.265)	Data 0.239 (0.239)	Loss 0.6056 (0.6056)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:44 - INFO - TRAINING - Epoch: [189][50/500]	Time 0.019 (0.026)	Data 0.000 (0.005)	Loss 0.6578 (0.5212)	Prec@1 81.000 (82.765)	Prec@5 97.000 (99.216)
2019-05-03 17:02:45 - INFO - TRAINING - Epoch: [189][100/500]	Time 0.026 (0.022)	Data 0.000 (0.002)	Loss 0.5344 (0.5143)	Prec@1 81.000 (83.218)	Prec@5 99.000 (99.178)
2019-05-03 17:02:46 - INFO - TRAINING - Epoch: [189][150/500]	Time 0.012 (0.022)	Data 0.000 (0.002)	Loss 0.5565 (0.5102)	Prec@1 77.000 (83.311)	Prec@5 100.000 (99.265)
2019-05-03 17:02:47 - INFO - TRAINING - Epoch: [189][200/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.5354 (0.5153)	Prec@1 85.000 (83.219)	Prec@5 98.000 (99.239)
2019-05-03 17:02:48 - INFO - TRAINING - Epoch: [189][250/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6174 (0.5168)	Prec@1 77.000 (83.100)	Prec@5 99.000 (99.235)
2019-05-03 17:02:49 - INFO - TRAINING - Epoch: [189][300/500]	Time 0.027 (0.021)	Data 0.000 (0.001)	Loss 0.4124 (0.5229)	Prec@1 88.000 (82.864)	Prec@5 99.000 (99.149)
2019-05-03 17:02:50 - INFO - TRAINING - Epoch: [189][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.5145 (0.5234)	Prec@1 80.000 (82.795)	Prec@5 99.000 (99.162)
2019-05-03 17:02:51 - INFO - TRAINING - Epoch: [189][400/500]	Time 0.020 (0.021)	Data 0.000 (0.001)	Loss 0.4226 (0.5222)	Prec@1 86.000 (82.870)	Prec@5 99.000 (99.145)
2019-05-03 17:02:51 - INFO - TRAINING - Epoch: [189][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.5690 (0.5222)	Prec@1 83.000 (82.858)	Prec@5 99.000 (99.162)
2019-05-03 17:02:53 - INFO - EVALUATING - Epoch: [189][0/100]	Time 0.355 (0.355)	Data 0.344 (0.344)	Loss 0.5253 (0.5253)	Prec@1 79.000 (79.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:53 - INFO - EVALUATING - Epoch: [189][50/100]	Time 0.005 (0.013)	Data 0.000 (0.007)	Loss 0.5213 (0.6093)	Prec@1 81.000 (79.725)	Prec@5 99.000 (98.882)
2019-05-03 17:02:53 - INFO - 
 Epoch: 190	Training Loss 0.5221 	Training Prec@1 82.832 	Training Prec@5 99.178 	Validation Loss 0.6036 	Validation Prec@1 79.830 	Validation Prec@5 98.930 	
2019-05-03 17:02:54 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:02:54 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:02:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:02:54 - INFO - TRAINING - Epoch: [190][0/500]	Time 0.280 (0.280)	Data 0.251 (0.251)	Loss 0.6354 (0.6354)	Prec@1 82.000 (82.000)	Prec@5 98.000 (98.000)
2019-05-03 17:02:55 - INFO - TRAINING - Epoch: [190][50/500]	Time 0.020 (0.025)	Data 0.000 (0.005)	Loss 0.6359 (0.5369)	Prec@1 83.000 (81.667)	Prec@5 99.000 (99.118)
2019-05-03 17:02:56 - INFO - TRAINING - Epoch: [190][100/500]	Time 0.020 (0.022)	Data 0.000 (0.003)	Loss 0.6156 (0.5255)	Prec@1 80.000 (82.198)	Prec@5 98.000 (99.149)
2019-05-03 17:02:57 - INFO - TRAINING - Epoch: [190][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.4851 (0.5199)	Prec@1 83.000 (82.583)	Prec@5 100.000 (99.172)
2019-05-03 17:02:58 - INFO - TRAINING - Epoch: [190][200/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5402 (0.5198)	Prec@1 83.000 (82.602)	Prec@5 99.000 (99.189)
2019-05-03 17:02:59 - INFO - TRAINING - Epoch: [190][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.6676 (0.5239)	Prec@1 78.000 (82.550)	Prec@5 98.000 (99.155)
2019-05-03 17:03:00 - INFO - TRAINING - Epoch: [190][300/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.5655 (0.5229)	Prec@1 82.000 (82.585)	Prec@5 100.000 (99.183)
2019-05-03 17:03:01 - INFO - TRAINING - Epoch: [190][350/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.6048 (0.5208)	Prec@1 82.000 (82.721)	Prec@5 97.000 (99.197)
2019-05-03 17:03:02 - INFO - TRAINING - Epoch: [190][400/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.4292 (0.5218)	Prec@1 82.000 (82.668)	Prec@5 100.000 (99.204)
2019-05-03 17:03:03 - INFO - TRAINING - Epoch: [190][450/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.7313 (0.5250)	Prec@1 77.000 (82.596)	Prec@5 98.000 (99.180)
2019-05-03 17:03:04 - INFO - EVALUATING - Epoch: [190][0/100]	Time 0.348 (0.348)	Data 0.342 (0.342)	Loss 0.5955 (0.5955)	Prec@1 79.000 (79.000)	Prec@5 99.000 (99.000)
2019-05-03 17:03:04 - INFO - EVALUATING - Epoch: [190][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.4742 (0.5956)	Prec@1 85.000 (80.275)	Prec@5 99.000 (98.706)
2019-05-03 17:03:05 - INFO - 
 Epoch: 191	Training Loss 0.5260 	Training Prec@1 82.574 	Training Prec@5 99.190 	Validation Loss 0.5873 	Validation Prec@1 80.560 	Validation Prec@5 98.800 	
2019-05-03 17:03:05 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:05 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:05 - INFO - TRAINING - Epoch: [191][0/500]	Time 0.283 (0.283)	Data 0.254 (0.254)	Loss 0.7470 (0.7470)	Prec@1 77.000 (77.000)	Prec@5 98.000 (98.000)
2019-05-03 17:03:06 - INFO - TRAINING - Epoch: [191][50/500]	Time 0.023 (0.025)	Data 0.000 (0.005)	Loss 0.4341 (0.5084)	Prec@1 86.000 (83.255)	Prec@5 100.000 (99.255)
2019-05-03 17:03:07 - INFO - TRAINING - Epoch: [191][100/500]	Time 0.027 (0.023)	Data 0.000 (0.003)	Loss 0.4029 (0.5100)	Prec@1 87.000 (83.030)	Prec@5 100.000 (99.287)
2019-05-03 17:03:08 - INFO - TRAINING - Epoch: [191][150/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.5174 (0.5072)	Prec@1 82.000 (83.033)	Prec@5 99.000 (99.285)
2019-05-03 17:03:09 - INFO - TRAINING - Epoch: [191][200/500]	Time 0.024 (0.022)	Data 0.000 (0.001)	Loss 0.9762 (0.5150)	Prec@1 73.000 (82.925)	Prec@5 99.000 (99.244)
2019-05-03 17:03:10 - INFO - TRAINING - Epoch: [191][250/500]	Time 0.029 (0.022)	Data 0.000 (0.001)	Loss 0.5818 (0.5161)	Prec@1 80.000 (82.896)	Prec@5 100.000 (99.251)
2019-05-03 17:03:11 - INFO - TRAINING - Epoch: [191][300/500]	Time 0.013 (0.021)	Data 0.000 (0.001)	Loss 0.4392 (0.5199)	Prec@1 89.000 (82.757)	Prec@5 99.000 (99.219)
2019-05-03 17:03:12 - INFO - TRAINING - Epoch: [191][350/500]	Time 0.019 (0.021)	Data 0.000 (0.001)	Loss 0.6353 (0.5225)	Prec@1 78.000 (82.749)	Prec@5 99.000 (99.205)
2019-05-03 17:03:13 - INFO - TRAINING - Epoch: [191][400/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4725 (0.5219)	Prec@1 82.000 (82.711)	Prec@5 100.000 (99.219)
2019-05-03 17:03:14 - INFO - TRAINING - Epoch: [191][450/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5546 (0.5255)	Prec@1 81.000 (82.645)	Prec@5 99.000 (99.188)
2019-05-03 17:03:15 - INFO - EVALUATING - Epoch: [191][0/100]	Time 0.349 (0.349)	Data 0.339 (0.339)	Loss 0.5477 (0.5477)	Prec@1 82.000 (82.000)	Prec@5 98.000 (98.000)
2019-05-03 17:03:16 - INFO - EVALUATING - Epoch: [191][50/100]	Time 0.004 (0.012)	Data 0.000 (0.007)	Loss 0.6204 (0.6216)	Prec@1 82.000 (79.882)	Prec@5 97.000 (98.627)
2019-05-03 17:03:16 - INFO - 
 Epoch: 192	Training Loss 0.5240 	Training Prec@1 82.718 	Training Prec@5 99.196 	Validation Loss 0.6158 	Validation Prec@1 80.180 	Validation Prec@5 98.760 	
2019-05-03 17:03:16 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:16 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:16 - INFO - TRAINING - Epoch: [192][0/500]	Time 0.259 (0.259)	Data 0.239 (0.239)	Loss 0.4386 (0.4386)	Prec@1 86.000 (86.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:17 - INFO - TRAINING - Epoch: [192][50/500]	Time 0.019 (0.024)	Data 0.000 (0.005)	Loss 0.6482 (0.5200)	Prec@1 76.000 (82.510)	Prec@5 99.000 (99.157)
2019-05-03 17:03:18 - INFO - TRAINING - Epoch: [192][100/500]	Time 0.020 (0.022)	Data 0.000 (0.002)	Loss 0.4299 (0.5224)	Prec@1 85.000 (82.376)	Prec@5 100.000 (99.228)
2019-05-03 17:03:19 - INFO - TRAINING - Epoch: [192][150/500]	Time 0.026 (0.021)	Data 0.000 (0.002)	Loss 0.4985 (0.5261)	Prec@1 84.000 (82.430)	Prec@5 99.000 (99.192)
2019-05-03 17:03:20 - INFO - TRAINING - Epoch: [192][200/500]	Time 0.029 (0.021)	Data 0.000 (0.001)	Loss 0.4176 (0.5249)	Prec@1 85.000 (82.463)	Prec@5 100.000 (99.199)
2019-05-03 17:03:21 - INFO - TRAINING - Epoch: [192][250/500]	Time 0.014 (0.021)	Data 0.000 (0.001)	Loss 0.5527 (0.5256)	Prec@1 82.000 (82.506)	Prec@5 99.000 (99.203)
2019-05-03 17:03:22 - INFO - TRAINING - Epoch: [192][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.3602 (0.5257)	Prec@1 89.000 (82.492)	Prec@5 99.000 (99.209)
2019-05-03 17:03:23 - INFO - TRAINING - Epoch: [192][350/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.6132 (0.5263)	Prec@1 77.000 (82.390)	Prec@5 100.000 (99.225)
2019-05-03 17:03:24 - INFO - TRAINING - Epoch: [192][400/500]	Time 0.016 (0.020)	Data 0.000 (0.001)	Loss 0.5791 (0.5252)	Prec@1 80.000 (82.436)	Prec@5 100.000 (99.212)
2019-05-03 17:03:25 - INFO - TRAINING - Epoch: [192][450/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.4479 (0.5246)	Prec@1 86.000 (82.483)	Prec@5 99.000 (99.208)
2019-05-03 17:03:27 - INFO - EVALUATING - Epoch: [192][0/100]	Time 0.340 (0.340)	Data 0.325 (0.325)	Loss 0.7393 (0.7393)	Prec@1 77.000 (77.000)	Prec@5 99.000 (99.000)
2019-05-03 17:03:27 - INFO - EVALUATING - Epoch: [192][50/100]	Time 0.005 (0.012)	Data 0.000 (0.007)	Loss 0.6042 (0.6146)	Prec@1 81.000 (79.765)	Prec@5 97.000 (98.804)
2019-05-03 17:03:27 - INFO - 
 Epoch: 193	Training Loss 0.5237 	Training Prec@1 82.530 	Training Prec@5 99.204 	Validation Loss 0.6210 	Validation Prec@1 79.420 	Validation Prec@5 98.830 	
2019-05-03 17:03:27 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:27 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:28 - INFO - TRAINING - Epoch: [193][0/500]	Time 0.255 (0.255)	Data 0.227 (0.227)	Loss 0.4929 (0.4929)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:29 - INFO - TRAINING - Epoch: [193][50/500]	Time 0.018 (0.024)	Data 0.000 (0.005)	Loss 0.5177 (0.5373)	Prec@1 83.000 (81.961)	Prec@5 98.000 (99.373)
2019-05-03 17:03:30 - INFO - TRAINING - Epoch: [193][100/500]	Time 0.019 (0.022)	Data 0.000 (0.002)	Loss 0.5445 (0.5347)	Prec@1 83.000 (82.347)	Prec@5 99.000 (99.238)
2019-05-03 17:03:31 - INFO - TRAINING - Epoch: [193][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.5880 (0.5283)	Prec@1 79.000 (82.404)	Prec@5 100.000 (99.172)
2019-05-03 17:03:32 - INFO - TRAINING - Epoch: [193][200/500]	Time 0.018 (0.021)	Data 0.000 (0.001)	Loss 0.2998 (0.5263)	Prec@1 90.000 (82.602)	Prec@5 100.000 (99.169)
2019-05-03 17:03:32 - INFO - TRAINING - Epoch: [193][250/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.4271 (0.5275)	Prec@1 85.000 (82.693)	Prec@5 99.000 (99.171)
2019-05-03 17:03:33 - INFO - TRAINING - Epoch: [193][300/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.4778 (0.5296)	Prec@1 85.000 (82.498)	Prec@5 99.000 (99.166)
2019-05-03 17:03:35 - INFO - TRAINING - Epoch: [193][350/500]	Time 0.025 (0.020)	Data 0.000 (0.001)	Loss 0.5854 (0.5273)	Prec@1 78.000 (82.584)	Prec@5 100.000 (99.199)
2019-05-03 17:03:35 - INFO - TRAINING - Epoch: [193][400/500]	Time 0.020 (0.020)	Data 0.000 (0.001)	Loss 0.6233 (0.5279)	Prec@1 80.000 (82.579)	Prec@5 98.000 (99.172)
2019-05-03 17:03:36 - INFO - TRAINING - Epoch: [193][450/500]	Time 0.017 (0.020)	Data 0.000 (0.001)	Loss 0.5526 (0.5252)	Prec@1 83.000 (82.698)	Prec@5 99.000 (99.186)
2019-05-03 17:03:37 - INFO - EVALUATING - Epoch: [193][0/100]	Time 0.329 (0.329)	Data 0.322 (0.322)	Loss 0.5547 (0.5547)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 17:03:38 - INFO - EVALUATING - Epoch: [193][50/100]	Time 0.006 (0.013)	Data 0.000 (0.007)	Loss 0.5102 (0.5882)	Prec@1 86.000 (80.980)	Prec@5 99.000 (98.804)
2019-05-03 17:03:38 - INFO - 
 Epoch: 194	Training Loss 0.5242 	Training Prec@1 82.670 	Training Prec@5 99.188 	Validation Loss 0.5850 	Validation Prec@1 81.040 	Validation Prec@5 98.940 	
2019-05-03 17:03:38 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:38 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:39 - INFO - TRAINING - Epoch: [194][0/500]	Time 0.269 (0.269)	Data 0.245 (0.245)	Loss 0.4592 (0.4592)	Prec@1 82.000 (82.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:40 - INFO - TRAINING - Epoch: [194][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.5023 (0.5077)	Prec@1 83.000 (83.020)	Prec@5 100.000 (99.275)
2019-05-03 17:03:40 - INFO - TRAINING - Epoch: [194][100/500]	Time 0.017 (0.021)	Data 0.000 (0.003)	Loss 0.5252 (0.5078)	Prec@1 82.000 (83.198)	Prec@5 98.000 (99.168)
2019-05-03 17:03:41 - INFO - TRAINING - Epoch: [194][150/500]	Time 0.015 (0.020)	Data 0.000 (0.002)	Loss 0.4559 (0.5117)	Prec@1 84.000 (83.086)	Prec@5 99.000 (99.166)
2019-05-03 17:03:42 - INFO - TRAINING - Epoch: [194][200/500]	Time 0.024 (0.019)	Data 0.000 (0.001)	Loss 0.5244 (0.5171)	Prec@1 81.000 (82.896)	Prec@5 98.000 (99.114)
2019-05-03 17:03:43 - INFO - TRAINING - Epoch: [194][250/500]	Time 0.020 (0.019)	Data 0.000 (0.001)	Loss 0.5450 (0.5192)	Prec@1 81.000 (82.653)	Prec@5 100.000 (99.108)
2019-05-03 17:03:44 - INFO - TRAINING - Epoch: [194][300/500]	Time 0.017 (0.018)	Data 0.000 (0.001)	Loss 0.3282 (0.5138)	Prec@1 90.000 (82.887)	Prec@5 99.000 (99.106)
2019-05-03 17:03:45 - INFO - TRAINING - Epoch: [194][350/500]	Time 0.021 (0.018)	Data 0.000 (0.001)	Loss 0.4519 (0.5125)	Prec@1 85.000 (83.003)	Prec@5 100.000 (99.123)
2019-05-03 17:03:46 - INFO - TRAINING - Epoch: [194][400/500]	Time 0.017 (0.018)	Data 0.000 (0.001)	Loss 0.4220 (0.5156)	Prec@1 86.000 (82.875)	Prec@5 99.000 (99.125)
2019-05-03 17:03:46 - INFO - TRAINING - Epoch: [194][450/500]	Time 0.019 (0.018)	Data 0.000 (0.001)	Loss 0.6728 (0.5155)	Prec@1 78.000 (82.860)	Prec@5 98.000 (99.146)
2019-05-03 17:03:48 - INFO - EVALUATING - Epoch: [194][0/100]	Time 0.350 (0.350)	Data 0.342 (0.342)	Loss 0.5442 (0.5442)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:48 - INFO - EVALUATING - Epoch: [194][50/100]	Time 0.008 (0.013)	Data 0.000 (0.007)	Loss 0.5098 (0.6263)	Prec@1 86.000 (79.725)	Prec@5 98.000 (98.725)
2019-05-03 17:03:48 - INFO - 
 Epoch: 195	Training Loss 0.5149 	Training Prec@1 82.886 	Training Prec@5 99.162 	Validation Loss 0.6248 	Validation Prec@1 79.750 	Validation Prec@5 98.790 	
2019-05-03 17:03:48 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:48 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:49 - INFO - TRAINING - Epoch: [195][0/500]	Time 0.268 (0.268)	Data 0.245 (0.245)	Loss 0.5700 (0.5700)	Prec@1 81.000 (81.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:49 - INFO - TRAINING - Epoch: [195][50/500]	Time 0.017 (0.022)	Data 0.000 (0.005)	Loss 0.5167 (0.5325)	Prec@1 83.000 (82.216)	Prec@5 99.000 (98.980)
2019-05-03 17:03:50 - INFO - TRAINING - Epoch: [195][100/500]	Time 0.012 (0.021)	Data 0.000 (0.003)	Loss 0.5525 (0.5254)	Prec@1 84.000 (82.455)	Prec@5 99.000 (99.079)
2019-05-03 17:03:51 - INFO - TRAINING - Epoch: [195][150/500]	Time 0.016 (0.020)	Data 0.000 (0.002)	Loss 0.5660 (0.5221)	Prec@1 82.000 (82.603)	Prec@5 99.000 (99.166)
2019-05-03 17:03:52 - INFO - TRAINING - Epoch: [195][200/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.6153 (0.5250)	Prec@1 83.000 (82.587)	Prec@5 98.000 (99.154)
2019-05-03 17:03:53 - INFO - TRAINING - Epoch: [195][250/500]	Time 0.023 (0.020)	Data 0.000 (0.001)	Loss 0.4953 (0.5226)	Prec@1 84.000 (82.689)	Prec@5 100.000 (99.195)
2019-05-03 17:03:54 - INFO - TRAINING - Epoch: [195][300/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.3997 (0.5216)	Prec@1 85.000 (82.684)	Prec@5 100.000 (99.209)
2019-05-03 17:03:55 - INFO - TRAINING - Epoch: [195][350/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5034 (0.5211)	Prec@1 82.000 (82.726)	Prec@5 100.000 (99.208)
2019-05-03 17:03:56 - INFO - TRAINING - Epoch: [195][400/500]	Time 0.019 (0.019)	Data 0.000 (0.001)	Loss 0.5231 (0.5190)	Prec@1 83.000 (82.853)	Prec@5 99.000 (99.209)
2019-05-03 17:03:57 - INFO - TRAINING - Epoch: [195][450/500]	Time 0.022 (0.019)	Data 0.000 (0.001)	Loss 0.3769 (0.5194)	Prec@1 87.000 (82.772)	Prec@5 99.000 (99.217)
2019-05-03 17:03:58 - INFO - EVALUATING - Epoch: [195][0/100]	Time 0.320 (0.320)	Data 0.303 (0.303)	Loss 0.5961 (0.5961)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 17:03:58 - INFO - EVALUATING - Epoch: [195][50/100]	Time 0.017 (0.013)	Data 0.000 (0.006)	Loss 0.5354 (0.6126)	Prec@1 84.000 (79.961)	Prec@5 97.000 (98.529)
2019-05-03 17:03:59 - INFO - 
 Epoch: 196	Training Loss 0.5177 	Training Prec@1 82.766 	Training Prec@5 99.234 	Validation Loss 0.6078 	Validation Prec@1 80.160 	Validation Prec@5 98.640 	
2019-05-03 17:03:59 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:03:59 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:03:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:03:59 - INFO - TRAINING - Epoch: [196][0/500]	Time 0.258 (0.258)	Data 0.226 (0.226)	Loss 0.4562 (0.4562)	Prec@1 83.000 (83.000)	Prec@5 99.000 (99.000)
2019-05-03 17:04:00 - INFO - TRAINING - Epoch: [196][50/500]	Time 0.018 (0.026)	Data 0.000 (0.005)	Loss 0.4801 (0.5077)	Prec@1 85.000 (83.373)	Prec@5 98.000 (99.000)
2019-05-03 17:04:01 - INFO - TRAINING - Epoch: [196][100/500]	Time 0.021 (0.023)	Data 0.000 (0.002)	Loss 0.4264 (0.5104)	Prec@1 85.000 (83.287)	Prec@5 100.000 (99.109)
2019-05-03 17:04:02 - INFO - TRAINING - Epoch: [196][150/500]	Time 0.016 (0.021)	Data 0.000 (0.002)	Loss 0.5123 (0.5082)	Prec@1 83.000 (83.172)	Prec@5 99.000 (99.139)
2019-05-03 17:04:03 - INFO - TRAINING - Epoch: [196][200/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4582 (0.5114)	Prec@1 85.000 (83.095)	Prec@5 100.000 (99.129)
2019-05-03 17:04:04 - INFO - TRAINING - Epoch: [196][250/500]	Time 0.021 (0.021)	Data 0.000 (0.001)	Loss 0.6621 (0.5138)	Prec@1 77.000 (82.996)	Prec@5 99.000 (99.131)
2019-05-03 17:04:05 - INFO - TRAINING - Epoch: [196][300/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.4333 (0.5110)	Prec@1 86.000 (83.153)	Prec@5 100.000 (99.186)
2019-05-03 17:04:06 - INFO - TRAINING - Epoch: [196][350/500]	Time 0.026 (0.020)	Data 0.000 (0.001)	Loss 0.5621 (0.5135)	Prec@1 79.000 (83.023)	Prec@5 100.000 (99.174)
2019-05-03 17:04:07 - INFO - TRAINING - Epoch: [196][400/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5000 (0.5156)	Prec@1 80.000 (82.873)	Prec@5 99.000 (99.180)
2019-05-03 17:04:08 - INFO - TRAINING - Epoch: [196][450/500]	Time 0.013 (0.020)	Data 0.000 (0.001)	Loss 0.4985 (0.5204)	Prec@1 86.000 (82.758)	Prec@5 98.000 (99.157)
2019-05-03 17:04:09 - INFO - EVALUATING - Epoch: [196][0/100]	Time 0.370 (0.370)	Data 0.356 (0.356)	Loss 0.6194 (0.6194)	Prec@1 80.000 (80.000)	Prec@5 98.000 (98.000)
2019-05-03 17:04:10 - INFO - EVALUATING - Epoch: [196][50/100]	Time 0.007 (0.013)	Data 0.000 (0.007)	Loss 0.4331 (0.5981)	Prec@1 86.000 (80.098)	Prec@5 97.000 (98.784)
2019-05-03 17:04:10 - INFO - 
 Epoch: 197	Training Loss 0.5188 	Training Prec@1 82.766 	Training Prec@5 99.174 	Validation Loss 0.5882 	Validation Prec@1 80.640 	Validation Prec@5 98.960 	
2019-05-03 17:04:10 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:04:10 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:04:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:04:10 - INFO - TRAINING - Epoch: [197][0/500]	Time 0.281 (0.281)	Data 0.261 (0.261)	Loss 0.3997 (0.3997)	Prec@1 87.000 (87.000)	Prec@5 99.000 (99.000)
2019-05-03 17:04:11 - INFO - TRAINING - Epoch: [197][50/500]	Time 0.018 (0.025)	Data 0.000 (0.005)	Loss 0.5546 (0.5369)	Prec@1 82.000 (82.118)	Prec@5 100.000 (99.216)
2019-05-03 17:04:12 - INFO - TRAINING - Epoch: [197][100/500]	Time 0.015 (0.022)	Data 0.000 (0.003)	Loss 0.6231 (0.5287)	Prec@1 80.000 (82.416)	Prec@5 97.000 (99.218)
2019-05-03 17:04:13 - INFO - TRAINING - Epoch: [197][150/500]	Time 0.015 (0.021)	Data 0.000 (0.002)	Loss 0.7939 (0.5217)	Prec@1 74.000 (82.748)	Prec@5 100.000 (99.212)
2019-05-03 17:04:14 - INFO - TRAINING - Epoch: [197][200/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.4980 (0.5165)	Prec@1 83.000 (82.881)	Prec@5 99.000 (99.234)
2019-05-03 17:04:15 - INFO - TRAINING - Epoch: [197][250/500]	Time 0.018 (0.020)	Data 0.000 (0.001)	Loss 0.5079 (0.5188)	Prec@1 83.000 (82.837)	Prec@5 99.000 (99.195)
2019-05-03 17:04:16 - INFO - TRAINING - Epoch: [197][300/500]	Time 0.029 (0.020)	Data 0.000 (0.001)	Loss 0.4809 (0.5210)	Prec@1 83.000 (82.694)	Prec@5 99.000 (99.169)
2019-05-03 17:04:17 - INFO - TRAINING - Epoch: [197][350/500]	Time 0.019 (0.020)	Data 0.000 (0.001)	Loss 0.5425 (0.5211)	Prec@1 78.000 (82.712)	Prec@5 100.000 (99.145)
2019-05-03 17:04:18 - INFO - TRAINING - Epoch: [197][400/500]	Time 0.022 (0.020)	Data 0.000 (0.001)	Loss 0.4849 (0.5214)	Prec@1 83.000 (82.701)	Prec@5 99.000 (99.130)
2019-05-03 17:04:19 - INFO - TRAINING - Epoch: [197][450/500]	Time 0.021 (0.020)	Data 0.000 (0.001)	Loss 0.5683 (0.5185)	Prec@1 84.000 (82.829)	Prec@5 100.000 (99.151)
2019-05-03 17:04:20 - INFO - EVALUATING - Epoch: [197][0/100]	Time 0.343 (0.343)	Data 0.332 (0.332)	Loss 0.5787 (0.5787)	Prec@1 81.000 (81.000)	Prec@5 99.000 (99.000)
2019-05-03 17:04:21 - INFO - EVALUATING - Epoch: [197][50/100]	Time 0.004 (0.013)	Data 0.000 (0.007)	Loss 0.5116 (0.5869)	Prec@1 84.000 (81.039)	Prec@5 98.000 (98.961)
2019-05-03 17:04:21 - INFO - 
 Epoch: 198	Training Loss 0.5189 	Training Prec@1 82.786 	Training Prec@5 99.166 	Validation Loss 0.5808 	Validation Prec@1 80.940 	Validation Prec@5 98.980 	
2019-05-03 17:04:21 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:04:21 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:04:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:04:21 - INFO - TRAINING - Epoch: [198][0/500]	Time 0.264 (0.264)	Data 0.242 (0.242)	Loss 0.4284 (0.4284)	Prec@1 90.000 (90.000)	Prec@5 100.000 (100.000)
2019-05-03 17:04:23 - INFO - TRAINING - Epoch: [198][50/500]	Time 0.025 (0.027)	Data 0.000 (0.005)	Loss 0.6840 (0.5287)	Prec@1 79.000 (82.608)	Prec@5 99.000 (99.196)
2019-05-03 17:04:24 - INFO - TRAINING - Epoch: [198][100/500]	Time 0.026 (0.023)	Data 0.000 (0.003)	Loss 0.4833 (0.5083)	Prec@1 84.000 (83.020)	Prec@5 99.000 (99.327)
2019-05-03 17:04:24 - INFO - TRAINING - Epoch: [198][150/500]	Time 0.025 (0.022)	Data 0.000 (0.002)	Loss 0.6123 (0.5187)	Prec@1 82.000 (82.662)	Prec@5 100.000 (99.258)
2019-05-03 17:04:25 - INFO - TRAINING - Epoch: [198][200/500]	Time 0.017 (0.022)	Data 0.000 (0.001)	Loss 0.5275 (0.5194)	Prec@1 86.000 (82.731)	Prec@5 100.000 (99.209)
2019-05-03 17:04:27 - INFO - TRAINING - Epoch: [198][250/500]	Time 0.025 (0.021)	Data 0.000 (0.001)	Loss 0.5828 (0.5244)	Prec@1 82.000 (82.578)	Prec@5 98.000 (99.159)
2019-05-03 17:04:28 - INFO - TRAINING - Epoch: [198][300/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.4942 (0.5243)	Prec@1 83.000 (82.625)	Prec@5 99.000 (99.123)
2019-05-03 17:04:29 - INFO - TRAINING - Epoch: [198][350/500]	Time 0.022 (0.021)	Data 0.000 (0.001)	Loss 0.6124 (0.5272)	Prec@1 81.000 (82.550)	Prec@5 98.000 (99.120)
2019-05-03 17:04:30 - INFO - TRAINING - Epoch: [198][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.4364 (0.5276)	Prec@1 84.000 (82.514)	Prec@5 100.000 (99.130)
2019-05-03 17:04:31 - INFO - TRAINING - Epoch: [198][450/500]	Time 0.034 (0.021)	Data 0.000 (0.001)	Loss 0.6055 (0.5280)	Prec@1 81.000 (82.528)	Prec@5 100.000 (99.115)
2019-05-03 17:04:32 - INFO - EVALUATING - Epoch: [198][0/100]	Time 0.324 (0.324)	Data 0.307 (0.307)	Loss 0.4979 (0.4979)	Prec@1 84.000 (84.000)	Prec@5 100.000 (100.000)
2019-05-03 17:04:32 - INFO - EVALUATING - Epoch: [198][50/100]	Time 0.005 (0.012)	Data 0.000 (0.006)	Loss 0.5911 (0.6419)	Prec@1 80.000 (79.137)	Prec@5 99.000 (98.431)
2019-05-03 17:04:32 - INFO - 
 Epoch: 199	Training Loss 0.5271 	Training Prec@1 82.538 	Training Prec@5 99.128 	Validation Loss 0.6275 	Validation Prec@1 79.150 	Validation Prec@5 98.660 	
2019-05-03 17:04:33 - DEBUG - OPTIMIZER - setting method = Adam
2019-05-03 17:04:33 - DEBUG - OPTIMIZER - setting lr = 0.02
2019-05-03 17:04:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2019-05-03 17:04:33 - INFO - TRAINING - Epoch: [199][0/500]	Time 0.284 (0.284)	Data 0.256 (0.256)	Loss 0.3679 (0.3679)	Prec@1 89.000 (89.000)	Prec@5 100.000 (100.000)
2019-05-03 17:04:34 - INFO - TRAINING - Epoch: [199][50/500]	Time 0.016 (0.025)	Data 0.000 (0.005)	Loss 0.4743 (0.5292)	Prec@1 89.000 (82.667)	Prec@5 100.000 (98.902)
2019-05-03 17:04:35 - INFO - TRAINING - Epoch: [199][100/500]	Time 0.014 (0.024)	Data 0.000 (0.003)	Loss 0.5557 (0.5148)	Prec@1 83.000 (82.881)	Prec@5 98.000 (99.069)
2019-05-03 17:04:36 - INFO - TRAINING - Epoch: [199][150/500]	Time 0.027 (0.023)	Data 0.000 (0.002)	Loss 0.4113 (0.5111)	Prec@1 87.000 (83.245)	Prec@5 100.000 (99.099)
2019-05-03 17:04:37 - INFO - TRAINING - Epoch: [199][200/500]	Time 0.022 (0.022)	Data 0.000 (0.001)	Loss 0.4936 (0.5133)	Prec@1 81.000 (83.139)	Prec@5 100.000 (99.174)
2019-05-03 17:04:38 - INFO - TRAINING - Epoch: [199][250/500]	Time 0.023 (0.021)	Data 0.000 (0.001)	Loss 0.6511 (0.5144)	Prec@1 79.000 (83.108)	Prec@5 100.000 (99.199)
2019-05-03 17:04:39 - INFO - TRAINING - Epoch: [199][300/500]	Time 0.016 (0.021)	Data 0.000 (0.001)	Loss 0.6219 (0.5128)	Prec@1 81.000 (83.169)	Prec@5 100.000 (99.209)
2019-05-03 17:04:40 - INFO - TRAINING - Epoch: [199][350/500]	Time 0.015 (0.021)	Data 0.000 (0.001)	Loss 0.5075 (0.5158)	Prec@1 83.000 (83.023)	Prec@5 100.000 (99.171)
2019-05-03 17:04:41 - INFO - TRAINING - Epoch: [199][400/500]	Time 0.024 (0.021)	Data 0.000 (0.001)	Loss 0.7385 (0.5140)	Prec@1 78.000 (83.130)	Prec@5 100.000 (99.192)
2019-05-03 17:04:42 - INFO - TRAINING - Epoch: [199][450/500]	Time 0.012 (0.021)	Data 0.000 (0.001)	Loss 0.5940 (0.5154)	Prec@1 78.000 (83.098)	Prec@5 98.000 (99.191)
2019-05-03 17:04:43 - INFO - EVALUATING - Epoch: [199][0/100]	Time 0.331 (0.331)	Data 0.315 (0.315)	Loss 0.5352 (0.5352)	Prec@1 80.000 (80.000)	Prec@5 100.000 (100.000)
2019-05-03 17:04:43 - INFO - EVALUATING - Epoch: [199][50/100]	Time 0.006 (0.012)	Data 0.000 (0.006)	Loss 0.5247 (0.6214)	Prec@1 83.000 (79.510)	Prec@5 98.000 (98.667)
2019-05-03 17:04:44 - INFO - 
 Epoch: 200	Training Loss 0.5165 	Training Prec@1 83.014 	Training Prec@5 99.198 	Validation Loss 0.6224 	Validation Prec@1 79.190 	Validation Prec@5 98.760 	
2019-05-03 17:04:44 - DEBUG - update_title_pos
2019-05-03 17:04:44 - DEBUG - findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/pami/anaconda3/envs/spacex/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2019-05-03 17:04:44 - DEBUG - update_title_pos
2019-05-03 17:04:44 - DEBUG - update_title_pos
2019-05-03 17:04:44 - DEBUG - update_title_pos
